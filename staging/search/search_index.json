{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"RDK Hardware Porting Kit (HPK)","text":"<p>The RDK Hardware Porting Kit (HPK) provides a centralized resource for vendors integrating their hardware layer with the RDK stack.  It simplifies this process by providing a unified set of tools, documentation, and test suites.</p> <p>Specifically, the HPK includes:</p> <ul> <li>Hardware Abstraction Layer (HAL) API header files: These define the interfaces vendors must implement to ensure compatibility.</li> <li>Comprehensive software tests: These validate the vendor's HAL implementation against RDK middleware requirements.</li> <li>Standards &amp; Best Practices: Guidelines on coding standards, documentation, branching strategies, and interface development.</li> <li>Testing Methodologies: Outlines various testing levels and frameworks, including TDD and system interface testing.</li> <li>Code Examples &amp; Advanced Topics: Practical examples for dynamic library loading, plugin development, virtual device development, and control plane overviews.</li> <li>FAQ &amp; Troubleshooting: Addresses common challenges related to Git, Vagrant, C macros, testing, and RDK tools.</li> <li>Technology Overviews: Explains key technologies and frameworks like UT-Core and the RDK Docker toolchain.</li> <li>vDevice Support:  Provides the ability to develop and test vendor layers using virtualized hardware within a VM.  This \"vDevice\" approach simulates hardware components and drivers, enabling early testing, cost-effectiveness, reproducibility, and flexibility.  It allows developers to test against various hardware profiles without needing physical hardware.</li> </ul> <p>The HPK serves as a single point of reference, streamlining vendor integration, reducing redundant effort, and promoting consistency across RDK platforms. It accelerates hardware enablement and improves the quality of the RDK ecosystem.</p> <p></p>"},{"location":"CHANGELOG/","title":"Changelog","text":""},{"location":"CHANGELOG/#changelog","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file. Dates are displayed in UTC.</p> <p>Generated by <code>auto-changelog</code>.</p>"},{"location":"CHANGELOG/#144","title":"1.4.4","text":"<ul> <li>Updated RELEASE.md 1.4.4 <code>0fb1221</code></li> <li>Merge tag '1.4.3' into develop <code>98564c0</code></li> </ul>"},{"location":"CHANGELOG/#143","title":"1.4.3","text":"<p>2 January 2025</p> <ul> <li>Updated RELEASE.md <code>d8ab02f</code></li> <li>Bumped CHANGELOG.md - 1.4.3 <code>6e136da</code></li> <li>Merge tag '1.4.2' into develop <code>4ae432e</code></li> </ul>"},{"location":"CHANGELOG/#142","title":"1.4.2","text":"<p>2 December 2024</p> <ul> <li>Bumped CHANGELOG.md - 1.4.2 <code>9bd8721</code></li> <li>Updated README.md &amp; RELEASE.md <code>ba8aeb2</code></li> <li>Merge tag '1.4.1' into develop <code>7fb7b26</code></li> </ul>"},{"location":"CHANGELOG/#141","title":"1.4.1","text":"<p>21 November 2024</p> <ul> <li>Updated README.md &amp; RELEASE.md <code>7624fd6</code></li> <li>Bumped CHANGELOG.md - 1.4.1 <code>7138b54</code></li> <li>Merge tag '1.4.0' into develop <code>e665c5c</code></li> </ul>"},{"location":"CHANGELOG/#140","title":"1.4.0","text":"<p>16 October 2024</p> <ul> <li>gh #6 Updated 1.4.0 release notes <code>#7</code></li> <li>gh #4: Update readme with python environment <code>#5</code></li> <li>Bumped CHANGELOG.md - 1.4.0 <code>9df1e69</code></li> <li>gh #4 resolve the merge conflicts <code>652bfb2</code></li> <li>Merge tag '1.3.0' into develop <code>2518da4</code></li> </ul>"},{"location":"CHANGELOG/#130","title":"1.3.0","text":"<p>16 August 2024</p> <ul> <li>Updated RELEASE.md <code>d2a13f4</code></li> <li>Update RELEASE.md <code>9d5ceba</code></li> <li>Bumped CHANGELOG.md - 1.3.0 <code>c4eeb5b</code></li> </ul>"},{"location":"CHANGELOG/#121","title":"1.2.1","text":"<p>17 July 2024</p> <ul> <li>Updated RELEASE.md,README.md <code>5779a36</code></li> <li>Bumped CHANGELOG.md - 1.2.1 <code>4cc7162</code></li> <li>Merge tag '1.2.0' into develop <code>c631dfe</code></li> </ul>"},{"location":"CHANGELOG/#120","title":"1.2.0","text":"<p>28 June 2024</p> <ul> <li>Updated the RELEASE.md <code>11ae3f2</code></li> <li>Bumped CHANGELOG.md - 1.2.0 <code>ab7e082</code></li> <li>Merge tag '1.1.0' into develop <code>5d9501f</code></li> </ul>"},{"location":"CHANGELOG/#110","title":"1.1.0","text":"<p>20 February 2024</p> <ul> <li>Updated tag versions in RELEASE.md <code>a64e3c3</code></li> <li>Bumped CHANGELOG.md - 1.1.0 <code>4c37b30</code></li> <li>Merge tag '1.0.0' into develop <code>02fae79</code></li> </ul>"},{"location":"CHANGELOG/#100","title":"1.0.0","text":"<p>12 December 2023</p> <ul> <li>Baseline version <code>#2</code></li> <li>gh #1 : Baseline version added <code>61910ae</code></li> <li>Added CHANGELOG.md - 1.0.0 <code>eb640b9</code></li> <li>gh #1 :Updated HPK info <code>869270f</code></li> </ul>"},{"location":"CONTRIBUTING/","title":"Contributing","text":"<ul> <li>If you wish to make code contributions to this project, the source is hosted at github.com/rdkcentral.</li> </ul> <p>You can submit your changes for review via that site, by raising an issue in github, (https://github.com/rdkcentral/xxxx/issues), and following the sequence below.</p> <ul> <li>create a branch with a name follow the guidelines gh(x)_(synopsis)</li> <li>where x is the ticket number</li> <li>where synopsis is a short synopsis for the reason for the branch.</li> <li>create a pull request (https://github.com/rdkcentral/xxxx/compare) when the code changes are ready for review.</li> <li> <p>The team will review, and if accepted your changes will be merged to the mainline.</p> </li> <li> <p>In order to contribute code, first-time users are requested to agree to the license.</p> </li> <li> <p>where <code>xxxx</code> is your module name</p> </li> </ul>"},{"location":"external_content/deepsleep_manager/","title":"Deep Sleep Manager HAL Documentation","text":""},{"location":"external_content/deepsleep_manager/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>HAL</code>:    Hardware Abstraction Layer</li> <li><code>CPE</code>:    Customer Premises Equipment</li> <li><code>IR</code>:     InfraRed</li> <li><code>CEC</code>:    Consumer Electronic Control</li> <li><code>LAN</code>:    Local Area Network</li> <li><code>STB</code>:    Set-top Box</li> <li><code>RCU</code>:    Remote Control Unit</li> <li><code>STR</code>:    Suspend To RAM</li> <li><code>HDMI</code>:   High-Definition Multimedia Interface</li> <li><code>GPIO</code>:   General Purpose Input/OutputManufacturers</li> <li><code>A/V</code>:    Audio/Video</li> <li><code>HDD</code>:    Hard Drive Disk</li> </ul>"},{"location":"external_content/deepsleep_manager/#description","title":"Description","text":"<p>The diagram below describes a high-level software architecture of the module stack.</p> <pre><code>%%{ init : { \"theme\" : \"forest\", \"flowchart\" : { \"curve\" : \"linear\" }}}%%\nflowchart TD\ny[Caller]&lt;--&gt;x[Deep Sleep Manager HAL];\nx[Deep Sleep Manager HAL]&lt;--&gt;z[SOC Drivers];\nstyle y fill:#99CCFF,stroke:#333,stroke-width:0.3px,align:left\nstyle z fill:#fcc,stroke:#333,stroke-width:0.3px,align:left\nstyle x fill:#9f9,stroke:#333,stroke-width:0.3px,align:left</code></pre> <p>The Deep Sleep Manager <code>HAL</code> provides a set of <code>APIs</code> to initialize, set the deep sleep state and wake-up from deep sleep state.</p> <p>Deep sleep is a power saving mode which turns off <code>STB</code> subsystems such as A/V, <code>HDMI</code>, front panels, <code>HDD</code> etc.</p> <ul> <li>The main purpose is to bring down the power consumption based on the actual usage. Also, the conditions for triggering and setting deep sleep mode will depend on the product requirements.</li> <li>It can also be triggered in other scenarios such as thermal shutdown, in case the temperature is above the threshold for a certain period of time.</li> <li>When the <code>STB</code> goes into deep sleep mode, it may be woken up for scheduled maintenance in a pre-determined time.</li> </ul>"},{"location":"external_content/deepsleep_manager/#component-runtime-execution-requirements","title":"Component Runtime Execution Requirements","text":""},{"location":"external_content/deepsleep_manager/#initialization-and-startup","title":"Initialization and Startup","text":"<p><code>Caller</code> must initialize by calling <code>PLAT_DS_INIT()</code> before calling any other <code>API</code>.</p>"},{"location":"external_content/deepsleep_manager/#threading-model","title":"Threading Model","text":"<p>This interface is not required to be thread safe. Any <code>caller</code>, while invoking these <code>HAL</code> <code>APIs</code> must ensure calls are made in a thread safe manner.</p>"},{"location":"external_content/deepsleep_manager/#process-model","title":"Process Model","text":"<p>This interface is not required to be thread safe. Any <code>caller</code>, while invoking these <code>HAL</code> <code>APIs</code> must ensure calls are made in a thread safe manner.</p>"},{"location":"external_content/deepsleep_manager/#memory-model","title":"Memory Model","text":"<p>The <code>caller</code> is responsible to pass message buffer and free it for transmit request.</p>"},{"location":"external_content/deepsleep_manager/#power-management-requirements","title":"Power Management Requirements","text":"<p>The Deep sleep manager <code>HAL</code> is involved in the power management operation:</p> <ul> <li>Transitions to Deep Sleep state which puts system into halt</li> <li>Wake up the system from deep sleep state by IR/RF, Bluetooth remote or through LAN wake-up based on the platform requirements</li> </ul>"},{"location":"external_content/deepsleep_manager/#asynchronous-notification-model","title":"Asynchronous Notification Model","text":"<p>This interface is not required to support asynchronous notification.</p>"},{"location":"external_content/deepsleep_manager/#blocking-calls","title":"Blocking calls","text":"<p>The following <code>APIs</code> are the blocking calls of this module:</p> <ul> <li>PLAT_DS_SetDeepSleep()</li> </ul> <p>This <code>API</code> call puts the system into halt state</p> <ul> <li>PLAT_DS_DeepSleepWakeup()</li> </ul> <p>This <code>API</code> call brings the system out of the halt state</p> <p>All other synchronous <code>API</code> calls must complete within a reasonable time period. Any call that can fail due to the lack of response from the connected device must have a timeout period and the function must return the relevant error code.</p>"},{"location":"external_content/deepsleep_manager/#internal-error-handling","title":"Internal Error Handling","text":"<p>All the <code>APIs</code> must return error synchronously as a return argument. <code>HAL</code> is responsible for handling system errors (e.g. out of memory) internally.</p>"},{"location":"external_content/deepsleep_manager/#persistence-model","title":"Persistence Model","text":"<p>There is no requirement for the interface to persist any setting information. <code>caller</code> is responsible to persist any settings related to the <code>HAL</code>.</p>"},{"location":"external_content/deepsleep_manager/#non-functional-requirements","title":"Non functional requirements","text":""},{"location":"external_content/deepsleep_manager/#logging-and-debugging-requirements","title":"Logging and debugging requirements","text":"<p>This interface is required to support DEBUG, INFO and ERROR messages. INFO and DEBUG must be disabled by default and enabled when required.</p>"},{"location":"external_content/deepsleep_manager/#memory-and-performance-requirements","title":"Memory and performance requirements","text":"<p>This interface is required to not cause excessive memory and CPU utilization.</p>"},{"location":"external_content/deepsleep_manager/#quality-control","title":"Quality Control","text":"<ul> <li>This interface is required to perform static analysis, our preferred tool is Coverity.</li> <li>Have a zero-warning policy with regards to compiling. All warnings are required to be treated as errors.</li> <li>Copyright validation is required to be performed, e.g.: Black duck, FossID.</li> <li>Use of memory analysis tools like Valgrind are encouraged to identify leaks/corruptions.</li> <li><code>HAL</code> Tests will endeavour to create worst case scenarios to assist investigations.</li> <li>Improvements by any party to the testing suite are required to be fed back.</li> </ul>"},{"location":"external_content/deepsleep_manager/#licensing","title":"Licensing","text":"<p>The <code>HAL</code> implementation is expected to released under the Apache License 2.0.</p>"},{"location":"external_content/deepsleep_manager/#build-requirements","title":"Build Requirements","text":"<p>The source code must build into a shared library and must be named as <code>libiarmmgrs-deepsleep-hal.so</code>. The build mechanism must be independent of Yocto.</p>"},{"location":"external_content/deepsleep_manager/#variability-management","title":"Variability Management","text":"<p>Any changes in the <code>APIs</code> must be reviewed and approved by the component architects.</p>"},{"location":"external_content/deepsleep_manager/#platform-or-product-customization","title":"Platform or Product Customization","text":"<p>This interface is not required to have any platform or product customizations.</p>"},{"location":"external_content/deepsleep_manager/#interface-api-documentation","title":"Interface API Documentation","text":"<p><code>API</code> documentation will be provided by Doxygen which will be generated from the header files.</p>"},{"location":"external_content/deepsleep_manager/#theory-of-operation-and-key-concepts","title":"Theory of operation and key concepts","text":"<p>The <code>caller</code> is expected to have complete control over the life cycle of the <code>HAL</code>.</p> <ul> <li> <p>Initialize the <code>HAL</code> using function: <code>PLAT_DS_INIT()</code> before making any other <code>API</code> calls.  If <code>PLAT_DS_INIT()</code> call fails, the <code>HAL</code> must return the respective error code, so that the <code>caller</code> can retry the operation</p> </li> <li> <p>Deep sleep state can be controlled using the function <code>PLAT_DS_SetDeepSleep()</code></p> </li> <li> <p>Any post-processing after wake up can be performed using the function <code>PLAT_DS_DeepSleepWakeup()</code></p> </li> <li> <p>Reason for last wake up can be queried using the function <code>PLAT_DS_GetLastWakeupReason()</code></p> </li> <li> <p>Reason for last wake up keycode can be queried using the function <code>PLAT_DS_GetLastWakeupKeyCode()</code></p> </li> <li> <p>De-initialize the <code>HAL</code> using the function: <code>PLAT_DS_TERM()</code></p> </li> </ul>"},{"location":"external_content/deepsleep_manager/#sequence-diagram","title":"Sequence Diagram","text":"<pre><code>%%{ init : { \"theme\" : \"default\", \"flowchart\" : { \"curve\" : \"stepBefore\" }}}%%\n   sequenceDiagram\n    participant Caller as Caller\n    participant HAL as Deep Sleep Manager HAL\n    participant Driver as HAL Device Control/Driver\n    Caller-&gt;&gt;HAL:PLAT_DS_INIT()\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:PLAT_DS_SetDeepSleep()\n    Note over HAL: Deep sleep is set using this call\n    HAL-&gt;&gt;Driver: Set Deepsleep\n    Driver--&gt;&gt;HAL: Return\n    HAL--&gt;&gt;HAL: Waiting for device to sleep.\n    Note over HAL: After few seconds CPU will freeze for all modules here\n    Driver--&gt;&gt;Driver: Wake up trigger. (IR, CEC, etc)\n    Note over HAL: CPU resumes for all modules\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:PLAT_DS_DeepSleepWakeup()\n    Note over HAL: Set the platform status after deepsleep wake-up.\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:PLAT_DS_GetLastWakeupReason()\n    Note over HAL: Reason for last wake up is returned using this call\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:PLAT_DS_GetLastWakeupKeyCode()\n    Note over HAL: Reason for last wake up keycode is returned using this call\n    HAL--&gt;&gt;Caller:return\n    Caller -&gt;&gt;HAL:PLAT_DS_TERM()\n    HAL--&gt;&gt;Caller:return</code></pre>"},{"location":"external_content/deepsleep_manager/CHANGELOG/","title":"Changelog","text":""},{"location":"external_content/deepsleep_manager/CHANGELOG/#changelog","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file. Dates are displayed in UTC.</p> <p>Generated by <code>auto-changelog</code>.</p>"},{"location":"external_content/deepsleep_manager/CHANGELOG/#104","title":"1.0.4","text":"<ul> <li>gh #4 Update based on L2 review discussions <code>#6</code></li> <li>post condation is added for plat_ds_init in the interface file <code>d246c28</code></li> <li>Changes based on L2 test discussion <code>c981a13</code></li> <li>Merge tag '1.0.3' into develop <code>70956e3</code></li> </ul>"},{"location":"external_content/deepsleep_manager/CHANGELOG/#103","title":"1.0.3","text":"<p>13 November 2023</p> <ul> <li>Bumped CHANGELOG.md - 1.0.3 <code>aa12921</code></li> <li>Updated License file name in header <code>ee0ea56</code></li> <li>Merge tag '1.0.2' into develop <code>657d8e9</code></li> </ul>"},{"location":"external_content/deepsleep_manager/CHANGELOG/#102","title":"1.0.2","text":"<p>9 November 2023</p> <ul> <li>updated build_ut &amp; gitignore <code>#1</code></li> <li>baseline version <code>80e3d29</code></li> <li>Added CHANGELOG.md - 1.0.2 <code>8183022</code></li> <li>Initial commit <code>b6e8db9</code></li> </ul>"},{"location":"external_content/deepsleep_manager/CONTRIBUTING/","title":"Contributing","text":"<ul> <li>If you wish to make code contributions to this project, the source is hosted at github.com/rdkcentral.</li> </ul> <p>You can submit your changes for review via that site, by raising an issue in github, (https://github.com/rdkcentral/xxxx/issues), and following the sequence below.</p> <ul> <li>create a branch with a name follow the guidelines gh(x)_(synopsis)</li> <li>where x is the ticket number</li> <li>where synopsis is a short synopsis for the reason for the branch.</li> <li>create a pull request (https://github.com/rdkcentral/xxxx/compare) when the code changes are ready for review.</li> <li> <p>The team will review, and if accepted your changes will be merged to the mainline.</p> </li> <li> <p>In order to contribute code, first-time users are requested to agree to the license.</p> </li> <li> <p>where <code>xxxx</code> is your module name</p> </li> </ul>"},{"location":"external_content/deepsleep_manager/docs/pages/CONTRIBUTING/","title":"Contributing","text":"<ul> <li>If you wish to make code contributions to this project, the source is hosted at github.com/rdkcentral.</li> </ul> <p>You can submit your changes for review via that site, by raising an issue in github, (https://github.com/rdkcentral/xxxx/issues), and following the sequence below.</p> <ul> <li>create a branch with a name follow the guidelines gh(x)_(synopsis)</li> <li>where x is the ticket number</li> <li>where synopsis is a short synopsis for the reason for the branch.</li> <li>create a pull request (https://github.com/rdkcentral/xxxx/compare) when the code changes are ready for review.</li> <li> <p>The team will review, and if accepted your changes will be merged to the mainline.</p> </li> <li> <p>In order to contribute code, first-time users are requested to agree to the license.</p> </li> <li> <p>where <code>xxxx</code> is your module name</p> </li> </ul>"},{"location":"external_content/deepsleep_manager/docs/pages/deepsleep-manager_halSpec/","title":"Deep Sleep Manager HAL Documentation","text":""},{"location":"external_content/deepsleep_manager/docs/pages/deepsleep-manager_halSpec/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>HAL</code>:    Hardware Abstraction Layer</li> <li><code>CPE</code>:    Customer Premises Equipment</li> <li><code>IR</code>:     InfraRed</li> <li><code>CEC</code>:    Consumer Electronic Control</li> <li><code>LAN</code>:    Local Area Network</li> <li><code>STB</code>:    Set-top Box</li> <li><code>RCU</code>:    Remote Control Unit</li> <li><code>STR</code>:    Suspend To RAM</li> <li><code>HDMI</code>:   High-Definition Multimedia Interface</li> <li><code>GPIO</code>:   General Purpose Input/OutputManufacturers</li> <li><code>A/V</code>:    Audio/Video</li> <li><code>HDD</code>:    Hard Drive Disk</li> </ul>"},{"location":"external_content/deepsleep_manager/docs/pages/deepsleep-manager_halSpec/#description","title":"Description","text":"<p>The diagram below describes a high-level software architecture of the module stack.</p> <pre><code>%%{ init : { \"theme\" : \"forest\", \"flowchart\" : { \"curve\" : \"linear\" }}}%%\nflowchart TD\ny[Caller]&lt;--&gt;x[Deep Sleep Manager HAL];\nx[Deep Sleep Manager HAL]&lt;--&gt;z[SOC Drivers];\nstyle y fill:#99CCFF,stroke:#333,stroke-width:0.3px,align:left\nstyle z fill:#fcc,stroke:#333,stroke-width:0.3px,align:left\nstyle x fill:#9f9,stroke:#333,stroke-width:0.3px,align:left</code></pre> <p>The Deep Sleep Manager <code>HAL</code> provides a set of <code>APIs</code> to initialize, set the deep sleep state and wake-up from deep sleep state.</p> <p>Deep sleep is a power saving mode which turns off <code>STB</code> subsystems such as A/V, <code>HDMI</code>, front panels, <code>HDD</code> etc.</p> <ul> <li>The main purpose is to bring down the power consumption based on the actual usage. Also, the conditions for triggering and setting deep sleep mode will depend on the product requirements.</li> <li>It can also be triggered in other scenarios such as thermal shutdown, in case the temperature is above the threshold for a certain period of time.</li> <li>When the <code>STB</code> goes into deep sleep mode, it may be woken up for scheduled maintenance in a pre-determined time.</li> </ul>"},{"location":"external_content/deepsleep_manager/docs/pages/deepsleep-manager_halSpec/#component-runtime-execution-requirements","title":"Component Runtime Execution Requirements","text":""},{"location":"external_content/deepsleep_manager/docs/pages/deepsleep-manager_halSpec/#initialization-and-startup","title":"Initialization and Startup","text":"<p><code>Caller</code> must initialize by calling <code>PLAT_DS_INIT()</code> before calling any other <code>API</code>.</p>"},{"location":"external_content/deepsleep_manager/docs/pages/deepsleep-manager_halSpec/#threading-model","title":"Threading Model","text":"<p>This interface is not required to be thread safe. Any <code>caller</code>, while invoking these <code>HAL</code> <code>APIs</code> must ensure calls are made in a thread safe manner.</p>"},{"location":"external_content/deepsleep_manager/docs/pages/deepsleep-manager_halSpec/#process-model","title":"Process Model","text":"<p>This interface is not required to be thread safe. Any <code>caller</code>, while invoking these <code>HAL</code> <code>APIs</code> must ensure calls are made in a thread safe manner.</p>"},{"location":"external_content/deepsleep_manager/docs/pages/deepsleep-manager_halSpec/#memory-model","title":"Memory Model","text":"<p>The <code>caller</code> is responsible to pass message buffer and free it for transmit request.</p>"},{"location":"external_content/deepsleep_manager/docs/pages/deepsleep-manager_halSpec/#power-management-requirements","title":"Power Management Requirements","text":"<p>The Deep sleep manager <code>HAL</code> is involved in the power management operation:</p> <ul> <li>Transitions to Deep Sleep state which puts system into halt</li> <li>Wake up the system from deep sleep state by IR/RF, Bluetooth remote or through LAN wake-up based on the platform requirements</li> </ul>"},{"location":"external_content/deepsleep_manager/docs/pages/deepsleep-manager_halSpec/#asynchronous-notification-model","title":"Asynchronous Notification Model","text":"<p>This interface is not required to support asynchronous notification.</p>"},{"location":"external_content/deepsleep_manager/docs/pages/deepsleep-manager_halSpec/#blocking-calls","title":"Blocking calls","text":"<p>The following <code>APIs</code> are the blocking calls of this module:</p> <ul> <li>PLAT_DS_SetDeepSleep()</li> </ul> <p>This <code>API</code> call puts the system into halt state</p> <ul> <li>PLAT_DS_DeepSleepWakeup()</li> </ul> <p>This <code>API</code> call brings the system out of the halt state</p> <p>All other synchronous <code>API</code> calls must complete within a reasonable time period. Any call that can fail due to the lack of response from the connected device must have a timeout period and the function must return the relevant error code.</p>"},{"location":"external_content/deepsleep_manager/docs/pages/deepsleep-manager_halSpec/#internal-error-handling","title":"Internal Error Handling","text":"<p>All the <code>APIs</code> must return error synchronously as a return argument. <code>HAL</code> is responsible for handling system errors (e.g. out of memory) internally.</p>"},{"location":"external_content/deepsleep_manager/docs/pages/deepsleep-manager_halSpec/#persistence-model","title":"Persistence Model","text":"<p>There is no requirement for the interface to persist any setting information. <code>caller</code> is responsible to persist any settings related to the <code>HAL</code>.</p>"},{"location":"external_content/deepsleep_manager/docs/pages/deepsleep-manager_halSpec/#non-functional-requirements","title":"Non functional requirements","text":""},{"location":"external_content/deepsleep_manager/docs/pages/deepsleep-manager_halSpec/#logging-and-debugging-requirements","title":"Logging and debugging requirements","text":"<p>This interface is required to support DEBUG, INFO and ERROR messages. INFO and DEBUG must be disabled by default and enabled when required.</p>"},{"location":"external_content/deepsleep_manager/docs/pages/deepsleep-manager_halSpec/#memory-and-performance-requirements","title":"Memory and performance requirements","text":"<p>This interface is required to not cause excessive memory and CPU utilization.</p>"},{"location":"external_content/deepsleep_manager/docs/pages/deepsleep-manager_halSpec/#quality-control","title":"Quality Control","text":"<ul> <li>This interface is required to perform static analysis, our preferred tool is Coverity.</li> <li>Have a zero-warning policy with regards to compiling. All warnings are required to be treated as errors.</li> <li>Copyright validation is required to be performed, e.g.: Black duck, FossID.</li> <li>Use of memory analysis tools like Valgrind are encouraged to identify leaks/corruptions.</li> <li><code>HAL</code> Tests will endeavour to create worst case scenarios to assist investigations.</li> <li>Improvements by any party to the testing suite are required to be fed back.</li> </ul>"},{"location":"external_content/deepsleep_manager/docs/pages/deepsleep-manager_halSpec/#licensing","title":"Licensing","text":"<p>The <code>HAL</code> implementation is expected to released under the Apache License 2.0.</p>"},{"location":"external_content/deepsleep_manager/docs/pages/deepsleep-manager_halSpec/#build-requirements","title":"Build Requirements","text":"<p>The source code must build into a shared library and must be named as <code>libiarmmgrs-deepsleep-hal.so</code>. The build mechanism must be independent of Yocto.</p>"},{"location":"external_content/deepsleep_manager/docs/pages/deepsleep-manager_halSpec/#variability-management","title":"Variability Management","text":"<p>Any changes in the <code>APIs</code> must be reviewed and approved by the component architects.</p>"},{"location":"external_content/deepsleep_manager/docs/pages/deepsleep-manager_halSpec/#platform-or-product-customization","title":"Platform or Product Customization","text":"<p>This interface is not required to have any platform or product customizations.</p>"},{"location":"external_content/deepsleep_manager/docs/pages/deepsleep-manager_halSpec/#interface-api-documentation","title":"Interface API Documentation","text":"<p><code>API</code> documentation will be provided by Doxygen which will be generated from the header files.</p>"},{"location":"external_content/deepsleep_manager/docs/pages/deepsleep-manager_halSpec/#theory-of-operation-and-key-concepts","title":"Theory of operation and key concepts","text":"<p>The <code>caller</code> is expected to have complete control over the life cycle of the <code>HAL</code>.</p> <ul> <li> <p>Initialize the <code>HAL</code> using function: <code>PLAT_DS_INIT()</code> before making any other <code>API</code> calls.  If <code>PLAT_DS_INIT()</code> call fails, the <code>HAL</code> must return the respective error code, so that the <code>caller</code> can retry the operation</p> </li> <li> <p>Deep sleep state can be controlled using the function <code>PLAT_DS_SetDeepSleep()</code></p> </li> <li> <p>Any post-processing after wake up can be performed using the function <code>PLAT_DS_DeepSleepWakeup()</code></p> </li> <li> <p>Reason for last wake up can be queried using the function <code>PLAT_DS_GetLastWakeupReason()</code></p> </li> <li> <p>Reason for last wake up keycode can be queried using the function <code>PLAT_DS_GetLastWakeupKeyCode()</code></p> </li> <li> <p>De-initialize the <code>HAL</code> using the function: <code>PLAT_DS_TERM()</code></p> </li> </ul>"},{"location":"external_content/deepsleep_manager/docs/pages/deepsleep-manager_halSpec/#sequence-diagram","title":"Sequence Diagram","text":"<pre><code>%%{ init : { \"theme\" : \"default\", \"flowchart\" : { \"curve\" : \"stepBefore\" }}}%%\n   sequenceDiagram\n    participant Caller as Caller\n    participant HAL as Deep Sleep Manager HAL\n    participant Driver as HAL Device Control/Driver\n    Caller-&gt;&gt;HAL:PLAT_DS_INIT()\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:PLAT_DS_SetDeepSleep()\n    Note over HAL: Deep sleep is set using this call\n    HAL-&gt;&gt;Driver: Set Deepsleep\n    Driver--&gt;&gt;HAL: Return\n    HAL--&gt;&gt;HAL: Waiting for device to sleep.\n    Note over HAL: After few seconds CPU will freeze for all modules here\n    Driver--&gt;&gt;Driver: Wake up trigger. (IR, CEC, etc)\n    Note over HAL: CPU resumes for all modules\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:PLAT_DS_DeepSleepWakeup()\n    Note over HAL: Set the platform status after deepsleep wake-up.\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:PLAT_DS_GetLastWakeupReason()\n    Note over HAL: Reason for last wake up is returned using this call\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:PLAT_DS_GetLastWakeupKeyCode()\n    Note over HAL: Reason for last wake up keycode is returned using this call\n    HAL--&gt;&gt;Caller:return\n    Caller -&gt;&gt;HAL:PLAT_DS_TERM()\n    HAL--&gt;&gt;Caller:return</code></pre>"},{"location":"external_content/deepsleep_manager_test/","title":"Unit Testing Suite For Deep Sleep Manager HAL","text":""},{"location":"external_content/deepsleep_manager_test/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Acronyms, Terms and Abbreviations</li> <li>Description</li> <li>Reference Documents</li> <li>Notes</li> </ul>"},{"location":"external_content/deepsleep_manager_test/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>HAL</code>- Hardware Abstraction Layer</li> <li><code>L1</code> - Functional Tests</li> <li><code>L2</code> - Module functional Testing</li> <li><code>L3</code> - Module testing with External Stimulus is required to validate and control device</li> <li><code>High-Level Test Specification</code> : These specification will provide a broad overview of the system's functionality from the callers' perspective. It focuses on major use cases, system behavior, and overall caller experience.</li> <li><code>Low-Level Test Specification</code> : These specification will delve deeper into the technical details. They will define specific test cases with inputs, expected outputs, and pass/fail criteria for individual functionalities, modules, or APIs.</li> </ul>"},{"location":"external_content/deepsleep_manager_test/#description","title":"Description","text":"<p>This repository contains the Unit Test Suites (L1, L2 &amp; L3) for Deep Sleep Manager <code>HAL</code>.</p>"},{"location":"external_content/deepsleep_manager_test/#reference-documents","title":"Reference Documents","text":"SNo Document Name Document Description Document Link 1 <code>HAL</code> Specification Document This document provides specific information on the APIs for which tests are written in this module deepsleep-manager_halSpec.md 2 High Level Test Specification Document High Level Test Specification Documentation this module deep-sleep-manager_High-Level_TestSpec.md 3 <code>L2</code> Low Level Test Specification Document <code>L2</code>Low Level Test Specification Documentation this module deep-sleep-manager_L2-Low-Level_TestSpec.md 4 <code>L3</code> Low Level Test Spec <code>L3</code> Low Level Test Specification deep-sleep-manager_L3-Low-Level_TestSpec.md 5 <code>L3</code> Test Procedure Document <code>L3</code> Test Procedure Document deep-sleep-manager_L3_TestProcedure.md"},{"location":"external_content/deepsleep_manager_test/#notes","title":"Notes","text":"<ul> <li>All APIs need to be implemented in this current version. If any API is not supported, please add stub implementation with return type DEEPSLEEPMGR_SUCCESS for the same.</li> <li>Building against the actual library may introduce <code>SOC</code> dependencies. Hence, a template SKELETON library is created without <code>SOC</code> dependencies. On the real platform (target), it can be mounted, copied and bound with the actual library.</li> <li>When executing the binary, ensure to include a platform-specific profile file as an argument for the designated test cases. The following example illustrates this:</li> </ul> <p><code>bash ./hal_test -p deepsleepmanagerExtendedEnumsNotSupported.yaml</code></p> <p>Alternatively, use the run.sh script with the profile file:</p> <p><code>bash ./run.sh -p /absolute/path/to/profile/file</code></p> <ul> <li>Profiles file available in here</li> <li>Install Python Environment and Activation Scripts please check the HPK Documentation</li> </ul>"},{"location":"external_content/deepsleep_manager_test/CHANGELOG/","title":"Changelog","text":""},{"location":"external_content/deepsleep_manager_test/CHANGELOG/#changelog","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file. Dates are displayed in UTC.</p> <p>Generated by <code>auto-changelog</code>.</p>"},{"location":"external_content/deepsleep_manager_test/CHANGELOG/#130","title":"1.3.0","text":"<ul> <li>gh #24 deepsleep: L3 Test case Development <code>#25</code></li> <li>gh #26 Updating the utcore version to 4.x <code>#27</code></li> <li>gh #19 deepsleep: L3 Test case Development <code>#20</code></li> <li>gh #21 initial l3 layout <code>#22</code></li> </ul>"},{"location":"external_content/deepsleep_manager_test/CHANGELOG/#123","title":"1.2.3","text":"<p>3 September 2024</p> <ul> <li>gh #17 Deep Sleep Timer value check  <code>#18</code></li> <li>gh #17 Deepsleep timer limit check <code>618a24f</code></li> <li>Bumped CHANGELOG.md - 1.2.3 <code>abe3231</code></li> <li>Merge tag '1.2.2' into develop <code>6774246</code></li> </ul>"},{"location":"external_content/deepsleep_manager_test/CHANGELOG/#122","title":"1.2.2","text":"<p>13 August 2024</p> <ul> <li>gh #15 Update the run.sh script &amp; README.md <code>#16</code></li> <li>Bumped CHANGELOG.md - 1.2.2 <code>1ddf0f2</code></li> <li>Merge tag '1.2.1' into develop <code>7b52e92</code></li> </ul>"},{"location":"external_content/deepsleep_manager_test/CHANGELOG/#121","title":"1.2.1","text":"<p>9 August 2024</p> <ul> <li>gh #13 Code Cleanup in L1 for deepsleep_manager <code>#14</code></li> <li>Bumped CHANGELOG.md - 1.2.1 <code>9aa8ca9</code></li> <li>Merge tag '1.2.0' into develop <code>af26887</code></li> </ul>"},{"location":"external_content/deepsleep_manager_test/CHANGELOG/#120","title":"1.2.0","text":"<p>26 June 2024</p> <ul> <li>gh #10 deep sleep manager make file update <code>#11</code></li> <li>gh #3 Test Specification document for Deep sleep manager <code>#4</code></li> <li>gh #3 Updated with L2 spec and test code initial version. <code>669d6c5</code></li> <li>gh #3 Added Test Specification <code>509da92</code></li> <li>Deepsleep hal L2 <code>0636d58</code></li> </ul>"},{"location":"external_content/deepsleep_manager_test/CHANGELOG/#111","title":"1.1.1","text":"<p>5 June 2024</p> <ul> <li>Bumped CHANGELOG.md - 1.1.1 <code>4dc8aef</code></li> <li>Updated README.md <code>c103a6d</code></li> <li>Merge tag '1.1.0' into develop <code>e73e709</code></li> </ul>"},{"location":"external_content/deepsleep_manager_test/CHANGELOG/#110","title":"1.1.0","text":"<p>5 June 2024</p> <ul> <li>gh #5 deepsleep: Adding MACRO ENABLE_ENHANCED_ERROR_CODE to enable/disable the enhanced <code>#6</code></li> <li>Enhanced error code moved to kvp  profiler <code>f2af2cf</code></li> <li>Disabling enhanced error code <code>51570f8</code></li> <li>Deepsleepmanager enhanced error code update <code>3918bab</code></li> </ul>"},{"location":"external_content/deepsleep_manager_test/CHANGELOG/#104","title":"1.0.4","text":"<p>20 February 2024</p> <ul> <li>Bumped CHANGELOG.md - 1.0.4 <code>a89bae8</code></li> <li>Updated tag version in README.md <code>5a6d6b6</code></li> <li>Merge tag '1.0.3' into develop <code>8690552</code></li> </ul>"},{"location":"external_content/deepsleep_manager_test/CHANGELOG/#103","title":"1.0.3","text":"<p>29 January 2024</p> <ul> <li>gh #1 Update code improve readability <code>4ebbc01</code></li> <li>gh #1 Update UT version2.0 <code>907745b</code></li> <li>Bumped CHANGELOG.md - 1.0.3 <code>14df554</code></li> </ul>"},{"location":"external_content/deepsleep_manager_test/CHANGELOG/#102","title":"1.0.2","text":"<p>12 December 2023</p> <ul> <li>Updated README.md with hal &amp; haltest supported version <code>59df134</code></li> <li>Bumped CHANGELOG.md - 1.0.2 <code>d9d4ddd</code></li> <li>Merge tag '1.0.1' into develop <code>3ec172e</code></li> </ul>"},{"location":"external_content/deepsleep_manager_test/CHANGELOG/#101","title":"1.0.1","text":"<p>7 December 2023</p> <ul> <li>Baseline version <code>9208f9f</code></li> <li>Added CHANGELOG.md - 1.0.1 <code>7f839e4</code></li> <li>Initial commit <code>24dfdb8</code></li> </ul>"},{"location":"external_content/deepsleep_manager_test/CONTRIBUTING/","title":"Contributing","text":"<ul> <li>If you wish to make code contributions to this project, the source is hosted at github.com/rdkcentral.</li> </ul> <p>You can submit your changes for review via that site, by raising an issue in github, (https://github.com/rdkcentral/xxxx/issues), and following the sequence below.</p> <ul> <li>create a branch with a name follow the guidelines gh(x)_(synopsis)</li> <li>where x is the ticket number</li> <li>where synopsis is a short synopsis for the reason for the branch.</li> <li>create a pull request (https://github.com/rdkcentral/xxxx/compare) when the code changes are ready for review.</li> <li> <p>The team will review, and if accepted your changes will be merged to the mainline.</p> </li> <li> <p>In order to contribute code, first-time users are requested to agree to the license.</p> </li> <li> <p>where <code>xxxx</code> is your module name</p> </li> </ul>"},{"location":"external_content/deepsleep_manager_test/docs/pages/CONTRIBUTING/","title":"Contributing","text":"<ul> <li>If you wish to make code contributions to this project, the source is hosted at github.com/rdkcentral.</li> </ul> <p>You can submit your changes for review via that site, by raising an issue in github, (https://github.com/rdkcentral/xxxx/issues), and following the sequence below.</p> <ul> <li>create a branch with a name follow the guidelines gh(x)_(synopsis)</li> <li>where x is the ticket number</li> <li>where synopsis is a short synopsis for the reason for the branch.</li> <li>create a pull request (https://github.com/rdkcentral/xxxx/compare) when the code changes are ready for review.</li> <li> <p>The team will review, and if accepted your changes will be merged to the mainline.</p> </li> <li> <p>In order to contribute code, first-time users are requested to agree to the license.</p> </li> <li> <p>where <code>xxxx</code> is your module name</p> </li> </ul>"},{"location":"external_content/deepsleep_manager_test/docs/pages/deep-sleep-manager_High-Level_TestSpec/","title":"Deep Sleep Manager High Level Test Specification Documentation","text":""},{"location":"external_content/deepsleep_manager_test/docs/pages/deep-sleep-manager_High-Level_TestSpec/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>HAL</code>- Hardware Abstraction Layer</li> <li><code>API</code>- Application Programming Interface</li> <li><code>L2</code> - Level2 Testing</li> <li><code>L3</code> - Level3 Testing</li> <li><code>NA</code> - Not Applicable</li> <li><code>Y</code> - Yes</li> </ul>"},{"location":"external_content/deepsleep_manager_test/docs/pages/deep-sleep-manager_High-Level_TestSpec/#introduction","title":"Introduction","text":"<p>This document provides an overview of High Level testing requirements for the Deep Sleep Manager module. It outlines the scope of testing, objectives, testing levels and approaches, specific test requirements, control plane emulator requirements and expected deliverables.</p> <p>Interface of the test is available here: DeepSleep Manager HAL header</p> <p>The Power manager Hal Spec document: DeepSleep Manager HAL Spec</p>"},{"location":"external_content/deepsleep_manager_test/docs/pages/deep-sleep-manager_High-Level_TestSpec/#test-scenarios","title":"Test Scenarios","text":"<p>The Deep-sleep Manager layer facilitates the deep-sleep sleep and wake up procedures.</p> # Test Functionality Description 1 Set deep sleep with timeout Set the deep sleep with timeout and verify the wake-up source 2 Test with Wake-up Source Configure the deep sleep mode with no timeout, ensuring that the Deep Sleep Manager facilitates wake-up sources, allowing the device to awaken from deep sleep."},{"location":"external_content/deepsleep_manager_test/docs/pages/deep-sleep-manager_High-Level_TestSpec/#set-deep-sleep-with-timeout","title":"Set Deep Sleep with timeout","text":"Description HAL APIs L2 L3 Control plane requirements Set the deep sleep with  of one second and verify the wake-up source PLAT_DS_SetDeepSleep <code>Y</code> <code>NA</code> <code>NA</code> Set the deep sleep with  of ten seconds and verify the wake-up source PLAT_DS_SetDeepSleep <code>Y</code> <code>NA</code> <code>NA</code> Verify that the device has come out of deep-sleep after the specified timeout period has ended. Verify that, based on how long the device sleep, it comes out with a time difference based on the platform configuration file. Also verify that the internal clock matches the network clock after wake up. PLAT_DS_SetDeepSleep <code>N</code> <code>Y</code> <code>NA</code>"},{"location":"external_content/deepsleep_manager_test/docs/pages/deep-sleep-manager_High-Level_TestSpec/#test-startup-requirement-set-deep-sleep-with-timeout","title":"Test Startup Requirement - Set Deep Sleep with timeout","text":"<p><code>NA</code></p>"},{"location":"external_content/deepsleep_manager_test/docs/pages/deep-sleep-manager_High-Level_TestSpec/#emulator-requirements-set-deep-sleep-with-timeout","title":"Emulator Requirements - Set Deep Sleep with timeout","text":"<ul> <li>Boot configuration: Wake-up sources supported by the device read from the platform profile. See DeepSleep_WakeupReason_t.</li> </ul>"},{"location":"external_content/deepsleep_manager_test/docs/pages/deep-sleep-manager_High-Level_TestSpec/#control-plane-requirements-set-deep-sleep-with-timeout","title":"Control Plane Requirements - Set Deep Sleep with timeout","text":"<ul> <li>Control plane must have some way to verify the time the device slept for before waking up.</li> </ul>"},{"location":"external_content/deepsleep_manager_test/docs/pages/deep-sleep-manager_High-Level_TestSpec/#test-with-wake-up-source","title":"Test with Wake-up Source","text":"Description HAL APIs L2 L3 Control plane requirements Configure the deep sleep mode with no timeout, ensuring that the Deep Sleep Manager facilitates wake-up sources( PLAT_API_SetWakeupSrc ) for all wake-up sources that the device supports, allowing the device to awaken from deep sleep. PLAT_DS_SetDeepSleep <code>NA</code> <code>Y</code> Control plane requirements to trigger non-timeout wake up source. Configure the deep sleep mode with a timeout, before triggering a wake-up from an external wake up source( PLAT_API_SetWakeupSrc ) for all wake-up sources that the device supports, allowing the device to awaken from deep sleep. PLAT_DS_SetDeepSleep <code>NA</code> <code>Y</code> Control plane requirements to trigger non-timeout wake up source. Configure the deep sleep mode with a one minute timeout. Verify that is a wake up source is not enabled, the device does not wake up when that external wake up source( PLAT_API_SetWakeupSrc ) is triggered. PLAT_DS_SetDeepSleep, PLAT_API_GetWakeupSrc <code>NA</code> <code>Y</code> Control plane requirements to trigger non-timeout wake up source. Configure the deep sleep mode with no timeout, ensuring that the Deep Sleep Manager does not wake up from deepsleep until an external wake up source triggers. Wait thirty seconds. PLAT_DS_SetDeepSleep <code>NA</code> <code>Y</code> Control plane requirements to trigger non-timeout wake up source. Configure the deep sleep mode with a ten second timeout but timeout wake up source is disabled, ensuring that the Deep Sleep Manager does not wake up from deepsleep until an external wake up source triggers. Wait thirty seconds. PLAT_DS_SetDeepSleep, PLAT_API_SetWakeupSrc <code>NA</code> <code>Y</code> Control plane requirements to trigger non-timeout wake up source. Configure the deep sleep mode with no timeout, ensuring that the Deep Sleep Manager facilitates wake-up sources( PLAT_API_SetWakeupSrc ) for different combinations of wake up sources being enabled. (PWRMGR_WAKEUPSRC_WIFI/PWRMGR_WAKEUPSRC_LAN) PLAT_DS_SetDeepSleep PLAT_API_GetWakeupSrc <code>NA</code> <code>Y</code> Control plane requirements to trigger non-timeout wake up source."},{"location":"external_content/deepsleep_manager_test/docs/pages/deep-sleep-manager_High-Level_TestSpec/#test-startup-requirement-test-with-wake-up-source","title":"Test Startup Requirement - Test with Wake-up Source","text":"<p><code>NA</code></p>"},{"location":"external_content/deepsleep_manager_test/docs/pages/deep-sleep-manager_High-Level_TestSpec/#emulator-requirements-test-with-wake-up-source","title":"Emulator Requirements - Test with Wake-up Source","text":"<ul> <li>Boot configuration: Wake-up sources supported by the device read from the platform profile. See DeepSleep_WakeupReason_t.</li> </ul>"},{"location":"external_content/deepsleep_manager_test/docs/pages/deep-sleep-manager_High-Level_TestSpec/#control-plane-requirements-test-with-wake-up-source","title":"Control Plane Requirements - Test with Wake-up Source","text":"<ul> <li>Control panel to trigger the wake-up source and supported wake-up sources are:</li> <li>Ability to trigger a power cycle if the a test fails a device remains within deepsleep for too long. The limit should be two minutes. It should be on a test by case basis.</li> </ul>"},{"location":"external_content/deepsleep_manager_test/docs/pages/deep-sleep-manager_High-Level_TestSpec/#check-power-consumption","title":"Check Power consumption","text":"Description HAL APIs L2 L3 Control plane requirements Set the deep sleep with and check that the decrease in power comsumption based on the test configuration file with network standby disabled. PLAT_DS_SetDeepSleep <code>NA</code> <code>Y</code> <code>NA</code> Set the deep sleep with and check that the decrease in power comsumption based on the test configuration file with network standby enabled. PLAT_DS_SetDeepSleep <code>NA</code> <code>Y</code> <code>NA</code>"},{"location":"external_content/deepsleep_manager_test/docs/pages/deep-sleep-manager_High-Level_TestSpec/#test-startup-requirement-check-power-consumption","title":"Test Startup Requirement - Check Power consumption","text":"<p><code>NA</code></p>"},{"location":"external_content/deepsleep_manager_test/docs/pages/deep-sleep-manager_High-Level_TestSpec/#emulator-requirements-check-power-consumption","title":"Emulator Requirements -Check Power consumption","text":"<ul> <li>Boot configuration: Wake-up sources supported by the device read from the platform profile. See DeepSleep_WakeupReason_t.</li> </ul>"},{"location":"external_content/deepsleep_manager_test/docs/pages/deep-sleep-manager_High-Level_TestSpec/#control-plane-requirements-check-power-consumption","title":"Control Plane Requirements - Check Power consumption","text":"<ul> <li>Control plane must have way to capture the power consumption changes when the device enters deep sleep</li> </ul>"},{"location":"external_content/deepsleep_manager_test/docs/pages/deep-sleep-manager_L2-Low-Level_TestSpec/","title":"Deep Sleep Manager L2 Low-Level Test Specification and Procedure Documentation","text":""},{"location":"external_content/deepsleep_manager_test/docs/pages/deep-sleep-manager_L2-Low-Level_TestSpec/#overview","title":"Overview","text":"<p>This document describes the L2 Low-Level Test Specification and Procedure Documentation for the Deep Sleep Manager module.</p>"},{"location":"external_content/deepsleep_manager_test/docs/pages/deep-sleep-manager_L2-Low-Level_TestSpec/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>HAL</code> - Hardware Abstraction Layer, may include some common components</li> <li><code>UT</code>  - Unit Test(s)</li> <li><code>OEM</code>  - Original Equipment Manufacture</li> <li><code>SoC</code>  - System on a Chip</li> </ul>"},{"location":"external_content/deepsleep_manager_test/docs/pages/deep-sleep-manager_L2-Low-Level_TestSpec/#definitions","title":"Definitions","text":"<ul> <li><code>ut-core</code> - Common Testing Framework https://github.com/rdkcentral/ut-core, which wraps an open-source framework that can be expanded to the requirements for future frameworks.</li> </ul>"},{"location":"external_content/deepsleep_manager_test/docs/pages/deep-sleep-manager_L2-Low-Level_TestSpec/#references","title":"References","text":"<ul> <li><code>High Level Test Specification</code> - DeepSleep Manager High Level TestSpec</li> <li><code>HAL Interface file</code> -  DeepSleep Manager HAL header</li> </ul>"},{"location":"external_content/deepsleep_manager_test/docs/pages/deep-sleep-manager_L2-Low-Level_TestSpec/#level-2-test-procedure","title":"Level 2 Test Procedure","text":"<p>The following functions are expected to test whether the module operates correctly.</p>"},{"location":"external_content/deepsleep_manager_test/docs/pages/deep-sleep-manager_L2-Low-Level_TestSpec/#test-1","title":"Test 1","text":"Title Details Function Name <code>test_l2_deepSleepMgr_SetDeepSleepAndVerifyWakeup1</code> Description Set the deep sleep with a duration of one second and verify the wake-up source Test Group 02 Test Case ID 001 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If the user chooses to run the test in interactive mode, then the test case has to be selected via the console.</p>"},{"location":"external_content/deepsleep_manager_test/docs/pages/deep-sleep-manager_L2-Low-Level_TestSpec/#test-procedure-test-1","title":"Test Procedure - Test 1","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the deep sleep manager using PLAT_DS_INIT None DEEPSLEEPMGR_SUCCESS Should be successful 02 Set the deep sleep with a duration of one second using PLAT_DS_SetDeepSleep deep_sleep_timeout=1, isGPIOWakeup=valid pointer, networkStandby=false DEEPSLEEPMGR_SUCCESS Should be successful 03 PLAT_DS_DeepSleepWakeup shall be called after wakeup to do any postprocessing None DEEPSLEEPMGR_SUCCESS Should be successful 04 Verify the wakeup source using PLAT_DS_GetLastWakeupReason wakeupReason = Valid pointer isGPIOWakeup=false, wakeup reason = DEEPSLEEP_WAKEUPREASON_TIMER Should be successful 05 Terminate the deep sleep manager using PLAT_DS_TERM None DEEPSLEEPMGR_SUCCESS Should be successful <pre><code>graph TB\nA[Call PLAT_DS_INIT] --&gt;|DEEPSLEEPMGR_SUCCESS| B[Call PLAT_DS_SetDeepSleep]\nA --&gt;|Failure| A1[Test case fail]\nB --&gt;|DEEPSLEEPMGR_SUCCESS| C[Wait for 1 second]\nB --&gt;|Failure| B1[Test case fail]\nC --&gt; D[Call PLAT_DS_DeepSleepWakeup]\nD --&gt; |DEEPSLEEPMGR_SUCCESS| E[verify the wakeup source using PLAT_DS_GetLastWakeupReason]\nD --&gt; |Failure| D1[Test case fail]\nE --&gt;|DEEPSLEEPMGR_SUCCESS| F[Call PLAT_DS_TERM]\nE --&gt;|Failure| E1[Test case fail]\nF --&gt;|DEEPSLEEPMGR_SUCCESS| G[Test case success]\nF --&gt;|Failure| F1[Test case fail]</code></pre>"},{"location":"external_content/deepsleep_manager_test/docs/pages/deep-sleep-manager_L2-Low-Level_TestSpec/#test-2","title":"Test 2","text":"Title Details Function Name <code>test_l2_deepSleepMgr_SetDeepSleepAndVerifyWakeUp10</code> Description Set the deep sleep with a duration of ten seconds and verify the wake-up source Test Group 02 Test Case ID 002 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If the user chooses to run the test in interactive mode, then the test case has to be selected via the console.</p>"},{"location":"external_content/deepsleep_manager_test/docs/pages/deep-sleep-manager_L2-Low-Level_TestSpec/#test-procedure-test2","title":"Test Procedure - Test2","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the deep sleep manager using PLAT_DS_INIT None DEEPSLEEPMGR_SUCCESS Should be successful 02 Set the deep sleep with a duration of one second using PLAT_DS_SetDeepSleep deep_sleep_timeout=10sec, isGPIOWakeup=valid pointer, networkStandby=false DEEPSLEEPMGR_SUCCESS Should be successful 03 PLAT_DS_DeepSleepWakeup shall be called after wakeup to do any postprocessing None DEEPSLEEPMGR_SUCCESS Should be successful 04 Verify the wakeup source using PLAT_DS_GetLastWakeupReason wakeupReason = Valid pointer isGPIOWakeup=false, wakeup reason = DEEPSLEEP_WAKEUPREASON_TIMER Should be successful 05 Terminate the deep sleep manager using PLAT_DS_TERM None DEEPSLEEPMGR_SUCCESS Should be successful <pre><code>graph TB\nA[Call PLAT_DS_INIT] --&gt;|DEEPSLEEPMGR_SUCCESS| B[Call PLAT_DS_SetDeepSleep]\nA --&gt;|Failure| A1[Test case fail]\nB --&gt;|DEEPSLEEPMGR_SUCCESS| C[Wait for 10 seconds]\nB --&gt;|Failure| B1[Test case fail]\nC --&gt; D[Call PLAT_DS_DeepSleepWakeup]\nD --&gt; |DEEPSLEEPMGR_SUCCESS| E[verify the wakeup source using PLAT_DS_GetLastWakeupReason]\nD --&gt; |Failure| D1[Test case fail]\nE --&gt;|DEEPSLEEPMGR_SUCCESS| F[Call PLAT_DS_TERM]\nE --&gt;|Failure| E1[Test case fail]\nF --&gt;|DEEPSLEEPMGR_SUCCESS| G[Test case success]\nF --&gt;|Failure| F1[Test case fail]</code></pre>"},{"location":"external_content/deepsleep_manager_test/docs/pages/deep-sleep-manager_L3-Low-Level_TestSpec/","title":"Deepsleep Manager L3 Low Level Test Specification and Procedure Documentation","text":""},{"location":"external_content/deepsleep_manager_test/docs/pages/deep-sleep-manager_L3-Low-Level_TestSpec/#overview","title":"Overview","text":"<p>This document describes the L3 Low Level Test Specification and Procedure Documentation for the Deepsleep Manager module.</p>"},{"location":"external_content/deepsleep_manager_test/docs/pages/deep-sleep-manager_L3-Low-Level_TestSpec/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>HAL</code> - Hardware Abstraction Layer, may include some common components</li> <li><code>UT</code>  - Unit Test(s)</li> <li><code>OEM</code> - Original Equipment Manufacture</li> <li><code>SoC</code> - System on a Chip</li> <li><code>LAN</code> - Local Area Network</li> <li><code>Y</code>   - yes supported</li> <li><code>NA</code>  - Not Supported</li> </ul>"},{"location":"external_content/deepsleep_manager_test/docs/pages/deep-sleep-manager_L3-Low-Level_TestSpec/#references","title":"References","text":"<ul> <li><code>High Level Test Specification</code> - DeepSleep Manager High Level TestSpec</li> <li><code>HAL Interface file</code> -  DeepSleep Manager HAL header</li> </ul>"},{"location":"external_content/deepsleep_manager_test/docs/pages/deep-sleep-manager_L3-Low-Level_TestSpec/#level-3-test-cases-high-level-overview","title":"Level 3 Test Cases High Level Overview","text":"# Test-case Description HAL APIs Source Sink 1 Verify the deepsleep wake up from Voice Trigger deepsleep, and trigger wake up from voice up source <code>PLAT_DS_SetDeepSleep()</code> <code>Y</code> <code>Y</code> 2 Verify the deepsleep wake up from Presence Detection Trigger deepsleep, and trigger wake up from presence detection <code>PLAT_DS_SetDeepSleep()</code> <code>Y</code> <code>Y</code> 3 Verify the deepsleep wake up from Bluetooth Trigger deepsleep, and trigger wake up from bluetooth <code>PLAT_DS_SetDeepSleep()</code> <code>Y</code> <code>Y</code> 4 Verify the deepsleep wake up from wifi Trigger deepsleep, and trigger wake up from wifi <code>PLAT_DS_SetDeepSleep()</code> <code>Y</code> <code>Y</code> 5 Verify the deepsleep wake up from IR Trigger deepsleep, and trigger wake up from IR <code>PLAT_DS_SetDeepSleep()</code> <code>Y</code> <code>Y</code> 6 Verify the deepsleep wake up from Power Key Trigger deepsleep, and trigger wake up from Power Key <code>PLAT_DS_SetDeepSleep()</code> <code>Y</code> <code>Y</code> 7 Verify the deepsleep wake up from CEC Trigger deepsleep, and trigger wake up from CEC <code>PLAT_DS_SetDeepSleep()</code> <code>Y</code> <code>Y</code> 8 Verify the deepsleep wake up from LAN Trigger deepsleep, and trigger wake up from LAN <code>PLAT_DS_SetDeepSleep()</code> <code>Y</code> <code>Y</code>"},{"location":"external_content/deepsleep_manager_test/docs/pages/deep-sleep-manager_L3-Low-Level_TestSpec/#level-3-python-test-cases-high-level-overview","title":"Level 3 Python Test Cases High Level Overview","text":"<p>The class diagram below illustrates the flow of Deepsleep Manager L3 Python test cases:</p> <pre><code>---\ntitle: deepsleep - Python Class Flow\n---\nclassDiagram\n    testControl &lt;|-- ut_raft : inherits\n    class ut_raft{\n    }\n    ut_raft &lt;|-- L3_TestClasses_Deepsleep : inherits\n    L3_TestClasses_Deepsleep ..&gt; deepsleep_tests : uses\n    note for testControl \"uses rackConfig.yaml and deviceConfig.yaml\"\n    note for L3_TestClasses_Deepsleep \"uses testSetupConfig.yaml\"\n    ut_raft &lt;|-- L3_TestClasses_Power : inherits\n    L3_TestClasses_Power ..&gt; deepsleep_tests : uses\n    note for L3_TestClasses_Power \"uses testSetupConfig.yaml\"\n    note for ut_raft \"suite Navigator uses testSuite.yaml\"</code></pre> <ul> <li>testControl</li> <li>Test Control Module for running rack Testing. This module configures the <code>DUT</code> based on the rack configuration file provided to the test.</li> <li>This class is defined in <code>RAFT</code> framework. For more details refer RAFT</li> <li>ut_raft</li> <li>Python based testing framework for writing engineering tests.</li> <li>It provides common functionalities like menu navigation, configuration reader, reading user response etc.</li> <li>For more details ut-raft.</li> <li>deepsleep manager</li> <li>This is test helper class which communicates with the <code>L3</code> C/C++ test running on the <code>DUT</code> through menu</li> <li>L3_TestClasses</li> <li>These are the L3 test case classes</li> <li>Each class covers the each test use-case defined in L3 Test use-cases table</li> </ul>"},{"location":"external_content/deepsleep_manager_test/docs/pages/deep-sleep-manager_L3-Low-Level_TestSpec/#yaml-file-inputs","title":"YAML File Inputs","text":"<ul> <li>rackConfig.yaml</li> <li>Identifies the rack configuration and platform used</li> <li>References platform-specific config from <code>deviceConfig.yaml</code></li> <li> <p>For more details refer RAFT and example_rack_config.yml</p> </li> <li> <p>deviceConfig.yaml</p> </li> <li>Specifies overall configuration for the platform</li> <li>Can be overridden by:<ul> <li>Changing locally .yaml file directory</li> <li>Using --deviceConfig command line switch</li> </ul> </li> <li>For more details refer RAFT and example_device_config.yml</li> </ul> <p>componentProfile.yaml/platformProfile.yaml   - Contains component-specific configurations   - Contains platform wide configuration broken down into separate components   - Example configuration file deepsleep_Settings</p> <ul> <li>testSetupConfig.yaml</li> <li>This configuration file contains the list of requirements for tests to execute. Eg: Copying the streams, setting environment variables etc.</li> <li> <p>Example configuration file deepsleep_L3_testSetup.yml</p> </li> <li> <p>testSuite.yaml</p> </li> <li>This configuration file contains the list of menu items for C/C++ L3 test running on <code>DUT</code></li> <li>Example configuration file deepsleep_testConfig.yml</li> </ul>"},{"location":"external_content/deepsleep_manager_test/docs/pages/deep-sleep-manager_L3_TestProcedure/","title":"DeepSleep HAL L3 Python Test Procedure","text":""},{"location":"external_content/deepsleep_manager_test/docs/pages/deep-sleep-manager_L3_TestProcedure/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>HAL</code>    - Hardware Abstraction Layer</li> <li><code>L3</code>     - Level 3 Testing</li> <li><code>DUT</code>    - Device Under Test</li> <li><code>RAFT</code>   - Rapid Automation Framework for Testing</li> <li><code>YAML</code>   - YAML Ain't Markup Language</li> <li><code>HDMI</code>   - High-Definition Multimedia Interface</li> <li><code>CEC</code>    - Consumer Electronics Control</li> <li><code>LAN</code>    - Local Area Network</li> <li><code>SSID</code>   - Service Set Identifier</li> <li><code>IP</code>     - Internet Protocal</li> </ul>"},{"location":"external_content/deepsleep_manager_test/docs/pages/deep-sleep-manager_L3_TestProcedure/#setting-up-test-environment","title":"Setting Up Test Environment","text":"<p>To execute <code>HAL</code> <code>L3</code> Python test cases, need a Python environment. Follow these steps mentioned in HPK Public Documentation</p>"},{"location":"external_content/deepsleep_manager_test/docs/pages/deep-sleep-manager_L3_TestProcedure/#update-configuration-files","title":"Update Configuration Files","text":""},{"location":"external_content/deepsleep_manager_test/docs/pages/deep-sleep-manager_L3_TestProcedure/#rack-configuration-file","title":"Rack Configuration File","text":"<p>Example Rack configuration File: example_rack_config.yml</p> <p>For more details refer RAFT and example_rack_config.yml</p> <p>In this file, update the configuration to define the console sessions for the <code>DUT</code> and the outbound settings:</p> Console Session Description default This session is used for basic operations, such as verifying the device status and retrieving the MAC address ssh_hal_deepsleep_test Executes the <code>HAL</code> binary for the deepsleep test case ssh_hal_power_test Executes the <code>HAL</code> binary for the power test case <pre><code>rackConfig:\n  - dut:\n      ip: \"XXX.XXX.XXX.XXX\"  # IP Address of the device\n      description: \"stb device under test\"\n      platform: \"stb\"\n      consoles:\n        - default:\n            type: \"ssh\"\n            port: 10022\n            username: \"root\"\n            ip: \"XXX.XXX.XXX\" # IP address of the device\n            password: ' '\n        - ssh_hal_deepsleep_test:\n            type: \"ssh\"\n            port: 10022\n            username: \"root\"\n            ip: \"XXX.XXX.XXX\" # IP address of the device\n            password: ' '\n        - ssh_hal_power_test:\n            type: \"ssh\"\n            port: 10022\n            username: \"root\"\n            ip: \"XXX.XXX.XXX\" # IP address of the device\n            password: ' '\n      outbound:\n        download_url: \"tftp://tftp-server.com/rack1/slot1/\"    # Download location for the CPE device\n        upload_url: \"sftp://server-address/home/workspace/tftp/rack1/slot1/\" # Upload location\n        upload_url_base_dir: \"sftp://server-address/home/workspace/tftp/rack1/slot1\"\n        httpProxy:   # Local proxy if required\n        workspaceDirectory: './logs/workspace'   # Local working directory\n</code></pre>"},{"location":"external_content/deepsleep_manager_test/docs/pages/deep-sleep-manager_L3_TestProcedure/#device-configuration-file","title":"Device Configuration File","text":"<p>Example Device configuration File: deviceConfig.yml</p> <p>For more details refer RAFT and example_device_config.yml</p> <p>Update the target directory where <code>HAL</code> binaries will be copied into the device. Also, map the profile to the source/sink settings <code>YAML</code> file path.</p> <p>Ensure the platform should match with the <code>DUT</code> platform in Rack Configuration</p> <pre><code>deviceConfig:\n  cpe1:\n    platform: \"stb\"    # Must match the platform in example_rack_config.yml\n    model: \"uk\"\n    target_directory: \"/tmp\"  # Path where HAL binaries are copied in device\n    test:\n      profile: \"../../../profiles/deepsleepmanagerExtendedEnumsNotSupported.yaml\"\n</code></pre>"},{"location":"external_content/deepsleep_manager_test/docs/pages/deep-sleep-manager_L3_TestProcedure/#test-setup-configuration-file","title":"Test Setup Configuration File","text":"<p>Example Test Setup configuration File the deepsleep side: deepsleep_L3_testSetup.yml</p> <p>Example Test Setup configuration File the power manager side: power_L3_testSetup.yml</p> <p>Streams required for each test case was provided in this file. Testing Deep sleep functionality doesn't require any streams.</p> <pre><code>deepsleep:  # Prefix must always exist\n  description: \"deepsleep Manager test setup\"\n  assets:\n    device:\n      test1_TestWakeupSources:\n        streams:\n\npower:  # Prefix must always exist\n  description: \"power Manager test setup\"\n  assets:\n    device:\n      test1_TestWakeupSources:\n        streams:\n</code></pre>"},{"location":"external_content/deepsleep_manager_test/docs/pages/deep-sleep-manager_L3_TestProcedure/#test-configuration","title":"Test Configuration","text":"<p>Example Test configuration File for deepsleep manager: deepsleep_testConfig.yml Example Test Setup configuration File for power manager: power_testConfig.yml</p> <p>The test copies the binary files from the path specified in the <code>artifacts</code> entry of the <code>yml</code> file. Ensure that the <code>HAL</code> test binaries for the deep sleep manager and power manager are available in the specified folder.</p> <p>Execute command to run the <code>HAL</code> binary was provided in this file.</p> <pre><code>deepsleep:\n    description: \"deepsleep Manager testing profile / menu system for UT\"\n    test:\n        artifacts:\n        #List of artifacts folders, test class copies the content of folder to the target device workspace\n          - \"../../../bin/deepsleepmanager/\"\n        # exectute command, this will appended with the target device workspace path\n        execute: \"run.sh\" #Execute command\n</code></pre> <pre><code>power:\n    description: \"power Manager testing profile / menu system for UT\"\n    test:\n        artifacts:\n        #List of artifacts folders, test class copies the content of folder to the target device workspace\n          - \"../../../bin/powermanager/\"\n        # exectute command, this will appended with the target device workspace path\n        execute: \"run.sh\" #Execute command\n</code></pre>"},{"location":"external_content/deepsleep_manager_test/docs/pages/deep-sleep-manager_L3_TestProcedure/#run-test-cases","title":"Run Test Cases","text":"<p>Once the environment is set up, you can execute the test cases with the following command</p> <pre><code>python &lt;TestCaseName.py&gt; --config &lt;/PATH&gt;/ut/host/tests/configs/example_rack_config.yml --deviceConfig &lt;/PATH&gt;/ut/host/tests/configs/deviceConfig.yml\n</code></pre>"},{"location":"external_content/deepsleep_manager_test/docs/pages/deep-sleep-manager_L3_TestProcedure/#test-setup-connections","title":"Test Setup Connections","text":"<p>Make sure the device under test <code>DUT</code> is connected to wifi, <code>LAN</code> and a <code>CEC</code> supported device for waking up from deepsleep before starting the test case.</p>"},{"location":"external_content/deepsleep_manager_test/docs/pages/deep-sleep-manager_L3_TestProcedure/#example-wifi-configuration","title":"Example WIFI Configuration","text":"<p>If the <code>DUT</code> supports WPA, follow these steps to configure the <code>WIFI</code>:</p> <p>Generate the WPA Configuration File:</p> <p>Use the router's <code>SSID</code> and password to create a configuration file:</p> <pre><code>wpa_passphrase &lt;\"Router SSID\"&gt; &lt;\"Passsword\" &gt; /data/wpa-supplicant.conf\n</code></pre> <p>Start the wpa_supplicant daemon: Run the following command to start the <code>wpa_supplicant</code> service:</p> <pre><code>wpa_supplicant -dd -B -i wlan0 -c /data/wpa-supplicant.conf\n</code></pre> <p>If still not getting <code>IP</code> for <code>wlan0</code> bridge interface try:</p> <pre><code>ifconfig wlan0 down\nifconfig wlan0 up\n</code></pre>"},{"location":"external_content/deepsleep_manager_test/docs/pages/deep-sleep-manager_L3_TestProcedure/#test-cases","title":"Test Cases","text":""},{"location":"external_content/deepsleep_manager_test/docs/pages/deep-sleep-manager_L3_TestProcedure/#test1_triggerdeepsleeppy","title":"test1_TriggerDeepsleep.py","text":""},{"location":"external_content/deepsleep_manager_test/docs/pages/deep-sleep-manager_L3_TestProcedure/#platform-support-test01","title":"Platform Support - test01","text":"<ul> <li>Sink/Source</li> </ul>"},{"location":"external_content/deepsleep_manager_test/docs/pages/deep-sleep-manager_L3_TestProcedure/#user-input-required-test01","title":"User Input Required - test01","text":"<p>Yes: User interaction is required to manually trigger wake-up events from deep sleep for specific wake-up sources. (This will be automated later).</p>"},{"location":"external_content/deepsleep_manager_test/docs/pages/deep-sleep-manager_L3_TestProcedure/#acceptance-criteria-test01","title":"Acceptance Criteria - test01","text":"<p>All supported wake-up sources must be validated and properly trigger the system to wake up from deep sleep</p>"},{"location":"external_content/deepsleep_manager_test/docs/pages/deep-sleep-manager_L3_TestProcedure/#expected-results-test01","title":"Expected Results - test01","text":"<p>All tested wake-up sources must successfully trigger the system to exit deep sleep without errors or failures. Upon waking, the recorded wake-up reason must accurately correspond to the triggered event.</p>"},{"location":"external_content/deepsleep_manager_test/docs/pages/deep-sleep-manager_L3_TestProcedure/#test-steps-test01","title":"Test Steps - test01","text":"<ul> <li> <p>Initiate the Test:</p> </li> <li> <p>Select and execute the Python file: <code>test1_TriggerDeepsleep.py</code></p> </li> <li> <p>The test will automatically download all required artifacts, copying them to the designated target directory before commencing execution.</p> </li> <li> <p>Trigger deepsleep prompt:</p> <p>The test will set the wake-up source and trigger a deepsleep.</p> <p>The above will loop through all supported wake up sources that applicable for the specific device based on the <code>yaml</code> file.</p> </li> <li> <p>Once in deepsleep the device will need to be manually awoken for some sources like <code>IR</code>, <code>CEC</code> and <code>Power_Key</code>.</p> <ul> <li> <p>During the <code>IR</code> test, use an <code>IR</code> remote to trigger the wake-up by pressing the power key or home key. If the device successfully wakes up from deep sleep using this method, the test evaluates whether the wake-up process was successful.</p> </li> <li> <p>During the <code>Power_Key</code> test, press the power key of the <code>dut</code> to wake-up. If the device successfully wakes up from deep sleep using this method, the test evaluates whether the wake-up process was successful.</p> </li> <li> <p>During the <code>CEC</code> test, initiate the wake-up process by connecting an <code>HDMI</code> cable to the device and sending a wake-up <code>CEC</code> command (e.g., <code>Image_View_On</code>) from the connected device to the <code>DUT</code>. If the device transitions successfully from deep sleep to an active state using this method, the test assesses the success of the wake-up operation.</p> </li> </ul> </li> <li> <p>The following tests should be done automaticaly.</p> <ul> <li> <p>When the device enters <code>LAN</code> test, test automatically triggers the wake up and validates whether the device successfully wakes up.</p> </li> <li> <p>When the device enters <code>wifi</code> test, test automatically triggers the wake up and validates whether the device successfully wakes up.</p> </li> <li> <p>When the device enters <code>Timer</code> test, <code>dut</code> wakes up after 60 seconds and test validates whether the device successfully wakes up.</p> </li> </ul> </li> </ul>"},{"location":"external_content/device_settings/","title":"Device Settings Module","text":""},{"location":"external_content/device_settings/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Acronyms, Terms and Abbreviations</li> <li>Description</li> <li>Device Settings Sub modules details</li> </ul>"},{"location":"external_content/device_settings/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>HPK</code> - Hardware Porting Kit</li> <li><code>HAL</code> - Hardware Abstraction Layer</li> <li><code>DS</code> - Device Settings</li> <li><code>NA</code> - Not Applicable</li> </ul>"},{"location":"external_content/device_settings/#description","title":"Description","text":"<p>This document provides the links for the specific sub-modules of the Device Settings.</p>"},{"location":"external_content/device_settings/#device-settings-sub-modules-details","title":"Device Settings Sub modules details","text":"SNo Sub-module Name <code>HAL</code> Specification Header File(s) Settings Template File 1 <code>DS</code> Host <code>DS</code> Host <code>HAL</code> Specification dsHost.h <code>NA</code> 2 <code>DS</code> Front Panel Display <code>DS</code> Front Panel Display <code>HAL</code> Specification dsFPD.h, dsFPDTypes.h frontPanelSettings_template.hpp 3 <code>DS</code> Display <code>DS</code> Display <code>HAL</code> Specification dsDisplay.h, dsAVDTypes.h <code>NA</code> 4 <code>DS</code> HDMI Input <code>DS</code> HDMI Input <code>HAL</code> Specification dsHdmiIn.h, dsHdmiInTypes.h <code>NA</code> 5 <code>DS</code> Composite Input <code>DS</code> Composite Input <code>HAL</code> Specification dsCompositeIn.h, dsCompositeInTypes.h <code>NA</code> 6 <code>DS</code> Audio <code>DS</code> Audio <code>HAL</code> Specification dsAudio.h, dsAVDTypes.h dsAudioSettings_template.h 7 <code>DS</code> Video Device <code>DS</code> Video Device <code>HAL</code> Specification dsVideoDevice.h, dsVideoDeviceTypes.h dsVideoDeviceSettings_template.h 8 <code>DS</code> Video Port <code>DS</code> Video Port <code>HAL</code> Specification dsVideoPort.h, dsAVDTypes.h dsVideoPortSettings_template.h, dsVideoResolutionSettings_template.h <p>For more information about Test suits and <code>HPK</code>,please check HPK repo</p>"},{"location":"external_content/device_settings/CHANGELOG/","title":"Changelog","text":""},{"location":"external_content/device_settings/CHANGELOG/#changelog","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file. Dates are displayed in UTC.</p> <p>Generated by <code>auto-changelog</code>.</p>"},{"location":"external_content/device_settings/CHANGELOG/#412","title":"4.1.2","text":"<ul> <li>gh #85 HDMI Hal header updation for the maximum number of HDMI ports <code>#86</code></li> <li>Merge tag '4.1.1' into develop <code>3c96217</code></li> </ul>"},{"location":"external_content/device_settings/CHANGELOG/#411","title":"4.1.1","text":"<p>27 December 2024</p> <ul> <li>gh #83 Mismatch in dialog enhancement range <code>#84</code></li> <li>Bumped CHANGELOG.md - 4.1.1 <code>c076606</code></li> <li>Modified the param description based on IDK version <code>87af9d0</code></li> <li>gh #83 Mismatch in the range of Dialog Enhancement Level <code>2b8546d</code></li> </ul>"},{"location":"external_content/device_settings/CHANGELOG/#410","title":"4.1.0","text":"<p>21 November 2024</p> <ul> <li>gh #80 Add Composite videoModeUpdate CB header <code>#81</code></li> <li>gh #80 Added Composite VideoModeCB Header <code>73ff15d</code></li> <li>gh #80 Added Composite VideoModeCB Header <code>01d3d32</code></li> <li>Update dsCompositeIn.h <code>509bab3</code></li> </ul>"},{"location":"external_content/device_settings/CHANGELOG/#401","title":"4.0.1","text":"<p>7 November 2024</p> <ul> <li>gh #72 Frame Rate Mode and Frame Rate API description update <code>#73</code></li> <li>Bumped CHANGELOG.md - 4.0.1 <code>f5ac950</code></li> <li>gh #72 Update Description for Framerate mode and Framerate APIs <code>0348d7b</code></li> <li>gh #73 Get and Set Framerate brief update <code>190698e</code></li> </ul>"},{"location":"external_content/device_settings/CHANGELOG/#400","title":"4.0.0","text":"<p>28 August 2024</p> <ul> <li>gh #64 Add new getHdmiVersion API <code>#68</code></li> <li>gh #67 Interface file update - dsHdmi Input - Parameter change in Select port <code>#69</code></li> <li>gh #62 Remove statement for Operation_Not_Supported in Get and SetFPS\u2026 <code>#63</code></li> <li>gh #59 Added HDMI VideoPort ALLM APIs <code>#61</code></li> <li>gh #59 Added ALLM Set/Get APIs <code>c790aa2</code></li> <li>gh #64 Minor corrections to HDMI version API and enum names <code>b382740</code></li> <li>Bumped CHANGELOG.md - 4.0.0 <code>1a9a7f7</code></li> </ul>"},{"location":"external_content/device_settings/CHANGELOG/#300","title":"3.0.0","text":"<p>27 June 2024</p> <ul> <li>gh #57 fp architectural comments <code>#58</code></li> <li>gh #55 Remove dsGetHDMIARCPortID() from dsAudio Interface <code>#56</code></li> <li>gh #50 Update based on review discussion <code>#51</code></li> <li>gh #53 Info about SEI Signalling in AVIContentTypeChangeCB <code>#54</code></li> <li>gh #25 DS Audio Interface update <code>#26</code></li> <li>gh #43 VideoDevice dsGetHDRCapabilities doxygen update <code>#44</code></li> <li>gh #41 dsGetAspectRatio Source related updates <code>#42</code></li> <li>gh #47 hdmi in interface architectural comments <code>#48</code></li> <li>gh #39 Video Port architectural comments <code>#40</code></li> <li>gh #36 updated the post conditions for display and composite  <code>#38</code></li> <li>gh #45 Remove the prerequisite dsCompositeInSelectPort() from dsCompositeInScaleVideo() <code>#46</code></li> <li>gh #30 Deprecate DTCP related APIs <code>#31</code></li> <li>Feature/issues15 video port interface update <code>#16</code></li> <li>gh #21 DS Video Device Interface Update <code>#22</code></li> <li>gh #23 DS HDMI IN Interface Document Update <code>#24</code></li> <li>gh #17 DS Display Interface Documentation Update <code>#18</code></li> <li>gh #25 Deprecating Encoding &amp; DelayOffset set/get APIs <code>dc7ba35</code></li> <li>gh #25 Removed wrongly uploaded Audio header <code>14f99bb</code></li> <li>gh #26 Updated Audio Header for both sink and source <code>1ce0e98</code></li> </ul>"},{"location":"external_content/device_settings/CHANGELOG/#210","title":"2.1.0","text":"<p>11 September 2024</p> <ul> <li>gh #78 Added ALLM Set/Get APIs in 2.0.0 tag <code>#79</code></li> <li>gh #76 Add new getHdmiVersion API to 2.0.0 <code>#77</code></li> <li>gh #64 Add new getHdmiVersion API <code>e74f6cb</code></li> </ul>"},{"location":"external_content/device_settings/CHANGELOG/#200","title":"2.0.0","text":"<p>22 March 2024</p> <ul> <li>Feature/issues11 Add set mixer levels API <code>#12</code></li> <li>Bumped CHANGELOG.md - 2.0.0 <code>72ba582</code></li> <li>gh #11 Added SetMixerLevels API <code>698703d</code></li> <li>gh #11 Generic Mixer(removed MS12) &amp; dsERR_GENERAL return value update <code>cb4eced</code></li> </ul>"},{"location":"external_content/device_settings/CHANGELOG/#108","title":"1.0.8","text":"<p>12 December 2023</p> <ul> <li>Bumped CHANGELOG.md - 1.0.8 <code>b1bc998</code></li> <li>updated frontPanelSettings_template.hpp file name in README.md <code>ab3616d</code></li> <li>Merge tag '1.0.7' into develop <code>cc1da17</code></li> </ul>"},{"location":"external_content/device_settings/CHANGELOG/#107","title":"1.0.7","text":"<p>11 December 2023</p> <ul> <li>Recent updates to the .h files to maintain versions, until we finish migrating to the new repo <code>#5</code></li> <li>Update AVD types with missing values <code>65abe30</code></li> <li>doxygen comments updated <code>f36dc8f</code></li> <li>Bumped CHANGELOG.md - 1.0.7 <code>b69b787</code></li> </ul>"},{"location":"external_content/device_settings/CHANGELOG/#106","title":"1.0.6","text":"<p>14 November 2023</p> <ul> <li>Updated build_ut.sh &amp; Updated LICENSE file name in header <code>#3</code></li> <li>Baseline version <code>2726111</code></li> <li>Updated LICENSE file name in header <code>032d968</code></li> <li>Updated CHANGELOG.md - 1.0.6 <code>4380b47</code></li> </ul>"},{"location":"external_content/device_settings/CHANGELOG/#020","title":"0.2.0","text":"<p>21 March 2024</p> <ul> <li>RDK6 Changes <code>e0942cb</code></li> <li>Added CHANGELOG.md - 0.2.0 <code>5e7e81b</code></li> <li>Initial commit <code>2f7ae7f</code></li> </ul>"},{"location":"external_content/device_settings/CHANGELOG/#012","title":"0.1.2","text":"<p>15 January 2024</p> <ul> <li>Baseline version <code>36805cd</code></li> <li>Initial commit <code>4506122</code></li> </ul>"},{"location":"external_content/device_settings/CHANGELOG/#011","title":"0.1.1","text":"<p>11 January 2024</p> <ul> <li>Baseline changes <code>78bde55</code></li> <li>Initial commit <code>e2cccba</code></li> </ul>"},{"location":"external_content/device_settings/CHANGELOG/#010","title":"0.1.0","text":"<p>27 December 2023</p> <ul> <li>baseline version <code>08c905d</code></li> <li>Initial commit <code>e6f05b0</code></li> </ul>"},{"location":"external_content/device_settings/CONTRIBUTING/","title":"Contributing","text":"<ul> <li>If you wish to make code contributions to this project, the source is hosted at github.com/rdkcentral.</li> </ul> <p>You can submit your changes for review via that site, by raising an issue in github, (https://github.com/rdkcentral/xxxx/issues), and following the sequence below.</p> <ul> <li>create a branch with a name follow the guidelines gh(x)_(synopsis)</li> <li>where x is the ticket number</li> <li>where synopsis is a short synopsis for the reason for the branch.</li> <li>create a pull request (https://github.com/rdkcentral/xxxx/compare) when the code changes are ready for review.</li> <li> <p>The team will review, and if accepted your changes will be merged to the mainline.</p> </li> <li> <p>In order to contribute code, first-time users are requested to agree to the license.</p> </li> <li> <p>where <code>xxxx</code> is your module name</p> </li> </ul>"},{"location":"external_content/device_settings/docs/pages/","title":"Device Settings Module","text":""},{"location":"external_content/device_settings/docs/pages/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Acronyms, Terms and Abbreviations</li> <li>Description</li> <li>Device Settings Sub modules details</li> </ul>"},{"location":"external_content/device_settings/docs/pages/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>HPK</code> - Hardware Porting Kit</li> <li><code>HAL</code> - Hardware Abstraction Layer</li> <li><code>DS</code> - Device Settings</li> <li><code>NA</code> - Not Applicable</li> </ul>"},{"location":"external_content/device_settings/docs/pages/#description","title":"Description","text":"<p>This document provides the links for the specific sub-modules of the Device Settings.</p>"},{"location":"external_content/device_settings/docs/pages/#device-settings-sub-modules-details","title":"Device Settings Sub modules details","text":"SNo Sub-module Name <code>HAL</code> Specification Header File(s) Settings Template File 1 <code>DS</code> Host <code>DS</code> Host <code>HAL</code> Specification dsHost.h <code>NA</code> 2 <code>DS</code> Front Panel Display <code>DS</code> Front Panel Display <code>HAL</code> Specification dsFPD.h, dsFPDTypes.h frontPanelSettings_template.hpp 3 <code>DS</code> Display <code>DS</code> Display <code>HAL</code> Specification dsDisplay.h, dsAVDTypes.h <code>NA</code> 4 <code>DS</code> HDMI Input <code>DS</code> HDMI Input <code>HAL</code> Specification dsHdmiIn.h, dsHdmiInTypes.h <code>NA</code> 5 <code>DS</code> Composite Input <code>DS</code> Composite Input <code>HAL</code> Specification dsCompositeIn.h, dsCompositeInTypes.h <code>NA</code> 6 <code>DS</code> Audio <code>DS</code> Audio <code>HAL</code> Specification dsAudio.h, dsAVDTypes.h dsAudioSettings_template.h 7 <code>DS</code> Video Device <code>DS</code> Video Device <code>HAL</code> Specification dsVideoDevice.h, dsVideoDeviceTypes.h dsVideoDeviceSettings_template.h 8 <code>DS</code> Video Port <code>DS</code> Video Port <code>HAL</code> Specification dsVideoPort.h, dsAVDTypes.h dsVideoPortSettings_template.h, dsVideoResolutionSettings_template.h <p>For more information about Test suits and <code>HPK</code>,please check HPK repo</p>"},{"location":"external_content/device_settings/docs/pages/CONTRIBUTING/","title":"Contributing","text":"<ul> <li>If you wish to make code contributions to this project, the source is hosted at github.com/rdkcentral.</li> </ul> <p>You can submit your changes for review via that site, by raising an issue in github, (https://github.com/rdkcentral/xxxx/issues), and following the sequence below.</p> <ul> <li>create a branch with a name follow the guidelines gh(x)_(synopsis)</li> <li>where x is the ticket number</li> <li>where synopsis is a short synopsis for the reason for the branch.</li> <li>create a pull request (https://github.com/rdkcentral/xxxx/compare) when the code changes are ready for review.</li> <li> <p>The team will review, and if accepted your changes will be merged to the mainline.</p> </li> <li> <p>In order to contribute code, first-time users are requested to agree to the license.</p> </li> <li> <p>where <code>xxxx</code> is your module name</p> </li> </ul>"},{"location":"external_content/device_settings/docs/pages/ds-audio_halSpec/","title":"DEVICE SETTINGS AUDIO HAL Documentation","text":""},{"location":"external_content/device_settings/docs/pages/ds-audio_halSpec/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>DS</code>     - Device Settings</li> <li><code>HAL</code>    - Hardware Abstraction Layer</li> <li><code>API</code>    - Application Programming Interface</li> <li><code>Caller</code> - Any user of the interface via the <code>APIs</code></li> <li><code>CB</code>     - Callback function (suffix)</li> <li><code>ARC</code>    - Audio Return Channel</li> <li><code>eARC</code>   - Enhanced Audio Return Channel</li> <li><code>SPDIF</code>  - Sony/Philips Digital Interface</li> <li><code>HDMI</code>   - High-Definition Multimedia Interface</li> <li><code>LE</code>     - Loudness Equivalence</li> <li><code>DRC</code>    - Dynamic Range Control</li> <li><code>MI</code>     - Media Intelligent</li> <li><code>RF</code>     - Radio Frequency</li> <li><code>dB</code>     - Decibel</li> <li><code>MS12</code>   - MultiStream 12</li> <li><code>AC4</code>    - Audio Compression 4</li> <li><code>ms</code>     - milliseconds</li> <li><code>CPU</code>    - Central Processing Unit</li> <li><code>SoC</code>    - System-on-Chip</li> </ul>"},{"location":"external_content/device_settings/docs/pages/ds-audio_halSpec/#description","title":"Description","text":"<p>The diagram below describes a high-level software architecture of the <code>DS</code> Audio module.</p> <pre><code>%%{ init : { \"theme\" : \"forest\", \"flowchart\" : { \"curve\" : \"linear\" }}}%%\nflowchart TD\ny[Caller]&lt;--&gt;x[DEVICE SETTINGS AUDIO HAL];\nx[DEVICE SETTINGS AUDIO HAL]&lt;--&gt;z[Audio SoC Driver];\nstyle y fill:#99CCFF,stroke:#333,stroke-width:0.3px,align:left\nstyle z fill:#fcc,stroke:#333,stroke-width:0.3px,align:left\nstyle x fill:#9f9,stroke:#333,stroke-width:0.3px,align:left</code></pre> <p>This interface provides a set of <code>APIs</code> to facilitate communication to the Audio <code>SoC</code> Driver.</p> <p>This interface provides control to enable or disable Audio Output ports like TV Internal Speakers, <code>ARC</code>/<code>eARC</code>, Headphones, <code>SPDIF</code> and allows <code>caller</code> to configure or retrieve various audio parameters like audio encoding, audio compression, dialog enhancement, dolby volume mode, intelligent equalizer, volume leveller, bass enhancer, <code>DRC</code> mode, surround virtualizer, <code>MI</code> steering, graphic equalizer, <code>MS12</code> audio profile, stereo mode, audio gain, audio <code>dB</code>, audio level, audio max and min <code>dB</code>, audio delay, fader control, primary language and secondary language. It also provides <code>APIs</code> to  enable loop through, set audio ducking, enable <code>LE</code>, get the Atmos capability of sink device</p>"},{"location":"external_content/device_settings/docs/pages/ds-audio_halSpec/#component-runtime-execution-requirements","title":"Component Runtime Execution Requirements","text":"<p>The component must adeptly manage resources to prevent issues like memory leaks and excessive utilization. It must also meet performance goals for response time, throughput, and resource use as per the platform's capabilities.</p> <p>Failure to meet these requirements will likely result in undefined and unexpected behaviour.</p>"},{"location":"external_content/device_settings/docs/pages/ds-audio_halSpec/#initialization-and-startup","title":"Initialization and Startup","text":"<p><code>Caller</code> must initialize by calling <code>dsAudioPortInit()</code> before calling any other <code>APIs</code>. The <code>Caller</code> is expected to have complete control over the life cycle of the <code>DS</code> Audio module.</p>"},{"location":"external_content/device_settings/docs/pages/ds-audio_halSpec/#threading-model","title":"Threading Model","text":"<p>This interface is not required to be thread safe. Any <code>caller</code> invoking the <code>APIs</code> must ensure calls are made in a thread safe manner. This interface is allowed to create internal threads for its operations without excessively consuming system resources. Any threads created by this interface must be handled gracefully and respective error codes must be returned if any corresponding <code>API</code> fails.</p>"},{"location":"external_content/device_settings/docs/pages/ds-audio_halSpec/#process-model","title":"Process Model","text":"<p>This interface is required to support a single instantiation with a single process.</p>"},{"location":"external_content/device_settings/docs/pages/ds-audio_halSpec/#memory-model","title":"Memory Model","text":"<p>This interface is not required to allocate any memory. Any pointers created by the interface must be cleaned up upon termination.</p>"},{"location":"external_content/device_settings/docs/pages/ds-audio_halSpec/#power-management-requirements","title":"Power Management Requirements","text":"<p>Although this interface is not required to be involved in any of the power management operations, the state transitions must not affect its operation. e.g. on resumption from a low power state, the interface must operate as if no transition has occurred.</p>"},{"location":"external_content/device_settings/docs/pages/ds-audio_halSpec/#asynchronous-notification-model","title":"Asynchronous Notification Model","text":"<p>AudioPort provides the following asynchronous registration :</p> <ul> <li><code>dsAudioOutRegisterConnectCB()</code> - Callback function to notify the audio port connection status to the <code>caller</code></li> <li><code>dsAudioFormatUpdateRegisterCB()</code> - Callback function to notify the audio format update to the <code>caller</code></li> <li><code>dsAudioAtmosCapsChangeRegisterCB()</code> - Callback function to notify the atmos capability update to the <code>caller</code></li> </ul> <p>This interface is allowed to establish its own thread context for its operation, ensuring minimal impact on system resources. Additionally, this interface is responsible for releasing the resources it creates for its operation once the respective operation concludes.</p>"},{"location":"external_content/device_settings/docs/pages/ds-audio_halSpec/#blocking-calls","title":"Blocking calls","text":"<p>This interface is not required to have any blocking calls. Synchronous calls must complete within a reasonable time period. Any call that can fail due to the lack of response from the connected device must have a timeout period and the function must return the relevant error code.</p>"},{"location":"external_content/device_settings/docs/pages/ds-audio_halSpec/#internal-error-handling","title":"Internal Error Handling","text":"<p>All the <code>APIs</code> must return error synchronously as a return argument. <code>HAL</code> is responsible for handling system errors (e.g. out of memory) internally.</p>"},{"location":"external_content/device_settings/docs/pages/ds-audio_halSpec/#persistence-model","title":"Persistence Model","text":"<p>There is no requirement for the interface to persist any setting information. <code>Caller</code> is responsible to persist any settings related to this interface.</p>"},{"location":"external_content/device_settings/docs/pages/ds-audio_halSpec/#non-functional-requirements","title":"Non-functional requirements","text":"<p>The following non-functional requirements will be supported by the module.</p>"},{"location":"external_content/device_settings/docs/pages/ds-audio_halSpec/#logging-and-debugging-requirements","title":"Logging and debugging requirements","text":"<p>This interface is required to support DEBUG, INFO and ERROR messages. INFO and DEBUG should be disabled by default and enabled when required.</p>"},{"location":"external_content/device_settings/docs/pages/ds-audio_halSpec/#memory-and-performance-requirements","title":"Memory and performance requirements","text":"<p>This interface will ensure optimal use of memory and <code>CPU</code> according to the specific capabilities of the platform.</p>"},{"location":"external_content/device_settings/docs/pages/ds-audio_halSpec/#quality-control","title":"Quality Control","text":"<ul> <li>This interface is required to perform static analysis, our preferred tool is Coverity.</li> <li>Have a zero-warning policy with regards to compiling. All warnings are required to be treated as errors.</li> <li>Copyright validation is required to be performed, e.g.: Black duck, and FossID.</li> <li>Use of memory analysis tools like Valgrind are encouraged, to identify leaks/corruptions.</li> <li><code>HAL</code> Tests will endeavour to create worst case scenarios to assist investigations.</li> <li>Improvements by any party to the testing suite are required to be fed back.</li> </ul>"},{"location":"external_content/device_settings/docs/pages/ds-audio_halSpec/#licensing","title":"Licensing","text":"<p>The <code>HAL</code> implementation is expected to released under the Apache License 2.0.</p>"},{"location":"external_content/device_settings/docs/pages/ds-audio_halSpec/#build-requirements","title":"Build Requirements","text":"<p>The source code must build into a shared library for <code>DS</code> as Audio is a part of <code>DS</code> and must be named as libdshal.so. The build mechanism must be independent of Yocto.</p>"},{"location":"external_content/device_settings/docs/pages/ds-audio_halSpec/#variability-management","title":"Variability Management","text":"<ul> <li>Any changes in the <code>APIs</code> must be reviewed and approved by the component architects.</li> <li>Any modification must support backward compatibility for the generic operations like image upgrade and downgrade.</li> <li>This interface must return the dsERR_OPERATION_NOT_SUPPORTED error code, if any of the interface - <code>APIs</code> are not supported by the underlying hardware.</li> </ul>"},{"location":"external_content/device_settings/docs/pages/ds-audio_halSpec/#platform-or-product-customization","title":"Platform or Product Customization","text":"<p>The configuration settings file (dsAudioSettings_template.h) for <code>DS</code> Audio can be used for adding platform specific configurations. The sample file is available here.</p>"},{"location":"external_content/device_settings/docs/pages/ds-audio_halSpec/#interface-api-documentation","title":"Interface API Documentation","text":"<p><code>API</code> documentation will be provided by Doxygen which will be generated from the header file.</p>"},{"location":"external_content/device_settings/docs/pages/ds-audio_halSpec/#theory-of-operation-and-key-concepts","title":"Theory of operation and key concepts","text":"<p>The <code>caller</code> is expected to have complete control over the life cycle of the <code>HAL</code></p> <ol> <li> <p>Initialize the <code>DS</code> Audio <code>HAL</code> using function: <code>dsAudioPortInit()</code> before making any other <code>API</code> calls.  If <code>dsAudioPortInit()</code> call fails, the <code>HAL</code> must return the respective error code, so that the <code>caller</code> can retry the operation.</p> </li> <li> <p>Once the Audio Ports are initialized, Audio Output ports like TV Internal Speakers, <code>ARC</code>/<code>eARC</code>, Headphones, <code>SPDIF</code> can be enabled or disabled using Audio Port Handle based on Audio Settings Template.</p> </li> <li> <p>The following Audio functionalities are supported:</p> </li> <li>Audio Encoding</li> <li>Audio Format</li> <li>Audio Compression</li> <li>Dialog Enhancement</li> <li>Dolby Volume Mode</li> <li>Audio Ducking</li> <li>Bass Enhancer</li> <li><code>MI</code> Steering</li> <li><code>LE</code></li> <li>Stereo Mode</li> <li>Audio Gain</li> <li>Loop Through</li> <li>Intelligent Equivalizer</li> <li>Dynamic Range Control</li> <li>Fader Control</li> <li><code>MS12</code> capabilities</li> <li>Audio Delay</li> <li>Audio Mixing</li> <li><code>AC4</code> Primary Language</li> <li><code>AC4</code> Secondary Language</li> <li> <p>Audio Mixer Levels(Sink specific)</p> </li> <li> <p>Callbacks can be set with:</p> <ul> <li><code>dsAudioOutRegisterConnectCB()</code> -  used when the audio port connection status changes`</li> <li><code>dsAudioFormatUpdateRegisterCB()</code> -  used when the audio format changes</li> <li><code>dsAudioAtmosCapsChangeRegisterCB()</code> -  used when the atmos capability changes</li> </ul> </li> <li> <p>De-initialize the <code>Audio HAL</code> using the function: <code>dsAudioPortTerm()</code></p> </li> </ol> <p>NOTE: The module would operate deterministically if the above call sequence is followed</p>"},{"location":"external_content/device_settings/docs/pages/ds-audio_halSpec/#diagrams","title":"Diagrams","text":""},{"location":"external_content/device_settings/docs/pages/ds-audio_halSpec/#operational-call-sequence","title":"Operational Call Sequence","text":"<pre><code>%%{ init : { \"theme\" : \"default\", \"flowchart\" : { \"curve\" : \"stepBefore\" }}}%%\n   sequenceDiagram\n    participant Caller as Caller\n    participant HAL as DEVICE SETTINGS AUDIO HAL\n    participant Driver as SoC\n    Caller-&gt;&gt;HAL:dsAudioPortInit()\n    Note over HAL: SoC initializes the Audio Ports\n    HAL-&gt;&gt;Driver: Initializes the Audio Output Ports\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:dsGetAudioPort()\n    Note over HAL: API to get Audio Port Handle\n    HAL-&gt;&gt;Driver: Get the Audio Port handle\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:dsEnableAudioPort()\n    Note over HAL: API to enable or disable specified Audio Output Port\n    HAL-&gt;&gt;Driver:Specified Audio Port is enabled or disabled\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:dsAudio_SetMethods\n    Note over HAL: APIs to set the Audio related parameters\n    HAL-&gt;&gt;Driver: Set the Audio Paramters using Audio Port Handle\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:dsAudio_GetMethods\n    Note over HAL: APIs to get the Audio related parameters\n    HAL-&gt;&gt;Driver: Get the Audio Paramters using Audio Port Handle\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:dsSetAudioDucking()\n    Note over HAL: API to set the Audio Ducking level of specified Audio Port\n    HAL-&gt;&gt;Driver:Set the Audio Ducking Level of Specified Audio Output Port\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:dsEnableLoopThru()\n    Note over HAL: API to set loop-through mode of the specified audio port\n    HAL-&gt;&gt;Driver:Set the loop-through mode of Specified Audio Output Port\n    Caller-&gt;&gt;HAL:dsGetHDMIARCPortId()\n    Note over HAL: API to get HDMI ARC Port ID of each platform\n    HAL-&gt;&gt;Driver: Get the HDMI ARC Port ID\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:dsAudioOutRegisterConnectCB()\n    Note over HAL: Registers the callback for when the audio port connection status changes\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:dsAudioFormatUpdateRegisterCB()\n    Note over HAL: Registers the callback for when the audio format changes\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:dsAudioAtmosCapsChangeRegisterCB()\n    Note over HAL: Registers the callback for when the atmos capability changes\n    HAL--&gt;&gt;Caller:return\n    Note over HAL: Audio Port connection status changed\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:dsAudioOutPortConnectCB_t callback returned\n    Note over HAL: Audio formate has changed\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:dsAudioFormatUpdateCB_t callback returned\n    Note over HAL: Atmos capabilities changed\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:dsAtmosCapsChangeCB_t callback returned\n    Caller -&gt;&gt;HAL:dsAudioTerm()\n    HAL -&gt;&gt; Driver:dsAudioTerm()\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return</code></pre>"},{"location":"external_content/device_settings/docs/pages/ds-composite-in_halSpec/","title":"Device Settings CompositeIn HAL Documentation","text":""},{"location":"external_content/device_settings/docs/pages/ds-composite-in_halSpec/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>HAL</code>         - Hardware Abstraction Layer</li> <li><code>API</code>         - Caller Programming Interface</li> <li><code>Caller</code>      - Any user of the interface via the <code>APIs</code></li> <li><code>CPU</code>         - Central Processing Unit</li> <li><code>DS</code>          - Device Settings</li> <li><code>SoC</code>         - System on chip</li> <li><code>CompositeIn</code> - Composite Input</li> </ul>"},{"location":"external_content/device_settings/docs/pages/ds-composite-in_halSpec/#description","title":"Description","text":"<p>The diagram below describes a high-level software architecture of the CompositeIn stack.</p> <pre><code>%%{ init : { \"theme\" : \"forest\", \"flowchart\" : { \"curve\" : \"linear\" }}}%%\nflowchart TD\ny[Caller]&lt;--&gt;x[Device Settings COmpositeIn HAL];\nx[Device Settings CompositeIn HAL]&lt;--&gt;z[SOC Drivers];\nstyle y fill:#99CCFF,stroke:#333,stroke-width:0.3px,align:left\nstyle z fill:#fcc,stroke:#333,stroke-width:0.3px,align:left\nstyle x fill:#9f9,stroke:#333,stroke-width:0.3px,align:left</code></pre> <p>DS <code>CompositeIn</code> <code>HAL</code> provides a set of <code>APIs</code> to initialize, query and set information about the Composite input ports such as getting the number of input ports, getting the current status of a selected input port, setting the video scale, selecting which Composite input to be selected as active and registering callbacks for asynchronous notifications.</p>"},{"location":"external_content/device_settings/docs/pages/ds-composite-in_halSpec/#component-runtime-execution-requirements","title":"Component Runtime Execution Requirements","text":"<p>This interface must adeptly manage resources to prevent issues like memory leaks and excessive utilization. It must also meet performance goals for response time, throughput and resource use as per the platform's capabilities.</p> <p>Failure to meet these requirements will likely result in undefined and unexpected behavior.</p>"},{"location":"external_content/device_settings/docs/pages/ds-composite-in_halSpec/#initialization-and-startup","title":"Initialization and Startup","text":"<p><code>Caller</code> must initialize this interface by calling <code>dsCompositeInInit()</code> before calling any other <code>APIs</code>. The <code>caller</code> is expected to have complete control over the life cycle of this module.</p>"},{"location":"external_content/device_settings/docs/pages/ds-composite-in_halSpec/#threading-model","title":"Threading Model","text":"<p>This interface is not required to be thread safe. Any <code>caller</code> invoking the <code>APIs</code> must ensure calls are made in a thread safe manner. This interface is allowed to create internal threads for its operations without excessively consuming system resources. Any threads created by this interface must be handled gracefully and respective error codes must be returned if any corresponding <code>API</code> fails.</p>"},{"location":"external_content/device_settings/docs/pages/ds-composite-in_halSpec/#process-model","title":"Process Model","text":"<p>This interface is required to support a single instantiation with a single process.</p>"},{"location":"external_content/device_settings/docs/pages/ds-composite-in_halSpec/#memory-model","title":"Memory Model","text":"<p>This interface is not required to allocate any memory. Any pointers created by the interface must be cleaned up upon termination.</p>"},{"location":"external_content/device_settings/docs/pages/ds-composite-in_halSpec/#power-management-requirements","title":"Power Management Requirements","text":"<p>Although this interface is not required to be involved in any of the power management operations, the state transitions must not affect its operation. e.g. on resumption from a low power state, the interface must operate as if no transition has occurred.</p>"},{"location":"external_content/device_settings/docs/pages/ds-composite-in_halSpec/#asynchronous-notification-model","title":"Asynchronous Notification Model","text":"<p>This interface must support asynchronous notifications operations:</p> <ul> <li><code>dsCompositeInRegisterConnectCB()</code> must facilitate asynchronous status notifications using the callback when the connection status of the callback <code>dsCompositeInConnectCB_t</code>. This callback must be used when the connection status when the Composite input port changes.</li> <li><code>dsCompositeInRegisterSignalChangeCB()</code> must facilitate asynchronous status notifications using the callback <code>dsCompositeInSignalChangeCB_t</code>. This callback must be used when the Composite input signal status changes.</li> <li><code>dsCompositeInRegisterStatusChangeCB()</code> must facilitate asynchronous status notifications using the callback <code>dsCompositeInStatusChangeCB_t</code>. This callback must be used when the Composite input status changes.</li> <li><code>dsCompositeInRegisterVideoModeUpdateCB()</code> must facilitate asynchronous status notifications using the callback <code>dsCompositeInVideoModeUpdateCB_t</code>. This callback must be used when the Composite video mode changes.</li> </ul> <p>This interface is allowed to establish its own thread context for its operation, ensuring minimal impact on system resources. Additionally, this interface is responsible for releasing the resources it creates for its operation once the respective operation concludes.</p>"},{"location":"external_content/device_settings/docs/pages/ds-composite-in_halSpec/#blocking-calls","title":"Blocking calls","text":"<p>This interface is not required to have any blocking calls. Synchronous calls must complete within a reasonable time period.</p>"},{"location":"external_content/device_settings/docs/pages/ds-composite-in_halSpec/#internal-error-handling","title":"Internal Error Handling","text":"<p>The <code>API</code> must return error synchronously as a return argument. This interface is responsible for handling system errors (e.g. out of memory) internally.</p>"},{"location":"external_content/device_settings/docs/pages/ds-composite-in_halSpec/#persistence-model","title":"Persistence Model","text":"<p>There is no requirement for the interface to persist any setting information. <code>Caller</code> is responsible to persist any settings related to this interface.</p>"},{"location":"external_content/device_settings/docs/pages/ds-composite-in_halSpec/#non-functional-requirements","title":"Non-functional requirements","text":"<p>The following non-functional requirements will be supported by the module.</p>"},{"location":"external_content/device_settings/docs/pages/ds-composite-in_halSpec/#logging-and-debugging-requirements","title":"Logging and debugging requirements","text":"<p>This interface is required to support DEBUG, INFO and ERROR messages. INFO and DEBUG must be disabled by default and enabled when required.</p>"},{"location":"external_content/device_settings/docs/pages/ds-composite-in_halSpec/#memory-and-performance-requirements","title":"Memory and performance requirements","text":"<p>This interface will ensure optimal use of memory and <code>CPU</code> according to the specific capabilities of the platform.</p>"},{"location":"external_content/device_settings/docs/pages/ds-composite-in_halSpec/#quality-control","title":"Quality Control","text":"<ul> <li>This interface is required to perform static analysis, our preferred tool is Coverity.</li> <li>Have a zero-warning policy with regards to compiling. All warnings are required to be treated as errors.</li> <li>Copyright validation is required to be performed, e.g.: Black duck, and FossID.</li> <li>Use of memory analysis tools like Valgrind are encouraged to identify leaks/corruptions.</li> <li><code>HAL</code> Tests will endeavour to create worst case scenarios to assist investigations.</li> <li>Improvements by any party to the testing suite are required to be fed back.</li> </ul>"},{"location":"external_content/device_settings/docs/pages/ds-composite-in_halSpec/#licensing","title":"Licensing","text":"<p>The <code>HAL</code> implementation is expected to released under the Apache License 2.0.</p>"},{"location":"external_content/device_settings/docs/pages/ds-composite-in_halSpec/#build-requirements","title":"Build Requirements","text":"<p>The source code must build into a shared library for DS as <code>CompositeIn</code> module is a part of DS and must be named as <code>libdshal.so</code>. The build mechanism must be independent of Yocto.</p>"},{"location":"external_content/device_settings/docs/pages/ds-composite-in_halSpec/#variability-management","title":"Variability Management","text":"<ul> <li>Any changes in the <code>APIs</code> must be reviewed and approved by the component architects.</li> <li>Any modification must support backward compatibility for the generic operations like image upgrade and downgrade.</li> <li>This interface must return the dsERR_OPERATION_NOT_SUPPORTED error code, if any of the interface - <code>APIs</code> are not supported by the underlying hardware.</li> </ul>"},{"location":"external_content/device_settings/docs/pages/ds-composite-in_halSpec/#platform-or-product-customization","title":"Platform or Product Customization","text":"<p>This interface is not required to have any platform or product customizations.</p>"},{"location":"external_content/device_settings/docs/pages/ds-composite-in_halSpec/#interface-api-documentation","title":"Interface API Documentation","text":"<p><code>API</code> documentation will be provided by Doxygen which will be generated from the header file.</p>"},{"location":"external_content/device_settings/docs/pages/ds-composite-in_halSpec/#theory-of-operation-and-key-concepts","title":"Theory of operation and key concepts","text":"<p>The <code>caller</code> is expected to have complete control over the life cycle of the <code>HAL</code>.</p> <ol> <li> <p>Initialize the <code>HAL</code> <code>dsCompositeInInit()</code> before making any other <code>APIs</code> calls.  If <code>dsCompositeInInit()</code> call fails, the <code>HAL</code> must return the respective error code, so that the <code>caller</code> can retry the operation.</p> </li> <li> <p>The <code>caller</code> can call <code>dsCompositeInSelectPort()</code>, and <code>dsCompositeInScaleVideo()</code> to set the needed information.</p> </li> <li> <p>The <code>caller</code> can call <code>dsCompositeInGetNumberOfInputs()</code> and <code>dsCompositeInGetStatus()</code> to query the needed information.</p> </li> <li> <p>Callbacks can be set with:</p> <ul> <li><code>dsCompositeInRegisterConnectCB()</code> - used when the CompositeIn port connection status changes</li> <li><code>dsCompositeInRegisterSignalChangeCB()</code> - used when the CompositeIn signal status changes</li> <li><code>dsCompositeInRegisterStatusChangeCB()</code> - used when the CompositeIn input status changes</li> <li><code>dsCompositeInRegisterVideoModeUpdateCB()</code> - used when the CompositeIn video mode changes</li> </ul> </li> <li> <p>De-initialize the <code>HAL</code> using <code>dsCompositeInTerm()</code></p> </li> </ol>"},{"location":"external_content/device_settings/docs/pages/ds-composite-in_halSpec/#diagrams","title":"Diagrams","text":""},{"location":"external_content/device_settings/docs/pages/ds-composite-in_halSpec/#operational-call-sequence","title":"Operational Call Sequence","text":"<pre><code>%%{ init : { \"theme\" : \"default\", \"flowchart\" : { \"curve\" : \"stepBefore\" }}}%%\n   sequenceDiagram\n    participant Caller as Caller\n    participant HAL as DS CompositeIn HAL\n    participant Driver as SoC\n    Caller-&gt;&gt;HAL:dsCompositeInInit()\n    Note over HAL: SOC initializes the underlying subsystems\n    HAL-&gt;&gt;Driver:Initializes the underlying subsystems\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:dsCompositeInSelectPort()\n    Note over HAL: Sets the passed port as active and available for presentation\n    HAL-&gt;&gt;Driver:Setting the selected port as active\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:dsCompositeInGetStatus()\n    Note over HAL: Gets the status of the Composite Input ports\n    HAL-&gt;&gt;Driver:Getting the status of the Composite Input ports\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:dsCompositeInGetNumberOfInputs()\n    Note over HAL: Gets the number of Composite Input ports\n    HAL-&gt;&gt;Driver:Getting the number of Composite Input Ports\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:dsCompositeInScaleVideo()\n    Note over HAL: Sets the video scale\n    HAL-&gt;&gt;Driver:Setting the video scale\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:dsCompositeInRegisterConnectCB()\n    Note over HAL: Registers the callback for when the Composite Input connection status changes\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:dsCompositeInRegisterSignalChangeCB()\n    Note over HAL: Registers the callback for when the Composite in signal status changes\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:dsCompositeInRegisterStatusChangeCB()\n    Note over HAL: Registers the callback for when the Composite in status changes\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:dsCompositeInRegisterVideoModeUpdateCB()\n    Note over HAL: Registers the callback for when the CompositeIn video mode changes\n    HAL--&gt;&gt;Caller:return\n    Note over HAL: Composite Input hotplug connection has changed\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:dsCompositeInConnectCB_t callback returned\n    Note over HAL: Composite Input signal status changed\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:dsCompositeInSignalChangeCB_t callback returned\n    Note over HAL: The Composite Input status changed\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:dsCompositeInStatusChangeCB_t callback returned\n    Note over HAL: The Composite Input video mode changed\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:dsCompositeInVideoModeUpdateCB_t callback returned\n    Caller -&gt;&gt;HAL:dsCompositeInTerm()\n    Note over HAL: Terminates the underlying sub-systems\n    HAL-&gt;&gt;Driver:Terminates the underlying sub-systems\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return</code></pre>"},{"location":"external_content/device_settings/docs/pages/ds-display_halSpec/","title":"DEVICE SETTINGS Display HAL Documentation","text":""},{"location":"external_content/device_settings/docs/pages/ds-display_halSpec/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>API</code>     - Caller Programming Interface</li> <li><code>Caller</code>  - Any user of the interface via the <code>API</code></li> <li><code>DS</code>      - Device Settings</li> <li><code>HAL</code>     - Hardware Abstraction Layer</li> <li><code>HDMI</code>    - High-Definition Multimedia Interface</li> <li><code>DVI</code>     - Digital Visual Interface</li> <li><code>EDID</code>    - Extended Display Identification Data</li> <li><code>HDCP</code>    - High-bandwidth Digital Content Protection</li> <li><code>SoC</code>     - System on chip</li> </ul>"},{"location":"external_content/device_settings/docs/pages/ds-display_halSpec/#description","title":"Description","text":"<p>The diagram below describes a high-level software architecture of the <code>DS</code> Display module.</p> <pre><code>%%{ init : { \"theme\" : \"forest\", \"flowchart\" : { \"curve\" : \"linear\" }}}%%\nflowchart TD\ny[Caller]&lt;--&gt;x[Device Settings Display HAL];\nx[DS Display HAL]&lt;--&gt;z[SOC Drivers];\nstyle y fill:#99CCFF,stroke:#333,stroke-width:0.3px,align:left\nstyle z fill:#fcc,stroke:#333,stroke-width:0.3px,align:left\nstyle x fill:#9f9,stroke:#333,stroke-width:0.3px,align:left</code></pre> <p><code>DS</code> Display <code>HAL</code> provides a set of <code>APIs</code> to manage operations related to display devices connected to <code>HDMI</code> Output port of the source devices.</p> <p>The primary objective of this module is to streamline communication between the <code>caller</code> and the <code>HAL</code> interface. This allows the <code>caller</code> to inquire about information related to the <code>EDID</code>, Aspect Ratio and other <code>HDMI</code> related information of the connected display device. Additionally, the module notifies the <code>caller</code> about Display Device parameters, such as Device Connection/Disconnection, <code>HDCP</code> Protocol Changes, and RX Sense ON/OFF etc.</p>"},{"location":"external_content/device_settings/docs/pages/ds-display_halSpec/#component-runtime-execution-requirements","title":"Component Runtime Execution Requirements","text":"<p>This interface must adeptly manage resources to prevent issues like memory leaks and excessive utilization. It must also meet performance goals for response time, throughput, and resource use as per the platform's capabilities.</p> <p>Failure to meet these requirements will likely result in undefined and unexpected behavior.</p>"},{"location":"external_content/device_settings/docs/pages/ds-display_halSpec/#initialization-and-startup","title":"Initialization and Startup","text":"<p><code>Caller</code> must initialize this interface by calling <code>dsDisplayInit()</code> before calling any other API. The <code>caller</code> is expected to have complete control over the life cycle of the this module.</p>"},{"location":"external_content/device_settings/docs/pages/ds-display_halSpec/#threading-model","title":"Threading Model","text":"<p>This interface is not required to be thread safe. Any <code>caller</code> invoking the <code>APIs</code> must ensure calls are made in a thread safe manner. <code>HAL</code> is allowed to create internal threads for its operations without excessively consuming system resources. Any threads created by the <code>HAL</code> must be handled gracefully and respective error codes must be returned if any corresponding <code>API</code> fails.</p>"},{"location":"external_content/device_settings/docs/pages/ds-display_halSpec/#process-model","title":"Process Model","text":"<p>This interface is required to support a single instantiation with a single process.</p>"},{"location":"external_content/device_settings/docs/pages/ds-display_halSpec/#memory-model","title":"Memory Model","text":"<p>This interface is not required to allocate any memory. Any pointers created by the interface must be cleaned up upon termination.</p>"},{"location":"external_content/device_settings/docs/pages/ds-display_halSpec/#power-management-requirements","title":"Power Management Requirements","text":"<p>The <code>DS</code> Display <code>HAL</code> is not involved in the power management operation.</p>"},{"location":"external_content/device_settings/docs/pages/ds-display_halSpec/#asynchronous-notification-model","title":"Asynchronous Notification Model","text":"<p>The below mentioned callback registration is used for aysnchronous notification:</p> <ul> <li>dsDisplayEventCallback_t() - is triggered when there is a change in display related events like Device Connection/Disconnection, HDCP Protocol Changes, and RX Sense                                       ON/OFF</li> </ul>"},{"location":"external_content/device_settings/docs/pages/ds-display_halSpec/#blocking-calls","title":"Blocking calls","text":"<p>This interface is not required to have any blocking calls. Synchronous calls must complete within a reasonable time period.</p>"},{"location":"external_content/device_settings/docs/pages/ds-display_halSpec/#internal-error-handling","title":"Internal Error Handling","text":"<p>All the <code>APIs</code> must return error synchronously as a return argument. <code>HAL</code> is responsible for handling system errors (e.g. out of memory) internally.</p>"},{"location":"external_content/device_settings/docs/pages/ds-display_halSpec/#persistence-model","title":"Persistence Model","text":"<p>There is no requirement for the interface to persist any setting information. <code>Caller</code> is responsible to persist any settings related to the <code>HAL</code>.</p>"},{"location":"external_content/device_settings/docs/pages/ds-display_halSpec/#non-functional-requirements","title":"Non-functional requirements","text":"<p>The following non-functional requirements will be supported by the module:</p>"},{"location":"external_content/device_settings/docs/pages/ds-display_halSpec/#logging-and-debugging-requirements","title":"Logging and debugging requirements","text":"<p>This interface is required to support DEBUG, INFO and ERROR messages. INFO and DEBUG must be disabled by default and enabled when required.</p>"},{"location":"external_content/device_settings/docs/pages/ds-display_halSpec/#memory-and-performance-requirements","title":"Memory and performance requirements","text":"<p>This interface will ensure optimal use of memory and <code>CPU</code> according to the specific capabilities of the system.</p>"},{"location":"external_content/device_settings/docs/pages/ds-display_halSpec/#quality-control","title":"Quality Control","text":"<ul> <li>This interface is required to perform static analysis, our preferred tool is Coverity.</li> <li>Have a zero-warning policy with regards to compiling. All warnings are required to be treated as errors.</li> <li>Copyright validation is required to be performed, e.g.: Black duck, and FossID.</li> <li>Use of memory analysis tools like Valgrind are encouraged to identify leaks/corruptions.</li> <li><code>HAL</code> Tests will endeavour to create worst case scenarios to assist investigations.</li> <li>Improvements by any party to the testing suite are required to be fed back.</li> </ul>"},{"location":"external_content/device_settings/docs/pages/ds-display_halSpec/#licensing","title":"Licensing","text":"<p>The <code>HAL</code> implementation is expected to released under the Apache License 2.0.</p>"},{"location":"external_content/device_settings/docs/pages/ds-display_halSpec/#build-requirements","title":"Build Requirements","text":"<p>The source code must build into a shared library for Device Settings as this module is a part of Device Settings and must be named as <code>libdshal.so</code>. The build mechanism must be independent of Yocto.</p>"},{"location":"external_content/device_settings/docs/pages/ds-display_halSpec/#variability-management","title":"Variability Management","text":"<ul> <li>Any changes in the <code>APIs</code> must be reviewed and approved by the component architects.</li> <li><code>DS</code> Display <code>HAL</code> modification must support backward compatibility for the generic operations like image upgrade and downgrade.</li> <li>This interface must return the dsERR_OPERATION_NOT_SUPPORTED error code, if any of the interface - <code>APIs</code> are not supported by the underlying hardware.</li> </ul>"},{"location":"external_content/device_settings/docs/pages/ds-display_halSpec/#platform-or-product-customization","title":"Platform or Product Customization","text":"<p>This interface is not required to have any platform or product customizations.</p>"},{"location":"external_content/device_settings/docs/pages/ds-display_halSpec/#interface-api-documentation","title":"Interface API Documentation","text":"<p><code>API</code> documentation will be provided by Doxygen which will be generated from the header file.</p>"},{"location":"external_content/device_settings/docs/pages/ds-display_halSpec/#theory-of-operation-and-key-concepts","title":"Theory of operation and key concepts","text":"<p>The <code>caller</code> is expected to have complete control over the life cycle of the <code>HAL</code>.</p> <ol> <li> <p>Initialize the interface using: <code>dsDisplayInit()</code> before making any other <code>API</code> calls.  If <code>dsDisplayInit()</code> call fails, the <code>HAL</code> must return the respective error code, so that the <code>caller</code> can retry the operation.</p> </li> <li> <p>The <code>caller</code> can call <code>dsGetEDID()</code>, <code>dsGetDisplayAspectRatio()</code> and <code>dsGetEDIDBytes()</code> to query the information of connected display device. This interface is also used to notify <code>HDCP</code> Protocol changes of display device to the <code>caller</code>.</p> </li> <li> <p>De-initialize the HAL using <code>dsDisplayTerm()</code>.</p> </li> </ol>"},{"location":"external_content/device_settings/docs/pages/ds-display_halSpec/#diagrams","title":"Diagrams","text":""},{"location":"external_content/device_settings/docs/pages/ds-display_halSpec/#operational-call-sequence","title":"Operational Call Sequence","text":"<pre><code>%%{ init : { \"theme\" : \"default\", \"flowchart\" : { \"curve\" : \"stepBefore\" }}}%%\n   sequenceDiagram\n    participant Caller as Caller\n    participant HAL as DS DISPLAY HAL\n    participant Driver as SoC\n    Caller-&gt;&gt;HAL:dsDisplayInit()\n    Note over HAL: SoC initializes the underlying Display subsystem\n    HAL-&gt;&gt;Driver:Initializes Display sub-system &amp; associated data structures\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:dsGetDisplay()\n    Note over HAL: Returns the handle for connected display Device\n    HAL-&gt;&gt;Driver:Getting the handle for connected display device\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:dsGetEDID()\n    Note over HAL: Gets the EDID Information from connected display device\n    HAL-&gt;&gt;Driver:Getting the EDID Info from HDMI/DVI display device\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:dsGetDisplayAspectRatio()\n    Note over HAL: Gets the Aspect Ratio of connected display device\n    HAL-&gt;&gt;Driver:Getting the Aspect Ratio of display device\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    Caller -&gt;&gt;HAL:dsDisplayTerm()\n    HAL-&gt;&gt;Driver:Deallocates the associated data structures &amp; releases display specific handles\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return</code></pre>"},{"location":"external_content/device_settings/docs/pages/ds-front-panel-display_halSpec/","title":"Device Settings Front Panel Display HAL Documentation","text":""},{"location":"external_content/device_settings/docs/pages/ds-front-panel-display_halSpec/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>DS</code>     - Device Settings</li> <li><code>HAL</code>    - Hardware Abstraction Layer</li> <li><code>API</code>    - Application Programming Interface</li> <li><code>Caller</code> - Any user of the interface via the <code>APIs</code></li> <li><code>FPD</code>    - Front Panel Display</li> <li><code>LED</code>    - Light-Emitting Diode</li> <li><code>CPU</code>    - Central Processing Unit</li> <li><code>SoC</code>    - System-On-Chip</li> </ul>"},{"location":"external_content/device_settings/docs/pages/ds-front-panel-display_halSpec/#description","title":"Description","text":"<p>The diagram below describes a high-level software architecture of the <code>DS</code> Front Panel Display stack.</p> <pre><code>%%{ init : { \"theme\" : \"forest\", \"flowchart\" : { \"curve\" : \"linear\" }}}%%\nflowchart TD\ny[Caller]&lt;--&gt;x[DEVICE SETTINGS FRONT PANEL DISPLAY HAL];\nx[DEVICE SETTINGS FRONT PANEL DISPLAY HAL]&lt;--&gt;z[Front Panel SoC Driver];\nstyle y fill:#99CCFF,stroke:#333,stroke-width:0.3px,align:left\nstyle z fill:#fcc,stroke:#333,stroke-width:0.3px,align:left\nstyle x fill:#9f9,stroke:#333,stroke-width:0.3px,align:left</code></pre> <p>This interface provides a set of <code>APIs</code> to facilitate communication to Front Panel <code>LED</code> Display <code>SoC</code> Drivers.</p> <p>The brightness, color and text of Front Panel <code>LEDs</code> can be set or retrieved. This interface also provides <code>API</code> to enable or disable the specified discrete <code>LED</code> on the Front Panel Display.</p>"},{"location":"external_content/device_settings/docs/pages/ds-front-panel-display_halSpec/#component-runtime-execution-requirements","title":"Component Runtime Execution Requirements","text":"<p>This interface must adeptly manage resources to prevent issues like memory leaks and excessive utilization. It must also meet performance goals for response time, throughput, and resource use as per the platform's capabilities.</p> <p>Failure to meet these requirements will likely result in undefined and unexpected behavior.</p>"},{"location":"external_content/device_settings/docs/pages/ds-front-panel-display_halSpec/#initialization-and-startup","title":"Initialization and Startup","text":"<p><code>Caller</code> must initialize by calling <code>dsFPInit()</code> before calling any other <code>APIs</code>. <code>Caller</code> has complete control over the <code>FPD</code>.</p>"},{"location":"external_content/device_settings/docs/pages/ds-front-panel-display_halSpec/#threading-model","title":"Threading Model","text":"<p>This interface is not required to be thread safe. Any <code>caller</code> invoking the <code>APIs</code> must ensure calls are made in a thread safe manner.</p>"},{"location":"external_content/device_settings/docs/pages/ds-front-panel-display_halSpec/#process-model","title":"Process Model","text":"<p>This interface is required to support a single instantiation with a single process.</p>"},{"location":"external_content/device_settings/docs/pages/ds-front-panel-display_halSpec/#memory-model","title":"Memory Model","text":"<p>This interface is not required to allocate any memory.</p>"},{"location":"external_content/device_settings/docs/pages/ds-front-panel-display_halSpec/#power-management-requirements","title":"Power Management Requirements","text":"<p>The <code>FPD</code> <code>HAL</code> is not involved in the power management operation directly. However, the <code>caller</code> will initiate the change in <code>LED</code> as part of power management handling.</p> <p>The <code>caller</code> is responsible for driving <code>LED</code> status in accordance with power mode change.</p>"},{"location":"external_content/device_settings/docs/pages/ds-front-panel-display_halSpec/#asynchronous-notification-model","title":"Asynchronous Notification Model","text":"<p>This interface is not required to have any asynchronous notification.</p>"},{"location":"external_content/device_settings/docs/pages/ds-front-panel-display_halSpec/#blocking-calls","title":"Blocking calls","text":"<p>This interface is not required to have any blocking calls. Synchronous calls must complete within a reasonable time period. Any call that can fail due to the lack of response from the connected device must have a timeout period and the function must return the relevant error code.</p>"},{"location":"external_content/device_settings/docs/pages/ds-front-panel-display_halSpec/#internal-error-handling","title":"Internal Error Handling","text":"<p>All the <code>APIs</code> must return error synchronously as a return argument. <code>HAL</code> is responsible for handling system errors (e.g. out of memory) internally.</p>"},{"location":"external_content/device_settings/docs/pages/ds-front-panel-display_halSpec/#persistence-model","title":"Persistence Model","text":"<p>There is no requirement for the interface to persist any setting information. <code>Caller</code> is responsible to persist any settings related to the <code>HAL</code>.</p>"},{"location":"external_content/device_settings/docs/pages/ds-front-panel-display_halSpec/#non-functional-requirements","title":"Non-functional requirements","text":""},{"location":"external_content/device_settings/docs/pages/ds-front-panel-display_halSpec/#logging-and-debugging-requirements","title":"Logging and debugging requirements","text":"<p>This interface is required to support DEBUG, INFO and ERROR messages. INFO and DEBUG must be disabled by default and enabled when required.</p>"},{"location":"external_content/device_settings/docs/pages/ds-front-panel-display_halSpec/#memory-and-performance-requirements","title":"Memory and performance requirements","text":"<p>This interface is required to not cause excessive memory and <code>CPU</code> utilization.</p>"},{"location":"external_content/device_settings/docs/pages/ds-front-panel-display_halSpec/#quality-control","title":"Quality Control","text":"<ul> <li>This interface is required to perform static analysis, our preferred tool is Coverity.</li> <li>Have a zero-warning policy with regards to compiling. All warnings are required to be treated as errors.</li> <li>Copyright validation is required to be performed, e.g.: Black duck, and FossID.</li> <li>Use of memory analysis tools like Valgrind are encouraged to identify leaks/corruptions.</li> <li><code>HAL</code> Tests will endeavour to create worst case scenarios to assist investigations.</li> <li>Improvements by any party to the testing suite are required to be fed back.</li> </ul>"},{"location":"external_content/device_settings/docs/pages/ds-front-panel-display_halSpec/#licensing","title":"Licensing","text":"<p>The <code>HAL</code> implementation is expected to released under the Apache License 2.0.</p>"},{"location":"external_content/device_settings/docs/pages/ds-front-panel-display_halSpec/#build-requirements","title":"Build Requirements","text":"<p>The source code must build into a shared library for Device Settings <code>HAL</code> as <code>FPD</code> is a part of Device Settings and must be named as <code>libdshal.so</code>. The build mechanism must be independent of Yocto.</p>"},{"location":"external_content/device_settings/docs/pages/ds-front-panel-display_halSpec/#variability-management","title":"Variability Management","text":"<p>Any changes in the <code>APIs</code> must be reviewed and approved by the component architects. <code>DS</code> <code>FPD</code> must return the dsERR_OPERATION_NOT_SUPPORTED error code if any of the interface <code>APIs</code> are not supported by the underlying hardware.</p>"},{"location":"external_content/device_settings/docs/pages/ds-front-panel-display_halSpec/#platform-or-product-customization","title":"Platform or Product Customization","text":"<p>The configuration settings file (dsFPDSettings.h) for <code>DS</code> Front Panel can be used for adding platform specific configurations. The sample file is available here.</p>"},{"location":"external_content/device_settings/docs/pages/ds-front-panel-display_halSpec/#interface-api-documentation","title":"Interface API Documentation","text":"<p><code>API</code> documentation will be provided by Doxygen which will be generated from the header file.</p>"},{"location":"external_content/device_settings/docs/pages/ds-front-panel-display_halSpec/#theory-of-operation-and-key-concepts","title":"Theory of operation and key concepts","text":"<p>The <code>caller</code> is expected to have complete control over the life cycle of the <code>HAL</code>.</p> <ol> <li> <p>Initialize the <code>FPD</code> <code>HAL</code> using <code>dsFPInit()</code> before making any other <code>API</code> calls.  If the init call fails, the <code>HAL</code> must return the respective error code, so that the <code>caller</code> can retry the operation.</p> </li> <li> <p>Once the <code>FPD</code> sub-system is initialized, <code>caller</code> can invoke <code>APIs</code> to control the Front Panel <code>LEDs</code>. The <code>FP</code> brightness, text, color, blink interval, <code>FP</code> <code>LED</code> state(ON/OFF), text scroll can be set or retrieved.</p> </li> <li> <p>De-initialize the <code>FP</code> <code>HAL</code> using <code>dsFPTerm()</code>.</p> </li> </ol> <p>Note : The module would operate deterministically if the above call sequence is followed</p> <p>The various <code>DS</code> <code>FP</code> <code>LED</code> states are as follows:</p> <ul> <li>Active</li> <li>Standby</li> <li>Connecting to WPS</li> <li>Connected to WPS</li> <li>WPS Error</li> <li>Factory Reset</li> <li>USB Upgrade</li> <li>Software Download Error</li> </ul>"},{"location":"external_content/device_settings/docs/pages/ds-front-panel-display_halSpec/#diagrams","title":"Diagrams","text":""},{"location":"external_content/device_settings/docs/pages/ds-front-panel-display_halSpec/#operational-call-sequence","title":"Operational Call Sequence","text":"<pre><code>%%{ init : { \"theme\" : \"default\", \"flowchart\" : { \"curve\" : \"stepBefore\" }}}%%\n   sequenceDiagram\n    participant Caller as Caller\n    participant HAL as DS FPD HAL\n    participant Driver as SoC\n    Caller-&gt;&gt;HAL:dsFPInit()\n    Note over HAL: SoC initializes the FPD subsystem\n    HAL-&gt;&gt;Driver: Allocates required resources for FPD\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL: ds_FP_SetMethods\n    Note over HAL: APIs to set the FPD Parameters\n    HAL-&gt;&gt;Driver:Sets the FPD Parameters\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL: ds_FP_GetMethods\n    Note over HAL: APIs to get the FPD Parameters\n    HAL-&gt;&gt;Driver:Gets the FPD Parameters\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:dsEnableClockDisplay()\n    Note over HAL: API to enable or disable Clock Display on FP LED\n    HAL-&gt;&gt;Driver: Enables or Disables the clock display on the Front Panel LED\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    Caller -&gt;&gt;HAL:dsFPTerm()\n    HAL -&gt;&gt; Driver: Releases all the resources allocated during FPD init\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return</code></pre>"},{"location":"external_content/device_settings/docs/pages/ds-hdmi-in_halSpec/","title":"Device Settings HdmiIn HAL Documentation","text":""},{"location":"external_content/device_settings/docs/pages/ds-hdmi-in_halSpec/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>HAL</code>    - Hardware Abstraction Layer</li> <li><code>API</code>    - Caller Programming Interface</li> <li><code>Caller</code> - Any user of the interface via the <code>APIs</code></li> <li><code>CPU</code>    - Central Processing Unit</li> <li><code>DS</code>     - Device Settings</li> <li><code>HAL</code>    - Hardware Abstraction Layer</li> <li><code>EDID</code>   - Extended Display Information Data</li> <li><code>CPU</code>    - Central Processing Unit</li> <li><code>SoC</code>    - System on chip</li> <li><code>AV</code>     - Audio-Visual</li> <li><code>HDMI</code>   - High-Definition Multimedia Interface</li> <li><code>SPD</code>    - Source Product Description.</li> <li><code>HdmiIn</code> - HDMI Input</li> <li><code>ALLM</code>   - Auto Low Latency Mode</li> </ul>"},{"location":"external_content/device_settings/docs/pages/ds-hdmi-in_halSpec/#description","title":"Description","text":"<p>The diagram below describes a high-level software architecture of the HdmiIn stack.</p> <pre><code>%%{ init : { \"theme\" : \"forest\", \"flowchart\" : { \"curve\" : \"linear\" }}}%%\nflowchart TD\ny[Caller]&lt;--&gt;x[Device Settings HdmiIn HAL];\nx[Device Settings HdmiIn HAL]&lt;--&gt;z[SOC Drivers];\nstyle y fill:#99CCFF,stroke:#333,stroke-width:0.3px,align:left\nstyle z fill:#fcc,stroke:#333,stroke-width:0.3px,align:left\nstyle x fill:#9f9,stroke:#333,stroke-width:0.3px,align:left</code></pre> <p>DS <code>HdmiIn</code> <code>HAL</code> provides a set of <code>APIs</code> to initialize, query and set information about the HDMI input ports such as getting the number of input ports, getting the current status of a selected input port, setting the video scale, selecting which HDMI input to be selected as active and registering callbacks for asynchronous notifications.</p>"},{"location":"external_content/device_settings/docs/pages/ds-hdmi-in_halSpec/#component-runtime-execution-requirements","title":"Component Runtime Execution Requirements","text":"<p>The component must adeptly manage resources to prevent issues like memory leaks and excessive utilization. It must also meet performance goals for response time, throughput and resource use as per the platform's capabilities.</p> <p>Failure to meet these requirements will likely result in undefined and unexpected behavior.</p>"},{"location":"external_content/device_settings/docs/pages/ds-hdmi-in_halSpec/#initialization-and-startup","title":"Initialization and Startup","text":"<p><code>Caller</code> must initialize this interface by calling <code>dsHdmiInInit()</code> before calling any other <code>APIs</code>. The <code>caller</code> is expected to have complete control over the life cycle of this module.</p>"},{"location":"external_content/device_settings/docs/pages/ds-hdmi-in_halSpec/#threading-model","title":"Threading Model","text":"<p>This interface is not required to be thread safe. Any <code>caller</code> invoking the <code>APIs</code> must ensure calls are made in a thread safe manner. This interface is allowed to create internal threads for its operations without excessively consuming system resources. Any threads created by this interface must be handled gracefully and respective error codes must be returned if any corresponding <code>API</code> fails.</p>"},{"location":"external_content/device_settings/docs/pages/ds-hdmi-in_halSpec/#process-model","title":"Process Model","text":"<p>This interface is required to support a single instantiation with a single process.</p>"},{"location":"external_content/device_settings/docs/pages/ds-hdmi-in_halSpec/#memory-model","title":"Memory Model","text":"<p>This interface is not required to allocate any memory. Any pointers created by the interface must be cleaned up upon termination.</p>"},{"location":"external_content/device_settings/docs/pages/ds-hdmi-in_halSpec/#power-management-requirements","title":"Power Management Requirements","text":"<p>Although this interface is not required to be involved in any of the power management operations, the state transitions must not affect its operation. e.g. on resumption from a low power state, the interface must operate as if no transition has occurred.</p>"},{"location":"external_content/device_settings/docs/pages/ds-hdmi-in_halSpec/#asynchronous-notification-model","title":"Asynchronous Notification Model","text":"<p>This interface must support asynchronous notifications operations:</p> <ul> <li><code>dsHdmiInRegisterConnectCB()</code> must facilitate asynchronous status notifications using the callback when the connection status of the callback <code>dsHdmiInConnectCB_t</code>. This callback must be used when the connection status when the HDMI input port changes.</li> <li><code>dsHdmiInRegisterSignalChangeCB()</code> must facilitate asynchronous status notifications using the callback <code>dsHdmiInSignalChangeCB_t</code>. This callback must be used when the signal status changes.</li> <li><code>dsHdmiInRegisterStatusChangeCB()</code> must facilitate asynchronous status notifications using the callback <code>dsHdmiInStatusChangeCB_t</code>. This callback must be used when the HDMI input status changes.</li> <li><code>dsHdmiInRegisterVideoModeUpdateCB()</code> must facilitate asynchronous status notifications using the callback <code>dsHdmiInVideoModeUpdateCB_t</code>. This callback must be used when the video mode changes. This callback must be used when the ALLM mode changes.</li> <li><code>dsHdmiInRegisterAllmChangeCB()</code> must facilitate asynchronous status notifications using the callback <code>dsHdmiInAllmChangeCB_t</code>.</li> <li><code>dsHdmiInRegisterAVLatencyChangeCB()</code> must facilitate asynchronous notifications using the callback <code>dsAVLatencyChangeCB_t</code> when the AV latency changes.</li> <li><code>dsHdmiInRegisterAviContentTypeChangeCB()</code> must facilitate asynchronous notifications using the call back <code>dsHdmiInAviContentTypeChangeCB_t</code> when HDMI input content type changes.</li> </ul> <p>This interface is allowed to establish its own thread context for its operation, ensuring minimal impact on system resources. Additionally, this interface is responsible for releasing the resources it creates for its operation once the respective operation concludes.</p>"},{"location":"external_content/device_settings/docs/pages/ds-hdmi-in_halSpec/#blocking-calls","title":"Blocking calls","text":"<p>This interface is not required to have any blocking calls. Synchronous calls must complete within a reasonable time period.</p>"},{"location":"external_content/device_settings/docs/pages/ds-hdmi-in_halSpec/#internal-error-handling","title":"Internal Error Handling","text":"<p>The <code>API</code> must return error synchronously as a return argument. This interface is responsible for handling system errors (e.g. out of memory) internally.</p>"},{"location":"external_content/device_settings/docs/pages/ds-hdmi-in_halSpec/#persistence-model","title":"Persistence Model","text":"<p>There is no requirement for the interface to persist any setting information. <code>Caller</code> is responsible to persist any settings related to this interface.</p>"},{"location":"external_content/device_settings/docs/pages/ds-hdmi-in_halSpec/#non-functional-requirements","title":"Non-functional requirements","text":"<p>The following non-functional requirements will be supported by the module.</p>"},{"location":"external_content/device_settings/docs/pages/ds-hdmi-in_halSpec/#logging-and-debugging-requirements","title":"Logging and debugging requirements","text":"<p>This interface is required to support DEBUG, INFO and ERROR messages. INFO and DEBUG must be disabled by default and enabled when required.</p>"},{"location":"external_content/device_settings/docs/pages/ds-hdmi-in_halSpec/#memory-and-performance-requirements","title":"Memory and performance requirements","text":"<p>This interface will ensure optimal use of memory and <code>CPU</code> according to the specific capabilities of the platform.</p>"},{"location":"external_content/device_settings/docs/pages/ds-hdmi-in_halSpec/#quality-control","title":"Quality Control","text":"<ul> <li>This interface is required to perform static analysis, our preferred tool is Coverity.</li> <li>Have a zero-warning policy with regards to compiling. All warnings are required to be treated as errors.</li> <li>Copyright validation is required to be performed, e.g.: Black duck, and FossID.</li> <li>Use of memory analysis tools like Valgrind are encouraged to identify leaks/corruptions.</li> <li><code>HAL</code> Tests will endeavour to create worst case scenarios to assist investigations.</li> <li>Improvements by any party to the testing suite are required to be fed back.</li> </ul>"},{"location":"external_content/device_settings/docs/pages/ds-hdmi-in_halSpec/#licensing","title":"Licensing","text":"<p>The <code>HAL</code> implementation is expected to released under the Apache License 2.0.</p>"},{"location":"external_content/device_settings/docs/pages/ds-hdmi-in_halSpec/#build-requirements","title":"Build Requirements","text":"<p>The source code must build into a shared library for DS as <code>HdmiIn</code> module is a part of DS and must be named as <code>libdshal.so</code>. The build mechanism must be independent of Yocto.</p>"},{"location":"external_content/device_settings/docs/pages/ds-hdmi-in_halSpec/#variability-management","title":"Variability Management","text":"<ul> <li>Any changes in the <code>APIs</code> must be reviewed and approved by the component architects.</li> <li>Any modification must support backward compatibility for the generic operations like image upgrade and downgrade.</li> <li>This interface must return the dsERR_OPERATION_NOT_SUPPORTED error code, if any of the interface - <code>APIs</code> are not supported by the underlying hardware.</li> </ul>"},{"location":"external_content/device_settings/docs/pages/ds-hdmi-in_halSpec/#platform-or-product-customization","title":"Platform or Product Customization","text":"<p>This interface is not required to have any platform or product customizations.</p>"},{"location":"external_content/device_settings/docs/pages/ds-hdmi-in_halSpec/#interface-api-documentation","title":"Interface API Documentation","text":"<p><code>API</code> documentation will be provided by Doxygen which will be generated from the header file.</p>"},{"location":"external_content/device_settings/docs/pages/ds-hdmi-in_halSpec/#theory-of-operation-and-key-concepts","title":"Theory of operation and key concepts","text":"<p>The <code>caller</code> is expected to have complete control over the life cycle of the <code>HAL</code>.</p> <ol> <li> <p>Initialize the <code>HAL</code> <code>dsHdmiInInit()</code> before making any other <code>APIs</code> calls.  If <code>dsHdmiInInit()</code> call fails, the <code>HAL</code> must return the respective error code, so that the <code>caller</code> can retry the operation.</p> </li> <li> <p>The <code>caller</code> can call <code>dsHdmiInSelectPort()</code>, <code>dsHdmiInScaleVideo()</code>, <code>dsSetEdidVersion()</code> and <code>dsHdmiInSelectZoomMode()</code> to set the needed information.</p> </li> <li> <p>The <code>caller</code> can call <code>dsHdmiInGetNumberOfInputs()</code>, <code>dsHdmiInGetStatus()</code>, <code>dsGetEDIDBytesInfo()</code>, <code>dsIsHdmiARCPort()</code>, <code>dsGetHDMISPDInfo()</code>,  <code>dsGetEdidVersion()</code>, <code>dsGetAllmStatus()</code>, <code>dsGetSupportedGameFeaturesList()</code>, <code>dsGetAVLatency()</code> and <code>dsHdmiInGetCurrentVideoMode()</code> to query the needed information.</p> </li> <li> <p>Callbacks can be set with:</p> <ul> <li><code>dsHdmiInRegisterConnectCB()</code> - used when the HDMIin port connection status changes</li> <li><code>dsHdmiInRegisterSignalChangeCB()</code> - used when the HDMIin signal status changes</li> <li><code>dsHdmiInRegisterStatusChangeCB()</code> - used when the HDMI input status changes</li> <li><code>dsHdmiInRegisterVideoModeUpdateCB()</code> - used when the HDMIin video mode changes</li> <li><code>dsHdmiInRegisterAllmChangeCB()</code> - used when the HDMI input ALLM mode changes</li> <li><code>dsHdmiInRegisterAVLatencyChangeCB()</code> - used when the AV latency changes</li> <li><code>dsHdmiInRegisterAviContentTypeChangeCB()</code> - used when the Avi Content type changes</li> </ul> </li> <li> <p>De-initialize the <code>HAL</code> using <code>dsHdmiInTerm()</code></p> </li> </ol>"},{"location":"external_content/device_settings/docs/pages/ds-hdmi-in_halSpec/#diagrams","title":"Diagrams","text":""},{"location":"external_content/device_settings/docs/pages/ds-hdmi-in_halSpec/#operational-call-sequence","title":"Operational Call Sequence","text":"<pre><code>%%{ init : { \"theme\" : \"default\", \"flowchart\" : { \"curve\" : \"stepBefore\" }}}%%\n   sequenceDiagram\n    participant Caller as Caller\n    participant HAL as DS HdmiIn HAL\n    participant Driver as SoC\n    Caller-&gt;&gt;HAL:dsHdmiInInit()\n    Note over HAL: SOC initializes the underlying subsystems\n    HAL-&gt;&gt;Driver:Initializes the underlying subsystems.\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:dsHdmiInSelectPort()\n    Note over HAL: Sets the passed port as active and available for presentation\n    HAL-&gt;&gt;Driver:Setting the selected port as active\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:dsHdmiInGetStatus()\n    Note over HAL: Gets the status of the current port\n    HAL-&gt;&gt;Driver:Getting the status of the current port\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:dsHdmiInScaleVideo()\n    Note over HAL: Sets the video scale\n    HAL-&gt;&gt;Driver:Setting the video scale\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:dsGetEDIDBytesInfo()\n    Note over HAL: Gets the EDID Bytes info\n    HAL-&gt;&gt;Driver:Getting the EDID Bytes info\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:dsHdmiInGetNumberOfInputs()\n    Note over HAL: Gets the number of HDMI inputs\n    HAL-&gt;&gt;Driver:Getting the number of HDMI inputs\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:dsHdmiInGetCurrentVideoMode()\n    Note over HAL: Gets the current video mode\n    HAL-&gt;&gt;Driver:Getting the current video mode\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:dsSetEdidVersion()\n    Note over HAL: Sets the EDID version\n    HAL-&gt;&gt;Driver:Sets the EDID version\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:dsGetEdidVersion()\n    Note over HAL: Gets the current EDID Version\n    HAL-&gt;&gt;Driver:Getting the current EDID Version\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:dsGetAllmStatus()\n    Note over HAL: Gets the ALLM status\n    HAL-&gt;&gt;Driver:Getting the ALLM status\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:dsGetSupportedGameFeaturesList()\n    Note over HAL: Gets the supported game features\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:dsIsHdmiARCPort()\n    Note over HAL: Gets whether the specified HDMI input port supports ARC\n    HAL-&gt;&gt;Driver:Getting whether the specified HDMI input port supports ARC\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:dsGetHDMISPDInfo()\n    Note over HAL: Gets the HDMI SPD info\n    HAL-&gt;&gt;Driver:Getting the HDMI SPD info\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:dsHdmiInSelectZoomMode()\n    Note over HAL: Sets the zoom mode\n    HAL-&gt;&gt;Driver:Setting the zoom mode\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:dsGetAVLatency()\n    Note over HAL: Gets the AV latency\n    HAL-&gt;&gt;Driver:Getting the AV latency\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:dsHdmiInRegisterConnectCB()\n    Note over HAL: Creates the callback for when the HDMI connection status changes.\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:dsHdmiInRegisterSignalChangeCB()\n    Note over HAL: Creates the callback for when the HDMI in signal status changes.\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:dsHdmiInRegisterStatusChangeCB()\n    Note over HAL: Creates the callback for when the HDMI in status changes.\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:dsHdmiInRegisterVideoModeUpdateCB()\n    Note over HAL: Creates the callback for when the video mode changes.\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:dsHdmiInRegisterAllmChangeCB()\n    Note over HAL: Creates the callback for when the ALLM mode changes.\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:dsHdmiInRegisterAVLatencyChangeCB()\n    Note over HAL: Creates the callback for when the AV latency changes.\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:dsHdmiInRegisterAviContentTypeChangeCB()\n    Note over HAL: Creates the callback for when the Avi Content type changes.\n    HAL--&gt;&gt;Caller:return\n    Note over HAL: HDMI Input connection status changed\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:dsHdmiInConnectCB_t callback returned\n    Note over HAL: The HDMI Input signal status changed\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:dsHdmiInSignalChangeCB_t callback returned\n    Note over HAL: HDMI Input status changed\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:dsHdmiInStatusChangeCB_t callback returned\n    Note over HAL: Hdmi Input video mode changed\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:dsHdmiInVideoModeUpdateCB_t callback returned\n    Note over HAL: HDMI Input mode changed\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:dsHdmiInAllmChangeCB_t callback returned\n    Note over HAL: AV latency changed\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:dsAVLatencyChangeCB_t callback returned\n    Note over HAL: Avi content type changed\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:dsHdmiInAviContentTypeChangeCB_t callback returned\n    Caller -&gt;&gt;HAL:dsHdmiInTerm()\n    Note over HAL: Terminates the underlying sub-systems\n    HAL-&gt;&gt;Driver:Terminates the underlying sub-systems\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return</code></pre>"},{"location":"external_content/device_settings/docs/pages/ds-hdmi-in_halSpec/#flow-diagram","title":"Flow Diagram","text":"<pre><code>stateDiagram-v2\nHDPI : HDMI Device Plugged In(Hotplug Callback)\nHSP : HDMI Select Port(from user)\nDS : DefaultSignal\nNSiG : No Signal (Signal Change Callback called if port is not connected)\nUS : Unstable (Signal Change Callback call if connection doesnot stabilize)\nNS : Not supported(signal change callback)\nStable : Stable(signal change callback)\nHDPS : HDMI port started(status change callback)\n\nHDPI --&gt; HSP\nHSP --&gt; DS : Starting at default signal\nDS --&gt; NSiG\nStable --&gt; HDPS\nNSiG --&gt; US : Port connected but unstable signal\nUS --&gt; NS : Connection stabilized but connection not supported\nUS --&gt; Stable : Connection stabilized\nNSiG --&gt; NSiG : No Port Connected\nUS --&gt; US : connection still unstable</code></pre>"},{"location":"external_content/device_settings/docs/pages/ds-host_halSpec/","title":"Device Settings Host HAL Documentation","text":""},{"location":"external_content/device_settings/docs/pages/ds-host_halSpec/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>HAL</code>    - Hardware Abstraction Layer</li> <li><code>API</code>    - Caller Programming Interface</li> <li><code>Caller</code> - Any user of the interface via the <code>API</code></li> <li><code>CPU</code>    - Central Processing Unit</li> <li><code>DS</code>     - Device Settings</li> <li><code>HAL</code>    - Hardware Abstraction Layer</li> <li><code>EDID</code>   - Extended Display Information Data</li> <li><code>CPU</code>    - Central Processing Unit</li> <li><code>SoC</code>    - System on chip</li> </ul>"},{"location":"external_content/device_settings/docs/pages/ds-host_halSpec/#description","title":"Description","text":"<p>The diagram below describes a high-level software architecture of the Device Settings Host module.</p> <pre><code>%%{ init : { \"theme\" : \"forest\", \"flowchart\" : { \"curve\" : \"linear\" }}}%%\nflowchart TD\ny[Caller]&lt;--&gt;x[Device Settings HOST HAL];\nx[Device Settings HOST HAL]&lt;--&gt;z[SOC Drivers];\nstyle y fill:#99CCFF,stroke:#333,stroke-width:0.3px,align:left\nstyle z fill:#fcc,stroke:#333,stroke-width:0.3px,align:left\nstyle x fill:#9f9,stroke:#333,stroke-width:0.3px,align:left</code></pre> <p><code>Device Settings Host</code> <code>HAL</code> provides a set of <code>APIs</code> to initialize, query information about the <code>SoC</code>.</p> <p>The main purpose of this module is to facilitate communication between the <code>caller</code>, and <code>HAL</code> interface, such that information about the Host EDID number, the current CPU temperature, and the SoC ID can be queried by the <code>caller</code>.</p>"},{"location":"external_content/device_settings/docs/pages/ds-host_halSpec/#component-runtime-execution-requirements","title":"Component Runtime Execution Requirements","text":"<p>This interface  must adeptly manage resources to prevent issues like memory leaks and excessive utilization. It must also meet performance goals for response time, throughput, and resource use as per the platform's capabilities.</p> <p>Failure to meet these requirements will likely result in undefined and unexpected behavior.</p>"},{"location":"external_content/device_settings/docs/pages/ds-host_halSpec/#initialization-and-startup","title":"Initialization and Startup","text":"<p><code>Caller</code> must initialize <code>dsHost</code> by calling <code>dsHostInit()</code> before calling any other <code>APIs</code>. The <code>caller</code> is expected to have complete control over the life cycle of the this module.</p>"},{"location":"external_content/device_settings/docs/pages/ds-host_halSpec/#threading-model","title":"Threading Model","text":"<p>This interface is not required to be thread safe. Any <code>caller</code> invoking the <code>APIs</code> must ensure calls are made in a thread safe manner. <code>HAL</code> is allowed to create internal threads for its operations without excessively consuming system resources. Any threads created by the <code>HAL</code> must be handled gracefully and respective error codes must be returned if any corresponding <code>API</code> fails.</p>"},{"location":"external_content/device_settings/docs/pages/ds-host_halSpec/#process-model","title":"Process Model","text":"<p>This interface is required to support a single instantiation with a single process.</p>"},{"location":"external_content/device_settings/docs/pages/ds-host_halSpec/#memory-model","title":"Memory Model","text":"<p>This interface is not required to allocate any memory. Any pointers created by the interface must be cleaned up upon termination.</p>"},{"location":"external_content/device_settings/docs/pages/ds-host_halSpec/#power-management-requirements","title":"Power Management Requirements","text":"<p>Although this interface is not required to be involved in any of the power management operations, the state transitions must not affect its operation. e.g. on resumption from a low power state, the interface must operate as if no transition has occurred.</p>"},{"location":"external_content/device_settings/docs/pages/ds-host_halSpec/#asynchronous-notification-model","title":"Asynchronous Notification Model","text":"<p>This interface is not required to support asynchronous notification.</p>"},{"location":"external_content/device_settings/docs/pages/ds-host_halSpec/#blocking-calls","title":"Blocking calls","text":"<p>This interface is not required to have any blocking calls. Synchronous calls must complete within a reasonable time period.</p>"},{"location":"external_content/device_settings/docs/pages/ds-host_halSpec/#internal-error-handling","title":"Internal Error Handling","text":"<p>All the <code>APIs</code> must return error synchronously as a return argument. <code>HAL</code> is responsible for handling system errors (e.g. out of memory) internally.</p>"},{"location":"external_content/device_settings/docs/pages/ds-host_halSpec/#persistence-model","title":"Persistence Model","text":"<p>There is no requirement for the interface to persist any setting information. <code>Caller</code> is responsible to persist any settings related to the <code>HAL</code>.</p>"},{"location":"external_content/device_settings/docs/pages/ds-host_halSpec/#non-functional-requirements","title":"Non-functional requirements","text":"<p>The following non-functional requirements will be supported by the module:</p>"},{"location":"external_content/device_settings/docs/pages/ds-host_halSpec/#logging-and-debugging-requirements","title":"Logging and debugging requirements","text":"<p>This interface is required to support DEBUG, INFO and ERROR messages. INFO and DEBUG must be disabled by default and enabled when required.</p>"},{"location":"external_content/device_settings/docs/pages/ds-host_halSpec/#memory-and-performance-requirements","title":"Memory and performance requirements","text":"<p>This interface will ensure optimal use of memory and <code>CPU</code> according to the specific capabilities of the system.</p>"},{"location":"external_content/device_settings/docs/pages/ds-host_halSpec/#quality-control","title":"Quality Control","text":"<ul> <li>This interface is required to perform static analysis, our preferred tool is Coverity.</li> <li>Have a zero-warning policy with regards to compiling. All warnings are required to be treated as errors.</li> <li>Copyright validation is required to be performed, e.g.: Black duck, and FossID.</li> <li>Use of memory analysis tools like Valgrind are encouraged to identify leaks/corruptions.</li> <li><code>HAL</code> Tests will endeavour to create worst case scenarios to assist investigations.</li> <li>Improvements by any party to the testing suite are required to be fed back.</li> </ul>"},{"location":"external_content/device_settings/docs/pages/ds-host_halSpec/#licensing","title":"Licensing","text":"<p>The <code>HAL</code> implementation is expected to released under the Apache License 2.0.</p>"},{"location":"external_content/device_settings/docs/pages/ds-host_halSpec/#build-requirements","title":"Build Requirements","text":"<p>The source code must build into a shared library for Device Settings as this module is a part of Device Settings and must be named as <code>libdshal.so</code>. The build mechanism must be independent of Yocto.</p>"},{"location":"external_content/device_settings/docs/pages/ds-host_halSpec/#variability-management","title":"Variability Management","text":"<ul> <li>Any changes in the <code>APIs</code> must be reviewed and approved by the component architects.</li> <li><code>DeviceSettings Host</code> <code>HAL</code> modification must support backward compatibility for the generic operations like image upgrade and downgrade.</li> <li>This interface must return the dsERR_OPERATION_NOT_SUPPORTED error code, if any of the interface - <code>APIs</code> are not supported by the underlying hardware.</li> </ul>"},{"location":"external_content/device_settings/docs/pages/ds-host_halSpec/#platform-or-product-customization","title":"Platform or Product Customization","text":"<p>This interface is not required to have any platform or product customizations.</p>"},{"location":"external_content/device_settings/docs/pages/ds-host_halSpec/#interface-api-documentation","title":"Interface API Documentation","text":"<p><code>API</code> documentation will be provided by Doxygen which will be generated from the header file.</p>"},{"location":"external_content/device_settings/docs/pages/ds-host_halSpec/#theory-of-operation-and-key-concepts","title":"Theory of operation and key concepts","text":"<p>The <code>caller</code> is expected to have complete control over the life cycle of the <code>HAL</code>.</p> <ol> <li> <p>Initialize the <code>HAL</code> using function: <code>dsHostInit()</code> before making any other <code>API</code> calls.  If <code>dsHostInit()</code> call fails, the <code>HAL</code> must return the respective error code, so that the <code>caller</code> can retry the operation.</p> </li> <li> <p>The <code>caller</code> can call <code>dsGetCPUTemperature()</code>, <code>dsGetHostEDID()</code> and <code>dsGetSocIDFromSDK()</code> to query the needed information.</p> </li> <li> <p>De-initialized the <code>HAL</code> using the function: <code>dsHostTerm()</code></p> </li> </ol>"},{"location":"external_content/device_settings/docs/pages/ds-host_halSpec/#diagrams","title":"Diagrams","text":""},{"location":"external_content/device_settings/docs/pages/ds-host_halSpec/#operational-call-sequence","title":"Operational Call Sequence","text":"<pre><code>%%{ init : { \"theme\" : \"default\", \"flowchart\" : { \"curve\" : \"stepBefore\" }}}%%\n   sequenceDiagram\n    participant Caller as Caller\n    participant HAL as DS HOST HAL\n    participant Driver as SoC\n    Caller-&gt;&gt;HAL:dsHostInit()\n    Note over HAL: SOC can initialize the underlying subsystems if needed\n    HAL-&gt;&gt;Driver:Initializing SoC Power Manager\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:dsGetCPUTemperature()\n    Note over HAL: Returns the current CPU temp\n    HAL-&gt;&gt;Driver:Getting the current CPU temp\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:dsGetSocIDFromSDK()\n    Note over HAL: Returns the SoC ID\n    HAL-&gt;&gt;Driver:Getting the SoC ID\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:dsGetHostEDID()\n    Note over HAL: Returns the Host EDID\n    HAL-&gt;&gt;Driver:Getting the Host EDID\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    Caller -&gt;&gt;HAL:dsHostTerm()\n    HAL-&gt;&gt;Driver:Terminating SoC Power Manager\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return</code></pre>"},{"location":"external_content/device_settings/docs/pages/ds-video-device_halSpec/","title":"DEVICE SETTINGS Video Device HAL Documentation","text":""},{"location":"external_content/device_settings/docs/pages/ds-video-device_halSpec/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>HAL</code>    - Hardware Abstraction Layer</li> <li><code>API</code>    - Caller Programming Interface</li> <li><code>Caller</code> - Any user of the interface via the <code>API</code></li> <li><code>CPU</code>    - Central Processing Unit</li> <li><code>DS</code>     - Device Settings</li> <li><code>HAL</code>    - Hardware Abstraction Layer</li> <li><code>EDID</code>   - Extended Display Information Data</li> <li><code>CPU</code>    - Central Processing Unit</li> <li><code>SoC</code>    - System on chip</li> </ul>"},{"location":"external_content/device_settings/docs/pages/ds-video-device_halSpec/#description","title":"Description","text":"<p>The diagram below describes a high-level software architecture of the Device Settings Video Device module.</p> <pre><code>%%{ init : { \"theme\" : \"forest\", \"flowchart\" : { \"curve\" : \"linear\" }}}%%\nflowchart TD\ny[Caller]&lt;--&gt;x[Device Settings VIDEO DEVICE HAL];\nx[Device Settings VIDEO DEVICE HAL]&lt;--&gt;z[SOC Drivers];\nstyle y fill:#99CCFF,stroke:#333,stroke-width:0.3px,align:left\nstyle z fill:#fcc,stroke:#333,stroke-width:0.3px,align:left\nstyle x fill:#9f9,stroke:#333,stroke-width:0.3px,align:left</code></pre> <p><code>Device Settings Video Device</code> <code>HAL</code> provides a set of <code>APIs</code> to initialize, query information about the <code>SoC</code>.</p> <p>The main purpose of this module is to facilitate communication between the <code>caller</code> and <code>HAL</code> interface, such that information about the zoom mode, HDR capabilities, Video encoding formats frame rate information and etc can be set and queried.</p>"},{"location":"external_content/device_settings/docs/pages/ds-video-device_halSpec/#component-runtime-execution-requirements","title":"Component Runtime Execution Requirements","text":"<p>This interface  must adeptly manage resources to prevent issues like memory leaks and excessive utilization. It must also meet performance goals for response time, throughput, and resource use as per the platform's capabilities.</p> <p>Failure to meet these requirements will likely result in undefined and unexpected behavior.</p>"},{"location":"external_content/device_settings/docs/pages/ds-video-device_halSpec/#initialization-and-startup","title":"Initialization and Startup","text":"<p><code>Caller</code> must initialize <code>dsVideoDevice</code> by calling <code>dsVideoDeviceInit()</code> before calling any other <code>APIs</code>. The <code>caller</code> is expected to have complete control over the life cycle of the this module.</p>"},{"location":"external_content/device_settings/docs/pages/ds-video-device_halSpec/#threading-model","title":"Threading Model","text":"<p>This interface is not required to be thread safe. Any <code>caller</code> invoking the <code>APIs</code> must ensure calls are made in a thread safe manner. <code>HAL</code> is allowed to create internal threads for its operations without excessively consuming system resources. Any threads created by the <code>HAL</code> must be handled gracefully and respective error codes must be returned if any corresponding <code>API</code> fails.</p>"},{"location":"external_content/device_settings/docs/pages/ds-video-device_halSpec/#process-model","title":"Process Model","text":"<p>This interface is required to support a single instantiation with a single process.</p>"},{"location":"external_content/device_settings/docs/pages/ds-video-device_halSpec/#memory-model","title":"Memory Model","text":"<p>This interface is not required to allocate any memory. Any pointers created by the interface must be cleaned up upon termination.</p>"},{"location":"external_content/device_settings/docs/pages/ds-video-device_halSpec/#power-management-requirements","title":"Power Management Requirements","text":"<p>Although this interface is not required to be involved in any of the power management operations, the state transitions must not affect its operation. e.g. on resumption from a low power state, the interface must operate as if no transition has occurred.</p>"},{"location":"external_content/device_settings/docs/pages/ds-video-device_halSpec/#asynchronous-notification-model","title":"Asynchronous Notification Model","text":"<ul> <li>The <code>dsVideoDevice</code> <code>API</code> <code>dsRegisterFrameratePreChangeCB()</code> should facilitate asynchronous status notifications using the callback before the framerate is changed using the callback <code>dsRegisterFrameratePreChangeCB_t</code>. This callback should used before the framerate is changed.</li> <li>The <code>dsVideoDevice</code> <code>API</code> <code>dsRegisterFrameratePostChangeCB()</code> should facilitate asynchronous status notifications using the callback after the framerate is changed using the callback <code>dsRegisterFrameratePostChangeCB_t</code>. This callback should be used after the framerate has been changed.</li> </ul>"},{"location":"external_content/device_settings/docs/pages/ds-video-device_halSpec/#blocking-calls","title":"Blocking calls","text":"<p>This interface is not required to have any blocking calls. Synchronous calls must complete within a reasonable time period.</p>"},{"location":"external_content/device_settings/docs/pages/ds-video-device_halSpec/#internal-error-handling","title":"Internal Error Handling","text":"<p>All the <code>APIs</code> must return error synchronously as a return argument. <code>HAL</code> is responsible for handling system errors (e.g. out of memory) internally.</p>"},{"location":"external_content/device_settings/docs/pages/ds-video-device_halSpec/#persistence-model","title":"Persistence Model","text":"<p>There is no requirement for the interface to persist any setting information. <code>Caller</code> is responsible to persist any settings related to the <code>HAL</code>.</p>"},{"location":"external_content/device_settings/docs/pages/ds-video-device_halSpec/#non-functional-requirements","title":"Non-functional requirements","text":"<p>The following non-functional requirements will be supported by the module:</p>"},{"location":"external_content/device_settings/docs/pages/ds-video-device_halSpec/#logging-and-debugging-requirements","title":"Logging and debugging requirements","text":"<p>This interface is required to support DEBUG, INFO and ERROR messages. INFO and DEBUG must be disabled by default and enabled when required.</p>"},{"location":"external_content/device_settings/docs/pages/ds-video-device_halSpec/#memory-and-performance-requirements","title":"Memory and performance requirements","text":"<p>This interface will ensure optimal use of memory and <code>CPU</code> according to the specific capabilities of the system.</p>"},{"location":"external_content/device_settings/docs/pages/ds-video-device_halSpec/#quality-control","title":"Quality Control","text":"<ul> <li>This interface is required to perform static analysis, our preferred tool is Coverity.</li> <li>Have a zero-warning policy with regards to compiling. All warnings are required to be treated as errors.</li> <li>Copyright validation is required to be performed, e.g.: Black duck, and FossID.</li> <li>Use of memory analysis tools like Valgrind are encouraged to identify leaks/corruptions.</li> <li><code>HAL</code> Tests will endeavour to create worst case scenarios to assist investigations.</li> <li>Improvements by any party to the testing suite are required to be fed back.</li> </ul>"},{"location":"external_content/device_settings/docs/pages/ds-video-device_halSpec/#licensing","title":"Licensing","text":"<p>The <code>HAL</code> implementation is expected to released under the Apache License 2.0.</p>"},{"location":"external_content/device_settings/docs/pages/ds-video-device_halSpec/#build-requirements","title":"Build Requirements","text":"<p>The source code must build into a shared library for Device Settings as this module is a part of Device Settings and must be named as <code>libdshal.so</code>. The build mechanism must be independent of Yocto.</p>"},{"location":"external_content/device_settings/docs/pages/ds-video-device_halSpec/#variability-management","title":"Variability Management","text":"<ul> <li>Any changes in the <code>APIs</code> must be reviewed and approved by the component architects.</li> <li><code>DeviceSettings Video Device</code> <code>HAL</code> modification must support backward compatibility for the generic operations like image upgrade and downgrade.</li> <li>This interface must return the dsERR_OPERATION_NOT_SUPPORTED error code, if any of the interface - <code>APIs</code> are not supported by the underlying hardware.</li> </ul>"},{"location":"external_content/device_settings/docs/pages/ds-video-device_halSpec/#platform-or-product-customization","title":"Platform or Product Customization","text":"<p>This interface is not required to have any platform or product customizations.</p>"},{"location":"external_content/device_settings/docs/pages/ds-video-device_halSpec/#interface-api-documentation","title":"Interface API Documentation","text":"<p><code>API</code> documentation will be provided by Doxygen which will be generated from the header file.</p>"},{"location":"external_content/device_settings/docs/pages/ds-video-device_halSpec/#theory-of-operation-and-key-concepts","title":"Theory of operation and key concepts","text":"<p>The <code>caller</code> is expected to have complete control over the life cycle of the <code>HAL</code>.</p> <ol> <li> <p>Initialize the <code>HAL</code> using function: <code>dsVideoDeviceInit()</code> before making any other <code>API</code> calls.  If <code>dsVideoDeviceInit()</code> call fails, the <code>HAL</code> must return the respective error code, so that the <code>caller</code> can retry the operation.</p> </li> <li> <p>The <code>caller</code> can call <code>dsGetVideoDevice()</code> to get the handle for a specific video device, to be used in the other function calls.</p> </li> <li> <p>The <code>caller</code> can call <code>dsSetDFC()</code>, <code>dsSetDisplayframerate()</code>, <code>dsSetFRFMode()</code> and <code>dsForceDisableHDRSupport()</code> to set the needed information.</p> </li> <li> <p>The <code>caller</code> can call <code>dsGetDFC()</code>, <code>dsGetHDRCapabilities()</code>, <code>dsGetSupportedVideoCodingFormats()</code>, <code>dsGetVideoCodecInfo()</code>, <code>dsGetFRFMode()</code>, <code>dsGetCurrentDisplayframerate()</code>, to query the needed information.</p> </li> <li> <p>Callbacks can be set with <code>dsRegisterFrameratePreChangeCB()</code> and <code>dsRegisterFrameratePostChangeCB()</code>.</p> <ul> <li><code>dsRegisterFrameratePreChangeCB()</code> is used before the framerate is changed.</li> <li><code>dsRegisterFrameratePostChangeCB()</code> is used after the framerate is changed.</li> </ul> </li> <li> <p>De-initialized the <code>HAL</code> using the function: <code>dsVideoDeviceTerm()</code></p> </li> </ol>"},{"location":"external_content/device_settings/docs/pages/ds-video-device_halSpec/#diagrams","title":"Diagrams","text":""},{"location":"external_content/device_settings/docs/pages/ds-video-device_halSpec/#operational-call-sequence","title":"Operational Call Sequence","text":"<pre><code>%%{ init : { \"theme\" : \"default\", \"flowchart\" : { \"curve\" : \"stepBefore\" }}}%%\n   sequenceDiagram\n    participant Caller as Caller\n    participant HAL as DS VIDEO DEVICE HAL\n    participant Driver as SoC\n    Caller-&gt;&gt;HAL:dsVideoDeviceInit()\n    Note over HAL: SoC initializes the Video Device subsystem\n    HAL-&gt;&gt;Driver: Allocates required resources for Video Device\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL: ds_Video_Device_SetMethods\n    Note over HAL: APIs to set the Video Device Parameters\n    HAL-&gt;&gt;Driver:Setting the Video Device Parameters\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL: ds_Video_Device_GetMethods\n    Note over HAL: APIs to get the Video Device Parameters\n    HAL-&gt;&gt;Driver:Getting the Video Device Parameters\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:dsRegisterFrameratePreChangeCB()\n    Note over HAL: Registers the callback for the pre-change framerate callback\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:dsRegisterFrameratePostChangeCB()\n    Note over HAL: Registers the callback for the post-change framerate callback\n    HAL--&gt;&gt;Caller:return\n    Driver--&gt;&gt;HAL:Frame rate about to change\n    Note over HAL: Framerate about to change\n    HAL--&gt;&gt;Caller:dsRegisterFrameratePreChangeCB_t callback returned\n    Driver--&gt;&gt;HAL:Framerate has changed\n    Note over HAL: Framerate has changed\n    HAL--&gt;&gt;Caller:dsRegisterFrameratePostChangeCB_t callback returned\n    Caller -&gt;&gt;HAL:dsVideoDeviceTerm()\n    HAL -&gt;&gt; Driver: Releases all the resources allocated during dsVideoDeviceInit()\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return</code></pre>"},{"location":"external_content/device_settings/docs/pages/ds-video-port_halSpec/","title":"Device Settings Video Port HAL Documentation","text":""},{"location":"external_content/device_settings/docs/pages/ds-video-port_halSpec/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>HAL</code>    - Hardware Abstraction Layer</li> <li><code>API</code>    - Caller Programming Interface</li> <li><code>Caller</code> - Any user of the interface via the <code>APIs</code></li> <li><code>CPU</code>    - Central Processing Unit</li> <li><code>DS</code>     - Device Settings</li> <li><code>SoC</code>    - System on Chip</li> <li><code>HDMI</code>   - High-Definition Multimedia Interface</li> <li><code>DTCP</code>   - Digital Transmission Content Protection</li> <li><code>HDCP</code>   - High-bandwidth Digital Content Protection</li> <li><code>HDR</code>    - High Dynamic Range</li> <li><code>SDR</code>    - Standard Dynamic Range</li> <li><code>EDID</code> - Extended Display Identification Data</li> </ul>"},{"location":"external_content/device_settings/docs/pages/ds-video-port_halSpec/#description","title":"Description","text":"<p>The diagram below describes a high-level software architecture of the <code>DS</code> Video Port stack.</p> <pre><code>%%{ init : { \"theme\" : \"forest\", \"flowchart\" : { \"curve\" : \"linear\" }}}%%\nflowchart TD\ny[Caller]&lt;--&gt;x[Device Settings Video Port HAL];\nx[Device Settings Video Port HAL]&lt;--&gt;z[SOC Drivers];\nstyle y fill:#99CCFF,stroke:#333,stroke-width:0.3px,align:left\nstyle z fill:#fcc,stroke:#333,stroke-width:0.3px,align:left\nstyle x fill:#9f9,stroke:#333,stroke-width:0.3px,align:left</code></pre> <p><code>DS</code> Video Port <code>HAL</code> provides a set of <code>APIs</code> to initialize, query and set information about the Video ports like getting  video port handle, fetching connected display information such as color depth, color space, matrix coefficients, quantization range, supported video resolutions using the video port handle. It also provides <code>APIs</code> to enable or disable content protection like <code>HDCP</code> and <code>DTCP</code>, to set the background color and preferred color depth of the video port.</p>"},{"location":"external_content/device_settings/docs/pages/ds-video-port_halSpec/#component-runtime-execution-requirements","title":"Component Runtime Execution Requirements","text":"<p>The interface must adeptly manage resources to prevent issues like memory leaks and excessive utilization. It must also meet performance goals for response time, throughput and resource use as per the platform's capabilities.</p> <p>Failure to meet these requirements will likely result in undefined and unexpected behavior.</p>"},{"location":"external_content/device_settings/docs/pages/ds-video-port_halSpec/#initialization-and-startup","title":"Initialization and Startup","text":"<p><code>Caller</code> must initialize this interface by calling <code>dsVideoPortInit()</code> before calling any other <code>APIs</code>. The <code>caller</code> is expected to have complete control over the life cycle of this module.</p>"},{"location":"external_content/device_settings/docs/pages/ds-video-port_halSpec/#threading-model","title":"Threading Model","text":"<p>This interface is not required to be thread safe. Any <code>caller</code> invoking the <code>APIs</code> must ensure calls are made in a thread safe manner. This interface is allowed to create internal threads for its operations without excessively consuming system resources. Any threads created by this interface must be handled gracefully and respective error codes must be returned if any corresponding <code>API</code> fails.</p>"},{"location":"external_content/device_settings/docs/pages/ds-video-port_halSpec/#process-model","title":"Process Model","text":"<p>This interface is required to support a single instantiation with a single process.</p>"},{"location":"external_content/device_settings/docs/pages/ds-video-port_halSpec/#memory-model","title":"Memory Model","text":"<p>This interface is not required to allocate any memory. Any pointers created by the interface must be cleaned up upon termination.</p>"},{"location":"external_content/device_settings/docs/pages/ds-video-port_halSpec/#power-management-requirements","title":"Power Management Requirements","text":"<p>Although this interface is not required to be involved in any of the power management operations, the state transitions must not affect its operation. e.g. on resumption from a low power state, the interface must operate as if no transition has occurred.</p>"},{"location":"external_content/device_settings/docs/pages/ds-video-port_halSpec/#asynchronous-notification-model","title":"Asynchronous Notification Model","text":"<p>This interface must support asynchronous notifications operations:</p> <ul> <li><code>dsHDCPStatusCallback_t</code> is triggered when the connection status when the HDCP status of video port changes.</li> <li><code>dsVideoFormatUpdateCB</code> is triggered when the video format changes.</li> </ul> <p>This interface is allowed to establish its own thread context for its operation, ensuring minimal impact on system resources. Additionally, this interface is responsible for releasing the resources it creates for its operation once the respective operation concludes.</p>"},{"location":"external_content/device_settings/docs/pages/ds-video-port_halSpec/#blocking-calls","title":"Blocking calls","text":"<p>This interface is not required to have any blocking calls. Synchronous calls must complete within a reasonable time period.</p>"},{"location":"external_content/device_settings/docs/pages/ds-video-port_halSpec/#internal-error-handling","title":"Internal Error Handling","text":"<p>The <code>API</code> must return error synchronously as a return argument. This interface is responsible for handling system errors (e.g. out of memory) internally.</p>"},{"location":"external_content/device_settings/docs/pages/ds-video-port_halSpec/#persistence-model","title":"Persistence Model","text":"<p>There is no requirement for the interface to persist any setting information. Caller is responsible to persist any settings related to the HAL.</p>"},{"location":"external_content/device_settings/docs/pages/ds-video-port_halSpec/#non-functional-requirements","title":"Non-functional requirements","text":"<p>The following non-functional requirements will be supported by the module.</p>"},{"location":"external_content/device_settings/docs/pages/ds-video-port_halSpec/#logging-and-debugging-requirements","title":"Logging and debugging requirements","text":"<p>This interface is required to support DEBUG, INFO and ERROR messages. INFO and DEBUG must be disabled by default and enabled when required.</p>"},{"location":"external_content/device_settings/docs/pages/ds-video-port_halSpec/#memory-and-performance-requirements","title":"Memory and performance requirements","text":"<p>This interface will ensure optimal use of memory and <code>CPU</code> according to the specific capabilities of the platform.</p>"},{"location":"external_content/device_settings/docs/pages/ds-video-port_halSpec/#quality-control","title":"Quality Control","text":"<ul> <li>This interface is required to perform static analysis, our preferred tool is Coverity.</li> <li>Have a zero-warning policy with regards to compiling. All warnings are required to be treated as errors.</li> <li>Copyright validation is required to be performed, e.g.: Black duck, and FossID.</li> <li>Use of memory analysis tools like Valgrind are encouraged to identify leaks/corruptions.</li> <li><code>HAL</code> Tests will endeavour to create worst case scenarios to assist investigations.</li> <li>Improvements by any party to the testing suite are required to be fed back.</li> </ul>"},{"location":"external_content/device_settings/docs/pages/ds-video-port_halSpec/#licensing","title":"Licensing","text":"<p>The <code>HAL</code> implementation is expected to released under the Apache License 2.0.</p>"},{"location":"external_content/device_settings/docs/pages/ds-video-port_halSpec/#build-requirements","title":"Build Requirements","text":"<p>The source code must build into a shared library for <code>DS</code> as Video Port module is a part of <code>DS</code> and must be named as <code>libdshal.so</code>. The build mechanism must be independent of Yocto.</p>"},{"location":"external_content/device_settings/docs/pages/ds-video-port_halSpec/#variability-management","title":"Variability Management","text":"<ul> <li>Any changes in the <code>APIs</code> must be reviewed and approved by the component architects.</li> <li>Any modification must support backward compatibility for the generic operations like image upgrade and downgrade.</li> <li>This interface must return the dsERR_OPERATION_NOT_SUPPORTED error code, if any of the interface - <code>APIs</code> are not supported by the underlying hardware.</li> </ul>"},{"location":"external_content/device_settings/docs/pages/ds-video-port_halSpec/#platform-or-product-customization","title":"Platform or Product Customization","text":"<p>The configuration settings file for <code>DS</code> Video Port can be used for adding platform specific configurations. The sample files are dsVideoPortSettings_template.h and dsVideoResolutionSettings_template.h</p>"},{"location":"external_content/device_settings/docs/pages/ds-video-port_halSpec/#interface-api-documentation","title":"Interface API Documentation","text":"<p><code>API</code> documentation will be provided by Doxygen which will be generated from the header file.</p>"},{"location":"external_content/device_settings/docs/pages/ds-video-port_halSpec/#theory-of-operation-and-key-concepts","title":"Theory of operation and key concepts","text":"<p>The <code>caller</code> is expected to have complete control over the life cycle of the <code>HAL</code>.</p> <ol> <li> <p>Initialize the <code>HAL</code> <code>dsVideoPortInit()</code> before making any other <code>APIs</code> calls.  If <code>dsVideoPortInit()</code> call fails, the <code>HAL</code> must return the respective error code, so that the <code>caller</code> can retry the operation.</p> </li> <li> <p>The <code>caller</code> can call <code>dsEnableDTCP()</code>, <code>dsEnableHDCP()</code>, <code>dsEnableVideoPort()</code>, <code>dsSetResolution()</code>, <code>dsSetActiveSource()</code>, <code>dsSetForceDisable4KSupport()</code>, <code>dsSetHdmiPreference()</code>, <code>dsSetBackgroundColor()</code>, <code>dsSetForceHDRMode()</code> and <code>dsSetPreferredColorDepth()</code> to set the needed information.</p> </li> <li> <p>The <code>caller</code> can call <code>dsGetVideoPort()</code>, <code>dsGetSurroundMode()</code>, <code>dsGetResolution()</code>, <code>dsIsVideoPortEnabled()</code>, <code>dsIsDisplayConnected()</code>,  <code>dsIsDisplaySurround()</code>, <code>dsGetSurroundMode()</code>, <code>dsIsVideoPortActive()</code>, <code>dsIsDTCPEnabled()</code> , <code>dsIsHDCPEnabled()</code>, <code>dsGetResolution()</code>, <code>dsGetHDCPStatus()</code>, <code>dsGetHDCPProtocol()</code>, <code>dsGetHDCPReceiverProtocol()</code>, <code>dsGetHDCPCurrentProtocol()</code>, <code>dsGetTVHDRCapabilities()</code>, <code>dsGetForceDisable4KSupport()</code>, <code>dsGetVideoEOTF()</code>, <code>dsGetMatrixCoefficients()</code>, <code>dsGetColorDepth()</code> to query the needed information.</p> </li> <li> <p>Callbacks can be set with:</p> <ul> <li><code>dsRegisterHdcpStatusCallback()</code> is triggered when there is a change in HDCP status of the video port</li> <li><code>dsVideoFormatUpdateCB()</code> is triggered when there is a change in video format of the content</li> </ul> </li> <li> <p>De-initialize the <code>HAL</code> using <code>dsVideoPortTerm()</code>.</p> </li> </ol>"},{"location":"external_content/device_settings/docs/pages/ds-video-port_halSpec/#diagrams","title":"Diagrams","text":""},{"location":"external_content/device_settings/docs/pages/ds-video-port_halSpec/#operational-call-sequence","title":"Operational Call Sequence","text":"<pre><code>%%{ init : { \"theme\" : \"default\", \"flowchart\" : { \"curve\" : \"stepBefore\" }}}%%\n   sequenceDiagram\n    participant Caller as Caller\n    participant HAL as DS Video Port HAL\n    participant Driver as SoC\n    Caller-&gt;&gt;HAL:dsVideoPortInit()\n    Note over HAL: SOC initializes the underlying Video Port sub-system\n    HAL-&gt;&gt;Driver:Initializes the Video Port sub-system\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:dsGetVideoPort()\n    Note over HAL: Gets the handle for video port\n    HAL-&gt;&gt;Driver:Getting the handle of video port\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:dsIsVideoPortEnabled()\n    Note over HAL: Indicates whether video port is enabled or not\n    HAL-&gt;&gt;Driver:Getting the status of the video port\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:dsIsDisplayConnected()\n    Note over HAL: Indicates whether video port is connected to display or not\n    HAL-&gt;&gt;Driver: Getting the connection status of display\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:dsIsDisplaySurround()\n    Note over HAL: Indicates whether connected display supports surround sound\n    HAL-&gt;&gt;Driver: Getting the surround capability of display connected to video port\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:dsGetSurroundMode()\n    Note over HAL: Gets the surround mode of display\n    HAL-&gt;&gt;Driver:Getting the surround mode of display connected to video port\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:dsEnableDTCP()\n    Note over HAL: Enables/Disables the DTCP for specified video port\n    HAL-&gt;&gt;Driver: DTCP is enabled / disabled based on input parameter\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:dsEnableHDCP()\n    Note over HAL: Enables/Disables the HDCP for specified video port\n    HAL-&gt;&gt;Driver: HDCP is enabled / disabled based on input parameter\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:dsSetResolution()\n    Note over HAL: Sets the resolution of video port\n    HAL-&gt;&gt;Driver: Setting the resolution of display corresponding to specified video port\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:dsGetResolution()\n    Note over HAL: Gets the resolution of video port\n    HAL-&gt;&gt;Driver:Getting the resolution of display corresponding to specified video port\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:dsGetHDCPReceiverProtocol()\n    Note over HAL: Gets the HDCP protocol version of Receiver/TV\n    HAL-&gt;&gt;Driver:Getting the  HDCP protocol version of display corresponding to specified video port\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:dsGetTVHDRCapabilities()\n    Note over HAL: Gets the HDR capabilities of TV\n    HAL-&gt;&gt;Driver:Getting the HDR capabilities of TV/Display corresponding to specified video port\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:dsSupportedTvResolutions()\n    Note over HAL: Gets the supported resolutions of TV\n    HAL-&gt;&gt;Driver:Getting the supported resolutions of TV corresponding to specified video port\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:dsGetVideoEOTF()\n    Note over HAL: Gets the current Electro-Optical Transfer Function (EOT) value\n    HAL-&gt;&gt;Driver:Getting the EOT function value of display corresponding to specified video port\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:dsRegisterHdcpStatusCallback()\n    Note over HAL: Creates the callback for getting the HDCP status on HDMI Ports\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:dsVideoFormatUpdateRegisterCB()\n    Note over HAL: Creates the callback for getting the video format updates\n    HAL--&gt;&gt;Caller:return\n    HAL--&gt;&gt;Caller:dsHDCPStatusCallback_t callback returned\n    Note over HAL: The HDCP status changed\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:dsVideoFormatUpdateCB callback returned\n    Note over HAL: Video Format changed\n    Driver--&gt;&gt;HAL:return\n    Caller -&gt;&gt;HAL:dsVideoPortTerm()\n    Note over HAL: Terminates the underlying Video Port sub-system\n    HAL-&gt;&gt;Driver:Terminates the underlying Video Port sub-system\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return</code></pre>"},{"location":"external_content/device_settings_test/","title":"Unit Testing Suite For Device Settings HAL","text":""},{"location":"external_content/device_settings_test/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Acronyms, Terms and Abbreviations</li> <li>Description</li> <li>Reference Documents</li> <li>Notes</li> </ul>"},{"location":"external_content/device_settings_test/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>L1</code>  - Functional Tests</li> <li><code>L2</code>  - Module functional Testing</li> <li><code>L3</code>  - Module testing with External Stimulus is required to validate and control device</li> <li><code>HAL</code> - Hardware Abstraction Layer</li> <li><code>API</code> - Application Programming Interface</li> <li><code>DS</code>  - Device Settings</li> <li><code>FPD</code> - Front Panel Display</li> <li><code>HDMIIn</code> - HDMI Input</li> <li><code>CompositeIn</code> - Composite Input</li> <li><code>High-Level Test Specification</code> : These specification will provide a broad overview of the system's functionality from the callers' perspective. It focuses on major use cases, system behavior, and overall caller experience.</li> <li><code>Low-Level Test Specification</code> : These specification will delve deeper into the technical details. They will define specific test cases with inputs, expected outputs, and pass/fail criteria for individual functionalities, modules, or APIs.</li> </ul>"},{"location":"external_content/device_settings_test/#description","title":"Description","text":"<p>This repository contains the Unit Test Suites (L1 &amp; L2) for the following submodules of Device Settings  <code>HAL</code> :</p> <ul> <li><code>DS</code> Audio <code>HAL</code></li> <li><code>DS</code> Video Device <code>HAL</code></li> <li><code>DS</code> Video Port <code>HAL</code></li> <li><code>DS</code> Display <code>HAL</code></li> <li><code>DS</code> Front Panel Display <code>HAL</code></li> <li><code>DS</code> Host <code>HAL</code></li> <li><code>DS</code> HDMI Input <code>HAL</code></li> <li><code>DS</code> Composite Input <code>HAL</code></li> </ul>"},{"location":"external_content/device_settings_test/#reference-documents","title":"Reference Documents","text":"SNo Document Name Document Description Document Link 1 Device Settings <code>HAL</code> This document provides specific information on each <code>DS</code> sub-module's <code>APIs</code> for which tests are written in this module <code>DS</code> <code>HAL</code> Guide 2 <code>DS</code> Audio Test Suits Specifications <code>L1</code>,<code>L2</code>,<code>L3</code> Test Specification Documentation for <code>DS</code> Audio module. Refer dsAudio 3 <code>DS</code> Video Device Test Suits Specifications <code>L1</code>,<code>L2</code>,<code>L3</code> Test Specification Documentation for <code>DS</code> Video Device module. Refer dsVideoDevice 4 <code>DS</code> Video Port  Test Suits Specifications <code>L1</code>,<code>L2</code>,<code>L3</code> Test Specification Documentation for <code>DS</code> Video Port  module. Refer dsVideoPort 5 <code>DS</code> Display Test Suits Specifications <code>L1</code>,<code>L2</code>,<code>L3</code> Test Specification Documentation for <code>DS</code> Display module. Refer dsDisplay 6 <code>DS</code> Front Panel Display Test Suits Specifications <code>L1</code>,<code>L2</code>,<code>L3</code> Test Specification Documentation for <code>DS</code> Front Panel Display module. Refer dsFPD 7 <code>DS</code> Host Test Suits Specifications <code>L1</code>,<code>L2</code>,<code>L3</code> Test Specification Documentation for <code>DS</code> Host module. Refer dsHost 8 <code>DS</code> HDMI Input Test Suits Specifications <code>L1</code>,<code>L2</code>,<code>L3</code> Test Specification Documentation for <code>DS</code> HDMI Input module. Refer dsHdmiIn 9 <code>DS</code> Composite Input Test Suits Specifications <code>L1</code>,<code>L2</code>,<code>L3</code> Test Specification Documentation for <code>DS</code> Composite Input module. Refer dsCompositeIn"},{"location":"external_content/device_settings_test/#l1-l2-l3-testprocedure-documents","title":"<code>L1</code> <code>L2</code> <code>L3</code> TestProcedure Documents","text":"<code>DS</code> Module L1 L2 TestProcedure docs L3 TestProcedure docs dsAudio ds-audio_High-Level_TestSpecification.md, ds-audio_L2_Low-Level_TestSpecification.md ds-audio_High-Level_TestSpecification.md, ds-audio_L3_Low-Level_TestSpecification.md, ds-audio_L3_TestProcedure.md dsDisplay ds-display-high-Level_TestSpec.md,  ds-display-L2-Low-Level_TestSpec.md ds-display-high-Level_TestSpec.md, ds-display_L3_Low-Level_TestSpecification.md, ds-display_L3_TestProcedure.md dsFPD ds-front-panel-display_High-Level_TestSpec.md, ds-front-panel-display_L2_Low-Level_TestSpecification.md ds-front-panel-display_High-Level_TestSpec.md, ds-front-panel-display_L3_Low-Level_TestSpecification.md, ds-front-panel-display_L3_TestProcedure.md dsHost ds-host_High-Level_TestSpecification.md, ds-host_L2_Low-Level_TestSpecification.md ds-host_High-Level_TestSpecification.md,ds-host_L3_TestProcedure.md, ds-host_L3_Low-Level_TestSpec.md dsCompositeIn ds-compositeIn-High-Level_TestSpec.md, ds-compositeIn-L2-Low-Level_TestSpec.md ds-compositeIn-High-Level_TestSpec.md, ds-compositeIn-L3-Low-Level-TestSpec.md, ds-compositeIn-L3-TestProcedure.md dsHdmiIn ds-hdmi-in-High-Level_TestSpec.md, ds-hdmi-in-L2-Low-Level_TestSpec.md ds-hdmi-in-High-Level_TestSpec.md, ds-Hdmi-In_L3_Low-Level_TestSpecification.mdds-hdmi-in_L3_Test-Procedure.md dsVideoDevice ds-video-device_High-Level_TestSpec.md, ds-video-device_L2-Low-Level_TestSpec.md ds-video-device_High-Level_TestSpec.md, ds-video-device_L3_Low-Level_TestSpecification.md, ds-video-device_L3_TestProcedure.md dsVideoPort ds-video-port_High-Level_TestSpec.md, ds-video-port_L2_Low-Level_TestSpecification.md ds-video-port_High-Level_TestSpec.md, ds-video-port_L3_Low-Level_TestSpecification.md, ds-video-port_L3_Test-Procedure.md"},{"location":"external_content/device_settings_test/#notes","title":"Notes","text":"<ul> <li>All APIs in each individual sub-module need to be implemented in this current version. If any API is not supported, please add stub implementation with return type dsERR_OPERATION_NOT_SUPPORTED for the same.</li> <li>Building against the actual library may introduce SOC dependencies. Hence, a template SKELETON library is created without SOC dependencies. On the real platform (target), it can be mounted, copied and bound with the actual library.</li> <li>When executing the binary, ensure to include a platform-specific profile file as an argument for the designated test cases. The following example illustrates this:</li> </ul> <p><code>bash  ./hal_test -p Sink_AudioSettings.yaml</code></p> <p>Alternatively, use the run.sh script with the profile file:</p> <p><code>bash ./run.sh -p /absolute/path/to/profile/file</code></p> <ul> <li>Profiles files defines the configuration for the platform available for sink and source</li> </ul> <code>DS</code> Module Sink Profile yaml Source Profile yaml dsAudio Sink_AudioSettings.yaml Source_AudioSettings.yaml dsDisplay Sink_4K_Display.yaml Source_4K_Display.yaml dsFPD Sink_FPD.yaml Source_FPD.yaml dsHost Sink_HostSettings.yaml Source_HostSettings.yaml dsCompositeIn Sink_CompositeInput.yaml <code>NA</code> dsHdmiIn Sink_HDMIIN.yaml Source_HDMIIN.yaml dsVideoDevice Sink_2K_VideoDevice.yaml Sink_4K_VideoDevice.yaml Source_VideoDevice.yaml dsVideoPort Sink_4K_VideoPort.yaml Source_4K_VideoPort.yaml <ul> <li>Install Python Environment and Activation Scripts please check theHPK Documentation</li> </ul>"},{"location":"external_content/device_settings_test/CHANGELOG/","title":"Tests Changelog","text":""},{"location":"external_content/device_settings_test/CHANGELOG/#changelog","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file. Dates are displayed in UTC.</p> <p>Generated by <code>auto-changelog</code>.</p>"},{"location":"external_content/device_settings_test/CHANGELOG/#350","title":"3.5.0","text":"<ul> <li>gh #280 Updated profile,testcase for Dialog Enhancement <code>#281</code></li> <li>gh #268 CompositeIn L3 testcase for new API <code>#269</code></li> <li>gh #137 dshdmi in l1 l2 dsGetHdmiVersion <code>#147</code></li> <li>gh #270 dsFPD L3 issue fix <code>#271</code></li> <li>gh #227 updated Make file with target=linux <code>#278</code></li> <li>gh #272 change the correct value for bitwise operation <code>#273</code></li> <li>gh #137 Update ds-hdmi-in-High-Level_TestSpec.md <code>b9a1653</code></li> <li>gh #268 L3 testcase for new API <code>602ba66</code></li> </ul>"},{"location":"external_content/device_settings_test/CHANGELOG/#340","title":"3.4.0","text":"<p>28 November 2024</p> <ul> <li>gh #266 Changing the UT Project version to 4.x <code>#267</code></li> <li>gh #262 updating the video port index for the L1 and L2 testcase <code>#265</code></li> <li>gh #260 dsDisplay L1 update <code>#261</code></li> <li>gh #263 : updated dsAudio L3 test procedure document <code>#264</code></li> <li>gh #251 dsHost: L3 Python test updates <code>#259</code></li> <li>Gh #245 dsFPD L3 Python update <code>#250</code></li> <li>gh #249 dsDisplay L3 Python update <code>#252</code></li> <li>gh #248  python l3 hdmiIn enhancement <code>#254</code></li> <li>gh #246 CompositeIn L3 enhancement changes <code>#255</code></li> <li>gh #244 dsVideoPort python improvements <code>#258</code></li> <li>gh #256  Remove Skeleton lib after build <code>#257</code></li> <li>gh #247 dsVideoDevice L3 python enhancement <code>#253</code></li> <li>gh #242 L1 test case for dsCompositeInRegisterVideoModeUpdateCB <code>#243</code></li> <li>gh #233 dsAudio Enhance python tests <code>#234</code></li> <li>gh #247 Python update (Need to test) <code>1b7db7a</code></li> <li>gh #248 HdmiIn L3 python testcases enhancement <code>50a19c8</code></li> <li>gh #262 updating the video port index for the L1 and L2 related test cases <code>932e4b8</code></li> </ul>"},{"location":"external_content/device_settings_test/CHANGELOG/#330","title":"3.3.0","text":"<p>6 November 2024</p> <ul> <li>gh #198 dsVideoDevice L3 Python Test Code <code>#216</code></li> <li>gh #202 l3 hdmiin python testcases <code>#215</code></li> <li>gh #200 dsDisplay L3 Python test cases <code>#208</code></li> <li>gh #201 dsFPD L3 Python Test Code <code>#238</code></li> <li>gh #199 dsCompositeIn L3 Python Test code <code>#210</code></li> <li>gh #205 dsHost L3 Python Test Cases <code>#206</code></li> <li>gh #239 Updated the install script with ut_raft tag <code>#240</code></li> <li>Fix #192 upgraded review comments <code>#192</code></li> <li>Fix #192 - corrected version selection bug <code>#192</code></li> <li>fix #192 - corrected calling ut-core with correct params <code>#192</code></li> <li>gh #198 test case python code <code>5a277c0</code></li> <li>gh #198 addressed review comments <code>ba4350d</code></li> <li>gh #198 updated test cases <code>7d6a383</code></li> </ul>"},{"location":"external_content/device_settings_test/CHANGELOG/#321","title":"3.2.1","text":"<p>5 November 2024</p> <ul> <li>gh #230 L1 Issue fixes - dsAudio <code>#232</code></li> <li>gh #229 VTS - L1 Issue fix -  dsVideoPort  <code>#231</code></li> <li>gh #217 L1 dsVideoDevice Issue fix <code>#218</code></li> <li>gh #236 dsHdmiIn L1 Issue Fix. <code>#237</code></li> <li>gh #192 make file upgrade correcting clean and framework make <code>#193</code></li> <li>Fix #192 upgraded review comments <code>#192</code></li> <li>Fix #192 - corrected version selection bug <code>#192</code></li> <li>fix #192 - corrected calling ut-core with correct params <code>#192</code></li> <li>update #192 - added debugging features <code>6c97a91</code></li> <li>updated #192 - corrected make of ut-core <code>f4940f7</code></li> <li>gh #217 dsVideoDevice L1 Issue fix <code>9f5c1f1</code></li> </ul>"},{"location":"external_content/device_settings_test/CHANGELOG/#320","title":"3.2.0","text":"<p>16 October 2024</p> <ul> <li>gh #226 ds audio update python tests <code>#228</code></li> <li>gh #220: dsAudio L3 Test Procedure document <code>#221</code></li> <li>gh #224 dsVideoPort L3 test procedure documentation <code>#225</code></li> <li>gh #222 Update the README.md <code>#223</code></li> <li>gh #190 dsvideo port l3 C and Python testcase Implementation  <code>#196</code></li> <li>gh #186 : dsAudio L3 development code <code>#187</code></li> <li>gh #212  dsFPD L1 issue fix  <code>#214</code></li> <li>gh #211 l1 issue fix dsDisplay <code>#213</code></li> <li>gh #184: dsFPD  get led state test step update <code>#185</code></li> <li>gh#148 dsVideoDevice L3 test suit code <code>#153</code></li> <li>gh #203 l3 linking issue fix <code>#204</code></li> <li>gh #151 - FPD L3 C Test <code>#155</code></li> <li>gh #145 HdmiIn l3 testcases implementation <code>#149</code></li> <li>gh #194 dshost l3 remove warnings <code>#197</code></li> <li>gh #150 dsDisplay L3 Test case Development  <code>#152</code></li> <li>gh #154 VTS - L3 dsCompisiteIn C-Test Spec and Code Implementation <code>#156</code></li> <li>gh #169 dsDisplay : L3 Low level Test specification <code>#170</code></li> <li>gh #175 Test Spec Document - FPD L3  <code>#176</code></li> <li>gh #179 l3 ds video device test doc <code>#180</code></li> <li>gh #157 dshost l3 c test code generation <code>#177</code></li> <li>gh #171 ds hdmi in l3 highlevl spec <code>#178</code></li> <li>gh #173 L3 ds composite-In Low level Test specification and procedure document <code>#174</code></li> <li>gh #188 VideoPort Updated L3 python Overview <code>#189</code></li> <li>gh #159: dsAudio L3 Python test code <code>#164</code></li> <li>gh #181: L3 C Test: Issues after merging dsAudio dsVideo <code>#182</code></li> <li>gh #115 dsAudio: L3 Test case Development <code>#116</code></li> <li>gh #101 dsAudio: L3 Low level Test specification and procedure document <code>#102</code></li> <li>gh #99 dsVideoPort L3 low-level Spec &amp; implementation  <code>#103</code></li> <li>fix #159 - minor correction to description <code>#159</code></li> <li>gh #190 Updated dsVideoPort python class &amp; add testcase <code>34b7820</code></li> <li>gh #186: dsAudio L3 developement code <code>71c4801</code></li> <li>gh #186: dsAudio L3 developement code <code>7c81638</code></li> </ul>"},{"location":"external_content/device_settings_test/CHANGELOG/#314","title":"3.1.4","text":"<p>20 September 2024</p> <ul> <li>gh #165 UT_ASSERT update for sting Comparison <code>#166</code></li> <li>Bumped CHANGELOG.md - 3.1.4 <code>da7f90f</code></li> <li>gh #165 UT_ASSERT Macro Update <code>1beb712</code></li> <li>Merge tag '3.1.3' into develop <code>29e88ac</code></li> </ul>"},{"location":"external_content/device_settings_test/CHANGELOG/#313","title":"3.1.3","text":"<p>20 September 2024</p> <ul> <li>gh #141 VideoDevice Profile update issue fixes <code>#142</code></li> <li>gh #162: Add helpers folder to python <code>#163</code></li> <li>gh #160: Initial python setup layout <code>#161</code></li> <li>gh #143 Added supported Resolutions for Source device profile file <code>#144</code></li> <li>gh #143 Added supported Resolutions for Source device profile &amp; L2 code <code>9c8f0d8</code></li> <li>gh #141 Update l2 for FRF Mode <code>7d3cdee</code></li> <li>gh #141 L1 Profile Update <code>6832971</code></li> </ul>"},{"location":"external_content/device_settings_test/CHANGELOG/#312","title":"3.1.2","text":"<p>15 August 2024</p> <ul> <li>gh #135 Corrected the kvp function to read number of indicators <code>#136</code></li> <li>Bumped CHANGELOG.md - 3.1.2 <code>8d9864d</code></li> <li>Merge tag '3.1.1' into develop <code>6a17314</code></li> </ul>"},{"location":"external_content/device_settings_test/CHANGELOG/#311","title":"3.1.1","text":"<p>14 August 2024</p> <ul> <li>gh #133 FIx Logic for setFPColor and getFP Color <code>#134</code></li> <li>gh #133 Fixing logic for setFPColor and getFPColor <code>eafd91a</code></li> <li>gh #133 setFPColor, getFPColor logic update <code>2dc5c10</code></li> <li>updated the l1,l2 and yaml files with the review comments <code>4f47564</code></li> </ul>"},{"location":"external_content/device_settings_test/CHANGELOG/#310","title":"3.1.0","text":"<p>13 August 2024</p> <ul> <li>gh #131 added run script &amp; Updated README.md <code>#132</code></li> <li>gh #94 Wrong size for Profile file string parsing <code>#95</code></li> <li>gh #112 code cleanup of dsFPD <code>#130</code></li> <li>gh #110 Code Cleanup of dsHdmiIn <code>#124</code></li> <li>gh #109 code clean up for audio <code>#128</code></li> <li>gh #108 L1 videoport code cleanup <code>#118</code></li> <li>gh #111 Code Cleanup of dsVideoDevice <code>#125</code></li> <li>gh #105 host code cleanup <code>#119</code></li> <li>gh #106 Code Cleanup of dsDisplay <code>#123</code></li> <li>gh #126 Updating source yaml file for display <code>#127</code></li> <li>gh #107 Code Cleanup of CompositeIn <code>#122</code></li> <li>gh #67 Test profile changes for dsFPD <code>#113</code></li> <li>gh #64 Test profile changes for HdmiIn <code>#73</code></li> <li>gh #63 Audio test profile modifications  <code>#114</code></li> <li>gh #120 Feature/gh120 kvp issue <code>#121</code></li> <li>gh #65 Test profile changes for VideoDevice <code>#104</code></li> <li>gh #60 Test profile changes for dsDisplay <code>#74</code></li> <li>gh #61 Test profile changes for dsCompositeIn <code>#80</code></li> <li>gh #89 dsFPD interface updates <code>#92</code></li> <li>gh #87 dshdmiIn interface updates <code>#91</code></li> <li>gh #82 Modified Audio l1 test cases as per latest interface  <code>#93</code></li> <li>gh #51 dsFPD : Enhanced error macro implementation  <code>#59</code></li> <li>gh #83 L1 videoport updated interface changes <code>#90</code></li> <li>gh #84 L1 dsVideoDevice updated interface changes <code>#96</code></li> <li>gh #50 dsCompositeIn: Enhanced error code macro implementation <code>#97</code></li> <li>gh #109 audio module review comments addressal <code>db343ed</code></li> <li>gh #110 Code Cleanup of  dsHdmin <code>249750f</code></li> <li>gh #110 Code Cleanup of  dsHdmin <code>e774ee0</code></li> </ul>"},{"location":"external_content/device_settings_test/CHANGELOG/#301","title":"3.0.1","text":"<p>28 June 2024</p> <ul> <li>gh #78 update flag for source and sink <code>#79</code></li> <li>Bumped CHANGELOG.md - 3.0.1 <code>234c77c</code></li> <li>Merge tag '3.0.0' into develop <code>1f22556</code></li> </ul>"},{"location":"external_content/device_settings_test/CHANGELOG/#300","title":"3.0.0","text":"<p>28 June 2024</p> <ul> <li>gh #76 Updated L2 code, README.md,doxygen <code>#77</code></li> <li>gh #23 ds fp test spec &amp; L2 code <code>#33</code></li> <li>gh #14 dsVideoPort High Level Test Spec &amp; L2 Code <code>#15</code></li> <li>gh #18 dsVideoDevice High Level Test Specification Documentation <code>#20</code></li> <li>gh #24 High Level spec &amp; L2 for Device Settings HDMI input &amp; L2 code <code>#32</code></li> <li>gh #11 DS Display HL changes and YAML changes <code>#48</code></li> <li>gh #7 updating the dsHost test specification and the code <code>#9</code></li> <li>gh #10 L2 code &amp; test spec  <code>#47</code></li> <li>gh #29  dsAudio - L2 Low level Specification and test implementation <code>#71</code></li> <li>gh #29: dsAudio - L2 Low level Specification and test implementation <code>20382e2</code></li> <li>gh #14 Update the L2 code and file names &amp; updated ut version <code>d86fc04</code></li> <li>gh #18 Updated Specification document and test cases <code>e681b80</code></li> </ul>"},{"location":"external_content/device_settings_test/CHANGELOG/#210","title":"2.1.0","text":"<p>5 June 2024</p> <ul> <li>gh #43 deviceSettings: Enhanced Error code for device settings <code>#45</code></li> <li>Updated with enhanced error code disabled checked in test_l1_dsAudio.c <code>#46</code></li> <li>updating the dsDisplay test spec <code>#13</code></li> <li>Adding testing scope changes for composite test spec <code>#16</code></li> <li>revert previous commit <code>b33cd08</code></li> <li>gh #43 remove DS_ASSERT_AUTO_TERM_NUMERICAL <code>0988071</code></li> <li>Enhanced Error code moved to kvp profiler <code>52242e0</code></li> </ul>"},{"location":"external_content/device_settings_test/CHANGELOG/#200","title":"2.0.0","text":"<p>22 March 2024</p> <ul> <li>gh #21 L1 TCs for dsSetAudioMixerLevels API <code>#22</code></li> <li>gh #21 Replaced DS_ASSERT with UT_ASSERT and review comment addressal <code>63cee4e</code></li> <li>gh #21 NULL(Global handle) check moved to positive test <code>c390284</code></li> <li>Update test_l1_dsAudio.c <code>7f1db52</code></li> </ul>"},{"location":"external_content/device_settings_test/CHANGELOG/#103","title":"1.0.3","text":"<p>12 December 2023</p> <ul> <li>Updated HAL and HALTEST supported version in README.md <code>8738deb</code></li> <li>Bumped CHANGELOG.md - 1.0.3 <code>ef904b6</code></li> <li>Merge tag '1.0.2' into develop <code>8d6a5f5</code></li> </ul>"},{"location":"external_content/device_settings_test/CHANGELOG/#102","title":"1.0.2","text":"<p>11 December 2023</p> <ul> <li>Fixed reference to License in src files <code>afa23b1</code></li> <li>Bumped CHANGELOG.md - 1.0.2 <code>ad72315</code></li> <li>Merge tag '1.0.1' into develop <code>66b92d5</code></li> </ul>"},{"location":"external_content/device_settings_test/CHANGELOG/#101","title":"1.0.1","text":"<p>11 December 2023</p> <ul> <li>baseline version <code>d0dca2e</code></li> <li>Added CHANGELOG.md - 1.0.1 <code>c5a4cfb</code></li> <li>added profiles/include <code>6976044</code></li> </ul>"},{"location":"external_content/device_settings_test/CONTRIBUTING/","title":"Contributing","text":"<ul> <li>If you wish to make code contributions to this project, the source is hosted at github.com/rdkcentral.</li> </ul> <p>You can submit your changes for review via that site, by raising an issue in github, (https://github.com/rdkcentral/xxxx/issues), and following the sequence below.</p> <ul> <li>create a branch with a name follow the guidelines gh(x)_(synopsis)</li> <li>where x is the ticket number</li> <li>where synopsis is a short synopsis for the reason for the branch.</li> <li>create a pull request (https://github.com/rdkcentral/xxxx/compare) when the code changes are ready for review.</li> <li> <p>The team will review, and if accepted your changes will be merged to the mainline.</p> </li> <li> <p>In order to contribute code, first-time users are requested to agree to the license.</p> </li> <li> <p>where <code>xxxx</code> is your module name</p> </li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/CONTRIBUTING/","title":"Contributing","text":"<ul> <li>If you wish to make code contributions to this project, the source is hosted at github.com/rdkcentral.</li> </ul> <p>You can submit your changes for review via that site, by raising an issue in github, (https://github.com/rdkcentral/xxxx/issues), and following the sequence below.</p> <ul> <li>create a branch with a name follow the guidelines gh(x)_(synopsis)</li> <li>where x is the ticket number</li> <li>where synopsis is a short synopsis for the reason for the branch.</li> <li>create a pull request (https://github.com/rdkcentral/xxxx/compare) when the code changes are ready for review.</li> <li> <p>The team will review, and if accepted your changes will be merged to the mainline.</p> </li> <li> <p>In order to contribute code, first-time users are requested to agree to the license.</p> </li> <li> <p>where <code>xxxx</code> is your module name</p> </li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_High-Level_TestSpecification/","title":"Audio Settings High Level Test Specification Document","text":""},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_High-Level_TestSpecification/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>HAL</code>    - Hardware Abstraction Layer</li> <li><code>API</code>    - Application Programming Interface</li> <li><code>L2</code>     - Level 2 Testing</li> <li><code>L3</code>     - Level 3 Testing</li> <li><code>NA</code>     - Not Applicable</li> <li><code>Y</code>      - Yes</li> <li><code>DS</code>     - Device Settings</li> <li><code>Caller</code> - Any user of the interface via the <code>APIs</code></li> <li><code>CB</code>     - Call-back function (suffix)</li> <li><code>ARC</code>    - Audio Return Channel</li> <li><code>eARC</code>   - Enhanced Audio Return Channel</li> <li><code>SAD</code>    - Short Audio Descriptor</li> <li><code>SPDIF</code>  - Sony/Philips Digital Interface</li> <li><code>HDMI</code>   - High-Definition Multimedia Interface</li> <li><code>LE</code>     - Loudness Equivalence</li> <li><code>DRC</code>    - Dynamic Range Control</li> <li><code>MI</code>     - Media Intelligent</li> <li><code>MS12</code>   - MultiStream 12</li> <li><code>PCM</code>    - Pulse Code Modulation</li> <li><code>AC3</code>    - Audio Codec 3</li> <li><code>EAC3</code>   - Enhanced <code>AC3</code></li> <li><code>WMA</code>    - Windows Media Audio</li> <li><code>AAC</code>    - Advanced Audio coding</li> <li><code>DD</code>     - DOLBY Digital</li> <li><code>DDPLUS</code> - DOLBY Digital Plus</li> <li><code>DAP</code>    - Digital Audio Processing</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_High-Level_TestSpecification/#introduction","title":"Introduction","text":"<p>This document provides an overview of the testing requirements for the Audio Settings module. It outlines the scope of testing, objectives, testing levels and approaches, specific test requirements, and expected deliverables.</p> <ul> <li>Interface of the test is available here - Audio Settings HAL header</li> <li><code>HAL</code> specification in this link - Audio Settings HAL Specification</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_High-Level_TestSpecification/#module-description","title":"Module Description","text":"<p>The Audio device setting interface provides control to enable or disable Audio Output ports like TV Internal Speakers, <code>ARC</code>/<code>eARC</code>, Headphones, <code>SPDIF</code> and allows <code>caller</code> to configure or retrieve various audio parameters like <code>MS12</code> <code>DAP</code> Capabilities, <code>MS12</code> audio profile, stereo mode, audio gain, audio delay, fader control, primary language and secondary language.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_High-Level_TestSpecification/#testing-scope","title":"Testing Scope","text":"# Test Functionality Description 01 Test Audio Port Test for audio port configuration 02 Test MS12 <code>DAP</code> Capabilities Test for MS12 <code>DAP</code> capabilities like compression, dialogue enhancement, volume mode, intelligent equalizer, bass enhancer Surround decode, <code>DRC</code> mode, Surround Virtualizer, <code>MI</code> Steering, Graphic equalizer, <code>LE</code> configuration 03 Test MS12 Capabilities Test for MS12 capabilities 04 Test <code>ARC</code> Support Sink Device Test for <code>ARC</code> Ports 05 Test Stereo Mode Support Test for Stereo mode configurations 06 Test Audio Gain and Mute Test for audio gain level configurations and mute functionality 07 Test Audio Delay Test for audio delay configuration 08 Test Atmos Mode Test for audio atmos capabilities 09 Test Audio Format Test for Audio Formats 10 Test Associated Audio Mixing Test for Associated Audio Mixing 11 Test Primary/Secondary Language Test for primary/secondary language configuration 12 Test Audio Mixer Levels Test for Primary and secondary Audio mixer levels"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_High-Level_TestSpecification/#emulator-requirements","title":"Emulator Requirements","text":"<p>Boot configuration: Various Audio ports, audio formats, Stereo modes and <code>Ms12</code> features supported by device</p> <ul> <li>Supported Audio Ports - dsAudioPortType_t</li> <li>Supported Audio Encoding Formats - dsAudioEncoding_t</li> <li>Supported Stereo Modes - dsSetStereoMode</li> <li>Supported <code>MS12</code> <code>DAP</code> Capabilities - dsMS12Capabilities_t</li> <li>Supported <code>MS12</code> Profiles - dsMS12AudioProfileList_t</li> <li>Supported <code>ARC</code> Types - dsAudioARCTypes_t</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_High-Level_TestSpecification/#audio-format-requirements-for-playback","title":"Audio Format Requirements for Playback","text":""},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_High-Level_TestSpecification/#test-audio-port","title":"Test Audio Port","text":"Description HAL APIs L2 L3 Source Sink Control plane requirements Loop through supported audio ports, Enable/disable audio ports and retrieve status for verification dsGetAudioPort(), dsEnableAudioPort(), dsIsAudioPortEnabled() <code>Y</code> <code>NA</code> <code>Y</code> <code>Y</code> <code>NA</code> Loop through supported audio ports, Enable/disable audio ports and verify using external analyzer with stream playback dsGetAudioPort(), dsEnableAudioPort() <code>NA</code> <code>Y</code> <code>Y</code> <code>Y</code> <code>Y</code> Loop through supported audio ports, get the handle for dsAUDIOPORT_TYPE_HEADPHONE port, check the connection status. Connection status should be false dsGetAudioPort(), dsAudioOutIsConnected() <code>Y</code> <code>NA</code> <code>NA</code> <code>Y</code> <code>NA</code> Loop through supported audio ports, get the handle for dsAUDIOPORT_TYPE_HEADPHONE port, check the connection status by connecting/disconnecting the port connections. dsGetAudioPort(), dsAudioOutIsConnected() <code>NA</code> <code>Y</code> <code>NA</code> <code>Y</code> <code>Y</code> Loop through supported audio ports, get the handle for dsAUDIOPORT_TYPE_HEADPHONE port, Check the connection status with call-back function by connecting/disconnecting the port connection dsGetAudioPort(), dsAudioOutRegisterConnectCB() <code>NA</code> <code>Y</code> <code>NA</code> <code>Y</code> <code>Y</code>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_High-Level_TestSpecification/#test-startup-requirement-test-audio-port","title":"Test Startup Requirement - Test Audio Port","text":"<p>Playback of stream is required for the L3 testcases. Audio Format Requirements for Playback</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_High-Level_TestSpecification/#emulator-requirements-test-audio-port","title":"Emulator Requirements - Test Audio Port","text":"<p>Emulator Requirements</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_High-Level_TestSpecification/#control-plane-requirements-test-audio-port","title":"Control Plane Requirements - Test Audio Port","text":"<ul> <li>Control the external analyzer</li> <li>Control the port connections</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_High-Level_TestSpecification/#test-ms12-dap-capabilities","title":"Test MS12 <code>DAP</code> Capabilities","text":"Description HAL APIs L2 L3 Source Sink Control plane requirements Retrieve the supported MS12 DAP capabilities of the device and verify them with the configuration YAML file. If it is a sink device, retrieve the value from the 'Sink_AudioSettings.yaml' file using the path \"Ports/1/MS12_Capabilities\" supported by the SPEAKER port. If it is a source device, retrieve the value from the 'Source_AudioSettings.yaml' file using the path \"Ports/2/MS12_Capabilities\" supported by the HDMI port. dsGetAudioPort(), dsGetMS12Capabilities() <code>Y</code> <code>NA</code> <code>Y</code> <code>Y</code> <code>NA</code> Loop through supported audio ports, Set various compression levels for supported ports and retrieve compression levels for verification dsGetAudioPort(), dsSetAudioCompression(), dsGetAudioCompression() <code>Y</code> <code>NA</code> <code>Y</code> <code>Y</code> <code>NA</code> Test various compression levels with stream playback. Loop through supported audio ports, Set various compression levels for supported ports and verify with external analyzer dsGetAudioPort(), dsSetAudioCompression() <code>NA</code> <code>Y</code> <code>Y</code> <code>Y</code> <code>Y</code> Loop through supported audio ports, Set Dialog Enhancement for supported ports and retrieve Dialog Enhancement for verification dsGetAudioPort(), dsSetDialogEnhancement(), dsGetDialogEnhancement() <code>Y</code> <code>NA</code> <code>Y</code> <code>Y</code> <code>NA</code> Test Dialog Enhancement for supported ports with stream playback. Loop through supported audio ports, Set Dialog Enhancement for supported ports and verify with external analyzer dsGetAudioPort(), dsSetDialogEnhancement() <code>NA</code> <code>Y</code> <code>Y</code> <code>Y</code> <code>Y</code> Loop through supported audio ports, Set DOLBY Volume Mode for supported ports and retrieve DOLBY Volume Mode for verification dsGetAudioPort(), dsSetDolbyVolumeMode(), dsGetDolbyVolumeMode() <code>Y</code> <code>NA</code> <code>Y</code> <code>Y</code> <code>NA</code> Test DOLBY Volume Mode for supported ports with stream playback. Loop through supported audio ports, Set DOLBY Volume Mode for supported ports and verify with external analyzer dsGetAudioPort(), dsSetDolbyVolumeMode() <code>NA</code> <code>Y</code> <code>Y</code> <code>Y</code> <code>Y</code> Loop through supported audio ports, Set Intelligent Equalizer Mode for supported ports and retrieve Intelligent Equalizer Mode for verification dsGetAudioPort(), dsSetIntelligentEqualizerMode(), dsGetIntelligentEqualizerMode() <code>Y</code> <code>NA</code> <code>Y</code> <code>Y</code> <code>NA</code> Test Intelligent Equalizer Mode with stream playback. Loop through supported audio ports, Set Intelligent Equalizer Mode for supported ports and verify with external analyzer dsGetAudioPort(), dsSetIntelligentEqualizerMode() <code>NA</code> <code>Y</code> <code>Y</code> <code>Y</code> <code>Y</code> Loop through supported audio ports, Set Volume leveller for supported ports and retrieve Volume leveller for verification dsGetAudioPort(), dsSetVolumeLeveller(), dsGetVolumeLeveller() <code>Y</code> <code>NA</code> <code>Y</code> <code>Y</code> <code>NA</code> Test Volume leveller for supported ports with stream playback. Loop through supported audio ports, Set Volume leveller for supported ports and verify with external analyzer dsGetAudioPort(), dsSetVolumeLeveller() <code>NA</code> <code>Y</code> <code>Y</code> <code>Y</code> <code>Y</code> Loop through supported audio ports, Set Bass Enhancer for supported ports and retrieve Bass Enhancer for verification dsGetAudioPort(), dsSetBassEnhancer(), dsGetBassEnhancer() <code>Y</code> <code>NA</code> <code>Y</code> <code>Y</code> <code>NA</code> Test Bass Enhancer for supported ports with stream playback. Loop through supported audio ports, Set Bass Enhancer for supported ports and verify with external analyzer dsGetAudioPort(), dsSetBassEnhancer() <code>NA</code> <code>Y</code> <code>Y</code> <code>Y</code> <code>Y</code> Loop through supported audio ports, Enable Surround Decoder for supported ports and retrieve Surround Decoder status for verification dsGetAudioPort(), dsEnableSurroundDecoder(), dsIsSurroundDecoderEnabled() <code>Y</code> <code>NA</code> <code>Y</code> <code>Y</code> <code>NA</code> Test Surround Decoder for supported ports with stream playback. Loop through supported audio ports, Set Bass Enhancer for supported ports and verify with external analyzer dsGetAudioPort(), dsEnableSurroundDecoder() <code>NA</code> <code>Y</code> <code>Y</code> <code>Y</code> <code>Y</code> Loop through supported audio ports, Set <code>DRC</code> Mode for supported ports and retrieve <code>DRC</code> Mode for verification dsGetAudioPort(), dsSetDRCMode(), dsGetDRCMode() <code>Y</code> <code>NA</code> <code>Y</code> <code>Y</code> <code>NA</code> Test <code>DRC</code> Mode for supported ports with stream playback. Loop through supported audio ports, Set <code>DRC</code> Mode for supported ports and verify with external analyzer dsGetAudioPort(), dsSetDRCMode() <code>NA</code> <code>Y</code> <code>Y</code> <code>Y</code> <code>Y</code> Loop through supported audio ports, Set Surround Virtualizer for supported ports and retrieve Surround Virtualizer for verification dsGetAudioPort(), dsSetSurroundVirtualizer(), dsGetSurroundVirtualizer() <code>Y</code> <code>NA</code> <code>Y</code> <code>Y</code> <code>NA</code> Test Surround Virtualizer for supported ports with stream playback. Loop through supported audio ports, Set Surround Virtualizer for supported ports and verify with external analyzer dsGetAudioPort(), dsSetSurroundVirtualizer() <code>NA</code> <code>Y</code> <code>Y</code> <code>Y</code> <code>Y</code> Loop through supported audio ports, Set <code>MI</code> Steering for supported ports and retrieve <code>MI</code> Steering for verification dsGetAudioPort(), dsSetMISteering(), dsGetMISteering() <code>Y</code> <code>NA</code> <code>Y</code> <code>Y</code> <code>NA</code> Test <code>MI</code> Steering for supported ports with stream playback. Loop through supported audio ports, Set <code>MI</code> Steering for supported ports and verify with external analyzer dsGetAudioPort(), dsSetMISteering() <code>NA</code> <code>Y</code> <code>Y</code> <code>Y</code> <code>Y</code> Loop through supported audio ports, Set Graphic Equalizer for supported ports and retrieve Graphic Equalizer for verification dsGetAudioPort(), dsSetGraphicEqualizerMode(), dsGetGraphicEqualizerMode() <code>Y</code> <code>NA</code> <code>Y</code> <code>Y</code> <code>NA</code> Test Graphic Equalizer for supported ports with stream playback. Loop through supported audio ports, Set Graphic Equalizer for supported ports and verify with external analyzer dsGetAudioPort(), dsSetGraphicEqualizerMode() <code>NA</code> <code>Y</code> <code>Y</code> <code>Y</code> <code>Y</code> Loop through supported audio ports, Enable/disable audio loudness equivalence and retrieve audio loudness equivalence status for verification dsGetAudioPort(), dsEnableLEConfig(), dsGetLEConfig() <code>Y</code> <code>NA</code> <code>Y</code> <code>Y</code> <code>NA</code> Test audio loudness equivalence for supported ports with stream playback. Loop through supported audio ports, Enable/Disable audio loudness equivalence for supported ports and verify with external analyzer dsGetAudioPort(), dsEnableLEConfig() <code>NA</code> <code>Y</code> <code>Y</code> <code>Y</code> <code>Y</code>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_High-Level_TestSpecification/#test-startup-requirement-test-ms12-dap-capabilities","title":"Test Startup Requirement - Test MS12 <code>DAP</code> Capabilities","text":"<p>Playback of stream is required for the L3 testcases. Audio Format Requirements for Playback</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_High-Level_TestSpecification/#emulator-requirements-test-ms12-dap-capabilities","title":"Emulator Requirements - Test MS12 <code>DAP</code> Capabilities","text":"<p>Emulator Requirements</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_High-Level_TestSpecification/#control-plane-requirements-test-ms12-dap-capabilities","title":"Control Plane Requirements - Test MS12 <code>DAP</code> Capabilities","text":"<ul> <li>Control the external analyzer</li> <li>Control the port connections</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_High-Level_TestSpecification/#test-ms12-capabilities","title":"Test MS12 Capabilities","text":"Description HAL APIs L2 L3 Source Sink Control plane requirements Loop through the supported audio ports and check whether the port supports MS12 decode using the configuration YAML file. For a sink device, retrieve the value from the 'Sink_AudioSettings.yaml' file using the path \"Ports/1/IsMS12Decode\" supported by the SPEAKER port. For a source device, retrieve the value from the 'Source_AudioSettings.yaml' file using the path \"Ports/2/IsMS12Decode\" supported by the HDMI port. dsGetAudioPort(), dsIsAudioMS12Decode() <code>Y</code> <code>NA</code> <code>Y</code> <code>Y</code> <code>NA</code> Loop through the supported audio ports and check whether the port supports MS11 decode using the configuration YAML file. For a sink device, retrieve the value from the 'Sink_AudioSettings.yaml' file using the path \"Ports/1/IsMS11Decode\" supported by the SPEAKER port. For a source device, retrieve the value from the 'Source_AudioSettings.yaml' file using the path \"Ports/2/IsMS11Decode\" supported by the HDMI port. dsGetAudioPort(), dsIsAudioMSDecode() <code>Y</code> <code>NA</code> <code>Y</code> <code>Y</code> <code>NA</code> Get the supported MS12 audio profiles and verify them with the configuration YAML file. For a sink device, retrieve the value from the 'Sink_AudioSettings.yaml' file using the path \"Ports/1/MS12_AudioProfiles\" supported by the SPEAKER port. For source devices, it is not supported. dsGetAudioPort(), dsGetMS12AudioProfileList() <code>Y</code> <code>NA</code> <code>NA</code> <code>Y</code> <code>NA</code> Get Supported <code>MS12</code> Audio profiles, Loop through supported audio ports, set various audio profiles for supported ports and retrieve audio profile for verification dsGetAudioPort(), dsGetMS12AudioProfileList(), dsSetMS12AudioProfile(), dsGetMS12AudioProfile() <code>Y</code> <code>NA</code> <code>NA</code> <code>Y</code> <code>NA</code>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_High-Level_TestSpecification/#test-startup-requirement-test-ms12-capabilities","title":"Test Startup Requirement - Test MS12 Capabilities","text":"<p><code>NA</code></p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_High-Level_TestSpecification/#emulator-requirements-test-ms12-capabilities","title":"Emulator Requirements - Test MS12 Capabilities","text":"<p>Emulator Requirements</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_High-Level_TestSpecification/#control-plane-requirements-test-ms12-capabilities","title":"Control Plane Requirements - Test MS12 Capabilities","text":"<p><code>NA</code></p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_High-Level_TestSpecification/#test-arc-support-sink-device","title":"Test <code>ARC</code> Support Sink Device","text":"Description HAL APIs L2 L3 Source Sink Control plane requirements Get the ARC port handle by looping through the supported audio ports, get the ARC type of the connected device, and verify it with the configuration YAML file. For a sink device, retrieve the value from the 'Sink_AudioSettings.yaml' file using the path \"Ports/2/Arc_Types\" as the sink device supports Arc_Types only on the HDMI_ARC port. It does not support for source device. dsGetAudioPort(), dsGetSupportedARCTypes() <code>NA</code> <code>Y</code> <code>NA</code> <code>Y</code> <code>Y</code> Get the <code>ARC</code> port handle by looping through supported audio ports, enable the <code>ARC</code> Port and check if the audio routed to <code>ARC</code> port using external analyzers dsGetAudioPort(), dsAudioEnableARC() <code>NA</code> <code>Y</code> <code>NA</code> <code>Y</code> <code>Y</code> Get the <code>ARC</code> port handle by looping through supported audio ports, enable the <code>ARC</code> Port, Set <code>SAD</code> for <code>ARC</code> port and verify using external analyzers dsGetAudioPort(), dsAudioEnableARC(), dsAudioSetSAD() <code>NA</code> <code>Y</code> <code>NA</code> <code>Y</code> <code>Y</code>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_High-Level_TestSpecification/#test-startup-requirement-test-arc-support","title":"Test Startup Requirement - Test <code>ARC</code> Support","text":"<p>Playback of stream is required for the L3 testcases. Audio Format Requirements for Playback</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_High-Level_TestSpecification/#emulator-requirements-test-arc-support","title":"Emulator Requirements - Test <code>ARC</code> Support","text":"<p>Emulator Requirements</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_High-Level_TestSpecification/#control-plane-requirements-test-arc-support","title":"Control Plane Requirements - Test <code>ARC</code> Support","text":"<ul> <li>Control the external analyzer</li> <li>Control the port connections</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_High-Level_TestSpecification/#test-stereo-mode-support","title":"Test Stereo Mode Support","text":"Description HAL APIs L2 L3 Source Sink Control plane requirements Loop through supported audio ports, Set Stereo mode for supported ports and retrieve Stereo mode for verification dsGetAudioPort(), dsSetStereoMode(), dsGetStereoMode() <code>Y</code> <code>NA</code> <code>Y</code> <code>Y</code> <code>NA</code> Loop through supported audio ports, Set various stereo modes for all supported ports and verify using the external analyzer dsGetAudioPort(), dsSetStereoMode() <code>NA</code> <code>Y</code> <code>Y</code> <code>Y</code> <code>Y</code> Loop through supported audio ports, Set Stereo Auto mode for supported ports and retrieve it for verification dsGetAudioPort(), dsSetStereoAuto(), dsGetStereoAuto() <code>Y</code> <code>NA</code> <code>NA</code> <code>Y</code> <code>NA</code> Loop through supported audio ports, Set Auto Stereo mode for all supported ports and verify using the external analyzer dsGetAudioPort(), dsSetStereoAuto() <code>NA</code> <code>Y</code> <code>NA</code> <code>Y</code> <code>Y</code>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_High-Level_TestSpecification/#test-startup-requirement-test-stereo-mode-support","title":"Test Startup Requirement - Test Stereo Mode Support","text":"<p>Playback of stream is required for the L3 testcases. Audio Format Requirements for Playback</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_High-Level_TestSpecification/#emulator-requirements-test-stereo-mode-support","title":"Emulator Requirements - Test Stereo Mode Support","text":"<p>Emulator Requirements</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_High-Level_TestSpecification/#control-plane-requirements-test-stereo-mode-support","title":"Control Plane Requirements - Test Stereo Mode Support","text":"<ul> <li>Control the external analyzer</li> <li>Control the port connections</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_High-Level_TestSpecification/#test-audio-gain-and-mute","title":"Test Audio Gain and Mute","text":"Description HAL APIs L2 L3 Source Sink Control plane requirements Loop through supported audio ports, Set various Linear Audio Gain Values for supported ports and retrieve Audio Gain for verification dsGetAudioPort(), dsSetAudioGain(), dsGetAudioGain() <code>Y</code> <code>NA</code> <code>NA</code> <code>Y</code> <code>NA</code> Loop through supported audio ports, Set various Linear Audio Gain Values for all supported ports and verify levels using the external analyzer dsGetAudioPort(), dsSetAudioGain() <code>NA</code> <code>Y</code> <code>NA</code> <code>Y</code> <code>Y</code> Loop through supported audio ports, Set various Audio Levels for supported ports and retrieve Audio Level for verification dsGetAudioPort(), dsSetAudioLevel(), dsGetAudioLevel() <code>Y</code> <code>NA</code> <code>NA</code> <code>Y</code> <code>NA</code> Loop through supported audio ports, Set various Audio Level for all supported ports and verify using the external analyzer dsGetAudioPort(), dsSetAudioLevel() <code>NA</code> <code>Y</code> <code>NA</code> <code>Y</code> <code>Y</code> Loop through supported audio ports, Enable/disable audio mute for supported ports and retrieve Mute status for verification dsGetAudioPort(), dsSetAudioMute(), dsIsAudioMute() <code>Y</code> <code>NA</code> <code>Y</code> <code>Y</code> <code>NA</code> Loop through supported audio ports, Enable/disable audio mute and verify mute status using external analyzer dsGetAudioPort(), dsSetAudioMute() <code>NA</code> <code>Y</code> <code>Y</code> <code>Y</code> <code>Y</code>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_High-Level_TestSpecification/#test-startup-requirement-test-audio-gain-and-mute","title":"Test Startup Requirement - Test Audio Gain and Mute","text":"<p>Playback of stream is required for the L3 testcases. Audio Format Requirements for Playback</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_High-Level_TestSpecification/#emulator-requirements-test-audio-gain-and-mute","title":"Emulator Requirements - Test Audio Gain and Mute","text":"<p>Emulator Requirements</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_High-Level_TestSpecification/#control-plane-requirements-test-audio-gain-and-mute","title":"Control Plane Requirements - Test Audio Gain and Mute","text":"<ul> <li>Control the external analyzer</li> <li>Control the port connections</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_High-Level_TestSpecification/#test-audio-delay","title":"Test Audio Delay","text":"Description HAL APIs L2 L3 Source Sink Control plane requirements Loop through supported audio ports, Set Audio delay for supported ports and retrieve delay for verification dsGetAudioPort(), dsSetAudioDelay(), dsGetAudioDelay() <code>Y</code> <code>NA</code> <code>Y</code> <code>Y</code> <code>NA</code> Loop through supported audio ports, Set Audio delay for supported ports and measure audio-video delay using external analyzers dsGetAudioPort(), dsSetAudioDelay() <code>NA</code> <code>Y</code> <code>Y</code> <code>Y</code> <code>Y</code>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_High-Level_TestSpecification/#test-startup-requirement-test-audio-delay","title":"Test Startup Requirement - Test Audio Delay","text":"<p>Playback of stream is required for the L3 testcases. Audio Format Requirements for Playback</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_High-Level_TestSpecification/#emulator-requirements-test-audio-delay","title":"Emulator Requirements - Test Audio Delay","text":"<p>Emulator Requirements</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_High-Level_TestSpecification/#control-plane-requirements-test-audio-delay","title":"Control Plane Requirements - Test Audio Delay","text":"<ul> <li>Control the external analyzer</li> <li>Control the port connections</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_High-Level_TestSpecification/#test-atmos-mode","title":"Test Atmos Mode","text":"Description HAL APIs L2 L3 Source Sink Control plane requirements Loop through supported audio ports, Set Atmos for supported ports and analyze with external device dsAudioPortInit(), dsSetAudioAtmosOutputMode() <code>NA</code> <code>Y</code> <code>Y</code> <code>Y</code> <code>Y</code> For sink devices, get the ATMOS capabilities of dsAUDIOPORT_TYPE_SPEAKER (internal speaker) and verify them with the configuration YAML file. Retrieve the value from the 'Sink_AudioSettings.yaml' file using the path \"Ports/1/ATMOS_Capabilities\" as the SPEAKER port number is 1. It is not supported for source device. dsGetAudioPort(), dsGetSinkDeviceAtmosCapability() <code>Y</code> <code>NA</code> <code>NA</code> <code>Y</code> <code>NA</code> Loop through supported audio ports, Get the ATMOS capabilities of connected devices and verify with configuration file. dsGetAudioPort(), dsGetSinkDeviceAtmosCapability() <code>NA</code> <code>Y</code> <code>Y</code> <code>Y</code> <code>Y</code> Register Atmos capability call-back, change the Atmos capabilities of connected device, and check whether the call-back is triggered or not dsAudioAtmosCapsChangeRegisterCB () <code>NA</code> <code>Y</code> <code>Y</code> <code>Y</code> <code>Y</code>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_High-Level_TestSpecification/#test-startup-requirement-test-atmos-mode","title":"Test Startup Requirement - Test Atmos Mode","text":"<p>Playback of stream is required for the L3 testcases. Audio Format Requirements for Playback</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_High-Level_TestSpecification/#emulator-requirements-test-atmos-mode","title":"Emulator Requirements - Test Atmos Mode","text":"<p>Emulator Requirements</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_High-Level_TestSpecification/#control-plane-requirements-test-atmos-mode","title":"Control Plane Requirements - Test Atmos Mode","text":"<ul> <li>Control the external analyzer</li> <li>Control the port connections</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_High-Level_TestSpecification/#test-audio-format","title":"Test Audio Format","text":"Description HAL APIs L2 L3 Source Sink Control plane requirements Get the audio format of stream played and verify with external analyzer dsGetAudioFormat() <code>NA</code> <code>Y</code> <code>Y</code> <code>Y</code> <code>NA</code> Get the audio capabilities of the device and verify with configuration YAML file. If it is a sink device, the value to be retrieved from the 'Sink_AudioSettings.yaml' file with the path of \"Audio_Capabilities\". For the source devices, the value to be retrieved from the 'Source_AudioSettings.yaml' file with the path of \"Audio_Capabilities\". dsGetAudioCapabilities() <code>Y</code> <code>NA</code> <code>Y</code> <code>Y</code> <code>NA</code> Register a call-back, Change the audio format of playback and check whether call-back is triggered or not dsAudioFormatUpdateRegisterCB(), dsGetAudioFormat() <code>NA</code> <code>Y</code> <code>Y</code> <code>Y</code> <code>NA</code>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_High-Level_TestSpecification/#test-startup-requirement-test-audio-format","title":"Test Startup Requirement - Test Audio Format","text":"<p>Playback of stream is required for the L3 testcases. Audio Format Requirements for Playback</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_High-Level_TestSpecification/#emulator-requirements-test-audio-format","title":"Emulator Requirements - Test Audio Format","text":"<p>Emulator Requirements</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_High-Level_TestSpecification/#control-plane-requirements-test-audio-format","title":"Control Plane Requirements - Test Audio Format","text":""},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_High-Level_TestSpecification/#test-associated-audio-mixing","title":"Test Associated Audio Mixing","text":"Description HAL APIs L2 L3 Source Sink Control plane requirements Loop through supported audio ports, Enable/disable Associated Audio Mixing for supported ports and retrieve it for verification dsGetAudioPort(), dsSetAssociatedAudioMixing(), dsGetAssociatedAudioMixing() <code>Y</code> <code>NA</code> <code>Y</code> <code>Y</code> <code>NA</code> Loop through supported audio ports, Enable Associated Audio Mixing for supported ports, Set various Fader Control values for supported ports and retrieve it for verification dsGetAudioPort(), dsSetAssociatedAudioMixing(), dsSetFaderControl(), dsGetFaderControl() <code>Y</code> <code>NA</code> <code>Y</code> <code>Y</code> <code>NA</code> Loop through supported audio ports, Test Associate Audio mixing and fader control with stream playback and verify with external analyzer dsGetAudioPort(), dsSetAssociatedAudioMixing(), dsSetFaderControl() <code>NA</code> <code>Y</code> <code>Y</code> <code>Y</code> <code>Y</code>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_High-Level_TestSpecification/#test-startup-requirement-associated-audio-mixing-test","title":"Test Startup Requirement - Associated Audio Mixing Test","text":"<p>Playback of stream is required for the L3 testcases. Audio Format Requirements for Playback</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_High-Level_TestSpecification/#emulator-requirements-associated-audio-mixing-test","title":"Emulator Requirements - Associated Audio Mixing Test","text":"<p>Emulator Requirements</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_High-Level_TestSpecification/#control-plane-requirements-associated-audio-mixing-test","title":"Control Plane Requirements - Associated Audio Mixing Test","text":"<ul> <li>Control the external analyzer</li> <li>Control the port connections</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_High-Level_TestSpecification/#test-primarysecondary-language","title":"Test Primary/Secondary Language","text":"Description HAL APIs L2 L3 Source Sink Control plane requirements Set Primary Language and retrieve the same for verification dsGetAudioPort(), dsSetPrimaryLanguage(), dsGetPrimaryLanguage() <code>Y</code> <code>NA</code> <code>Y</code> <code>Y</code> <code>NA</code> Set Primary Language with stream playback and verify with external analyzer dsGetAudioPort(), dsSetPrimaryLanguage() <code>NA</code> <code>Y</code> <code>Y</code> <code>Y</code> <code>Y</code> Set Secondary Language and retrieve the same for verification dsGetAudioPort(), dsSetSecondaryLanguage(), dsGetSecondaryLanguage() <code>Y</code> <code>NA</code> <code>Y</code> <code>Y</code> <code>NA</code> Set Primary Language with stream playback and verify with external analyzer dsGetAudioPort(), dsSetSecondaryLanguage() <code>NA</code> <code>Y</code> <code>Y</code> <code>Y</code> <code>Y</code>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_High-Level_TestSpecification/#test-startup-requirement-language-test","title":"Test Startup Requirement - Language Test","text":"<p>Playback of stream is required for the L3 testcases. Audio Format Requirements for Playback</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_High-Level_TestSpecification/#emulator-requirements-language-test","title":"Emulator Requirements - Language Test","text":"<p>Emulator Requirements</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_High-Level_TestSpecification/#control-plane-requirements-language-test","title":"Control Plane Requirements - Language Test","text":"<ul> <li>Control the external analyzer</li> <li>Control the port connections</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_High-Level_TestSpecification/#test-audio-mixer-levels","title":"Test Audio Mixer Levels","text":"Description HAL APIs L2 L3 Source Sink Control plane requirements Set Audio mixer levels for Primary and system audio with stream playback and verify with external analyzer dsGetAudioPort(), dsSetAudioMixerLevels() <code>NA</code> <code>Y</code> <code>NA</code> <code>Y</code> <code>Y</code>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_High-Level_TestSpecification/#test-startup-requirement-test-audio-mixer-levels","title":"Test Startup Requirement - Test Audio Mixer Levels","text":"<p>Playback of stream is required for the L3 testcases. Audio Format Requirements for Playback</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_High-Level_TestSpecification/#emulator-requirements-test-audio-mixer-levels","title":"Emulator Requirements -Test Audio Mixer Levels","text":"<p>Emulator Requirements</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_High-Level_TestSpecification/#control-plane-requirements-test-audio-mixer-levels","title":"Control Plane Requirements - Test Audio Mixer Levels","text":"<ul> <li>Control the external analyzer</li> <li>Control the port connections</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L2_Low-Level_TestSpecification/","title":"Audio Settings L2 Low Level Test Specification and Procedure Documentation","text":""},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L2_Low-Level_TestSpecification/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>HAL</code>    - Hardware Abstraction Layer</li> <li><code>API</code>    - Application Programming Interface</li> <li><code>L2</code>     - Level 2 Testing</li> <li><code>L3</code>     - Level 3 Testing</li> <li><code>DS</code>     - Device Settings</li> <li><code>ARC</code>    - Audio Return Channel</li> <li><code>HDMI</code>   - High-Definition Multimedia Interface</li> <li><code>LE</code>     - Loudness Equivalence</li> <li><code>DRC</code>    - Dynamic Range Control</li> <li><code>MI</code>     - Media Intelligent</li> <li><code>MS12</code>   - MultiStream 12</li> <li><code>MS11</code>   - MultiStream 11</li> <li><code>DAP</code>    - Digital Audio Processing</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L2_Low-Level_TestSpecification/#overview","title":"Overview","text":"<p>This document describes the Low Level L2 Test Specification and Procedure for the Device Settings Audio module.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L2_Low-Level_TestSpecification/#definitions","title":"Definitions","text":"<ul> <li><code>ut-core</code> - Common Testing Framework https://github.com/rdkcentral/ut-core, which wraps a open-source framework that can be expanded to the requirements for future framework.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L2_Low-Level_TestSpecification/#references","title":"References","text":"<ul> <li>dsAudio HAL Interface - dsAudio.h</li> <li>High Level Test Specification - ds-audio_High-Level_TestSpecification.md</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L2_Low-Level_TestSpecification/#level-2-test-procedure","title":"Level 2 Test Procedure","text":"<p>The following functions are expecting to test the module operates correctly.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L2_Low-Level_TestSpecification/#test-1","title":"Test 1","text":"Title Details Function Name <code>test_l2_dsAudio_EnableDisableAndVerifyAudioPortStatus</code> Description Loop through supported audio ports, enable/disable audio ports and retrieve status for verification Test Group 02 Test Case ID 001 Priority High <p>Pre-Conditions : None</p> <p>Dependencies : None</p> <p>User Interaction : If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L2_Low-Level_TestSpecification/#test-procedure-test-1","title":"Test Procedure - Test 1","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize audio port using <code>dsAudioPortInit</code> None <code>dsERR_NONE</code> Should be successful 02 Loop through supported audio ports and get audio port using <code>dsGetAudioPort</code> supported number of audio ports = <code>dsAudio/Number_of_supported_ports</code> field and port id = <code>dsAudio/Port/[port number]/Typeid</code> of configuration file <code>dsERR_NONE</code> Should be successful 03 Enable audio port using <code>dsEnableAudioPort</code> handle = obtained from <code>dsGetAudioPort</code>, enabled = true <code>dsERR_NONE</code> Should be successful 04 Check if audio port is enabled using <code>dsIsAudioPortEnabled</code> handle = obtained from <code>dsGetAudioPort</code> <code>dsERR_NONE</code>, enabled = <code>true</code> Should be successful 05 Disable audio port using <code>dsEnableAudioPort</code> handle = obtained from <code>dsGetAudioPort</code>, enabled = <code>false</code> <code>dsERR_NONE</code> Should be successful 06 Check if audio port is disabled using <code>dsIsAudioPortEnabled</code> handle = obtained from <code>dsGetAudioPort</code> <code>dsERR_NONE</code>, enabled = <code>false</code> Should be successful 07 Terminate audio port using <code>dsAudioPortTerm</code> None <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\n    A[Call dsAudioPortInit] --&gt;|dsERR_NONE|B{Loop: Call dsGetAudioPort &lt;br&gt; for each supported type}\n    A --&gt;|Failure|A1[Test case fail]\n    B --&gt;|dsERR_NONE and valid handle|C[Call dsEnableAudioPort with handle and true]\n    B --&gt;|Not dsERR_NONE or invalid handle|B\n    C --&gt;|dsERR_NONE|D[Call dsIsAudioPortEnabled with handle]\n    D --&gt;|dsERR_NONE and true|E[Call `dsEnableAudioPort` with handle and false]\n    E --&gt;|dsERR_NONE|F[Call dsIsAudioPortEnabled with handle]\n    F --&gt;|dsERR_NONE and false|B\n    F --&gt;|Fail|F1[Test case fail]\n    F1 --&gt; B\n    B --&gt;|End of loop|G[Call dsAudioPortTerm]\n    G --&gt;|dsERR_NONE|H[Test case success]\n    G --&gt;|Failure|G1[Test case fail]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L2_Low-Level_TestSpecification/#test-2","title":"Test 2","text":"Title Details Function Name <code>test_l2_dsAudio_CheckHeadphoneConnectionStatus_sink</code> Description Loop through supported audio ports, get the handle for <code>dsAUDIOPORT_TYPE_HEADPHONE</code> port, check the connection status. Connection status should be false Test Group 02 Test Case ID 003 Priority High <p>Pre-Conditions : None</p> <p>Dependencies : None</p> <p>User Interaction : If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L2_Low-Level_TestSpecification/#test-procedure-test-2","title":"Test Procedure - Test 2","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the audio port using <code>dsAudioPortInit</code> None <code>dsERR_NONE</code> Should be successful 02 Loop through supported audio ports and get audio port using <code>dsGetAudioPort</code> supported number of audio ports = <code>dsAudio/Number_of_supported_ports</code> field and port id = <code>dsAudio/Port/[port number]/Typeid</code> of configuration file <code>dsERR_NONE</code> Should be successful 03 If the port type is <code>dsAUDIOPORT_TYPE_HEADPHONE</code>, check the connection status using <code>dsAudioOutIsConnected</code> handle = obtained from <code>dsGetAudioPort</code> <code>dsERR_NONE</code> Should be successful 04 Assert that the connection status is false isConnected = <code>false</code> <code>false</code> Should be successful 05 Terminate the audio port using <code>dsAudioPortTerm</code> None <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\n    A[Call dsAudioPortInit] --&gt;|dsERR_NONE|B{Loop through &lt;br&gt; supported audio ports &lt;br&gt;call dsGetAudioPort}\n    A --&gt;|Failure|A1[Test case fail]\n    B --&gt;|dsERR_NONE and valid handle|C{Check if port type is &lt;br&gt; dsAUDIOPORT_TYPE_HEADPHONE}\n    B --&gt;|Not dsERR_NONE or invalid handle|B\n    C --&gt;|Yes|D[Call dsAudioOutIsConnected with &lt;br&gt; handle from step 3]\n    C --&gt;|No|B\n    B --&gt;|End of loop|E[Call dsAudioPortTerm]\n    D --&gt;|dsERR_NONE and false output|B\n    D --&gt; |Fail|D1[Test case fail]\n    D1 --&gt; B\n    E --&gt;|dsERR_NONE|F[Test case success]\n    E --&gt;|Failure|E1[Test case fail]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L2_Low-Level_TestSpecification/#test-3","title":"Test 3","text":"Title Details Function Name <code>test_l2_dsAudio_RetrieveAndVerifyMS12Capabilities</code> Description Retrieve the supported MS12 DAP capabilities of the device and verify them with the configuration file Test Group 02 Test Case ID 003 Priority High <p>Pre-Conditions : None</p> <p>Dependencies : None</p> <p>User Interaction : If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L2_Low-Level_TestSpecification/#test-procedure-test-3","title":"Test Procedure - Test 3","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the audio port using <code>dsAudioPortInit</code> None <code>dsERR_NONE</code> Should be successful 02 Loop through supported audio ports and get audio port using <code>dsGetAudioPort</code> supported number of audio ports = <code>dsAudio/Number_of_supported_ports</code> field and port id = <code>dsAudio/Port/[port number]/Typeid</code> of configuration file <code>dsERR_NONE</code> Should be successful 03 Get the MS12 capabilities using <code>dsGetMS12Capabilities</code> handle = obtained from <code>dsGetAudioPort</code> <code>dsERR_NONE</code> Should be successful 04 Compare MS12 capabilities from API and value retrieved from configuration file MS12 capabilities = <code>dsAudio/Port/[port number]/MS12_Capabilities</code> of configuration file Match Should be successful 05 Terminate the audio port using <code>dsAudioPortTerm</code> None <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\n    Step1[Call dsAudioPortInit API] -- dsERR_NONE --&gt; Step2{Loop through &lt;br&gt; supported audio ports &lt;br&gt;call dsGetAudioPort}\n    Step1 -- Not dsERR_NONE --&gt; Fail1[Test Case Failed]\n    Step2 -- dsERR_NONE and valid handle --&gt; Step3[Call dsGetMS12Capabilities API with the handle]\n    Step2 --&gt;|End of loop|Step6\n    Step2 --&gt;|Not dsERR_NONE or invalid handle|Step2\n    Step3 -- dsERR_NONE and valid capabilities --&gt; Step4[Retrieve MS12 capabilities from configuration file]\n    Step3 -- Not dsERR_NONE or invalid capabilities --&gt; Fail3[Test Case Failed]\n    Step4 --&gt; Step5[Compare capabilities from API and YAML file]\n    Step5 -- Match --&gt; Step2\n    Step5 -- Not Match --&gt; Fail4[Test Case Failed]\n    Fail4 --&gt; Step2\n    Step6 -- dsERR_NONE --&gt; End[Test Case Passed]\n    Step6 -- Not dsERR_NONE --&gt; Fail5[Test Case Failed]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L2_Low-Level_TestSpecification/#test-4","title":"Test 4","text":"Title Details Function Name <code>test_l2_dsAudio_SetAndGetAudioCompression</code> Description Loop through supported audio ports, set various compression levels for supported ports and retrieve compression levels for verification Test Group 02 Test Case ID 004 Priority High <p>Pre-Conditions : None</p> <p>Dependencies : None</p> <p>User Interaction : If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L2_Low-Level_TestSpecification/#test-procedure-test-4","title":"Test Procedure - Test 4","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the audio port using <code>dsAudioPortInit</code> None <code>dsERR_NONE</code> Should be successful 02 Loop through supported audio ports and get audio port using <code>dsGetAudioPort</code> supported number of audio ports = <code>dsAudio/Number_of_supported_ports</code> field and port id = <code>dsAudio/Port/[port number]/Typeid</code> of configuration file <code>dsERR_NONE</code> Should be successful 03 For each port, set various compression levels using <code>dsSetAudioCompression</code> handle = obtained from <code>dsGetAudioPort</code>, compression = 0 to 10. supported compressions = <code>dsAudio/Ports/[port number]/number_of_supported_compressions</code> from configuration file. compression types = <code>dsAudio/Ports/[port number]/compressions</code> of configuration file <code>dsERR_NONE</code> Should be successful 04 Retrieve the set compression level using <code>dsGetAudioCompression</code> handle = obtained from <code>dsGetAudioPort</code> <code>dsERR_NONE</code> Should be successful 05 Verify the set and retrieved compression levels are same compression = set value, getCompression = retrieved value compression should be equal to getCompression Should be successful 06 Terminate the audio port using <code>dsAudioPortTerm</code> None <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\n    A[call dsAudioPortInit] --&gt;|dsERR_NONE|B{Loop through the &lt;br&gt;supported audio ports &lt;br&gt; call dsGetAudioPort}\n    A --&gt;|Not dsERR_NONE|A1[Test case fail]\n    B --&gt;|dsERR_NONE and valid handle|C[Set various compression level &lt;br&gt; by calling the API dsSetAudioCompression]\n    B --&gt;|Not dsERR_NONE or invalid handle|B\n    C --&gt;|dsERR_NONE|E[Retrieve the compression level&lt;br&gt; call dsGetAudioCompression]\n    E --&gt;|dsERR_NONE and same compression level|B\n    E --&gt;|Fail|E1[Test case fail]\n    E1 --&gt; B\n    B --&gt;|End of loop|F[ call dsAudioPortTerm]\n    F --&gt;|dsERR_NONE|G[Test case success]\n    F --&gt;|Not dsERR_NONE|F1[Test case fail]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L2_Low-Level_TestSpecification/#test-5","title":"Test 5","text":"Title Details Function Name <code>test_l2_dsAudio_SetAndGetDialogEnhancement</code> Description Loop through supported audio ports, Set Dialog Enhancement for supported ports and retrieve Dialog Enhancement for verification Test Group 02 Test Case ID 005 Priority High <p>Pre-Conditions : None</p> <p>Dependencies : None</p> <p>User Interaction : If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L2_Low-Level_TestSpecification/#test-procedure-test-5","title":"Test Procedure - Test 5","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the audio port using <code>dsAudioPortInit</code> None <code>dsERR_NONE</code> Should be successful 02 Loop through supported audio ports and get audio port using <code>dsGetAudioPort</code> supported number of audio ports = <code>dsAudio/Number_of_supported_ports</code> field and port id = <code>dsAudio/Port/[port number]/Typeid</code> of configuration file <code>dsERR_NONE</code> Should be successful 03 For each audio port, set the Dialog Enhancement level using <code>dsSetDialogEnhancement</code> handle = obtained from <code>dsGetAudioPort</code>, level = 0 to 16 <code>dsERR_NONE</code> Should be successful 04 For each audio port, get the Dialog Enhancement level using <code>dsGetDialogEnhancement</code> handle = obtained from <code>dsGetAudioPort</code> <code>dsERR_NONE</code> Should be successful 05 Verify the set and get Dialog Enhancement levels are same getLevel = obtained from <code>dsGetDialogEnhancement</code>, level = set in <code>dsSetDialogEnhancement</code> getLevel should be equal to level Should be successful 06 Terminate the audio port using <code>dsAudioPortTerm</code> None <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\n    A[dsAudioPortInit] --&gt;|dsERR_NONE|B{Loop through audio ports &lt;br&gt; call dsGetAudioPort}\n    A --&gt;|!= dsERR_NONE|A1[Test case fail]\n    B --&gt;|Not dsERR_NONE or invalid handle|B\n    B --&gt;|dsERR_NONE and valid handle|C[Call dsSetDialogEnhancement with handle and level 0-16]\n    C --&gt;|dsERR_NONE|D[Call dsGetDialogEnhancement with handle]\n    D --&gt;|dsERR_NONE|E[Verify dialog enhancement values ]\n    E --&gt;|Match|B\n    E --&gt;|No Match|E1[Test case fail]\n    E1 --&gt; B\n    B --&gt;|End of loop|F[Call dsAudioPortTerm]\n    F --&gt;|dsERR_NONE|G[Test case success]\n    F --&gt;|!= dsERR_NONE|F1[Test case fail]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L2_Low-Level_TestSpecification/#test-6","title":"Test 6","text":"Title Details Function Name <code>test_l2_dsAudio_SetAndGetDolbyVolumeMode</code> Description Loop through supported audio ports, Set DOLBY Volume Mode for supported ports and retrieve DOLBY Volume Mode for verification Test Group 02 Test Case ID 006 Priority High <p>Pre-Conditions : None</p> <p>Dependencies : None</p> <p>User Interaction : If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L2_Low-Level_TestSpecification/#test-procedure-test-6","title":"Test Procedure - Test 6","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the audio port using <code>dsAudioPortInit</code> None <code>dsERR_NONE</code> Should be successful 02 Loop through supported audio ports and get audio port using <code>dsGetAudioPort</code> supported number of audio ports = <code>dsAudio/Number_of_supported_ports</code> field and port id = <code>dsAudio/Port/[port number]/Typeid</code> of configuration file <code>dsERR_NONE</code> Should be successful 03 Set DOLBY Volume Mode for the retrieved audio port using <code>dsSetDolbyVolumeMode</code> handle = retrieved handle, mode = <code>true</code> <code>dsERR_NONE</code> Should be successful 04 Retrieve DOLBY Volume Mode for the set audio port using <code>dsGetDolbyVolumeMode</code> handle = retrieved handle <code>dsERR_NONE</code> and mode = <code>true</code> Should be successful 05 Set DOLBY Volume Mode for the retrieved audio port using <code>dsSetDolbyVolumeMode</code> handle = retrieved handle, mode = <code>false</code> <code>dsERR_NONE</code> Should be successful 06 Retrieve DOLBY Volume Mode for the set audio port using <code>dsGetDolbyVolumeMode</code> handle = retrieved handle dsERR_NONE and mode = <code>false</code> Should be successful 07 Terminate the audio port using <code>dsAudioPortTerm</code> None <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\n    A[dsAudioPortInit] --&gt;|dsERR_NONE|B{Loop through audio ports &lt;br&gt; call dsGetAudioPort}\n    A --&gt;|!=dsERR_NONE|A1[Test case fail]\n    B --&gt;|dsERR_NONE and valid handle|C[dsSetDolbyVolumeMode true]\n    B --&gt;|Not dsERR_NONE or invalid handle|B\n    C --&gt;|dsERR_NONE|D[dsGetDolbyVolumeMode]\n    D --&gt;|dsERR_NONE and mode true|E[dsSetDolbyVolumeMode false]\n    E --&gt;|dsERR_NONE|F[dsGetDolbyVolumeMode]\n    F --&gt;|dsERR_NONE and mode false|B\n    F --&gt;|Fail|F1[Test case fail]\n    F1 --&gt; B\n    B --&gt;|End of loop|G[dsAudioPortTerm]\n    G --&gt;|dsERR_NONE|H[Test case success]\n    G --&gt;|!=dsERR_NONE|G1[Test case fail]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L2_Low-Level_TestSpecification/#test-7","title":"Test 7","text":"Title Details Function Name <code>test_l2_dsAudio_SetAndGetIntelligentEqualizerMode</code> Description Loop through supported audio ports, Set Intelligent Equalizer Mode for supported ports and retrieve Intelligent Equalizer Mode for verification Test Group 02 Test Case ID 007 Priority High <p>Pre-Conditions : None</p> <p>Dependencies : None</p> <p>User Interaction : If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L2_Low-Level_TestSpecification/#test-procedure-test-7","title":"Test Procedure - Test 7","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the audio port using <code>dsAudioPortInit</code> None <code>dsERR_NONE</code> Should be successful 02 Loop through supported audio ports and get audio port using <code>dsGetAudioPort</code> supported number of audio ports = <code>dsAudio/Number_of_supported_ports</code> field and port id = <code>dsAudio/Port/[port number]/Typeid</code> of configuration file <code>dsERR_NONE</code> Should be successful 03 Set Intelligent Equalizer Mode for each supported port using <code>dsSetIntelligentEqualizerMode</code> handle = obtained from <code>dsGetAudioPort</code>, mode = 0 to 6 <code>dsERR_NONE</code> Should be successful 04 Retrieve Intelligent Equalizer Mode for each supported port using <code>dsGetIntelligentEqualizerMode</code> handle = obtained from <code>dsGetAudioPort</code> <code>dsERR_NONE</code> Should be successful 05 Verify the set and retrieved Intelligent Equalizer Mode are same mode = set mode, getMode = retrieved mode mode should be equal to getMode Should be successful 06 Terminate the audio port using <code>dsAudioPortTerm</code> None <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\nA[dsAudioPortInit] --&gt;|dsERR_NONE|B{ Loop through supported audio ports &lt;br&gt; call dsGetAudioPort}\nA --&gt;|Failure|A_Fail[Test case fail]\nB --&gt;|dsERR_NONE|C[dsSetIntelligentEqualizerMode, mode 0-6]\nB --&gt;|Not dsERR_NONE or invalid handle|B\nC --&gt;|dsERR_NONE|D[dsGetIntelligentEqualizerMode]\nD --&gt;|dsERR_NONE|E[Compare get and set values]\nE --&gt;|Match|B\nE --&gt;|Fail|E1[Test case fail]\nE1 --&gt; B\nB --&gt;|End of loop|F[dsAudioPortTerm]\nF --&gt;|dsERR_NONE|G[Test case success]\nF --&gt;|Failure|F_Fail[Test case fail]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L2_Low-Level_TestSpecification/#test-8","title":"Test 8","text":"Title Details Function Name <code>test_l2_dsAudio_SetAndGetVolumeLeveller</code> Description Loop through supported audio ports, set Volume leveller for supported ports and retrieve Volume leveller for verification Test Group 02 Test Case ID 008 Priority High <p>Pre-Conditions : None</p> <p>Dependencies : None</p> <p>User Interaction : If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L2_Low-Level_TestSpecification/#test-procedure-test-8","title":"Test Procedure - Test 8","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the audio port using <code>dsAudioPortInit</code> None <code>dsERR_NONE</code> Should be successful 02 Loop through supported audio ports and get audio port using <code>dsGetAudioPort</code> supported number of audio ports = <code>dsAudio/Number_of_supported_ports</code> field and port id = <code>dsAudio/Port/[port number]/Typeid</code> of configuration file <code>dsERR_NONE</code> Should be successful 03 Set the volume leveller for the retrieved audio port using <code>dsSetVolumeLeveller</code> handle = retrieved handle, volLeveller = <code>dsERR_NONE</code> Should be successful 04 Retrieve the volume leveller for the same audio port using <code>dsGetVolumeLeveller</code> handle = retrieved handle <code>dsERR_NONE</code> Should be successful 05 Verify the set and retrieved volume leveller are same volLevellerSet.mode = volLevellerGet.mode, volLevellerSet.level = volLevellerGet.level volLevellerSet.mode, volLevellerSet.level Should be successful 06 Terminate the audio port using <code>dsAudioPortTerm</code> None <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\n    A[dsAudioPortInit] --&gt;|dsERR_NONE|B{Loop through audio ports &lt;br&gt; call dsGetAudioPort}\n    A --&gt;|Failure|A1[Test case fail]\n    B --&gt;|dsERR_NONE and valid handle|C[dsSetVolumeLeveller]\n    B --&gt;|Not dsERR_NONE or invalid handle|B\n    C --&gt;|dsERR_NONE|D[dsGetVolumeLeveller]\n    D --&gt; D1[Compare the Volume leveller]\n    D1 --&gt; |Fail|D2[Test case fail]\n    D2 --&gt; B\n    D1 --&gt;|dsERR_NONE and same structure|B\n    B --&gt;|End of loop|E[dsAudioPortTerm]\n    E --&gt;|dsERR_NONE|F[Test case success]\n    E --&gt;|Failure|E1[Test case fail]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L2_Low-Level_TestSpecification/#test-9","title":"Test 9","text":"Title Details Function Name <code>test_l2_dsAudio_SetAndGetBassEnhancer</code> Description Loop through supported audio ports, Set Bass Enhancer for supported ports and retrieve Bass Enhancer for verification Test Group 02 Test Case ID 009 Priority High <p>Pre-Conditions : None</p> <p>Dependencies : None</p> <p>User Interaction : If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L2_Low-Level_TestSpecification/#test-procedure-test-9","title":"Test Procedure - Test 9","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the audio port using <code>dsAudioPortInit</code> None <code>dsERR_NONE</code> Should be successful 02 Loop through supported audio ports and get audio port using <code>dsGetAudioPort</code> supported number of audio ports = <code>dsAudio/Number_of_supported_ports</code> field and port id = <code>dsAudio/Port/[port number]/Typeid</code> of configuration file <code>dsERR_NONE</code> Should be successful 03 Set Bass Enhancer for the retrieved audio port using <code>dsSetBassEnhancer</code> handle = retrieved handle, boost = 0 to 100 <code>dsERR_NONE</code> Should be successful 04 Retrieve Bass Enhancer for the same audio port using <code>dsGetBassEnhancer</code> handle = retrieved handle <code>dsERR_NONE</code> Should be successful 05 Verify the set and retrieved Bass Enhancer values are same setBoost = retrieved boost setBoost Should be successful 06 Terminate the audio port using <code>dsAudioPortTerm</code> None <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\n    A[dsAudioPortInit] --&gt;|dsERR_NONE|B{Loop dsGetAudioPort &lt;br&gt; through audio ports }\n    A --&gt;|!= dsERR_NONE|A1[Test case fail]\n    B --&gt;|dsERR_NONE|C[dsSetBassEnhancer boost 0-100]\n    B --&gt;|Not dsERR_NONE or invalid handle|B\n    C --&gt;|dsERR_NONE|D[dsGetBassEnhancer]\n    D --&gt;|dsERR_NONE|E[Compare get and set values]\n    E --&gt;|Fail|E1[Test case fail]\n    E1 --&gt; B\n    E --&gt;|Match|B\n    B --&gt;|End of loop|F[dsAudioPortTerm]\n    F --&gt;|dsERR_NONE|G[Test case success]\n    F --&gt;|!= dsERR_NONE|F1[Test case fail]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L2_Low-Level_TestSpecification/#test-10","title":"Test 10","text":"Title Details Function Name <code>test_l2_dsAudio_EnableAndVerifySurroundDecoder</code> Description Loop through supported audio ports, Enable Surround Decoder for supported ports and retrieve Surround Decoder status for verification Test Group 02 Test Case ID 010 Priority High <p>Pre-Conditions : None</p> <p>Dependencies : None</p> <p>User Interaction : If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L2_Low-Level_TestSpecification/#test-procedure-test-10","title":"Test Procedure - Test 10","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the audio port using <code>dsAudioPortInit</code> None <code>dsERR_NONE</code> Should be successful 02 Loop through supported audio ports and get audio port using <code>dsGetAudioPort</code> supported number of audio ports = <code>dsAudio/Number_of_supported_ports</code> field and port id = <code>dsAudio/Port/[port number]/Typeid</code> of configuration file <code>dsERR_NONE</code> Should be successful 03 Enable Surround Decoder for each supported port using <code>dsEnableSurroundDecoder</code> handle = obtained handle, enabled = <code>true</code> <code>dsERR_NONE</code> Should be successful 04 Retrieve Surround Decoder status for each port using <code>dsIsSurroundDecoderEnabled</code> handle = obtained handle, enabled = valid buffer <code>dsERR_NONE</code> and enabled = <code>true</code> Should be successful 05 Terminate the audio port using <code>dsAudioPortTerm</code> None <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\n    A[Call dsAudioPortInit] --&gt;|dsERR_NONE|B{Loop through &lt;br&gt; supported audio ports &lt;br&gt; call dsGetAudioPort}\n    A --&gt;|!= dsERR_NONE|A1[Test case fail]\n    B --&gt;|dsERR_NONE and valid handle|C[Call dsEnableSurroundDecoder]\n    B --&gt;|Not dsERR_NONE or invalid handle|B\n    C --&gt;|dsERR_NONE|D[Call dsIsSurroundDecoderEnabled]\n    D --&gt;|Not dsERR_NONE or enabled false|D1[Test case fail]\n    D1 --&gt; B\n    D --&gt;|dsERR_NONE and enabled true|B\n    B --&gt;|End of loop|E[Call dsAudioPortTerm]\n    E --&gt;|dsERR_NONE|F[Test case success]\n    E --&gt;|!= dsERR_NONE|E1[Test case fail]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L2_Low-Level_TestSpecification/#test-11","title":"Test 11","text":"Title Details Function Name <code>test_l2_dsAudio_SetAndGetDRCMode</code> Description Loop through supported audio ports, Set <code>DRC</code> Mode for supported ports and retrieve <code>DRC</code> Mode for verification Test Group 02 Test Case ID 011 Priority High <p>Pre-Conditions : None</p> <p>Dependencies : None</p> <p>User Interaction : If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L2_Low-Level_TestSpecification/#test-procedure-test-11","title":"Test Procedure - Test 11","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the audio port using <code>dsAudioPortInit</code> None <code>dsERR_NONE</code> Should be successful 02 Loop through supported audio ports and get audio port using <code>dsGetAudioPort</code> supported number of audio ports = <code>dsAudio/Number_of_supported_ports</code> field and port id = <code>dsAudio/Port/[port number]/Typeid</code> of configuration file <code>dsERR_NONE</code> Should be successful 03 For each valid audio port handle, loop through all <code>DRC</code> modes (0 and 1), set the <code>DRC</code> mode using <code>dsSetDRCMode</code> handle = valid handle, mode = 0 or 1 <code>dsERR_NONE</code> Should be successful 04 For each set <code>DRC</code> mode, get the <code>DRC</code> mode using <code>dsGetDRCMode</code> handle = valid handle <code>dsERR_NONE</code> Should be successful 05 Verify the set and get <code>DRC</code> modes are equal getMode = mode mode Should be successful 06 Terminate the audio port using <code>dsAudioPortTerm</code> None <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\n    A[dsAudioPortInit] --&gt;|dsERR_NONE|B{Loop through supported &lt;br&gt; audio ports &lt;br&gt; call dsGetAudioPort}\n    A --&gt;|!= dsERR_NONE|A1[Test case fail]\n    B --&gt;|dsERR_NONE and valid handle|C[dsSetDRCMode mode 0 to 1]\n    B --&gt;|Not dsERR_NONE or invalid handle|B\n    C --&gt;|dsERR_NONE|D[dsGetDRCMode]\n    D --&gt;|dsERR_NONE and same mode as set|B\n    D --&gt;|not dsERR_NONE or mode not match|D1[Test case fail]\n    D1 --&gt; B\n    B --&gt;|End of loop|E[dsAudioPortTerm]\n    E --&gt;|dsERR_NONE|F[Test case success]\n    E --&gt;|!= dsERR_NONE|E1[Test case fail]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L2_Low-Level_TestSpecification/#test-12","title":"Test 12","text":"Title Details Function Name <code>test_l2_dsAudio_SetAndGetSurroundVirtualizer</code> Description Loop through supported audio ports, Set Surround Virtualizer for supported ports and retrieve Surround Virtualizer for verification Test Group 02 Test Case ID 012 Priority High <p>Pre-Conditions : None</p> <p>Dependencies : None</p> <p>User Interaction : If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L2_Low-Level_TestSpecification/#test-procedure-test-12","title":"Test Procedure - Test 12","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the audio port using <code>dsAudioPortInit</code> None <code>dsERR_NONE</code> Should be successful 02 Loop through supported audio ports and get audio port using <code>dsGetAudioPort</code> supported number of audio ports = <code>dsAudio/Number_of_supported_ports</code> field and port id = <code>dsAudio/Port/[port number]/Typeid</code> of configuration file <code>dsERR_NONE</code> Should be successful 03 Set Surround Virtualizer for the retrieved audio port using <code>dsSetSurroundVirtualizer</code> handle = retrieved handle, virtualizer = <code>dsERR_NONE</code> Should be successful 04 Retrieve Surround Virtualizer for the same audio port using <code>dsGetSurroundVirtualizer</code> handle = retrieved handle <code>dsERR_NONE</code> Should be successful 05 Verify the set and retrieved Surround Virtualizer are same mode: (0-1), boost: (0-96 in steps of 16) <code>dsERR_NONE</code> Should be successful 06 Terminate the audio port using <code>dsAudioPortTerm</code> None <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\n    A[call dsAudioPortInit] --&gt;|dsERR_NONE|B{Loop through the &lt;br&gt; supported audio ports &lt;br&gt; call dsGetAudioPort }\n    A --&gt;|Failure|A1[Test case fail]\n    B --&gt;|dsERR_NONE and a valid handle|C[dsSetSurroundVirtualizer API]\n    B --&gt;|Not dsERR_NONE or invalid handle|B\n    C --&gt;|dsERR_NONE|D[dsGetSurroundVirtualizer API]\n    D --&gt;|dsERR_NONE and values match|B\n    D --&gt;|not dsERR_NONE or values don't match|D1[Test case fail]\n    D1 --&gt; B\n    B --&gt;|End of loop|E[dsAudioPortTerm API]\n    E --&gt;|dsERR_NONE|F[Test case success]\n    E --&gt;|Failure|E1[Test case fail]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L2_Low-Level_TestSpecification/#test-13","title":"Test 13","text":"Title Details Function Name <code>test_l2_dsAudio_SetAndGetMISteering</code> Description Loop through supported audio ports, set <code>MI</code> Steering for supported ports and retrieve <code>MI</code> Steering for verification Test Group 02 Test Case ID 013 Priority High <p>Pre-Conditions : None</p> <p>Dependencies : None</p> <p>User Interaction : If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L2_Low-Level_TestSpecification/#test-procedure-test-13","title":"Test Procedure - Test 13","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the audio port using <code>dsAudioPortInit</code> None <code>dsERR_NONE</code> Should be successful 02 Loop through supported audio ports and get audio port using <code>dsGetAudioPort</code> supported number of audio ports = <code>dsAudio/Number_of_supported_ports</code> field and port id = <code>dsAudio/Port/[port number]/Typeid</code> of configuration file <code>dsERR_NONE</code> Should be successful 03 Set <code>MI</code> Steering for the retrieved audio port using <code>dsSetMISteering</code> handle = retrieved handle, enabled = <code>true</code> <code>dsERR_NONE</code> Should be successful 04 Retrieve <code>MI</code> Steering for the audio port using <code>dsGetMISteering</code> handle = retrieved handle <code>dsERR_NONE</code> Should be successful 05 Verify the <code>MI</code> Steering status enabled = retrieved status <code>true</code> Should be successful 06 Terminate the audio port using <code>dsAudioPortTerm</code> None <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\n    A[dsAudioPortInit] --&gt;|dsERR_NONE|B{Loop through audio ports &lt;br&gt; call dsGetAudioPort}\n    A --&gt;|!= dsERR_NONE|AF[Test case fail]\n    B --&gt;|dsERR_NONE and valid handle|C[dsSetMISteering]\n    B --&gt;|Not dsERR_NONE or invalid handle|B\n    C --&gt;|dsERR_NONE|D[dsGetMISteering]\n    D --&gt;|dsERR_NONE and enabled = true|B\n    D --&gt;|not dsERR_NONE or enabled = false|D1[Test case fail]\n    D1 --&gt; B\n    B --&gt;|End of loop|E[dsAudioPortTerm]\n    E --&gt;|dsERR_NONE|F[Test case pass]\n    E --&gt;|!= dsERR_NONE|EF[Test case fail]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L2_Low-Level_TestSpecification/#test-14","title":"Test 14","text":"Title Details Function Name <code>test_l2_dsAudio_SetAndGetGraphicEqualizerMode</code> Description Loop through supported audio ports, Set Graphic Equalizer for supported ports and retrieve Graphic Equalizer for verification Test Group 02 Test Case ID 014 Priority High <p>Pre-Conditions : None</p> <p>Dependencies : None</p> <p>User Interaction : If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L2_Low-Level_TestSpecification/#test-procedure-test-14","title":"Test Procedure - Test 14","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the audio port using <code>dsAudioPortInit</code> None <code>dsERR_NONE</code> Should be successful 02 Loop through supported audio ports and get audio port using <code>dsGetAudioPort</code> supported number of audio ports = <code>dsAudio/Number_of_supported_ports</code> field and port id = <code>dsAudio/Port/[port number]/Typeid</code> of configuration file <code>dsERR_NONE</code> Should be successful 03 For each audio port, set the Graphic Equalizer mode using <code>dsSetGraphicEqualizerMode</code> handle = obtained from <code>dsGetAudioPort</code>, mode = 0 to 3 <code>dsERR_NONE</code> Should be successful 04 For each audio port, get the Graphic Equalizer mode using <code>dsGetGraphicEqualizerMode</code> handle = obtained from <code>dsGetAudioPort</code> <code>dsERR_NONE</code> Should be successful 05 Verify the set and get Graphic Equalizer mode are same mode = set mode, getMode = obtained from <code>dsGetGraphicEqualizerMode</code> mode should be equal to getMode Should be successful 06 Terminate the audio port using <code>dsAudioPortTerm</code> None <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\n    A[dsAudioPortInit] --&gt;|dsERR_NONE|B{Loop through audio ports &lt;br&gt; call dsGetAudioPort}\n    A --&gt;|Failure|A1[Test case fail]\n    B --&gt;|dsERR_NONE|C[dsSetGraphicEqualizerMode mode 0 to 3]\n    B --&gt;|Not dsERR_NONE or invalid handle|B\n    C --&gt;|dsERR_NONE|D[dsGetGraphicEqualizerMode]\n    D --&gt;|dsERR_NONE, set and get match|B\n    D --&gt;|not dsERR_NONE or set and get don't match|D1[Test case fail]\n    D1 --&gt; B\n    B --&gt;|End of loop|E[dsAudioPortTerm]\n    E --&gt;|dsERR_NONE|F[Test case success]\n    E --&gt;|Failure|E1[Test case fail]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L2_Low-Level_TestSpecification/#test-15","title":"Test 15","text":"Title Details Function Name <code>test_l2_dsAudio_EnableDisableAndRetrieveLEConfig</code> Description Loop through supported audio ports, enable/disable audio loudness equivalence and retrieve audio loudness equivalence status for verification Test Group 02 Test Case ID 015 Priority High <p>Pre-Conditions : None</p> <p>Dependencies : None</p> <p>User Interaction : If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L2_Low-Level_TestSpecification/#test-procedure-test-15","title":"Test Procedure - Test 15","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the audio port using <code>dsAudioPortInit</code> None <code>dsERR_NONE</code> Should be successful 02 Loop through supported audio ports and get audio port using <code>dsGetAudioPort</code> supported number of audio ports = <code>dsAudio/Number_of_supported_ports</code> field and port id = <code>dsAudio/Port/[port number]/Typeid</code> of configuration file <code>dsERR_NONE</code> Should be successful 03 Enable loudness equivalence configuration using <code>dsEnableLEConfig</code> handle = obtained handle, enable = <code>true</code> <code>dsERR_NONE</code> Should be successful 04 Retrieve loudness equivalence configuration using <code>dsGetLEConfig</code> handle = obtained handle <code>dsERR_NONE</code> and enable = <code>true</code> Should be successful 05 Disable loudness equivalence configuration using <code>dsEnableLEConfig</code> handle = obtained handle, enable = <code>false</code> <code>dsERR_NONE</code> Should be successful 06 Retrieve loudness equivalence configuration using <code>dsGetLEConfig</code> handle = obtained handle <code>dsERR_NONE</code> and enable = <code>false</code> Should be successful 07 Terminate the audio port using <code>dsAudioPortTerm</code> None <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\n    A[Call dsAudioPortInit] --&gt;|dsERR_NONE|B{Loop through &lt;br&gt; supported audio ports &lt;br&gt; Call dsGetAudioPort}\n    A --&gt;|Failure|A1[Test case fail]\n    B --&gt;|dsERR_NONE and valid handle|C[Call dsEnableLEConfig &lt;br&gt; with enable as true]\n    B --&gt;|Not dsERR_NONE or invalid handle|B\n    C --&gt;|dsERR_NONE|D[Call dsGetLEConfig]\n    D --&gt;|dsERR_NONE and enable as true|E[Call dsEnableLEConfig  &lt;br&gt; with enable as false]\n    E --&gt;|dsERR_NONE|F[Call dsGetLEConfig]\n    F --&gt;|not dsERR_NONE or &lt;br&gt; enable as true|F1[Test case fail]\n    F1 --&gt; B\n    F --&gt;|dsERR_NONE and &lt;br&gt; enable as false|B\n    B --&gt;|End of loop|G[Call dsAudioPortTerm]\n    G --&gt;|dsERR_NONE|H[Test case success]\n    G --&gt;|Failure|G1[Test case fail]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L2_Low-Level_TestSpecification/#test-16","title":"Test 16","text":"Title Details Function Name <code>test_l2_dsAudio_CheckMS12DecodeSupport</code> Description Loop through the supported audio ports and check whether the port supports <code>MS12</code> decode using the configuration file Test Group 02 Test Case ID 016 Priority High <p>Pre-Conditions : None</p> <p>Dependencies : None</p> <p>User Interaction : If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L2_Low-Level_TestSpecification/#test-procedure-test-16","title":"Test Procedure - Test 16","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the audio port using <code>dsAudioPortInit</code> None <code>dsERR_NONE</code> Should be successful 02 Loop through supported audio ports and get audio port using <code>dsGetAudioPort</code> supported number of audio ports = <code>dsAudio/Number_of_supported_ports</code> field and port id = <code>dsAudio/Port/[port number]/Typeid</code> of configuration file <code>dsERR_NONE</code> Should be successful 03 Check if the port supports <code>MS12</code> decode using <code>dsIsAudioMS12Decode</code> handle <code>dsERR_NONE</code> Should be successful 04 Compare configuration value with <code>dsIsAudioMS12Decode</code> value from API MS12 support =  <code>dsAudio/Port/[port number]/IsMS12Decode</code> of configuration file Matches Should be successful 05 Terminate the audio port using <code>dsAudioPortTerm</code> None <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\n    A[Call dsAudioPortInit] --&gt;|dsERR_NONE|B{Loop through &lt;br&gt; supported audio ports}\n    B --&gt;|Not dsERR_NONE or invalid handle|B\n    B --&gt;|dsERR_NONE and valid handle|D[Call dsIsAudioMS12Decode]\n    D --&gt;|dsERR_NONE and boolean value|E[Retrieve value from configuration]\n    E --&gt; F[Compare configuration value with dsIsAudioMS12Decode value]\n    F --&gt;|Fail| F1[Test case fail]\n    F1 --&gt; B\n    F --&gt;|Match|B\n    B --&gt;|End of loop|I[Call dsAudioPortTerm]\n    I --&gt;|dsERR_NONE|J[Test case success]\n    A --&gt;|Not dsERR_NONE|K[Test case fail]\n    I --&gt;|Not dsERR_NONE|N[Test case fail]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L2_Low-Level_TestSpecification/#test-17","title":"Test 17","text":"Title Details Function Name <code>test_l2_dsAudio_CheckMS11DecodeSupport</code> Description Loop through the supported audio ports and check whether the port supports <code>MS11</code> decode using the configuration file. Test Group 02 Test Case ID 017 Priority High <p>Pre-Conditions : None</p> <p>Dependencies : None</p> <p>User Interaction : If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L2_Low-Level_TestSpecification/#test-procedure-test-17","title":"Test Procedure - Test 17","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the audio port using <code>dsAudioPortInit</code> None <code>dsERR_NONE</code> Should be successful 02 Loop through supported audio ports and get audio port using <code>dsGetAudioPort</code> supported number of audio ports = <code>dsAudio/Number_of_supported_ports</code> field and port id = <code>dsAudio/Port/[port number]/Typeid</code> of configuration file <code>dsERR_NONE</code> Should be successful 03 Check whether the port supports <code>MS11</code> decode using <code>dsIsAudioMSDecode</code> handle = obtained from <code>dsGetAudioPort</code> <code>dsERR_NONE</code> Should be successful 04 Compare configuration value with <code>dsIsAudioMSDecode</code> value from <code>API</code> MS11 Support =  <code>dsAudio/Port/[port number]/IsMS11Decode</code> of configuration file Matches Should be successful 05 Terminate the audio port using <code>dsAudioPortTerm</code> None <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\nA[dsAudioPortInit] --&gt; B{For Each Audio Port}\nB --&gt; C[dsGetAudioPort for SPEAKER port]\nB --&gt;|Not dsERR_NONE or invalid handle|B\nC --&gt;|dsERR_NONE|D[dsIsAudioMSDecode]\nD --&gt;|dsERR_NONE|E[Compare value from configuration file]\nE --&gt;|Fail|E1[Test case fail]\nE1 --&gt; B\nE --&gt;|Match|B\nB--&gt;|End of loop|F[dsAudioPortTerm]\nF --&gt;|dsERR_NONE|H[Test case pass]\nF --&gt;|Not dsERR_NONE|F1[Test case fail]\nA --&gt;|Not dsERR_NONE|A1[Test case fail]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L2_Low-Level_TestSpecification/#test-18","title":"Test 18","text":"Title Details Function Name <code>test_l2_dsAudio_VerifyMS12AudioProfiles_sink</code> Description Get the supported <code>MS12</code> audio profiles and verify them with the configuration file Test Group 02 Test Case ID 018 Priority High <p>Pre-Conditions : None</p> <p>Dependencies : None</p> <p>User Interaction : If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L2_Low-Level_TestSpecification/#test-procedure-test-18","title":"Test Procedure - Test 18","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the audio port using <code>dsAudioPortInit</code> None <code>dsERR_NONE</code> Should be successful 02 Loop through supported audio ports and get audio port using <code>dsGetAudioPort</code> supported number of audio ports = <code>dsAudio/Number_of_supported_ports</code> field and port id = <code>dsAudio/Port/[port number]/Typeid</code> of configuration file <code>dsERR_NONE</code> Should be successful 02 Get the MS12 audio profile list using <code>dsGetMS12AudioProfileList</code> handle = valid handle, profiles = valid pointer <code>dsERR_NONE</code> Should be successful 04 Verify the retrieved audio profile list with the expected profile string MS12 audio profile count = <code>dsAudio/Port/[port number]/MS12_AudioProfileCount</code>, MS12 audio profiles =  <code>dsAudio/Port/[port number]/MS12_AudioProfiles</code> of configuration file profiles.audioProfileList = valid profile list Should be successful 05 Terminate the audio port using <code>dsAudioPortTerm</code> None <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\nA[dsAudioPortInit] --&gt; B{For Each Audio Port}\nB --&gt;|Not dsERR_NONE or invalid handle|B\nB --&gt;|dsERR_NONE and valid handle|C{Check if port supports &lt;br&gt; MS12 audioprofiles}\nC --&gt;|Yes|D[dsGetMS12AudioProfileList]\nC --&gt;|No|B\nD --&gt;|dsERR_NONE|E[Compare value from configuration file]\nE --&gt; |don't match|E1[Test case fail]\nE1 --&gt; B\nE --&gt;|Match|B\nB--&gt;|End of loop|F[dsAudioPortTerm]\nF --&gt;|dsERR_NONE|H[Test case pass]\nF --&gt;|Not dsERR_NONE|F1[Test case fail]\nA --&gt;|Not dsERR_NONE|A1[Test case fail]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L2_Low-Level_TestSpecification/#test-19","title":"Test 19","text":"Title Details Function Name <code>test_l2_dsAudio_SetAndGetMS12AudioProfile_sink</code> Description Get Supported <code>MS12</code> Audio profiles, loop through supported audio ports, set various audio profiles for supported ports and retrieve audio profile for verification. Test Group 02 Test Case ID 019 Priority High <p>Pre-Conditions : None</p> <p>Dependencies : None</p> <p>User Interaction : If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L2_Low-Level_TestSpecification/#test-procedure-test-19","title":"Test Procedure - Test 19","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the audio port using <code>dsAudioPortInit</code> None <code>dsERR_NONE</code> Should be successful 02 Loop through supported audio ports and get audio port using <code>dsGetAudioPort</code> supported number of audio ports = <code>dsAudio/Number_of_supported_ports</code> field and port id = <code>dsAudio/Port/[port number]/Typeid</code> of configuration file <code>dsERR_NONE</code> Should be successful 03 Get <code>MS12</code> audio profile list using <code>dsGetMS12AudioProfileList</code> handle = obtained from <code>dsGetAudioPort</code> <code>dsERR_NONE</code> Should be successful 04 Loop through all profiles and set <code>MS12</code> audio profile using <code>dsSetMS12AudioProfile</code> handle = obtained from <code>dsGetAudioPort</code>, profile = profileName <code>dsERR_NONE</code> Should be successful 05 Get <code>MS12</code> audio profile using <code>dsGetMS12AudioProfile</code> handle = obtained from <code>dsGetAudioPort</code> <code>dsERR_NONE</code> Should be successful 06 Assert that the set and get profiles are equal profile = obtained from <code>dsGetMS12AudioProfile</code>, profileName = set in <code>dsSetMS12AudioProfile</code> <code>True</code> Should be successful 07 Terminate the audio port using <code>dsAudioPortTerm</code> None <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\nA[Call dsAudioPortInit] --&gt;|dsERR_NONE|B{Loop through supported audio ports}\nA --&gt;|Failure|A1[Test case fail]\nB --&gt;|dsERR_NONE and valid handle|BC{Check if port supports &lt;br&gt; MS12 audioprofiles}\nB --&gt;|Not dsERR_NONE or invalid handle|B\nBC --&gt;|Yes|C[dsGetMS12AudioProfileList]\nBC --&gt;|No|B\nC --&gt;|dsERR_NONE|D[Loop through supported audio profiles]\nD --&gt;|dsERR_NONE|E[Call dsSetMS12AudioProfile for each profile]\nE --&gt;|dsERR_NONE|F[Call dsGetMS12AudioProfile for each profile]\nF --&gt;|Comparison Fails|F1[Test case fail]\nF1--&gt;B\nF --&gt;|dsERR_NONE|B\nB --&gt;|End of loop|G[Call dsAudioPortTerm]\nG --&gt;|dsERR_NONE|H[Test case success]\nG --&gt;|Failure|G1[Test case fail]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L2_Low-Level_TestSpecification/#test-20","title":"Test 20","text":"Title Details Function Name <code>test_l2_dsAudio_SetAndGetStereoMode</code> Description Loop through supported audio ports, set Stereo mode for supported ports and retrieve Stereo mode for verification Test Group 02 Test Case ID 020 Priority High <p>Pre-Conditions : None</p> <p>Dependencies : None</p> <p>User Interaction : If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L2_Low-Level_TestSpecification/#test-procedure-test-20","title":"Test Procedure - Test 20","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the audio port using <code>dsAudioPortInit</code> None <code>dsERR_NONE</code> Should be successful 02 Loop through supported audio ports and get audio port using <code>dsGetAudioPort</code> supported number of audio ports = <code>dsAudio/Number_of_supported_ports</code> field and port id = <code>dsAudio/Port/[port number]/Typeid</code> of configuration file <code>dsERR_NONE</code> Should be successful 03 Set the stereo mode for the retrieved audio port handle using <code>dsSetStereoMode</code> handle = retrieved handle, supported Stereo modes = <code>dsAudio/Port/[port number]/stereo_modes</code> of configuration file <code>dsERR_NONE</code> Should be successful 04 Get the stereo mode for the same audio port handle using <code>dsGetStereoMode</code> handle = retrieved handle <code>dsERR_NONE</code> Should be successful 05 Assert that the retrieved stereo mode is the same as the set stereo mode mode = retrieved mode mode = getmode Should be successful 06 Terminate the audio port using <code>dsAudioPortTerm</code> None <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\n    A[Call dsAudioPortInit] --&gt;|dsERR_NONE|B{Loop through &lt;br&gt; supported audio ports}\n    A --&gt;|!= dsERR_NONE|A1[Test case fail]\n    B --&gt;|dsERR_NONE and valid handle|C[Call dsSetStereoMode &lt;br&gt; with various stereo modes]\n    B --&gt;|Not dsERR_NONE or invalid handle|B\n    C --&gt;|dsERR_NONE|D[Call dsGetStereoMode with handle]\n    D --&gt;|Comparison Fails|D1[Test case fail]\n    D1 --&gt; B\n    D --&gt;|dsERR_NONE, set and get matches|B\n    B --&gt;|End of loop|E[Call dsAudioPortTerm]\n    E --&gt;|dsERR_NONE|F[Test case success]\n    E --&gt;|!= dsERR_NONE|E1[Test case fail]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L2_Low-Level_TestSpecification/#test-21","title":"Test 21","text":"Title Details Function Name <code>test_l2_dsAudio_SetAndGetStereoAuto_sink</code> Description Loop through supported audio ports, set Stereo Auto mode for supported ports and retrieve it for verification Test Group 02 Test Case ID 021 Priority High <p>Pre-Conditions : None</p> <p>Dependencies : None</p> <p>User Interaction : If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L2_Low-Level_TestSpecification/#test-procedure-test-21","title":"Test Procedure - Test 21","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the audio port using <code>dsAudioPortInit</code> None <code>dsERR_NONE</code> Should be successful 02 Loop through supported audio ports and get audio port using <code>dsGetAudioPort</code> supported number of audio ports = <code>dsAudio/Number_of_supported_ports</code> field and port id = <code>dsAudio/Port/[port number]/Typeid</code> of configuration file <code>dsERR_NONE</code> Should be successful 03 Check if the port support Stereo auto mode from the <code>Port/[port number]/stereo_auto_mode</code> of configuration file. Set Stereo Auto mode for the retrieved audio port using <code>dsSetStereoAuto</code> handle = retrieved handle, autoMode = 1 <code>dsERR_NONE</code> Should be successful 04 Retrieve the Stereo Auto mode for the same audio port using <code>dsGetStereoAuto</code> handle = retrieved handle <code>dsERR_NONE</code> Should be successful 05 Verify the set and retrieved Stereo Auto mode are same getAutoMode = retrieved auto mode, autoMode = 1 getAutoMode should be equal to autoMode Should be successful 06 Terminate the audio port using <code>dsAudioPortTerm</code> None <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\nA[Call dsAudioPortInit] --&gt;|dsERR_NONE|B{Loop through supported &lt;br&gt; audio ports}\nB --&gt;|dsERR_NONE|C[Call dsSetStereoAuto &lt;br&gt; with autoMode=true]\nB --&gt;|Not dsERR_NONE or invalid handle|B\nC --&gt;|dsERR_NONE|D[Call dsGetStereoAuto with handle]\nD --&gt;|Comparison Fail|D1[Test case fail]\nD1 --&gt; B\nD --&gt;|dsERR_NONE &amp; get and set matches|B\nB --&gt;|End of loop|E[Call dsAudioPortTerm]\nE --&gt;|dsERR_NONE|F[Test case pass]\nE --&gt;|Failure|E1[Test case fail]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L2_Low-Level_TestSpecification/#test-22","title":"Test 22","text":"Title Details Function Name <code>test_l2_dsAudio_SetAndGetAudioGain_sink</code> Description Loop through supported audio ports, set various Linear Audio Gain Values for supported ports and retrieve Audio Gain for verification Test Group 02 Test Case ID 022 Priority High <p>Pre-Conditions : None</p> <p>Dependencies : None</p> <p>User Interaction : If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L2_Low-Level_TestSpecification/#test-procedure-test-22","title":"Test Procedure - Test 22","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the audio port using <code>dsAudioPortInit</code> None <code>dsERR_NONE</code> Should be successful 02 Loop through supported audio ports and get audio port using <code>dsGetAudioPort</code> supported number of audio ports = <code>dsAudio/Number_of_supported_ports</code> field and port id = <code>dsAudio/Port/[port number]/Typeid</code> of configuration file <code>dsERR_NONE</code> Should be successful 03 Set various Linear Audio Gain Values for supported ports using <code>dsSetAudioGain</code> handle = valid handle, gain = -2080 to 480 in steps of 10 <code>dsERR_NONE</code> Should be successful 04 Retrieve Audio Gain for verification using <code>dsGetAudioGain</code> handle = valid handle <code>dsERR_NONE</code>, gain = set gain value Should be successful 05 Terminate the audio port using <code>dsAudioPortTerm</code> None <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\n    A[dsAudioPortInit] --&gt;|dsERR_NONE|B{Loop through &lt;br&gt; supported audio ports}\n    A --&gt;|Failure|A1[Test case fail]\n    B --&gt;|dsERR_NONE|C[dsSetAudioGain with &lt;br&gt;various gain values]\n    B --&gt;|Not dsERR_NONE or invalid handle|B\n    C --&gt;|dsERR_NONE|D[dsGetAudioGain to &lt;br&gt; retrieve the audio gain value]\n    D --&gt; |Comparison Fail|D1[Test case fail]\n    D1 --&gt; B\n    D --&gt;|dsERR_NONE and &lt;br&gt; gain value matches|B\n    B --&gt;|End of loop|E[dsAudioPortTerm]\n    E --&gt;|dsERR_NONE|F[Test case success]\n    E --&gt;|Failure|E1[Test case fail]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L2_Low-Level_TestSpecification/#test-23","title":"Test 23","text":"Title Details Function Name <code>test_l2_dsAudio_SetAndGetAudioLevel_sink</code> Description Loop through supported audio ports, set various Audio Levels for supported ports and retrieve Audio Level for verification Test Group 02 Test Case ID 023 Priority High <p>Pre-Conditions : None</p> <p>Dependencies : None</p> <p>User Interaction : If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L2_Low-Level_TestSpecification/#test-procedure-test-23","title":"Test Procedure - Test 23","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the audio port using <code>dsAudioPortInit</code> None <code>dsERR_NONE</code> Should be successful 02 Loop through supported audio ports and get audio port using <code>dsGetAudioPort</code> supported number of audio ports = <code>dsAudio/Number_of_supported_ports</code> field and port id = <code>dsAudio/Port/[port number]/Typeid</code> of configuration file <code>dsERR_NONE</code> Should be successful 03 Set various Audio Levels for the obtained audio port handle using <code>dsSetAudioLevel</code> handle = obtained handle, level = 0 to 100 in steps of 10 <code>dsERR_NONE</code> Should be successful 04 Retrieve the Audio Level for the set level using <code>dsGetAudioLevel</code> handle = obtained handle <code>dsERR_NONE</code>, level = set level Should be successful 05 Terminate the audio port using <code>dsAudioPortTerm</code> None <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\n    A[dsAudioPortInit] --&gt;|dsERR_NONE|B{Loop through the &lt;br&gt; supported audio ports}\n    A --&gt;|Failure|A1[Test case fail]\n    B --&gt;|dsERR_NONE and valid handle|C[Set various audio levels &lt;br&gt; dsSetAudioLevel]\n    B --&gt;|Not dsERR_NONE or invalid handle|B\n    C --&gt;|dsERR_NONE|D[Retrieve the audio level &lt;br&gt; dsGetAudioLevel]\n    D --&gt;|Comparison Fail|D1[Test case fail]\n    D1 --&gt; B\n    D --&gt;|dsERR_NONE and same audio level|B\n    B --&gt;|End of loop|E[dsAudioPortTerm]\n    E --&gt;|dsERR_NONE|F[Test case pass]\n    E --&gt;|Failure|E1[Test case fail]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L2_Low-Level_TestSpecification/#test-24","title":"Test 24","text":"Title Details Function Name <code>test_l2_dsAudio_AudioMuteVerification</code> Description Loop through supported audio ports, enable/disable audio mute for supported ports and retrieve Mute status for verification Test Group 02 Test Case ID 024 Priority High <p>Pre-Conditions : None</p> <p>Dependencies : None</p> <p>User Interaction : If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L2_Low-Level_TestSpecification/#test-procedure-test-24","title":"Test Procedure - Test 24","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the audio port using <code>dsAudioPortInit</code> None <code>dsERR_NONE</code> Should be successful 02 Loop through supported audio ports and get audio port using <code>dsGetAudioPort</code> supported number of audio ports = <code>dsAudio/Number_of_supported_ports</code> field and port id = <code>dsAudio/Port/[port number]/Typeid</code> of configuration file <code>dsERR_NONE</code> Should be successful 03 Set audio mute to true using <code>dsSetAudioMute</code> handle = obtained handle, mute = true <code>dsERR_NONE</code> Should be successful 04 Verify audio mute status using <code>dsIsAudioMute</code> handle = obtained handle, mute = pointer to mute status <code>dsERR_NONE</code>, mute = <code>true</code> Should be successful 05 Set audio mute to false using <code>dsSetAudioMute</code> handle = obtained handle, mute = <code>false</code> <code>dsERR_NONE</code> Should be successful 06 Verify audio mute status using <code>dsIsAudioMute</code> handle = obtained handle, mute = pointer to mute status <code>dsERR_NONE</code>, mute = <code>false</code> Should be successful 07 Terminate the audio port using <code>dsAudioPortTerm</code> None <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\nA[Call dsAudioPortInit] --&gt;|dsERR_NONE|B{Loop through &lt;br&gt; supported audio ports}\nB -- dsERR_NONE &amp; valid handle --&gt; C[Call dsSetAudioMute with mute=true]\nB --&gt;|Not dsERR_NONE or invalid handle|B\nC -- dsERR_NONE --&gt; D[Call dsIsAudioMute]\nD -- dsERR_NONE &amp; muted=true --&gt; E[Call dsSetAudioMute with mute=false]\nE -- dsERR_NONE --&gt; F[Call dsIsAudioMute]\nF --&gt;|mute != false| F1[Test case fail]\nF1 --&gt; B\nF -- dsERR_NONE &amp; muted=false --&gt; B\nB -- End of loop --&gt; G[Call dsAudioPortTerm]\nG -- dsERR_NONE --&gt; H[Test case success]\nG -- Not dsERR_NONE --&gt; G1[Test case fail]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L2_Low-Level_TestSpecification/#test-25","title":"Test 25","text":"Title Details Function Name <code>test_l2_dsAudio_SetAndGetAudioDelay</code> Description Loop through supported audio ports, set Audio delay for supported ports and retrieve delay for verification Test Group 02 Test Case ID 025 Priority High <p>Pre-Conditions : None</p> <p>Dependencies : None</p> <p>User Interaction : If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L2_Low-Level_TestSpecification/#test-procedure-test-25","title":"Test Procedure - Test 25","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the audio port using <code>dsAudioPortInit</code> None <code>dsERR_NONE</code> Should be successful 02 Loop through supported audio ports and get audio port using <code>dsGetAudioPort</code> supported number of audio ports = <code>dsAudio/Number_of_supported_ports</code> field and port id = <code>dsAudio/Port/[port number]/Typeid</code> of configuration file <code>dsERR_NONE</code> Should be successful 03 Set the audio delay for the retrieved audio port using <code>dsSetAudioDelay</code> handle = retrieved handle, delay = 100ms <code>dsERR_NONE</code> Should be successful 04 Retrieve the audio delay for the same audio port using <code>dsGetAudioDelay</code> handle = retrieved handle <code>dsERR_NONE</code> Should be successful 05 Verify the set and retrieved audio delay are same setDelay = 100ms, getDelay = retrieved delay getDelay should be equal to setDelay Should be successful 06 Terminate the audio port using <code>dsAudioPortTerm</code> None <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\n    A[ dsAudioPortInit] --&gt;|dsERR_NONE|B{Loop through the &lt;br&gt; supported audio ports}\n    B --&gt;|dsERR_NONE|D[ call dsSetAudioDelay &lt;br&gt;with delay value]\n    B --&gt;|Not dsERR_NONE or invalid handle|B\n    D --&gt;|dsERR_NONE|E[call dsGetAudioDelay ]\n    E --&gt;|dsERR_NONE|F[Verify audio delay matches &lt;br&gt; the set audio delay]\n    F --&gt; F1[Test case fail]\n    F1 --&gt;|Comparison Fail| B\n    F --&gt; B\n    B --&gt;|End of Loop|G[ call dsAudioPortTerm]\n    G --&gt;|dsERR_NONE|H[Test case success]\n    A --&gt;|Failure|I[Test case fail]\n    G --&gt;|Failure|M[Test case fail]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L2_Low-Level_TestSpecification/#test-26","title":"Test 26","text":"Title Details Function Name <code>test_l2_dsAudio_VerifyAtmosCapabilities_sink</code> Description For sink devices, get the ATMOS capabilities and verify them with the configuration file Test Group 02 Test Case ID 026 Priority High <p>Pre-Conditions : None</p> <p>Dependencies : None</p> <p>User Interaction : If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L2_Low-Level_TestSpecification/#test-procedure-test-26","title":"Test Procedure - Test 26","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the audio port using <code>dsAudioPortInit</code> None <code>dsERR_NONE</code> Should be successful 02 Loop through supported audio ports and get audio port using <code>dsGetAudioPort</code> supported number of audio ports = <code>dsAudio/Number_of_supported_ports</code> field and port id = <code>dsAudio/Port/[port number]/Typeid</code> of configuration file <code>dsERR_NONE</code> Should be successful 03 Get the ATMOS capability of the sink device using <code>dsGetSinkDeviceAtmosCapability</code> handle=valid handle <code>dsERR_NONE</code> Should be successful 04 Verify the ATMOS capability of the sink device ATMOS capabilities = <code>dsAudio/Port/[port number]/ATMOS_Capabilities</code> of configuration file Matches Should be successful 05 Terminate the audio port using <code>dsAudioPortTerm</code> None <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\n    A[ dsAudioPortInit] --&gt;|dsERR_NONE|B{Loop through the &lt;br&gt; supported audio ports}\n    B --&gt;|dsERR_NONE|D[call dsGetSinkDeviceAtmosCapability]\n    B --&gt;|Not dsERR_NONE or invalid handle|B\n    D --&gt;|dsERR_NONE|E[Verify the ATMOS Capabilities with the configuration file]\n    E --&gt; |Comparison Fail|E1[Test case fail]\n    E1 --&gt; B\n    E --&gt; B\n    B --&gt;|End of Loop|G[ call dsAudioPortTerm]\n    G --&gt;|dsERR_NONE|H[Test case success]\n    A --&gt;|Failure|I[Test case fail]\n    G --&gt;|Failure|M[Test case fail]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L2_Low-Level_TestSpecification/#test-27","title":"Test 27","text":"Title Details Function Name <code>test_l2_dsAudio_GetAudioCapabilities</code> Description Get the audio capabilities of the device and verify with configuration file Test Group 02 Test Case ID 027 Priority High <p>Pre-Conditions : None</p> <p>Dependencies : None</p> <p>User Interaction : If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L2_Low-Level_TestSpecification/#test-procedure-test-27","title":"Test Procedure - Test 27","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the audio port using <code>dsAudioPortInit</code> None <code>dsERR_NONE</code> Should be successful 02 Get the audio port using <code>dsGetAudioPort</code> type = Any supported port from the configuration file <code>dsAudio/Port/[port number]/Typeid</code> <code>dsERR_NONE</code> Should be successful 03 Get the audio capabilities using <code>dsGetAudioCapabilities</code> with the handle obtained from previous step handle = obtained from step 02 <code>dsERR_NONE</code> Should be successful 04 Verify the obtained capabilities with the expected value from the configuration file Read audio capabilities from the <code>Audio_Capabilities</code> of configuration file capabilities = obtained from step 03 Should be successful 05 Terminate the audio port using <code>dsAudioPortTerm</code> None <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\n    A[Call dsAudioPortInit] --&gt;|return dsERR_NONE|B[Call dsGetAudioPort with &lt;br&gt; supported port]\n    A --&gt;|return not dsERR_NONE|A1[Test case fail]\n    B --&gt;|return dsERR_NONE|C[Call dsGetAudioCapabilities]\n    B --&gt;|return not dsERR_NONE|B1[Test case fail]\n    C --&gt;|return dsERR_NONE|D[Compare obtained audio capabilities with yaml file]\n    C --&gt;|return not dsERR_NONE|C1[Test case fail]\n    D --&gt;|Values match|E[Call dsAudioPortTerm]\n    D --&gt;|Values do not match|D1[Test case fail]\n    E --&gt;|return dsERR_NONE|F[Test case success]\n    E --&gt;|return not dsERR_NONE|E1[Test case fail]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L2_Low-Level_TestSpecification/#test-28","title":"Test 28","text":"Title Details Function Name <code>test_l2_dsAudio_EnableDisableRetrieveAudioMixing</code> Description Loop through supported audio ports, Enable/disable Associated Audio Mixing for supported ports and retrieve it for verification Test Group 02 Test Case ID 028 Priority High <p>Pre-Conditions : None</p> <p>Dependencies : None</p> <p>User Interaction : If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L2_Low-Level_TestSpecification/#test-procedure-test-28","title":"Test Procedure - Test 28","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the audio port using <code>dsAudioPortInit</code> None <code>dsERR_NONE</code> Should be successful 02 Get the audio port using <code>dsGetAudioPort</code> type = Any supported port from the configuration file <code>dsAudio/Port/[port number]/Typeid</code> <code>dsERR_NONE</code> Should be successful 03 Enable Associated Audio Mixing for the retrieved port using <code>dsSetAssociatedAudioMixing</code> handle = retrieved handle, mixing = true <code>dsERR_NONE</code> Should be successful 04 Retrieve the Associated Audio Mixing status using <code>dsGetAssociatedAudioMixing</code> handle = retrieved handle, mixing = pointer to bool <code>dsERR_NONE</code> and mixing = <code>true</code> Should be successful 05 Disable Associated Audio Mixing for the retrieved port using <code>dsSetAssociatedAudioMixing</code> handle = retrieved handle, mixing = <code>false</code> <code>dsERR_NONE</code> Should be successful 06 Retrieve the Associated Audio Mixing status using <code>dsGetAssociatedAudioMixing</code> handle = retrieved handle, mixing = pointer to bool <code>dsERR_NONE</code> and mixing = <code>false</code> Should be successful 07 Terminate the audio port using <code>dsAudioPortTerm</code> None <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\n    A[Call dsAudioPortInit] --&gt;|dsERR_NONE|B[Get audio port]\n    A --&gt;|Failure|AF[Test case fail]\n    B --&gt;|dsERR_NONE|C[Call dsSetAssociatedAudioMixing to &lt;br&gt; enable and disable audio mixing]\n    C --&gt; |!dsERR_NONE|C1[Test case fail]\n    C --&gt;|dsERR_NONE|D[Call dsGetAssociatedAudioMixing to &lt;br&gt; retrieve audio mixing status]\n    D --&gt; |Comparison Fail|D1[Test case fail]\n    D --&gt;|dsERR_NONE &amp; get and set matches|E[dsAudioPortTerm]\n    E --&gt;|dsERR_NONE|F[Test case success]\n    E --&gt;|Failure|EF[Test case fail]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L2_Low-Level_TestSpecification/#test-29","title":"Test 29","text":"Title Details Function Name <code>test_l2_dsAudio_AudioPortControl</code> Description Loop through supported audio ports, Enable Associated Audio Mixing for supported ports, Set various Fader Control values for supported ports and retrieve it for verification Test Group 02 Test Case ID 029 Priority High <p>Pre-Conditions : None</p> <p>Dependencies : None</p> <p>User Interaction : If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L2_Low-Level_TestSpecification/#test-procedure-test-29","title":"Test Procedure - Test 29","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the audio port using <code>dsAudioPortInit</code> None <code>dsERR_NONE</code> Should be successful 02 Get the audio port using <code>dsGetAudioPort</code> type = Any supported port from the configuration file <code>dsAudio/Port/[port number]/Typeid</code> <code>dsERR_NONE</code> Should be successful 03 Enable Associated Audio Mixing for the retrieved port using <code>dsSetAssociatedAudioMixing</code> handle = retrieved handle, mixing = true <code>dsERR_NONE</code> Should be successful 04 Set various Fader Control values for the retrieved port using <code>dsSetFaderControl</code> handle = retrieved handle, mixerbalance = -32 to 32 in steps of 8 <code>dsERR_NONE</code> Should be successful 05 Retrieve the Fader Control value for verification using <code>dsGetFaderControl</code> handle = retrieved handle, getMixerbalance = buffer to store the retrieved value <code>dsERR_NONE</code>, getMixerbalance = mixerbalance Should be successful 06 Terminate the audio port using <code>dsAudioPortTerm</code> None <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\nA[dsAudioPortInit] --&gt;|dsERR_NONE|B[Get audio port]\nB --&gt;|dsERR_NONE|C[dsSetAssociatedAudioMixing]\nC --&gt; |!dsERR_NONE|C1[Test case fail]\nC --&gt;|dsERR_NONE|D[dsSetFaderControl]\nD --&gt; |!dsERR_NONE|D1[Test case fail]\nD --&gt;|dsERR_NONE|E[dsGetFaderControl]\nE --&gt; |Comparison Fail|E1[Test case fail]\nE --&gt;|dsERR_NONE &amp; &lt;br&gt;get and set matches|I[dsAudioPortTerm]\nI --&gt;|dsERR_NONE|J[Test case success]\nI --&gt;|!= dsERR_NONE|K[Test case fail]\nA --&gt;|!= dsERR_NONE|L[Test case fail]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L2_Low-Level_TestSpecification/#test-30","title":"Test 30","text":"Title Details Function Name <code>test_l2_dsAudio_SetAndGetPrimaryLanguage</code> Description Set Primary Language and retrieve the same for verification Test Group 02 Test Case ID 030 Priority High <p>Pre-Conditions : None</p> <p>Dependencies : None</p> <p>User Interaction : If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L2_Low-Level_TestSpecification/#test-procedure-test-30","title":"Test Procedure - Test 30","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the audio port using <code>dsAudioPortInit</code> None <code>dsERR_NONE</code> Should be successful 02 Get the audio port using <code>dsGetAudioPort</code> type = Any supported port from the configuration file <code>dsAudio/Port/[port number]/Typeid</code> <code>dsERR_NONE</code> Should be successful 03 Set the primary language using <code>dsSetPrimaryLanguage</code> with handle and valid language code handle = obtained handle, setLang = \"eng\" <code>dsERR_NONE</code> Should be successful 04 Get the primary language using <code>dsGetPrimaryLanguage</code> with handle handle = obtained handle, getLang = valid buffer <code>dsERR_NONE</code> Should be successful 05 Verify the set and get languages are same setLang = \"eng\", getLang = obtained language setLang should be equal to getLang Should be successful 06 Terminate the audio port using <code>dsAudioPortTerm</code> None <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\nA[Call dsAudioPortInit] --&gt;|dsERR_NONE|B[Call dsGetAudioPort]\nA --&gt;|!=dsERR_NONE|A1[Test case fail]\nB --&gt;|dsERR_NONE and valid handle|C[Call dsSetPrimaryLanguage]\nB --&gt;|!=dsERR_NONE or invalid handle|B1[Test case fail]\nC --&gt;|dsERR_NONE|D[Call dsGetPrimaryLanguage]\nC --&gt;|!=dsERR_NONE|C1[Test case fail]\nD --&gt;|dsERR_NONE and same language code|E[Call dsAudioPortTerm]\nD --&gt;|!=dsERR_NONE or different language code|D1[Test case fail]\nE --&gt;|dsERR_NONE|F[Test case success]\nE --&gt;|!=dsERR_NONE|E1[Test case fail]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L2_Low-Level_TestSpecification/#test-31","title":"Test 31","text":"Title Details Function Name <code>test_l2_dsAudio_SetAndGetSecondaryLanguage</code> Description Set Secondary Language and retrieve the same for verification Test Group 02 Test Case ID 031 Priority High <p>Pre-Conditions : None</p> <p>Dependencies : None</p> <p>User Interaction : If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L2_Low-Level_TestSpecification/#test-procedure-test-31","title":"Test Procedure - Test 31","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the audio port using <code>dsAudioPortInit</code> None <code>dsERR_NONE</code> Should be successful 02 Get the audio port using <code>dsGetAudioPort</code> type = Any supported port from the configuration file <code>dsAudio/Port/[port number]/Typeid</code> <code>dsERR_NONE</code> Should be successful 03 Set the secondary language using <code>dsSetSecondaryLanguage</code> handle = obtained handle, language = \"eng\" <code>dsERR_NONE</code> Should be successful 04 If setting secondary language fails, terminate the audio port using <code>dsAudioPortTerm</code> and return None <code>dsERR_NONE</code> Should be successful 05 Get the secondary language using <code>dsGetSecondaryLanguage</code> handle = obtained handle, language = valid buffer <code>dsERR_NONE</code> Should be successful 06 Verify the set and get languages are same setLang = \"eng\", getLang = obtained language setLang should be equal to getLang Should be successful 07 Terminate the audio port using <code>dsAudioPortTerm</code> None <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\nA[Call dsAudioPortInit] --&gt;|dsERR_NONE|B[Call dsGetAudioPort]\nA --&gt;|!=dsERR_NONE|A1[Test case fail]\nB --&gt;|dsERR_NONE|C[Call dsSetSecondaryLanguage]\nB --&gt;|!=dsERR_NONE|B1[Test case fail]\nC --&gt;|dsERR_NONE|D[Call dsGetSecondaryLanguage]\nC --&gt;|!=dsERR_NONE|C1[Test case fail]\nD --&gt;|dsERR_NONE &amp; get and set same|E[Call dsAudioPortTerm]\nD --&gt;|!=dsERR_NONE|D1[Test case fail]\nE --&gt;|dsERR_NONE|F[Test case pass]\nE --&gt;|!=dsERR_NONE|E1[Test case fail]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_Low-Level_TestSpecification/","title":"Audio Settings L3 Low Level Test Specification and Procedure Documentation","text":""},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_Low-Level_TestSpecification/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>HAL</code>    - Hardware Abstraction Layer</li> <li><code>API</code>    - Application Programming Interface</li> <li><code>L2</code>     - Level 2 Testing</li> <li><code>L3</code>     - Level 3 Testing</li> <li><code>DS</code>     - Device Settings</li> <li><code>ARC</code>    - Audio Return Channel</li> <li><code>HDMI</code>   - High-Definition Multimedia Interface</li> <li><code>LE</code>     - Loudness Equivalence</li> <li><code>DRC</code>    - Dynamic Range Control</li> <li><code>MI</code>     - Media Intelligent</li> <li><code>MS12</code>   - MultiStream 12</li> <li><code>MS11</code>   - MultiStream 11</li> <li><code>DAP</code>    - Digital Audio Processing</li> <li><code>PCM</code>    - Pulse Code Modulation</li> <li><code>WAV</code>    - Waveform</li> <li><code>DUT</code>    - Device Under Test</li> <li><code>NA</code>     - Not Applicable</li> <li><code>RAFT</code>   - Rapid Automation Framework for Testing</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_Low-Level_TestSpecification/#overview","title":"Overview","text":"<p>This document describes the L3 Test Procedure for the Device Settings Audio module.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_Low-Level_TestSpecification/#references","title":"References","text":"<ul> <li>dsAudio HAL Interface - dsAudio.h</li> <li>High Level Test Specification - ds-audio_High-Level_TestSpecification.md</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_Low-Level_TestSpecification/#audio-streams-requirement","title":"Audio Streams Requirement","text":"# Stream Name Description 01 tones_string_48k_stereo.ac3 <code>AC3</code> format audio with tones (single notes) across various frequencies 02 Dolby_stream_supports_Dialogue_Enhancer <code>AC4</code> format audio with speech frequencies, designed to test the dialogue enhancer feature 03 music_8k_stereo.ac3 <code>AC3</code> format audio with music, used to test features like the equalizer 04 tone_500Hz_compress_48k_stereo.ac3 <code>AC3</code> format with a 500Hz tone, which alternates between two volume levels (-25dB and -5dB), useful for compression and dynamic range testing 05 tone_bassrange_150Hz_48k_stereo.ac3 <code>AC3</code> format with a 150Hz tone at -10dB 06 Dolby_atmos_stream_supports_surround_mode Dolby <code>AC4</code>, <code>EAC3_ATMOS</code>, and <code>AC4_ATMOS</code> formats to test surround sound mode 07 tones_string_48k_stereo.wav <code>WAV</code> (<code>PCM</code>) format with tones across various frequencies 08 tones_string_48k_stereo.eac3 <code>EAC3</code> format with tones across various frequencies 09 tones_string_48k_stereo.aac <code>AAC</code> format with tones across various frequencies 10 tones_string_48k_stereo.ogg <code>VORBIS</code> format with tones across various frequencies 11 tones_string_48k_stereo.wma <code>WMA</code> format with tones across various frequencies 12 Audio_supports_MAT_format Dolby <code>MAT</code> format 13 Dolby_audio_supports_TRUEHD_format Dolby <code>TRUEHD</code> format 14 DolbyDigitalPlus_atmos_audio Dolby <code>EAC3_ATMOS</code> format 15 TRUEHD_atmos_audio Dolby <code>TRUEHD_ATMOS</code> format 16 MAT_atmos_audio Dolby <code>MAT_ATMOS</code> format 17 Dolby_atmos_audio Dolby <code>AC4_ATMOS</code> format 18 Dolby_stream_supports_AVsync Dolby stream specifically designed to test <code>AV</code> synchronization 19 Dolby_stream_supports_Multi-Language <code>AC4</code> format with three language tracks (Chinese, English, and Spanish) and additional audio options, used to test multi-language audio capabilities 20 primary_audio_48k_2ch.ac3 <code>AC3</code> format with two-channel audio (stereo) containing dialogue 21 system_audio_48k_2ch.wav <code>WAV</code> (<code>PCM</code>) format with two-channel audio containing dialogue"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_Low-Level_TestSpecification/#level-3-test-cases-high-level-overview","title":"Level 3 Test Cases High Level Overview","text":"<p>Below are top test use-case for the audio port.</p> # Test-case Description HAL APIs Source Sink Streams Number 1 Enable/disable audio ports Play the predefined audio streams. Iterate through the supported audio ports, enabling or disabling them, and check if the stream is being played through each port <code>dsEnableAudioPort()</code> <code>Y</code> <code>Y</code> 01 2 Verify the Headphone connection status Enable the headphone port and verify the connection status by disconnecting and reconnecting the port. Additionally, confirm if the callback is triggered <code>dsAudioOutIsConnected()</code> <code>N</code> <code>Y</code> <code>NA</code> 3 Verify MS12 Audio Compression Loop through the ports which supports Audio Compression and verify <code>dsSetAudioCompression()</code> <code>Y</code> <code>Y</code> 01 4 Verify MS12 <code>DAP</code> Dialog enhancement Loop through the ports which supports <code>MS12</code> <code>DAP</code> Capabilities and verify Dialog enhancement <code>dsSetDialogEnhancement()</code> <code>Y</code> <code>Y</code> 02 5 Verify MS12 <code>DAP</code> Dolby Volume mode Loop through the ports which supports <code>MS12</code> <code>DAP</code> Capabilities and verify Dolby Volume mode <code>dsSetDolbyVolumeMode()</code> <code>Y</code> <code>Y</code> 01 6 Verify MS12 <code>DAP</code> Intelligent Equalizer Loop through the ports which supports <code>MS12</code> <code>DAP</code> Capabilities and verify the Intelligent Equalizer <code>dsSetIntelligentEqualizerMode()</code> <code>Y</code> <code>Y</code> 03 7 Verify MS12 <code>DAP</code> Volume leveller Loop through the ports which supports <code>MS12</code> <code>DAP</code> Capabilities and verify Volume leveller <code>dsSetVolumeLeveller()</code> <code>Y</code> <code>Y</code> 04 8 Verify MS12 <code>DAP</code> Bass enhancer Loop through the ports which supports <code>MS12</code> <code>DAP</code> Capabilities and verify Bass enhancer <code>dsSetBassEnhancer()</code> <code>Y</code> <code>Y</code> 05 9 Verify MS12 <code>DAP</code> Surround Decoder Loop through the ports which supports <code>MS12</code> <code>DAP</code> Capabilities and verify Surround Decoder <code>dsEnableSurroundDecoder()</code> <code>Y</code> <code>Y</code> 06 10 Verify MS12 <code>DAP</code> <code>DRC</code> Mode Loop through the ports which supports <code>MS12</code> <code>DAP</code> Capabilities and verify <code>DRC</code> Mode <code>dsSetDRCMode()</code> <code>Y</code> <code>Y</code> 04 11 Verify MS12 <code>DAP</code> Surround Virtualizer Loop through the ports which supports <code>MS12</code> <code>DAP</code> Capabilities and verify Surround Virtualizer <code>dsSetSurroundVirtualizer()</code> <code>Y</code> <code>Y</code> 06 12 Verify MS12 <code>DAP</code> <code>MI</code> Steering Loop through the ports which supports <code>MS12</code> <code>DAP</code> Capabilities and verify <code>MI</code> Steering <code>dsSetMISteering()</code> <code>Y</code> <code>Y</code> 01 13 Verify MS12 <code>DAP</code> Graphics Equalizer Loop through the ports which supports <code>MS12</code> <code>DAP</code> Capabilities and verify Graphics Equalizer <code>dsSetGraphicEqualizerMode()</code> <code>Y</code> <code>Y</code> 01 14 Verify MS12 <code>DAP</code> <code>LE</code> Config Loop through the ports which supports <code>MS12</code> <code>DAP</code> Capabilities and verify <code>LE</code> Config <code>dsEnableLEConfig()</code> <code>Y</code> <code>Y</code> 04 15 Test <code>ARC</code> Port Enable the <code>ARC</code> port, retrieve the connected device's capabilities, and verify them <code>dsGetSupportedARCTypes()</code> <code>N</code> <code>Y</code> <code>NA</code> 16 Test <code>ARC</code> Port <code>SAD</code> Enable the <code>ARC</code> port, set the set the <code>SAD</code> and verify <code>dsAudioSetSAD()</code> <code>N</code> <code>Y</code> <code>NA</code> 17 Test output mode Play the predefined audio streams. Iterate through the audio ports which supports stereo modes, set various stereo modes and verify <code>dsSetStereoMode()</code> <code>Y</code> <code>Y</code> 01, 07, 08 18 Test Audio Level Play the predefined audio streams. Iterate through the audio ports, set the gain and verify <code>dsSetAudioLevel()</code> <code>N</code> <code>Y</code> 01 19 Test Audio Gain Play the predefined audio streams. set the gain for Speaker port and verify <code>dsSetAudioGain()</code> <code>N</code> <code>Y</code> 01 20 Test Audio Mute Play the predefined audio streams. Iterate through the audio ports, set the Mute, Un-mute and verify <code>dsSetAudioMute()</code> <code>Y</code> <code>Y</code> 01 21 Test Audio Delay Play the predefined audio streams. Iterate through the audio ports, set the delay and verify <code>dsSetAudioDelay()</code> <code>Y</code> <code>Y</code> 18 22 Test Audio Format Play the predefined audio streams. verify the audio format using <code>API</code>. Additionally, confirm if the callback is triggered <code>dsGetAudioFormat()</code> <code>Y</code> <code>Y</code> 01, 07, 08, 09, 10, 11, 12, 13, 14, 15, 16, 17 23 Test Associated Audio Mixing Play the predefined audio streams. Set the mixer levels and verify <code>dsSetAssociatedAudioMixing()</code>, <code>dsSetFaderControl()</code> <code>Y</code> <code>Y</code> 19 24 Test Primary/Secondary Language Play the predefined audio streams. Set the primary and secondary languages and verify <code>dsSetPrimaryLanguage()</code>, <code>dsSetSecondaryLanguage()</code> <code>Y</code> <code>Y</code> 19 25 Test Audio Mixer Levels Play the predefined audio streams. Set the mixer levels for primary and system audio and verify <code>dsSetAudioMixerLevels()</code> <code>N</code> <code>Y</code> 20, 21 26 Test MS12 Audio Profiles Play the predefined audio streams. Set the MS12 profiles and verify <code>dsSetMS12AudioProfile()</code> <code>N</code> <code>Y</code> 03"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_Low-Level_TestSpecification/#level-3-python-test-cases-high-level-overview","title":"Level 3 Python Test Cases High Level Overview","text":"<p>The class diagram below illustrates the flow of dsAudio L3 Python test cases:</p> <pre><code>---\ntitle: dsAudio - Python Class Flow\n---\nclassDiagram\n    testControl &lt;|-- ut_raft : inherits\n    class ut_raft{\n    }\n    ut_raft &lt;|-- dsAudioHelperClass : inherits\n    dsAudioHelperClass &lt;|-- L3_TestClasses : inherits\n    L3_TestClasses ..&gt; dsAudio : uses\n    note for testControl \"uses rackConfig.yaml and deviceConfig.yaml\"\n    note for dsAudio \"uses platformProfile.yaml\"\n    note for L3_TestClasses \"uses testSetupConfig.yaml\"\n    note for ut_raft \"suite Navigator uses testSuite.yaml\"</code></pre> <ul> <li>testControl</li> <li>Test Control Module for running rack Testing. This module configures the <code>DUT</code> based on the rack configuration file provided to the test.</li> <li>This class is defined in <code>RAFT</code> framework. For more details refer RAFT</li> <li>ut_raft</li> <li>Python based testing framework for writing engineering tests.</li> <li>It provides common functionalities like menu navigation, configuration reader, reading user response etc.</li> <li>For more details ut-raft.</li> <li>dsAudio</li> <li>This is test helper class which communicates with the <code>L3</code> C/C++ test running on the <code>DUT</code> through menu</li> <li>L3_TestClasses</li> <li>These are the L3 test case classes</li> <li>Each class covers the each test use-case defined in L3 Test use-cases table</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_Low-Level_TestSpecification/#yaml-file-inputs","title":"YAML File Inputs","text":"<ul> <li>rackConfig.yaml</li> <li>Identifies the rack configuration and platform used</li> <li>References platform-specific config from <code>deviceConfig.yaml</code></li> <li> <p>For more details refer RAFT and example_rack_config.yml</p> </li> <li> <p>deviceConfig.yaml</p> </li> <li>Specifies overall configuration for the platform</li> <li>Can be overridden by:<ul> <li>Changing locally .yaml file directory</li> <li>Using --deviceConfig command line switch</li> </ul> </li> <li> <p>For more details refer RAFT and example_device_config.yml</p> </li> <li> <p>componentProfile.yaml/platformProfile.yaml</p> </li> <li>Contains component-specific configurations</li> <li>Contains platform wide configuration broken down into separate components</li> <li> <p>Example configuration file dsAudio_Settings</p> </li> <li> <p>testSetupConfig.yaml</p> </li> <li>This configuration file contains the list of requirements for tests to execute. Eg: Copying the streams, setting environment variables etc.</li> <li> <p>Example configuration file dsAudio_L3_testSetup.yml</p> </li> <li> <p>testConfig.yaml</p> </li> <li>This configuration file contains the list of menu items for C/C++ L3 test running on <code>DUT</code></li> <li>Example configuration file dsAudio_test_suite.yml</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/","title":"dsAudio HAL L3 Python Test Procedure","text":""},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>HAL</code>    - Hardware Abstraction Layer</li> <li><code>L3</code>     - Level 3 Testing</li> <li><code>ARC</code>    - Audio Return Channel</li> <li><code>eARC</code>   - Enhanced Audio Return Channel</li> <li><code>SAD</code>    - Short Audio Descriptor</li> <li><code>SPDIF</code>  - Sony/Philips Digital Interface</li> <li><code>HDMI</code>   - High-Definition Multimedia Interface</li> <li><code>LE</code>     - Loudness Equivalence</li> <li><code>DRC</code>    - Dynamic Range Control</li> <li><code>MI</code>     - Media Intelligent</li> <li><code>MS12</code>   - MultiStream 12</li> <li><code>PCM</code>    - Pulse Code Modulation</li> <li><code>AC3</code>    - Audio Codec 3</li> <li><code>EAC3</code>   - Enhanced <code>AC3</code></li> <li><code>WMA</code>    - Windows Media Audio</li> <li><code>AAC</code>    - Advanced Audio coding</li> <li><code>DD</code>     - DOLBY Digital</li> <li><code>DDPLUS</code> - DOLBY Digital Plus</li> <li><code>MAT</code>    - Metadata-enhanced Audio Transmission</li> <li><code>DAP</code>    - Digital Audio Processing</li> <li><code>DUT</code>    - Device Under Test</li> <li><code>RAFT</code>   - Rapid Automation Framework for Testing</li> <li><code>YAML</code>   - YAML Ain't Markup Language</li> <li><code>avr</code>    - Audio Video Receiver</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#setting-up-test-environment","title":"Setting Up Test Environment","text":"<p>To execute <code>HAL</code> <code>L3</code> Python test cases, need a Python environment. Follow these steps mentioned in HPK Public Documentation</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#update-configuration-files","title":"Update Configuration Files","text":""},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#rack-configuration-file","title":"Rack Configuration File","text":"<p>Example Rack configuration File: example_rack_config.yml</p> <p>For more details refer RAFT and example_rack_config.yml</p> <p>In this file, update the configuration to define the console sessions for the <code>DUT</code> and the outbound settings:</p> Console Session Description default Downloads the streams required for test cases ssh_player Plays the stream required for test case ssh_player_secondary Plays a secondary stream, if required for test case ssh_hal_test Executes the <code>HAL</code> binary for the test case <pre><code>rackConfig:\n  - dut:\n      ip: \"XXX.XXX.XXX.XXX\"  # IP Address of the device\n      description: \"stb device under test\"\n      platform: \"stb\"\n      consoles:\n        - default:\n            type: \"ssh\"\n            port: 10022\n            username: \"root\"\n            ip: \"XXX.XXX.XXX\" # IP address of the device\n            password: ' '\n        - ssh_player:\n            type: \"ssh\"\n            port: 10022\n            username: \"root\"\n            ip: \"XXX.XXX.XXX\" # IP address of the device\n            password: ' '\n        - ssh_player_secondary:\n            type: \"ssh\"\n            port: 10022\n            username: \"root\"\n            ip: \"XXX.XXX.XXX\" # IP address of the device\n            password: ' '\n        - ssh_hal_test:\n            type: \"ssh\"\n            port: 10022\n            username: \"root\"\n            ip: \"XXX.XXX.XXX\" # IP address of the device\n            password: ' '\n      outbound:\n        download_url: \"http://localhost:8000/\"    # download location for the CPE device\n        httpProxy:   # Local Proxy if required\n        workspaceDirectory: './logs/workspace'   # Local working directory\n</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#device-configuration-file","title":"Device Configuration File","text":"<p>Example Device configuration File: deviceConfig.yml</p> <p>For more details refer RAFT and example_device_config.yml</p> <p>Update below fileds in the device configuration file:</p> <ul> <li>Set the path for <code>target_directory</code> where <code>HAL</code> binaries will be copied onto the device.</li> <li> <p>Add <code>soc_vendor</code> inorder to run prerequisites required for the player in the path <code>&lt;PATH&gt;/ut/host/tests/raft/framework/plugins/ut_raft/configs/utPlayerConfig.yml</code></p> <pre><code>intel: # soc ID\n  gstreamer: # player Name\n    prerequisites: # Prerequisites if any to run the player\n      - export XDG_RUNTIME_DIR=\"/tmp\"\n      - westros-init &amp;\n</code></pre> </li> <li> <p>Specify the device profile path in <code>test/profile</code></p> </li> <li>Update <code>streams_download_url</code> with the URL from which the streams will be downloaded</li> <li>Ensure the <code>platform</code> should match with the <code>DUT</code> <code>platform</code> in Rack Configuration</li> </ul> <pre><code>deviceConfig:\n    cpe1:\n        platform: \"linux\"\n        model: \"uk\"\n        soc_vendor: \"intel\"\n        target_directory: \"/tmp/\"  # Target Directory on device\n        prompt: \"\" # Prompt string on console\n        test:\n            profile: \"../../../../profiles/sink/Sink_AudioSettings.yaml\"\n            streams_download_url: \"&lt;URL_Path&gt;\" #URL path from which the streams are downloaded to the device\n</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#test-setup-configuration-file","title":"Test Setup Configuration File","text":"<p>Example Test Setup configuration File: dsAudio_L3_testSetup.yml</p> <p>Streams required for each test case was provided in this file. This path is appended with <code>streams_download_url</code> entry from Device Configuration File</p> <p>If a test case requires multiple streams or needs to be validated using several streams, ensure that all necessary streams are added sequentially for that specific test case.</p> <pre><code>dsAudio:\n  description: \"dsAudio Device Settings test setup\"\n  assets:\n    device:\n      test01_EnableDisableAndVerifyAudioPortStatus:\n        streams:\n          - \"streams/tones_string_48k_stereo.ac3\"\n      test02_PortConnectionStatus:\n        streams:\n      test03_MS12AudioCompression:\n        streams:\n          - \"streams/tones_string_48k_stereo.ac3\"\n      test25_AudioMix:\n        streams:\n          - \"streams/primary_audio_48k_2ch.ac3\"\n          - \"streams/system_audio_48k_2ch.wav\"\n</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#test-configuration","title":"Test Configuration","text":"<p>Example Test Setup configuration File: dsAudio_testConfig.yml</p> <p>Execute command to run te HAL binary was provided in this file.</p> <pre><code>dsAudio:\n    description: \"dsAudio Device Settings testing profile / menu system for UT\"\n    test:\n        artifacts:\n        #List of artifacts folders, test class copies the content of folder to the target device workspace\n          - \"../../../bin/\"\n        # exectute command, this will appended with the target device workspace path\n        execute: \"run.sh\"\n        type: UT-C # C (UT-C Cunit) / C++ (UT-G (g++ ut-core gtest backend))\n</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#run-test-cases","title":"Run Test Cases","text":"<p>Once the environment is set up, you can execute the test cases with the following command</p> <pre><code>python &lt;TestCaseName.py&gt; --config &lt;/PATH&gt;/ut/host/tests/configs/example_rack_config.yml --deviceConfig &lt;/PATH&gt;/ut/host/tests/configs/deviceConfig.yml\n</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#streams-required","title":"Streams Required","text":"<p>Refer ds-audio_L3_Low-Level_TestSpecification.md for the stream details</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#test-cases","title":"Test Cases","text":""},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#dsaudio_l3_runall_sinkpy","title":"dsAudio_L3_Runall_Sink.py","text":"<p>This python file runs all the tests supported by <code>sink</code> devices</p> <pre><code>python dsAudio_L3_Runall_Sink.py --config &lt;/PATH&gt;/ut/host/tests/configs/example_rack_config.yml --deviceConfig &lt;/PATH&gt;/ut/host/tests/configs/deviceConfig.yml\n</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#dsaudio_l3_runall_sourcepy","title":"dsAudio_L3_Runall_Source.py","text":"<p>This python file runs all the tests supported by <code>source</code> devices</p> <pre><code>python dsAudio_L3_Runall_Source.py --config &lt;/PATH&gt;/ut/host/tests/configs/example_rack_config.yml --deviceConfig &lt;/PATH&gt;/ut/host/tests/configs/deviceConfig.yml\n</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#dsaudio_test01_enabledisableandverifyaudioportstatuspy","title":"dsAudio_test01_EnableDisableAndVerifyAudioPortStatus.py","text":""},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#platform-support-test01","title":"Platform Support - test01","text":"<ul> <li>Source</li> <li>Sink</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#user-input-required-test01","title":"User Input Required - test01","text":"<p>Yes: User interaction is necessary to confirm audio playback status (This will be automated later).</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#acceptance-criteria-test01","title":"Acceptance Criteria - test01","text":"<p>Play Stream #1 and confirm that audio is heard through the supported ports.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#expected-results-test01","title":"Expected Results - test01","text":"<p>The test enables the specified audio ports, plays the audio stream, and subsequently disables the ports</p> <p>Success Criteria</p> <ul> <li>User should hear audio through the enabled port during playback</li> <li>User should not hear any audio when the port is disabled.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#test-steps-test01","title":"Test Steps - test01","text":"<ul> <li> <p>Initiate the Test:</p> </li> <li> <p>Select and execute the Python file: <code>dsAudio_test01_EnableDisableAndVerifyAudioPortStatus.py</code></p> </li> <li> <p>The test will automatically download all required artifacts and streams, copying them to the designated target directory before commencing execution.</p> </li> <li> <p>Audio Playback Verification:</p> <p>The test will play the designated audio stream and prompt the user with the following:</p> </li> <li> <p>Question: \"Is audio playing on the enabled audio port? (Y/N)\"</p> </li> <li>Press Y if audio is heard (this will mark the step as PASS).</li> <li> <p>Press N if no audio is heard (this will mark the step as FAIL).</p> </li> <li> <p>Audio Status Confirmation (Port Disabled):</p> </li> </ul> <p>After confirming audio playback, the test will disable the audio port and prompt the user again:</p> <ul> <li>Question: \"Is audio playing when the port is disabled? (Y/N)\"</li> <li>Press N if no audio is heard (this will mark the step as PASS).</li> <li> <p>Press Y if audio is heard (this will mark the step as FAIL).</p> </li> <li> <p>Repeat for All Ports:</p> </li> </ul> <p>The test will iterate through all available audio ports, enabling/disabling each one and collecting user feedback accordingly.</p> <ul> <li>Test Conclusion:</li> </ul> <p>Upon receiving user responses for all ports, the test will conclude and present a final result: PASS or FAIL based on the user inputs throughout the test execution.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#dsaudio_test02_portconnectionstatuspy","title":"dsAudio_test02_PortConnectionStatus.py","text":""},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#platform-supported-test02","title":"Platform Supported - test02","text":"<ul> <li>Sink</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#user-input-required-test02","title":"User Input Required - test02","text":"<ul> <li>Yes (This will be automated later).</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#acceptance-criteria-test02","title":"Acceptance Criteria - test02","text":"<ul> <li>Verify the Headphone connection status.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#expected-results-test02","title":"Expected Results - test02","text":"<ul> <li>This test checks whether the headphones are connected or disconnected.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#test-steps-test02","title":"Test Steps - test02","text":"<ul> <li>Run the test file: <code>dsAudio_test02_PortConnectionStatus.py</code></li> <li>Execution process:</li> </ul> <p>Upon execution, the test will:</p> <ul> <li>Download all the required artifacts.</li> <li>Copy them to the target directory.</li> <li> <p>Automatically start the test execution.</p> </li> <li> <p>User prompt for action:</p> </li> </ul> <p>During the test, the user will be prompted to connect or disconnect the headphones. When prompted:</p> <ul> <li>The message \"Connect/Disconnect the HEADPHONES and press Enter\" will appear.</li> <li> <p>The user must physically connect or disconnect the headphones as requested, then press Enter to proceed.</p> </li> <li> <p>Completion and Result:</p> </li> </ul> <p>Once all necessary user actions are completed, the test will evaluate the results and display whether the test Passed or Failed.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#dsaudio_test03_ms12audiocompressionpy","title":"dsAudio_test03_MS12AudioCompression.py","text":""},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#platform-supported-test03","title":"Platform Supported - test03","text":"<ul> <li>Source</li> <li>Sink</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#user-input-required-test03","title":"User Input Required - test03","text":"<p>Yes (This will be automated later).</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#acceptance-criteria-test03","title":"Acceptance Criteria - test03","text":"<p>Verify the changes in audio compression levels across the supported audio ports for Stream #1.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#expected-results-test03","title":"Expected Results - test03","text":"<p>The test will evaluate the audio compression levels for various settings. The user should notice a change in audio playback as different compression levels are applied.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#test-steps-test03","title":"Test Steps - test03","text":"<ul> <li> <p>Select the test file:</p> </li> <li> <p>Run the Python script <code>dsAudio_test03_MS12AudioCompression.py</code></p> </li> <li> <p>Execution process:</p> </li> </ul> <p>The test will:</p> <ul> <li>Download all the required artifacts and audio streams.</li> <li>Copy them to the target directory.</li> <li> <p>Automatically start the test execution.</p> </li> <li> <p>Play the audio stream:</p> </li> </ul> <p>Test starts the audio stream playback specified in the test setup configuration file, and the user will be prompted to assess the applied audio compression levels on the supported ports.</p> <ul> <li>User interaction for verification:</li> </ul> <p>For each iteration:</p> <ul> <li>The test will ask: \"Is the audio compression level applied to the supported ports? (Y/N) ?\"</li> <li>If the compression level is noticeable, the user should press Y to confirm (passing that step).</li> <li> <p>If not, press N (failing the step).</p> </li> <li> <p>Iterating through compression levels:</p> </li> </ul> <p>The test will repeat for different audio compression levels. The user must confirm each response accordingly.</p> <ul> <li>Completion and results:</li> </ul> <p>After all iterations are complete and the user provides the required responses, the test will conclude and display the final result (PASS/FAIL).</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#dsaudio_test04_ms12dialogueenhancerpy","title":"dsAudio_test04_MS12DialogueEnhancer.py","text":""},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#platform-supported-test04","title":"Platform Supported - test04","text":"<ul> <li>Source</li> <li>Sink</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#user-input-required-test04","title":"User Input Required - test04","text":"<p>Yes (This will be automated later).</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#acceptance-criteria-test04","title":"Acceptance Criteria - test04","text":"<p>Verify the impact of the dialogue enhancer levels on the supported audio ports for Stream #2.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#expected-results-test04","title":"Expected Results - test04","text":"<p>This test will evaluate the dialogue enhancer levels. The user should notice an improvement in audio clarity as different enhancement levels are applied.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#test-steps-test04","title":"Test Steps - test04","text":"<ul> <li> <p>Select the test file:</p> </li> <li> <p>Run the Python script <code>dsAudio_test04_MS12DialogueEnhancer.py</code></p> </li> <li> <p>Execution process:</p> </li> </ul> <p>The test will:</p> <ul> <li>Download all required artifacts and audio streams.</li> <li>Copy them to the target directory.</li> <li> <p>Automatically begin the test execution.</p> </li> <li> <p>Play the audio stream:</p> </li> </ul> <p>Test starts the audio stream playback specified in the test setup configuration file, and the user will be prompted to verify whether the Dialogue Enhancer level has been applied.</p> <ul> <li>User interaction for verification:</li> </ul> <p>For each iteration:</p> <ul> <li>The test will ask: \"Is the Dialogue Enhancer level applied to the supported ports? (Y/N) ?\"</li> <li>If the enhancer is noticeable, the user should press Y to confirm (passing that step).</li> <li> <p>If not, press N (failing the step).</p> </li> <li> <p>Iterating through enhancement levels:</p> </li> </ul> <p>The test will iterate through various dialogue enhancer levels, and the user must confirm the response for each level.</p> <ul> <li>Completion and results:</li> </ul> <p>After receiving all user inputs, the test will conclude and provide a final result (PASS/FAIL).</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#dsaudio_test05_ms12dolbyvolumepy","title":"dsAudio_test05_MS12DolbyVolume.py","text":""},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#platform-supported-test05","title":"Platform Supported - test05","text":"<ul> <li>Source</li> <li>Sink</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#user-input-required-test05","title":"User Input Required - test05","text":"<p>Yes (This will be automated later).</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#acceptance-criteria-test05","title":"Acceptance Criteria - test05","text":"<p>Verify the audio playback with Dolby Volume enabled/disabled (TRUE/FALSE) for all supported audio ports for Stream #1.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#expected-results-test05","title":"Expected Results - test05","text":"<p>The test evaluates the effect of Dolby Volume on audio playback. The user should notice a clear difference in audio output when Dolby Volume is toggled between TRUE and FALSE.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#test-steps-test05","title":"Test Steps - test05","text":"<ul> <li> <p>Run the Test:</p> </li> <li> <p>Select and run the Python script: <code>dsAudio_test05_MS12DolbyVolume.py</code></p> </li> <li> <p>Download and Setup:</p> </li> </ul> <p>The test will automatically download all necessary artifacts and streams, and copy them to the target directory on the device.</p> <ul> <li> <p>Stream Playback:</p> </li> <li> <p>The test will play the designated audio stream.</p> </li> <li> <p>During playback, the test will prompt the user to verify whether Dolby Volume (TRUE/FALSE) is applied to the supported ports.</p> </li> <li> <p>User Interaction:</p> </li> </ul> <p>For each prompt, the user should assess the audio output and respond:</p> <ul> <li>If the Dolby Volume (TRUE/FALSE) change is noticeable, the user should press Y to confirm that it was applied (this will pass the step).</li> <li> <p>If not, press N (this will fail the step).</p> </li> <li> <p>Completion:</p> </li> </ul> <p>After receiving all necessary user inputs, the test case will conclude and display the final result: PASS or FAIL.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#dsaudio_test06_ms12intelligentequalizerpy","title":"dsAudio_test06_MS12IntelligentEqualizer.py","text":""},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#platform-supported-test06","title":"Platform Supported - test06","text":"<ul> <li>Source</li> <li>Sink</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#user-input-required-test06","title":"User Input Required - test06","text":"<p>Yes (This will be automated later).</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#acceptance-criteria-test06","title":"Acceptance Criteria - test06","text":"<p>Verify the audio playback for different Intelligent Equalizer modes on all supported audio ports for Stream #3.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#expected-results-test06","title":"Expected Results - test06","text":"<p>The test evaluates the various modes of the Intelligent Equalizer. The user should observe clear differences in audio quality as different equalizer modes are applied.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#test-steps-test06","title":"Test Steps - test06","text":"<ul> <li> <p>Run the Test</p> </li> <li> <p>Select and execute the Python script: <code>dsAudio_test06_MS12IntelligentEqualizer.py</code></p> </li> <li> <p>Download and Setup:</p> </li> </ul> <p>The test will automatically:</p> <ul> <li>Download all required artifacts and audio streams.</li> <li>Copy them to the target directory on the device.</li> <li> <p>Start the test execution.</p> </li> <li> <p>Stream Playback:</p> </li> <li> <p>The test will play the specified audio stream.</p> </li> <li> <p>During playback, the test will prompt the user to verify whether the Intelligent Equalizer mode has been successfully applied to the supported ports (Y/N)?</p> </li> <li> <p>User Interaction:</p> </li> </ul> <p>For each prompt, The user must assess the audio output and respond:</p> <ul> <li>If the Intelligent Equalizer mode is applied and noticeable, the user should press Y (this passes the step).</li> <li> <p>If not, press N (this fails the step).</p> </li> <li> <p>Iteration Through Modes:</p> </li> </ul> <p>The test will iterate through various Intelligent Equalizer modes, and the user will be prompted to confirm their observations for each mode.</p> <ul> <li>Completion:</li> </ul> <p>After collecting all user inputs for the different equalizer modes, the test case will conclude and display the final result: PASS or FAIL.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#dsaudio_test07_ms12volumelevellerpy","title":"dsAudio_test07_MS12Volumeleveller.py","text":""},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#platform-supported-test07","title":"Platform Supported - test07","text":"<ul> <li>Source</li> <li>Sink</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#user-input-required-test07","title":"User Input Required - test07","text":"<p>Yes (This will be automated later).</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#acceptance-criteria-test07","title":"Acceptance Criteria - test07","text":"<p>Verify the behavior of the Volume Leveller across different modes and levels for supported audio ports for Stream #4.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#expected-results-test07","title":"Expected Results - test07","text":"<p>This test will evaluate the impact of various Volume Leveller settings. The user should observe distinct changes in audio transitions when the stream shifts from low to high frequency.</p> <p>The Expected Resultss for the different modes are as follows:</p> <ul> <li>Mode 0 (Volume Leveller OFF): No change in the audio transition.</li> <li>Mode 2 (Volume Leveller AUTO): Noticeable change in audio transition as the volume adjusts automatically.</li> <li>Mode 1 (Volume Leveller ON): The transition will be less abrupt, as the leveller reduces audio peaks if the level increases.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#test-steps-test07","title":"Test Steps - test07","text":"<ul> <li> <p>Run the Test:</p> </li> <li> <p>Select and execute the Python script: <code>dsAudio_test07_MS12VolumeLeveller.py</code></p> </li> <li> <p>Download and Setup:</p> </li> </ul> <p>The test will automatically:</p> <ul> <li>Download all required artifacts and audio streams.</li> <li>Copy them to the target directory on the device.</li> <li> <p>Start the test execution.</p> </li> <li> <p>Stream Playback:</p> </li> <li> <p>The test will play the specified audio stream.</p> </li> <li> <p>The user will be prompted to confirm whether the Volume Leveller mode and level are applied to the supported audio ports.</p> </li> <li> <p>User Interaction:</p> </li> </ul> <p>For each prompt:</p> <ul> <li>The test will ask: \"Is the Volume Leveller mode and level applied to the supported ports? (Y/N)\"</li> <li>If the leveller is functioning as expected, the user should press Y (this passes the step).</li> <li> <p>If not, press N (this fails the step).</p> </li> <li> <p>Iteration Through Modes and Levels:</p> </li> </ul> <p>The test will iterate through the different Volume Leveller Modes (0, 1, 2) and Levels (0, 5, 10), and the user must confirm their observations for each setting.</p> <ul> <li>Completion:</li> </ul> <p>After collecting all user inputs for the various modes and levels, the test will conclude and display the final result: PASS or FAIL.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#dsaudio_test08_ms12bassenhancerpy","title":"dsAudio_test08_MS12BassEnhancer.py","text":""},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#platform-supported-test08","title":"Platform Supported - test08","text":"<ul> <li>Source</li> <li>Sink</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#user-input-required-test08","title":"User Input Required - test08","text":"<p>Yes (This will be automated later).</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#acceptance-criteria-test08","title":"Acceptance Criteria - test08","text":"<p>Verify the functionality of the Bass Enhancer at various boost levels for all supported audio ports for Stream #5.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#expected-results-test08","title":"Expected Results - test08","text":"<p>This test will assess the Bass Enhancer by applying different boost values. The user should be able to detect an enhancement in the bass levels when these boost values are applied.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#test-steps-test08","title":"Test Steps - test08","text":"<ul> <li> <p>Run the Test:</p> </li> <li> <p>Select and execute the Python script: <code>dsAudio_test08_MS12BassEnhancer.py</code></p> </li> <li> <p>Download and Setup:</p> </li> </ul> <p>The test will automatically:</p> <ul> <li>Download all required artifacts and audio streams.</li> <li>Copy them to the target directory on the device.</li> <li> <p>Begin the test execution.</p> </li> <li> <p>Stream Playback:</p> </li> <li> <p>The test will play the specified audio stream.</p> </li> <li> <p>During playback, the user will be prompted to confirm whether the Bass Boost level is applied to the supported ports.</p> </li> <li> <p>User Interaction:</p> </li> </ul> <p>For each prompt:</p> <ul> <li>The test will ask: \"Is the Bass Boost level applied to the supported ports? (Y/N)\"</li> <li>If the user detects enhanced bass, they should press Y (this passes the step).</li> <li> <p>If not, press N (this fails the step).</p> </li> <li> <p>Iteration Through Boost Levels:</p> </li> </ul> <p>The test will iterate through multiple Bass Boost levels, and the user must confirm their observations for each level.</p> <ul> <li>Completion:</li> </ul> <p>After collecting all user inputs for the various bass boost levels, the test case will conclude and display the final result: PASS or FAIL.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#dsaudio_test09_ms12surrounddecoderpy","title":"dsAudio_test09_MS12SurroundDecoder.py","text":""},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#platform-supported-test09","title":"Platform Supported - test09","text":"<ul> <li>Source</li> <li>Sink</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#user-input-required-test09","title":"User Input Required - test09","text":"<p>Yes (This will be automated later).</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#acceptance-criteria-test09","title":"Acceptance Criteria - test09","text":"<p>Verify the status of the Surround Decoder Mode for supported audio ports for Stream #6.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#expected-results-test09","title":"Expected Results - test09","text":"<p>This test will evaluate the functionality of the Surround Decoder Mode. The user should observe a noticeable change in audio playback when the surround decoder is enabled or disabled.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#test-steps-test09","title":"Test Steps - test09","text":"<ul> <li> <p>Run the Test:</p> </li> <li> <p>Select and execute the Python script: <code>dsAudio_test09_MS12SurroundDecoder.py</code></p> </li> <li> <p>Download and Setup:</p> </li> </ul> <p>The test will automatically:</p> <ul> <li>Download all required artifacts and the audio stream.</li> <li>Copy them to the target directory on the device.</li> <li> <p>Begin the test execution.</p> </li> <li> <p>Stream Playback:</p> </li> <li> <p>The test will play the specified audio stream.</p> </li> <li> <p>During playback, the user will be prompted to confirm whether the Surround Decoder mode (TRUE/FALSE) is applied to the supported audio ports.</p> </li> <li> <p>User Interaction:</p> </li> </ul> <p>For each prompt:</p> <ul> <li>The test will ask: \"Is the Surround Decoder mode applied to the supported ports? (Y/N)\"</li> <li>If the user detects the feature is working as expected for TRUE/FALSE mode, they should press Y (this passes the step).</li> <li> <p>If not, press N (this fails the step).</p> </li> <li> <p>Completion:</p> </li> </ul> <p>After collecting user inputs, the test will conclude and display the final result: PASS or FAIL.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#dsaudio_test10_ms12drcmodepy","title":"dsAudio_test10_MS12DRCMode.py","text":""},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#platform-supported-test10","title":"Platform Supported - test10","text":"<ul> <li>Source</li> <li>Sink</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#user-input-required-test10","title":"User Input Required - test10","text":"<p>Yes (This will be Automated later).</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#acceptance-criteria-test10","title":"Acceptance Criteria - test10","text":"<p>Play Stream #4 and verify the Dynamic Range Compression (DRC) Modes for all supported audio ports.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#expected-results-test10","title":"Expected Results - test10","text":"<p>This test evaluates the functionality of DRC Modes. The user should notice a distinct change in audio output when different DRC modes are applied.</p> <p>DRC Modes:</p> <ul> <li>Mode 0 = Line Mode -- Balances the volume during high-frequency audio playback.</li> <li>Mode 1 = RF Mode -- Enhances the volume for low-frequency audio playback.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#test-steps-test10","title":"Test Steps - test10","text":"<ul> <li> <p>Run the Test:</p> </li> <li> <p>Select and execute the Python script: <code>dsAudio_test10_MS12DRCMode.py</code></p> </li> <li> <p>Download and Setup:</p> </li> </ul> <p>The test will automatically:</p> <ul> <li>Download all required artifacts and the audio stream.</li> <li>Copy them to the target directory on the device.</li> <li> <p>Begin test execution.</p> </li> <li> <p>Stream Playback:</p> </li> <li> <p>The test will play the specified audio stream.</p> </li> <li> <p>During playback, the user will be prompted to confirm whether the DRC Mode (Line or RF) is applied to the supported audio ports.</p> </li> <li> <p>User Interaction:</p> </li> </ul> <p>For each prompt:</p> <ul> <li>The test will ask: \"Is the DRC Mode applied to the supported ports ? (Y/N)\"</li> <li>If the user detects the mode is applied, they should press Y (this passes the step).</li> <li> <p>If not, press N (this fails the step).</p> </li> <li> <p>DRC Mode Iteration:</p> </li> </ul> <p>The test will loop through the available DRC modes. The user must confirm their observations for each mode.</p> <ul> <li>Completion:</li> </ul> <p>Once all user inputs are collected, the test case concludes and provides a final result: PASS or FAIL.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#dsaudio_test11_ms12surroundvirtualizerpy","title":"dsAudio_test11_MS12SurroundVirtualizer.py","text":""},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#platform-supported-test11","title":"Platform Supported - test11","text":"<ul> <li>Source</li> <li>Sink</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#user-input-required-test11","title":"User Input Required - test11","text":"<p>Yes (This will be automated later).</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#acceptance-criteria-test11","title":"Acceptance Criteria - test11","text":"<p>Play Stream #6 and verify the Surround Virtualizer modes for supported audio ports.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#expected-results-test11","title":"Expected Results - test11","text":"<p>This test evaluates the functionality of the Surround Virtualizer by checking different modes and levels. The user should observe a noticeable change in the audio experience when these modes and levels are applied.</p> <p>Surround Virtualizer Modes:</p> <ul> <li>Mode 0 = OFF (No virtual surround effect)</li> <li>Mode 2 = Auto Mode (Automatically adjusts the surround effect based on the audio content)</li> <li>Mode 1 = ON (Enables virtual surround)</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#test-steps-test11","title":"Test Steps - test11","text":"<ul> <li> <p>Run the Test:</p> </li> <li> <p>Select and execute the Python script: <code>dsAudio_test11_MS12SurroundVirtualizer.py</code></p> </li> <li> <p>Download and Setup:</p> </li> </ul> <p>The test will:</p> <ul> <li>Automatically download all required artifacts and the audio stream.</li> <li>Copy them to the target directory on the device.</li> <li> <p>Begin execution.</p> </li> <li> <p>Stream Playback:</p> </li> <li> <p>The test will play the specified audio stream.</p> </li> <li> <p>During playback, the user will be prompted to confirm whether the Surround Virtualizer Mode and levels are applied to the supported audio ports.</p> </li> <li> <p>User Interaction:</p> </li> </ul> <p>For each prompt:</p> <ul> <li>The test will ask: \"Is the Surround Virtualizer Mode and level applied to the supported ports? (Y/N)\"</li> <li>If the user detects the mode or level is applied, they should press Y (this passes the step).</li> <li> <p>If not, press N (this fails the step).</p> </li> <li> <p>Surround Virtualizer Mode Iteration:</p> </li> <li> <p>The test will loop through the available Surround Virtualizer Modes and levels.</p> </li> <li> <p>The user must confirm their observations for each combination.</p> </li> <li> <p>Completion:</p> </li> </ul> <p>Once all user inputs are collected, the test case will conclude and display a final result: PASS or FAIL.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#dsaudio_test12_ms12misteeringpy","title":"dsAudio_test12_MS12MISteering.py","text":""},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#platform-supported-test12","title":"Platform Supported - test12","text":"<ul> <li>Source</li> <li>Sink</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#user-input-required-test12","title":"User Input Required - test12","text":"<p>Yes (This will be Automated later).</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#acceptance-criteria-test12","title":"Acceptance Criteria - test12","text":"<p>Play Stream #1 and verify the MI Steering functionality for supported audio ports.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#expected-results-test12","title":"Expected Results - test12","text":"<p>This test evaluates the MI Steering feature by enabling and disabling it. The user should observe a distinct change in the audio output when this functionality is applied.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#test-steps-test12","title":"Test Steps - test12","text":"<ul> <li> <p>Run the Test:</p> </li> <li> <p>Select and execute the Python script: <code>dsAudio_test12_MS12MISteering.py</code></p> </li> <li> <p>Download and Setup:</p> </li> </ul> <p>The test will:</p> <ul> <li>Automatically download all necessary artifacts and the audio stream.</li> <li>Copy them to the target directory on the device.</li> <li> <p>Begin execution.</p> </li> <li> <p>Stream Playback:</p> </li> <li> <p>The test will play the specified audio stream.</p> </li> <li> <p>During playback, the user will be prompted to confirm whether MI Steering (TRUE/FALSE) is applied to the supported audio ports.</p> </li> <li> <p>User Interaction:</p> </li> </ul> <p>For each prompt:</p> <ul> <li>The test will ask: \"Is MI Steering applied to the supported ports? (Y/N)\"</li> <li>If the user detects the MI Steering feature (TRUE/FALSE) is applied, they should press Y (this passes the step).</li> <li> <p>If not, press N (this fails the step).</p> </li> <li> <p>Completion:</p> </li> </ul> <p>Once all user inputs are gathered, the test will conclude with a final result: PASS or FAIL.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#dsaudio_test13_ms12graphicequalizerpy","title":"dsAudio_test13_MS12GraphicEqualizer.py","text":""},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#platform-supported-test13","title":"Platform Supported - test13","text":"<ul> <li>Source</li> <li>Sink</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#user-input-required-test13","title":"User Input Required - test13","text":"<p>Yes (This wil be Automated later).</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#acceptance-criteria-test13","title":"Acceptance Criteria - test13","text":"<p>Play Stream #1 and verify the functionality of the Graphic Equalizer Modes for supported audio ports.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#expected-results-test13","title":"Expected Results - test13","text":"<p>This test evaluates the different modes of the Graphic Equalizer. The user should be able to detect an audible change in the sound output when each mode is applied.</p> <p>Graphic Equalizer Modes:</p> <ul> <li>Mode 0: Off (No effect on audio output)</li> <li>Mode 1: Open (Wider soundstage, emphasis on clarity)</li> <li>Mode 2: Rich (Deeper, fuller sound profile)</li> <li>Mode 3: Focused (More concentrated, detailed sound)</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#test-steps-test13","title":"Test Steps - test13","text":"<ul> <li> <p>Run the Test:</p> </li> <li> <p>Select and execute the Python script: <code>dsAudio_test13_MS12GraphicEqualizer.py</code></p> </li> <li> <p>Download and Setup:</p> </li> </ul> <p>The test will:</p> <ul> <li>Automatically download all required artifacts and the audio stream.</li> <li>Copy them to the target directory on the device.</li> <li> <p>Begin execution.</p> </li> <li> <p>Stream Playback:</p> </li> <li> <p>The test will play the specified audio stream.</p> </li> <li> <p>During playback, the user will be prompted to confirm whether the Graphic Equalizer mode is applied to the supported audio ports.</p> </li> <li> <p>User Interaction:</p> </li> <li> <p>For each mode, the test will ask: \"Is the Graphic Equalizer mode applied to the supported ports? (Y/N)\"</p> </li> <li>If the user detects the mode is applied correctly, they should press Y (this passes the step).</li> <li> <p>If not, press N (this fails the step).</p> </li> <li> <p>Mode Iteration:</p> </li> </ul> <p>The test will iterate through all Graphic Equalizer modes (Off, Open, Rich, Focused). The user should confirm their response for each mode.</p> <ul> <li>Completion:</li> </ul> <p>Once all user inputs are collected, the test concludes with a final result: PASS or FAIL.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#dsaudio_test14_ms12leconfigpy","title":"dsAudio_test14_MS12LEConfig.py","text":""},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#platform-supported-test14","title":"Platform Supported - test14","text":"<ul> <li>Source</li> <li>Sink</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#user-input-required-test14","title":"User Input Required - test14","text":"<p>Yes (This will be Automated later).</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#acceptance-criteria-test14","title":"Acceptance Criteria - test14","text":"<p>Play Stream #4 and verify the functionality of the LE Config for supported audio ports.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#expected-results-test14","title":"Expected Results - test14","text":"<p>This test evaluates the LE Config functionality. The user should notice changes in the audio output as the stream transitions from low frequency to high frequency when LE Config is enabled or disabled.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#test-steps-test14","title":"Test Steps - test14","text":"<ul> <li> <p>Run the Test:</p> </li> <li> <p>Select and execute the Python script: <code>dsAudio_test14_MS12LEConfig.py</code></p> </li> <li> <p>Download and Setup:</p> </li> </ul> <p>The test will:</p> <ul> <li>Automatically download all required artifacts and the audio stream.</li> <li>Copy them to the target directory on the device.</li> <li> <p>Begin execution.</p> </li> <li> <p>Stream Playback:</p> </li> <li> <p>The test will play the specified audio stream.</p> </li> <li> <p>During playback, the user will be prompted to confirm whether LE Config (TRUE/FALSE) is applied to the supported audio ports.</p> </li> <li> <p>User Interaction:</p> </li> <li> <p>For each configuration, the test will ask: \"Is the LE Config (TRUE/FALSE) applied to the supported ports? (Y/N)\"</p> </li> <li>If the user confirms that LE Config (TRUE/FALSE) is applied correctly, they should press Y (this passes the step).</li> <li> <p>If not, press N (this fails the step).</p> </li> <li> <p>Completion:</p> </li> </ul> <p>Once all user inputs are collected, the test concludes with a final result: PASS or FAIL.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#dsaudio_test15_arcportpy","title":"dsAudio_test15_ARCPort.py","text":""},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#platform-supported-test15","title":"Platform Supported - test15","text":"<ul> <li>Sink</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#user-input-required-test15","title":"User Input Required - test15","text":"<p>Yes (This will be Automated later).</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#acceptance-criteria-test15","title":"Acceptance Criteria - test15","text":"<p>Verify the HDMI ARC/eARC port connection status.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#expected-results-test15","title":"Expected Results - test15","text":"<p>This test checks the status of the HDMI ARC or eARC connection. The user will be required to connect or disconnect the ARC/eARC port and confirm the status.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#test-steps-test15","title":"Test Steps - test15","text":"<ul> <li> <p>Run the Test:</p> </li> <li> <p>Select and execute the Python script: <code>dsAudio_test15_ARCPort.py</code></p> </li> <li> <p>Download and Setup:</p> </li> </ul> <p>The test will:</p> <ul> <li>Automatically download all necessary artifacts.</li> <li>Copy them to the target directory on the device.</li> <li> <p>Start execution.</p> </li> <li> <p>ARC/eARC Port Interaction:</p> </li> <li> <p>During the test, the user will be prompted to connect or disconnect the ARC/eARC port.</p> </li> <li> <p>Once the action is performed, the user must press ENTER to proceed.</p> </li> <li> <p>User Confirmation:</p> </li> </ul> <p>The test may prompt the user multiple times to interact with the ARC/eARC connection, asking for confirmation of the status.</p> <ul> <li>Completion:</li> </ul> <p>If all user interactions and responses are successfully received, the test will conclude with a final result: PASS or FAIL.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#dsaudio_test16_arcsadpy","title":"dsAudio_test16_ARCSAD.py","text":""},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#platform-supported-test16","title":"Platform Supported - test16","text":"<ul> <li>Sink</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#user-input-required-test16","title":"User Input Required - test16","text":"<p>Yes (This will be Automated later).</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#acceptance-criteria-test16","title":"Acceptance Criteria - test16","text":"<p>Verify the SAD (Short Audio Descriptor) functionality for the HDMI ARC audio port.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#expected-results-test16","title":"Expected Results - test16","text":"<p>This test will send SAD values to the ARC device, and the user is required to verify that these values are correctly received and applied on the ARC device.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#test-steps-test16","title":"Test Steps - test16","text":"<ul> <li> <p>Run the Test:</p> </li> <li> <p>Select and execute the Python script: <code>dsAudio_test16_ARCSAD.py</code></p> </li> <li> <p>Download and Setup:</p> </li> </ul> <p>The test will:</p> <ul> <li>Automatically download all necessary artifacts.</li> <li>Copy them to the target directory on the device.</li> <li> <p>Initiate the test execution.</p> </li> <li> <p>SAD Value Transmission:</p> </li> <li> <p>The test will send SAD values (Short Audio Descriptors) to the connected ARC device.</p> </li> <li> <p>The user will be prompted to verify if the values were received and applied on the ARC device.</p> </li> <li> <p>User Confirmation:</p> </li> <li> <p>After each SAD value is transmitted, the test will prompt the user with the question: \"Was the SAD value sent to the ARC device? (Y/N)\".</p> </li> <li>If the SAD value was received, the user should press Y to pass the step.</li> <li> <p>If the value was not received, the user should press N to fail the step.</p> </li> <li> <p>Iterate through SAD Values:</p> </li> </ul> <p>The test will loop through multiple SAD values, and for each value, the user will be asked to confirm whether it was successfully transmitted and received.</p> <ul> <li>Completion:</li> </ul> <p>Once all the SAD values have been processed and user responses are collected, the test case will conclude with a final result: PASS or FAIL based on the user's inputs.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#dsaudio_test17_outputmodepy","title":"dsAudio_test17_OutputMode.py","text":""},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#platform-supported-test17","title":"Platform Supported - test17","text":"<ul> <li>Source</li> <li>Sink</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#user-input-required-test17","title":"User Input Required - test17","text":"<p>Yes (This will be Automated later).</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#acceptance-criteria-test17","title":"Acceptance Criteria - test17","text":"<p>Play Streams #7, #1, and #8 and verify the audio output mode for all supported audio ports.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#expected-results-test17","title":"Expected Results - test17","text":"<p>This test will play different audio output modes for streams on the supported audio ports. The user should verify the audio output format when various output modes are applied.</p> Stream OutputMode (Format) tones_string_48k_stereo.wav STEREO (PCM), PASSTHRU (PCM) tones_string_48k_stereo.ac3 STEREO (PCM), DD (DD), PASSTHRU (DD) tones_string_48k_stereo.eac3 STEREO (PCM), DD (DD), DDPLUS (DD+), PASSTHRU (DD+)"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#test-steps-test17","title":"Test Steps - test17","text":"<ul> <li> <p>Run the Test:</p> </li> <li> <p>Select and execute the Python script: <code>dsAudio_test17_OutputMode.py</code></p> </li> <li> <p>Download and Setup:</p> </li> </ul> <p>The test will:</p> <ul> <li>Download all necessary artifacts and streams.</li> <li>Copy the files to the target directory.</li> <li> <p>Begin the test execution.</p> </li> <li> <p>Audio Output Verification:</p> </li> <li> <p>The test will play the specified streams and prompt the user to verify if the output mode on the supported ports is in the correct format.</p> </li> <li>The user will be asked: \"For the currently playing stream is the output mode on the supported port was in the correct format? (Y/N)\"</li> <li>If the format is correct for the output mode, the user should press Y (this passes the step).</li> <li> <p>If the format is incorrect, the user should press N (this fails the step).</p> </li> <li> <p>Iterate through Output Modes and Streams:</p> </li> </ul> <p>The test will loop through different streams and output modes, and for each combination, the user should confirm whether the audio format is correct.</p> <ul> <li>Completion:</li> </ul> <p>Once all the streams and output modes have been tested and user responses are collected, the test case will conclude with a final result: PASS or FAIL based on the user\u2019s inputs.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#dsaudio_test18_audiolevelpy","title":"dsAudio_test18_AudioLevel.py","text":""},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#platform-supported-test18","title":"Platform Supported - test18","text":"<ul> <li>Sink</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#user-input-required-test18","title":"User Input Required - test18","text":"<p>Yes (This will be automated later)</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#acceptance-criteria-test18","title":"Acceptance Criteria - test18","text":"<p>Play Stream #1 and verify the audio level functionality across supported audio ports.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#expected-results-test18","title":"Expected Results - test18","text":"<p>This test evaluates the incremental adjustment of audio levels. The user should observe a noticeable increase in volume as the test applies different audio levels.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#test-steps-test18","title":"Test Steps - test18","text":"<ul> <li> <p>Run the Test Script:</p> </li> <li> <p>Select the Python file <code>dsAudio_test18_AudioLevel.py</code> and execute it.</p> </li> <li> <p>Download and Prepare Artifacts:</p> </li> <li> <p>The test will automatically download all necessary artifacts and streams, copying them to the target directory before starting the execution.</p> </li> <li> <p>Play the Stream:</p> </li> <li> <p>The test will play Stream and prompt the user to confirm if the specified volume level is applied to the supported audio ports.</p> </li> <li> <p>The user should press Y if the volume level is correctly applied (this will pass the step) or N if it is not (this will fail the step).</p> </li> <li> <p>Iterate Through Audio Levels:</p> </li> </ul> <p>The test will continue iterating through various audio levels. The user should respond at each prompt to confirm whether the volume level is applied.</p> <ul> <li>Test Conclusion:</li> </ul> <p>Once the test receives all user responses, it will conclude and output the final test result: PASS or FAIL.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#dsaudio_test19_speakeraudiogainpy","title":"dsAudio_test19_SpeakerAudioGain.py","text":""},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#platform-supported-test19","title":"Platform Supported - test19","text":"<ul> <li>Sink</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#user-input-required-test19","title":"User Input Required - test19","text":"<p>Yes (This will be Automated later).</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#acceptance-criteria-test19","title":"Acceptance Criteria - test19","text":"<p>Play Stream #1 and verify the audio gain values for the speaker output port.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#expected-results-test19","title":"Expected Results - test19","text":"<p>This test assesses different audio gain values for the speaker. The user should notice distinct volume changes as varying audio gain levels are applied.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#test-steps-test19","title":"Test Steps - test19","text":"<ul> <li> <p>Run the Test Script:</p> </li> <li> <p>Select the Python file <code>dsAudio_test19_SpeakerAudioGain.py</code> and execute it.</p> </li> <li> <p>Download and Prepare Artifacts:</p> </li> </ul> <p>The test will automatically download all required artifacts and streams, copying them to the target directory before execution begins.</p> <ul> <li> <p>Play the Stream:</p> </li> <li> <p>The test will play Stream and prompt the user to confirm whether the correct volume gain value is applied to the speaker port.</p> </li> <li> <p>The user should press Y if the gain value is correctly applied (this passes the step) or N if it is not (this fails the step).</p> </li> <li> <p>Iterate Through Audio Gain Values:</p> </li> </ul> <p>The test will iterate through multiple audio gain values, and the user will need to verify each level, confirming if the volume changes accordingly.</p> <ul> <li>Test Completion</li> </ul> <p>After gathering all user responses, the test will conclude and display the final test result: PASS or FAIL.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#dsaudio_test20_muteunmutepy","title":"dsAudio_test20_MuteUnMute.py","text":""},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#platform-supported-test20","title":"Platform Supported - test20","text":"<ul> <li>Source</li> <li>Sink</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#user-input-required-test20","title":"User Input Required - test20","text":"<p>Yes (This will be Automated later).</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#acceptance-criteria-test20","title":"Acceptance Criteria- test20","text":"<p>Play Stream #1 and verify the Mute and Unmute functionalities for the supported audio ports.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#expected-results-test20","title":"Expected Results - test20","text":"<p>The test will play the stream and evaluate the mute/unmute functionality on supported audio ports.</p> <ul> <li>When muted, the user should not hear any audio.</li> <li>When unmuted, the user should hear the audio clearly.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#test-steps-test20","title":"Test Steps - test20","text":"<ul> <li> <p>Run the Test Script:</p> </li> <li> <p>Select the Python file <code>dsAudio_test20_MuteUnMute.py</code> and execute it.</p> </li> <li> <p>Download and Prepare Artifacts:</p> </li> </ul> <p>The test will automatically download all required artifacts and streams, copying them to the target directory before execution begins.</p> <ul> <li> <p>Play the Stream and Respond to Prompts:</p> </li> <li> <p>The test will play Stream and prompt the user with the following question for each supported port:</p> <ul> <li>\"Is audio playing on the supported port ? (Y/N)\"</li> <li>In the Mute case: The user should press N if no sound is heard (this passes the step), otherwise Y (this fails the step).</li> <li>In the Unmute case: The user should press Y if audio is heard (this passes the step), otherwise N (this fails the step).</li> </ul> </li> <li> <p>Iterate Through Supported Ports:</p> </li> </ul> <p>The test will loop through each supported audio port (e.g., speakers, HDMI ARC, SPDIF, etc.), and the user must confirm if the mute/unmute functionality is working as expected.</p> <ul> <li>Test Completion:</li> </ul> <p>After gathering all user responses for each audio port, the test will conclude and display the final test result.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#dsaudio_test21_audiodelaypy","title":"dsAudio_test21_AudioDelay.py","text":""},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#platform-supported-test21","title":"Platform Supported - test21","text":"<ul> <li>Source</li> <li>Sink</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#user-input-required-test21","title":"User Input Required - test21","text":"<p>Yes (This will be Automated later).</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#acceptance-criteria-test21","title":"Acceptance Criteria - test21","text":"<p>Play Stream #18 and verify the Audio Delay functionality for supported audio ports.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#expected-results-test21","title":"Expected Results - test21","text":"<ul> <li>The test will play the stream and apply different delay values to evaluate the Audio Delay feature on the supported audio ports.</li> <li>The user should be able to notice the delay in audio relative to the video playback for various delay values.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#test-steps-test21","title":"Test Steps - test21","text":"<ul> <li> <p>Run the Test Script:</p> </li> <li> <p>Select the Python file <code>dsAudio_test21_AudioDelay.py</code> and execute it.</p> </li> <li> <p>Download and Prepare Artifacts:</p> </li> </ul> <p>The test will automatically download all required artifacts and streams, copying them to the target directory before the execution begins.</p> <ul> <li> <p>Play the Stream and Respond to Prompts:</p> </li> <li> <p>The test will play Stream and prompt the user with the following question for each supported port:</p> <ul> <li>\"Is the audio delay value applied to the supported port? (Y/N)\"</li> <li>The user should press Y if the audio delay is correctly observed (this passes the step), or N if the delay is not observed (this fails the step).</li> </ul> </li> <li> <p>Iterate Through Different Audio Delay Values:</p> </li> </ul> <p>The test will loop through different audio delay values (e.g., increasing or decreasing delay) and evaluate them across all supported audio ports. The user must confirm if the delay is noticeable and accurate for each configuration.</p> <ul> <li>Test Completion:</li> </ul> <p>After receiving all user responses for each audio delay setting and port, the test will conclude and display the final test result.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#dsaudio_test22_audioformatpy","title":"dsAudio_test22_AudioFormat.py","text":""},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#platform-supported-test22","title":"Platform Supported - test22","text":"<ul> <li>Source</li> <li>Sink</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#user-input-required-test22","title":"User Input Required - test22","text":"<p>No (Fully automated test case).</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#acceptance-criteria-test22","title":"Acceptance Criteria - test22","text":"<p>Play the Streams #7, #1, #8, #9, #10, #11, #19, #12, #13, #14, #15, #16, #17 sequentially, and the test case will automatically verify the audio formats based on device feedback.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#expected-results-test22","title":"Expected Results - test22","text":"<ul> <li>This test will automatically play streams with different audio formats and verify the formats based on the callbacks reported by the device.</li> <li>The system should accurately detect and validate the audio format of each stream, confirming whether the format matches the expected result.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#test-steps-test22","title":"Test Steps - test22","text":"<ul> <li> <p>Run the Test Script:</p> </li> <li> <p>Select the Python file <code>dsAudio_test22_AudioFormat.py</code> and execute it.</p> </li> <li> <p>Download and Prepare Artifacts:</p> </li> </ul> <p>The test will automatically download all necessary artifacts and streams and copy them to the designated target directory before starting the execution.</p> <ul> <li> <p>Stream Playback and Automated Verification:</p> </li> <li> <p>The test case will sequentially play the predefined streams on the device.</p> </li> <li> <p>As each stream is played, the device will report callbacks indicating the detected audio format.</p> </li> <li> <p>Result Evaluation:</p> </li> <li> <p>The test case will automatically verify the audio format based on the reported callbacks from the device and evaluate whether the correct format is detected for each stream.</p> </li> <li> <p>Each step will be marked PASS or FAIL based on whether the expected audio format matches the actual format reported.</p> </li> <li> <p>Test Completion:</p> </li> </ul> <p>Once all streams have been tested, the test will conclude and provide a final result (PASS/FAIL) based on the overall success or failure of the format verification.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#dsaudio_test23_associatemixpy","title":"dsAudio_test23_AssociateMix.py","text":""},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#platform-supported-test23","title":"Platform Supported - test23","text":"<ul> <li>Source</li> <li>Sink</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#user-input-required-test23","title":"User Input Required - test23","text":"<p>Yes (This will be Automated later)</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#acceptance-criteria-test23","title":"Acceptance Criteria - test23","text":"<p>Play Stream #19 and verify the associate audio mixing functionality for supported audio ports.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#expected-results-test23","title":"Expected Results - test23","text":"<p>This test will play a stream containing two audio tracks (main and associate) and adjust the fader control values to test audio mixing.</p> <ul> <li>when mixing is false, user should hear only main Audio</li> <li>When the mixing is TRUE and fader control value is set to -32, the user should hear only the main audio.</li> <li>When the mixing is TRUE and fader control value is set to 32, the user should hear only the associate audio.</li> <li>When the mixing is TRUE and fader control value is set to 0, the user should hear both the main and associate audios mixed together.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#test-steps-test23","title":"Test Steps - test23","text":"<ul> <li> <p>Run the Test Script:</p> </li> <li> <p>Select the Python file <code>dsAudio_test23_AssociateMix.py</code> and execute it.</p> </li> <li> <p>Download and Prepare Artifacts:</p> </li> </ul> <p>The test will automatically download all required artifacts and streams, then copy them to the designated target directory before starting the execution.</p> <ul> <li> <p>Stream Playback and User Verification:</p> </li> <li> <p>The test will play the stream containing both main and associate audio tracks and prompt the user to verify if the audio mixing and fader control are working correctly.</p> </li> <li> <p>The test will ask the user: \"Is audio playing on the supported port with mixing (TRUE/FALSE) and fader control value (Y/N)?\"</p> </li> <li> <p>Test Loop:</p> </li> </ul> <p>The test will continue through a loop, testing the different fader control values (-32, 0, 32). The user must respond accordingly to each scenario.</p> <ul> <li> <p>Mixing and Fader Control Verification:</p> </li> <li> <p>If Mixing is False, Press Y (this pass the step) if only main audio audio is heard other N (this fails the step).</p> </li> <li> <p>If Mixing is True and:</p> <ul> <li> <p>For fader value -32:</p> </li> <li> <p>The user should hear only the main audio.</p> </li> <li> <p>If the main audio is heard, press Y (this pass the step), otherwise press N (this fails the step).</p> </li> <li> <p>For fader value 32:</p> </li> <li> <p>The user should hear only the associate audio.</p> </li> <li> <p>If the associate audio is heard, press Y (this pass the step), otherwise press N (this fails the step).</p> </li> <li> <p>For fader value 0:</p> </li> <li> <p>The user should hear both the main and associate audios mixed together.</p> </li> <li>If both audios are heard, press Y (this pass the step), otherwise press N (this fails the step).</li> </ul> </li> <li> <p>Test Completion:</p> </li> </ul> <p>Once all user responses are received, the test case will conclude and provide a final result. If all steps pass, the test ends with Result: PASS/FAIL.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#dsaudio_test24_primarysecondarylanguagepy","title":"dsAudio_test24_PrimarySecondaryLanguage.py","text":""},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#platform-supported-test24","title":"Platform Supported - test24","text":"<ul> <li>Source</li> <li>Sink</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#user-input-required-test24","title":"User Input Required - test24","text":"<p>Yes (This will be Automated later).</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#acceptance-criteria-test24","title":"Acceptance Criteria - test24","text":"<p>Play Stream #19 and verify the primary and secondary language functionality for the supported audio ports.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#expected-results-test24","title":"Expected Results - test24","text":"<ul> <li>This test will play a stream containing multiple PIDs (Program Identifiers) associated with different languages.</li> <li>The test will switch between different languages for both primary and secondary audio streams, and the user should verify that the audio is being played in the selected language.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#test-steps-test24","title":"Test Steps - test24","text":"<ul> <li> <p>Run the Test Script</p> </li> <li> <p>Select the Python file <code>dsAudio_test24_PrimarySecondaryLanguage.py</code> and execute it.</p> </li> <li> <p>Download and Prepare Artifacts:</p> </li> </ul> <p>The test will automatically download all required artifacts and streams, and copy them to the target directory before starting the execution.</p> <ul> <li> <p>Stream Playback and Language Verification:</p> </li> <li> <p>The test will play the stream containing multiple audio tracks in different languages.</p> </li> <li>The test will prompt the user to verify if the correct primary and secondary languages are applied to the audio port:</li> <li>\"Is audio playing on supported port with applied primary/secondary language ? (Y/N)\"</li> <li>The user must respond based on what they hear:</li> <li>If the audio is playing in the correct language, press Y to pass the step.</li> <li> <p>If the audio is not in the correct language, press N this fails the step.</p> </li> <li> <p>Language Switching Loop:</p> </li> <li> <p>The test will iterate through various language configurations for both primary and secondary audio tracks.</p> </li> <li> <p>After each language change, the user will be prompted to verify the language and respond accordingly.</p> </li> <li> <p>Test Completion:</p> </li> </ul> <p>Once all user responses are received, the test will conclude and provide a final result. If all language configurations are verified correctly, the test will end with Result: PASS/FAIL.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#dsaudio_test25_audiomixpy","title":"dsAudio_test25_AudioMix.py","text":""},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#platform-supported-test25","title":"Platform Supported - test25","text":"<ul> <li>Sink</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#user-input-required-test25","title":"User Input Required - test25","text":"<p>Yes (This will be Automated later).</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#acceptance-criteria-test25","title":"Acceptance Criteria - test25","text":"<p>Play Streams #20 and #21 and verify the audio mixing volume levels for supported audio ports.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#expected-results-test25","title":"Expected Results - test25","text":"<p>This test will play multiple streams simultaneously, adjusting different mixing volume levels for both the primary and system audio tracks. The user should hear both audio sources with the applied volume settings.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#test-steps-test25","title":"Test Steps - test25","text":"<ul> <li> <p>Run the Test Script:</p> </li> <li> <p>Select the Python file <code>dsAudio_test25_AudioMix.py</code> and execute it.</p> </li> <li> <p>Download and Prepare Artifacts:</p> </li> </ul> <p>The test will automatically download all required artifacts and streams, copying them to the target directory before execution begins.</p> <ul> <li> <p>Stream Playback and Volume Mixing Verification:</p> </li> <li> <p>The test will start playing the stream and prompt the user to verify if the audio mixing and volume settings are correctly applied:</p> </li> <li>\"Is the audio playing on supported port with Mixing and applied primary and system volume levels ? (Y/N)\"</li> <li>If the user hears the correct audio mixing with the applied volume levels, they should press Y to pass the step.</li> <li> <p>If the volume levels are not correctly applied, the user should press N this fails the step.</p> </li> <li> <p>Volume Mixing Loop:</p> </li> <li> <p>The test will iterate through various combinations of volume levels for both the primary and system audio tracks.</p> </li> <li> <p>After each change in the volume levels, the user will be prompted to verify the audio mix and respond accordingly.</p> </li> <li> <p>Test Completion:</p> </li> <li> <p>Once all user responses are collected, the test will end, providing a final result.</p> </li> <li>If all volume levels for the primary and system audios are verified successfully, the test will end with Result: PASS. Otherwise, it will conclude with Result: FAIL.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#dsaudio_test26_ms12audioprofilespy","title":"dsAudio_test26_MS12AudioProfiles.py","text":""},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#platform-supported-test26","title":"Platform Supported - test26","text":"<ul> <li>Sink</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#user-input-required-test26","title":"User Input Required - test26","text":"<p>Yes (This will be Automated later).</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#acceptance-criteria-test26","title":"Acceptance Criteria - test26","text":"<p>Play Stream #3 and verify the MS12 Audio Profile modes for the supported audio ports.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#expected-results-test26","title":"Expected Results - test26","text":"<ul> <li> <p>This test will play the stream and apply different MS12 Audio Profile modes. The user should notice a change in the audio output when these modes are applied.</p> </li> <li> <p>MS12 Audio Profile Modes:</p> </li> <li>Mode: Off</li> <li>Mode: User</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsAudio/ds-audio_L3_TestProcedure/#test-steps-test26","title":"Test Steps - test26","text":"<ul> <li> <p>Run the Test Script:</p> </li> <li> <p>Select the Python file <code>dsAudio_test26_MS12AudioProfiles.py</code> and execute it.</p> </li> <li> <p>Download and Prepare Artifacts:</p> </li> </ul> <p>The test will automatically download all required artifacts and streams, copying them to the target directory before execution begins.</p> <ul> <li> <p>Stream Playback and Profile Mode Verification:</p> </li> <li> <p>The test will play the stream and prompt the user:</p> </li> <li>\"Is the MS12 Audio Profile mode applied to the supported port ? (Y/N)\"</li> <li>If the correct audio profile mode is applied and the user notices the change in audio, they should press Y to pass the step.</li> <li> <p>If no change is noticed or the mode is not applied, the user should press N this fails the step.</p> </li> <li> <p>Profile Mode Loop:</p> </li> <li> <p>The test will iterate through different MS12 Audio Profile modes (Off, User).</p> </li> <li> <p>After each mode is applied, the user will be prompted to verify the change in audio and respond accordingly.</p> </li> <li> <p>Test Completion:</p> </li> <li> <p>Once all user responses are collected, the test will conclude.</p> </li> <li>If all profile modes are verified successfully, the test will end with Result: PASS. If any of the modes fail, the test will conclude with Result: FAIL.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-High-Level_TestSpec/","title":"Device Settings CompositeIn High Level Test Specification Document","text":""},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-High-Level_TestSpec/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>HAL</code>   - Hardware Abstraction layer</li> <li><code>API</code>   - Application programming interface</li> <li><code>RDK</code>   - Reference Design Kit</li> <li><code>dsComposite</code> - Device Settings Composite</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-High-Level_TestSpec/#introduction","title":"Introduction","text":"<p>This document provides an overview of the high level testing requirements for the <code>dsComposite</code> module. It outlines the scope of testing, objectives, testing levels and approaches, specific test requirements, emulator requirements, control plane requirements and expected deliverables.</p> <ul> <li>Interface of the test is available in this link -  https://github.com/rdkcentral/rdk-halif-device_settings/blob/main/include/dsCompositeIn.h</li> <li>Hal Specification in this link - https://github.com/rdkcentral/rdk-halif-device_settings/blob/main/docs/pages/ds-composite-in_halSpec.md</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-High-Level_TestSpec/#module-description","title":"Module Description","text":"<p>High level overview:</p> <ul> <li><code>dsComposite</code> provides a variety of APIs for accessing information regarding the Composite Inputs on sink devices.</li> <li>It facilitates interaction with Composite Input ports, aiding in their configuration and utilization within the system. This information is then passed to the caller.</li> <li>For the sink devices, to retrieve the available Composite Input information, an external device must be connected.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-High-Level_TestSpec/#testing-scope","title":"Testing Scope","text":"# Test Functionality Test Description 1 Get Number of Inputs The test aims to verify the availability of Composite Input ports by confirming the number present. 2 Get the Input Status The test is to verify the status of all Composite Input ports 3 Set the Composite port The test is to set the Composite Input port for Presentation 4 Scale the Composite Input Video The test scales the COMPOSITE input video, ensuring that the width and height, determined by the x and y coordinates respectively, do not surpass the current resolution limits of the device. 5 Callback for connection Status The test aims to verify the Callback function used for notifying applications of the COMPOSITE In hot plug/unplug status. 6 Callback for Signal Change The test aims to verify the callback function used to inform applications about changes in the signal status of the Composite In.(NoSignal/UnstableSignal/NotSupportedSignal/StableSignal) 7 Callback for Status Change The test validates the functionality of the callback function designed to notify applications of Composite Input status change events.(Port,IsPresented flag status) 8 Callback for Video Mode Change The test validates the functionality of the callback function designed to notify applications of Composite Input video mode change events.(Port,resolution status) -----------"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-High-Level_TestSpec/#get-number-of-inputs","title":"Get Number of Inputs","text":"Description HAL APIs L2 L3 Control plane requirements Ensure that the function returns the expected number of COMPOSITE input ports by comparing the input port values parsed from the configuration YAML file 'Panel_CompositeInput.yaml'. The value to be retrieved from the YAML is 'composite_input_configurations/number_of_ports'. dsCompositeInGetNumberOfInputs Y N N"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-High-Level_TestSpec/#emulator-requirement-get-number-of-inputs","title":"Emulator Requirement - Get Number of Inputs","text":"<p>Emulator will boot with the port informations coming from the configuration file.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-High-Level_TestSpec/#control-plane-requirement-get-number-of-inputs","title":"Control Plane Requirement - Get Number of Inputs","text":"<p>None</p>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-High-Level_TestSpec/#get-the-input-status","title":"Get the Input Status","text":"Description HAL APIs L2 L3 Control plane requirements Verify the status of the Composite Input by ensuring it is in disable status. dsCompositeInGetStatus Y N N Verify the status of the Composite Input by ensuring it is enabled, connected to the source, and that the composite input port is active. dsCompositeInGetStatus N Y Y"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-High-Level_TestSpec/#test-startup-requirement-get-the-input-status","title":"Test Startup Requirement - Get the Input Status","text":"<p>Connection of the source device with the CompositeIn.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-High-Level_TestSpec/#emulator-requirement-get-the-input-status","title":"Emulator Requirement - Get the Input Status","text":"<p>Emulator will boot with the port informations coming from the configuration file.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-High-Level_TestSpec/#control-plane-requirement-get-the-input-status","title":"Control Plane Requirement - Get the Input Status","text":"<p>Connecting and disconnecting source devices in the CompositeIn will be handled by the Control Plane.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-High-Level_TestSpec/#set-the-composite-port","title":"Set the Composite port","text":"Description HAL APIs L2 L3 Control plane requirements Loop through the all composite ports, verify that the function successfully sets the specified COMPOSITE Input port when there is no connection of source device, and check the disable status of the port information using \"Get status\". dsCompositeInSelectPort, dsCompositeInGetStatus Y N N Loop through the all composite ports, verify that the function successfully sets the specified COMPOSITE Input port as active for presentation, and check the port information using \"Get status\". dsCompositeInSelectPort, dsCompositeInGetStatus N Y Y"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-High-Level_TestSpec/#test-startup-requirement-set-the-composite-port","title":"Test Startup Requirement - Set the Composite port","text":"<p>Connection of the source device with the CompositeIn.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-High-Level_TestSpec/#emulator-requirement-set-the-composite-port","title":"Emulator Requirement - Set the Composite port","text":"<p>Emulator will boot with the port informations coming from the configuration file.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-High-Level_TestSpec/#control-plane-requirement-set-the-composite-port","title":"Control Plane Requirement - Set the Composite port","text":"<ul> <li>Connecting and disconnecting source devices in the CompositeIn will be handled by the Control Plane.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-High-Level_TestSpec/#scale-the-composite-input-video","title":"Scale the Composite Input Video","text":"Description HAL APIs L2 L3 Control plane requirements Verify that the function successfully scales the COMPOSITE input video when valid coordinates and dimensions are provided within the current resolution limits. Based on video resolution need to check whether the coordinates are in range dsCompositeInSelectPort(), dsCompositeInScaleVideo() N Y Y"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-High-Level_TestSpec/#test-startup-requirement-scale-the-composite-input-video","title":"Test Startup Requirement - Scale the Composite Input Video","text":"<p>The test begins by setting up the video analyzer, and the video should be played. </p>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-High-Level_TestSpec/#emulator-requirement-scale-the-composite-input-video","title":"Emulator Requirement - Scale the Composite Input Video","text":"<p>Emulator will boot with the port informations coming from the configuration file.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-High-Level_TestSpec/#control-plane-requirement-scale-the-composite-input-video","title":"Control Plane Requirement - Scale the Composite Input Video","text":"<ul> <li>Connecting and disconnecting source devices in the CompositeIn will be handled by the Control Plane.</li> <li>The Control Plane handles the changing of various resolutions.</li> <li>The Control Plane checks and validates the coordinates and dimensions by comparing the values from the video analyzer.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-High-Level_TestSpec/#callback-for-connection-status","title":"Callback for connection Status","text":"Description HAL APIs L2 L3 Control plane requirements Verify that the callback function properly updates the connection/disconnection status flag and notifies the application when a COMPOSITE Input port is connected or disconnected. dsCompositeInRegisterConnectCB N Y Y Verify that the callback function properly updates the isPresented status in <code>dsCompositeInStatus_t</code>, if the connected port is active and presents video after being connected. dsCompositeInRegisterConnectCB N Y Y"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-High-Level_TestSpec/#test-startup-requirement-callback-for-connection-status","title":"Test Startup Requirement - Callback for connection Status","text":"<p>Connection of the source device with the CompositeIn.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-High-Level_TestSpec/#emulator-requirement-callback-for-connection-status","title":"Emulator Requirement - Callback for connection Status","text":"<p>Emulator will boot with the port information coming from the configuration file.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-High-Level_TestSpec/#control-plane-requirement-callback-for-connection-status","title":"Control Plane Requirement - Callback for connection Status","text":"<p>Connecting and disconnecting source devices in the CompositeIn will be handled by the Control Plane.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-High-Level_TestSpec/#callback-for-signal-change","title":"Callback for Signal Change","text":"Description HAL APIs L2 L3 Control plane requirements Verify that the callback function properly notifies the application whenever there is a change in the signal statuses (e.g., NoSignal, UnstableSignal, NotSupportedSignal, StableSignal) for the composite Input port. dsCompositeInRegisterSignalChangeCB N Y Y"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-High-Level_TestSpec/#test-startup-requirement-callback-for-signal-change","title":"Test Startup Requirement - Callback for Signal Change","text":"<p>Connection of the source device with the CompositeIn.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-High-Level_TestSpec/#emulator-requirement-callback-for-signal-change","title":"Emulator Requirement - Callback for Signal Change","text":"<p>Emulator will boot with the port informations coming from the configuration file.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-High-Level_TestSpec/#control-plane-requirement-callback-for-signal-change","title":"Control Plane Requirement - Callback for Signal Change","text":"<ul> <li>Connecting and disconnecting source devices in the CompositeIn will be handled by the Control Plane.</li> <li>Provide resolution changes or configurations changes on the connected device that affects the output signal.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-High-Level_TestSpec/#callback-for-status-change","title":"Callback for Status Change","text":"Description HAL APIs L2 L3 Control plane requirements Verify that the callback function properly triggers whenever the dsCompositeInStatus_t is updated and notifies the application of the Composite Input Status Change event. dsCompositeInRegisterStatusChangeCB N Y Y"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-High-Level_TestSpec/#test-startup-requirement-callback-for-status-change","title":"Test Startup Requirement - Callback for Status Change","text":"<p>Connection of the source device with the CompositeIn.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-High-Level_TestSpec/#emulator-requirement-callback-for-status-change","title":"Emulator Requirement - Callback for Status Change","text":"<p>Emulator will boot with the port informations coming from the configuration file.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-High-Level_TestSpec/#control-plane-requirement-callback-for-status-change","title":"Control Plane Requirement - Callback for Status Change","text":"<p>Connecting and disconnecting source devices in the CompositeIn will be handled by the Control Plane.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-High-Level_TestSpec/#callback-for-video-mode-change","title":"Callback for video mode change","text":"Description HAL APIs L2 L3 Control plane requirements Verify that the callback function properly updates the video mode changes and notifies the application when a COMPOSITE Input video mode changes after the composite signal is stable dsCompositeInRegisterVideoModeUpdateCB N Y Y"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-High-Level_TestSpec/#test-startup-requirement-callback-for-video-mode-change","title":"Test Startup Requirement - Callback for video mode change","text":"<p>Launching of the source device with the CompositeIn connected.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-High-Level_TestSpec/#emulator-requirement-callback-for-video-mode-change","title":"Emulator Requirement - Callback for video mode change","text":"<p>Emulator will boot with the port information and its video mode change information received from the configuration file.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-High-Level_TestSpec/#control-plane-requirement-callback-for-video-mode-change","title":"Control Plane Requirement - Callback for video mode change","text":"<ul> <li>Connecting and disconnecting source devices in the CompositeIn will be handled by the Control Plane.</li> <li>Provide resolution changes or configurations changes on the connected device that changes the video mode info.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-L2-Low-Level_TestSpec/","title":"Device Settings Composite Input L2 Low Level Test Specification and Procedure Documentation","text":""},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-L2-Low-Level_TestSpec/#overview","title":"Overview","text":"<p>This document describes the Low Level L2 Test Specification and Procedure for the Device Settings Composite Input module.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-L2-Low-Level_TestSpec/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>HAL</code> - Hardware Abstraction Layer, may include some common components</li> <li><code>UT</code>  - Unit Test(s)</li> <li><code>OEM</code>  - Original Equipment Manufacture</li> <li><code>SoC</code>  - System on a Chip</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-L2-Low-Level_TestSpec/#definitions","title":"Definitions","text":"<ul> <li><code>ut-core</code> - Common Testing Framework https://github.com/rdkcentral/ut-core, which wraps a open-source framework that can be expanded to the requirements for future framework.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-L2-Low-Level_TestSpec/#references","title":"References","text":"<ul> <li><code>High Level Test Specification</code> - ds-compositeIn-High-Level_TestSpec.md</li> <li><code>HAL Interface file</code> - dsCompositeIn Header</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-L2-Low-Level_TestSpec/#level-2-test-procedure","title":"Level 2 Test Procedure","text":"<p>The following functions are expecting to test the module operates correctly.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-L2-Low-Level_TestSpec/#test-1","title":"Test 1","text":"Title Details Function Name <code>test_l2_dsCompositeIn_GetNumberOfInputs</code> Description Ensure that the function returns the expected number of COMPOSITE input ports by comparing the input port values parsed from the configuration YAML file for the platform under test. The value to be retrieved from the YAML is <code>dsCompositeIn/composite_input_configurations/number_of_ports</code>. Test Group 02 Test Case ID 001 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-L2-Low-Level_TestSpec/#test-procedure-test-1","title":"Test Procedure - Test 1","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the COMPOSITE Input module using <code>dsCompositeInInit</code> None <code>dsERR_NONE</code> Should be successful 02 Get the number of COMPOSITE Input ports using <code>dsCompositeInGetNumberOfInputs</code> numInputs = valid buffer <code>dsERR_NONE</code> Should be successful 03 Compare the value returned by <code>dsCompositeInGetNumberOfInputs</code> with the value retrieved from the YAML file numInputs, <code>dsCompositeIn/composite_input_configurations/number_of_ports</code> from configuration file They should match Should be successful 04 Terminate the COMPOSITE Input module using <code>dsCompositeInTerm</code> None <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\nA[Call dsCompositeInInit] --&gt;|Success| B[Parse 'Panel_CompositeInput.yaml']\nA --&gt;|Failure| A1[Test case fail: dsCompositeInInit failed]\nB --&gt;|Success| C[Call dsCompositeInGetNumberOfInputs]\nB --&gt;|Failure| B1[Test case fail: Parsing YAML file failed]\nC --&gt;|Success| E[Compare num of ports values]\nC --&gt;|Failure| C1[Test case fail: dsCompositeInGetNumberOfInputs failed]\nE --&gt;|Success| F[Call dsCompositeInTerm]\nE --&gt;|Failure| E1[Test case fail]\nF --&gt;|Success| G[Test case success]\nF --&gt;|Failure| F1[Test case fail: dsCompositeInTerm failed]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-L2-Low-Level_TestSpec/#test-2","title":"Test 2","text":"Title Details Function Name <code>test_l2_dsCompositeIn_VerifyCompositeInputStatus</code> Description Verify the status of the Composite Inputs by ensuring it is in disable status. Test Group 02 Test Case ID 002 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-L2-Low-Level_TestSpec/#test-procedure-test-2","title":"Test Procedure - Test 2","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the Composite Input using <code>dsCompositeInInit</code> None <code>dsERR_NONE</code> Should be successful 02 Get the status of the Composite Input using <code>dsCompositeInGetStatus</code> status = valid buffer <code>dsERR_NONE</code> Should be successful 03 Check if the Composite Input is presented or not isPresented = false false Should be successful 04 Loop through and check if each of the Composite Input Port existing on the platform is connected or not status.isPortConnected[Port No] = false false Should be successful 05 Check the active port of the Composite Input status.activePort = <code>dsCOMPOSITE_IN_PORT_NONE</code> <code>dsCOMPOSITE_IN_PORT_NONE</code> Should be successful 06 Terminate the Composite Input using <code>dsCompositeInTerm</code> None <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\n    Step1[Call dsCompositeInInit] --&gt;|dsERR_NONE| Step2[Call dsCompositeInGetStatus]\n    Step1 --&gt;|Failure| Fail1[Test Case Failed: dsCompositeInInit failed]\n    Step2 --&gt;|dsERR_NONE| Step3[Check 'isPresented' field]\n    Step2 --&gt;|Failure| Fail2[Test Case Failed: dsCompositeInGetStatus failed]\n    Step3 --&gt;|isPresented = false| Step4Loop{Loop through each port as per test profile} --&gt; Step4\n    Step3 --&gt;|Failure| Fail3[Test Case Failed: isPresented field check failed]\n    Step4[Check 'isPortConnected' field] --&gt;|Failure| Fail4[Test Case Failed: isPortConnected field check failed] --&gt;     Step5LoopCheck[Loop check]\n    Step4 --&gt;|Passed| Pass1[isPortConnected field check passed] --&gt; Step5LoopCheck[Loop check]\n    Step5LoopCheck --&gt;|More ports| Step4Loop\n    Step5LoopCheck --&gt;|Loop ends| Step6[Check 'activePort' field]\n    Step6 --&gt;|activePort = dsCOMPOSITE_IN_PORT_NONE| Step7[Call dsCompositeInTerm]\n    Step6 --&gt;|Failure| Fail5[Test Case Failed: activePort field check failed]\n    Step7 --&gt;|dsERR_NONE| Step8[Test Case Passed]\n    Step7 --&gt;|Failure| Fail6[Test Case Failed: dsCompositeInTerm failed]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-L2-Low-Level_TestSpec/#test-3","title":"Test 3","text":"Title Details Function Name <code>test_l2_dsCompositeIn_VerifyCompositeInPortSelectionAndStatus</code> Description Loop through all the existing composite ports on the platform, verify that the function successfully sets the specified COMPOSITE Input port when there is no connection of source device, and check the disable status of the port information using Get status. Test Group 02 Test Case ID 003 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-L2-Low-Level_TestSpec/#test-procedure-test-3","title":"Test Procedure - Test 3","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the COMPOSITE Input module using <code>dsCompositeInInit</code> None <code>dsERR_NONE</code> Should be successful 02 Loop through the supported COMPOSITE Input ports on the platform based on the get number of Inputs and select each port using <code>dsCompositeInSelectPort</code> port = <code>dsCompositeInGetNumberOfInputs</code> <code>dsERR_NONE</code> Should be successful 03 Get the status of the selected COMPOSITE Input port using <code>dsCompositeInGetStatus</code> status = valid buffer <code>dsERR_NONE</code> Should be successful 04 Check if the active port is the selected port ,if the port is not presented and if the port is not connected activePort = port, isPresented = false, isPortConnected = false activePort = port, isPresented = false, isPortConnected = false Should be successful 05 Terminate the COMPOSITE Input module using <code>dsCompositeInTerm</code> None <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\n    A[Call dsCompositeInInit] --&gt;|Success| B{Loop through &lt;br&gt; all composite &lt;br&gt; ports}\n    A --&gt;|Failure| A1[Test case fail]\n    B --&gt;|dsCOMPOSITE_IN_PORT_0 to dsCOMPOSITE_IN_PORT_MAX| C[Call dsCompositeInSelectPort &lt;br&gt; with current port]\n    C --&gt;|Success| D[Verify function sets &lt;br&gt; specified COMPOSITE &lt;br&gt; Input port]\n    D --&gt; E[Call dsCompositeInGetStatus]\n    E --&gt;|Success| F[Check disable status of the port]\n    F --&gt; G{End of Loop?}\n    G --&gt;|No| B\n    G --&gt;|Yes| H[Call dsCompositeInTerm]\n    H --&gt;|Success| I[Test case success]\n    H --&gt;|Failure| H1[Test case fail]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-L3-Low-Level-TestSpec/","title":"Device Settings Composite Input L3 Low Level Test Specification and Procedure Documentation","text":""},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-L3-Low-Level-TestSpec/#overview","title":"Overview","text":"<p>This document describes the L3 Low Level Test Specification and Procedure Documentation for the Device Settings Composite Input module.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-L3-Low-Level-TestSpec/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>HAL</code>    - Hardware Abstraction Layer</li> <li><code>API</code>    - Application Programming Interface</li> <li><code>L3</code>     - Level 3 Testing</li> <li><code>DS</code>     - Device Settings</li> <li><code>DUT</code>    - Device Under Test</li> <li><code>NA</code>     - Not Applicable</li> <li><code>RAFT</code>   - Rapid Automation Framework for Testing</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-L3-Low-Level-TestSpec/#references","title":"References","text":"<ul> <li> <p><code>High Level Test Specification</code> - ds-compositeIn-High-Level_TestSpec.md</p> </li> <li> <p><code>HAL Interface file</code> - dsCompositeIn Header 4.0.0</p> </li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-L3-Low-Level-TestSpec/#level-3-test-cases-high-level-overview","title":"Level 3 Test Cases High Level Overview","text":"# Streams Name Streams description 1 vts_SDR_stream Format: SDR,Resolution: 1920 x 1080 <p>Below are top test use-case for the Composite Input.</p> # Test-case Description Focus APIs 1 Verify the CompositeIn port connection with callbacks Connect/disconnect the CompositeIn source device on each of compositeIn port and check the callbacks is triggered when the connection status changes <code>dsCompositeInRegisterConnectCB()</code> 2 Verify the CompositeIn active port status with callbacks Connect a CompositeIn source device, select the CompositeIn port and check the callbacks is triggered when the active status changes(i.e like isPresented, activeport) <code>dsCompositeInRegisterStatusChangeCB()</code> 3 Scale the video and verify Play the video stream(<code>vts_SDR_stream</code>) in CompositeIn source device connected to the active CompositeIn port and scale the video resolution <code>dsCompositeInScaleVideo()</code> 4 Verify the CompositeIn Signal change with callback Connect a CompositeIn source device, select the CompositeIn port and check the callback is triggered when the change in signal status occurs(i.e like no signal , unstable signal, stable signal) <code>dsCompositeInRegisterSignalChangeCB()</code> 5 Verify the CompositeIn video mode change with callback Connect a CompositeIn source device, select the CompositeIn port, and verify that the callback is triggered when there is a change in the video mode on the source device <code>dsCompositeInRegisterVideoModeUpdateCB()</code>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-L3-Low-Level-TestSpec/#level-3-python-test-cases-high-level-overview","title":"Level 3 Python Test Cases High Level Overview","text":"<p>The class diagram below illustrates the flow of dsCompositeIn L3 Python test cases:</p> <pre><code>---\ntitle: dsCompositeIn - Python Class Flow\n---\nclassDiagram\n    testControl &lt;|-- ut_raft : inherits\n    class ut_raft{\n    }\n    ut_raft &lt;|-- dsCompositeInHelperClass : inherits\n    dsCompositeInHelperClass &lt;|-- L3_TestClasses : inherits\n    L3_TestClasses ..&gt; dsCompositeIn : uses\n    note for testControl \"uses rackConfig.yaml and deviceConfig.yaml\"\n    note for dsCompositeIn \"uses platformProfile.yaml\"\n    note for L3_TestClasses \"uses testSetupConfig.yaml\"\n    note for ut_raft \"suite Navigator uses testConfig.yaml\"</code></pre> <ul> <li>testControl</li> <li>Test Control Module for running rack Testing. This module configures the <code>DUT</code> based on the rack configuration file provided to the test.</li> <li>This class is defined in <code>RAFT</code> framework. For more details refer RAFT</li> <li>ut_raft</li> <li>Python based testing framework for writing engineering tests.</li> <li>It provides common functionalities like menu navigation, configuration reader, reading user response etc.</li> <li>For more details ut-raft.</li> <li>dsCompositeIn</li> <li>This is test helper class which communicates with the <code>L3</code> C/C++ test running on the <code>DUT</code> through menu</li> <li>L3_TestClasses</li> <li>These are the L3 test case classes</li> <li>Each class covers the each test use-case defined in L3 Test use-cases table</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-L3-Low-Level-TestSpec/#yaml-file-inputs","title":"YAML File Inputs","text":"<ul> <li>rackConfig.yaml</li> <li>Identifies the rack configuration and platform used</li> <li>References platform-specific config from <code>deviceConfig.yaml</code></li> <li> <p>For more details refer RAFT and example_rack_config.yml</p> </li> <li> <p>deviceConfig.yaml</p> </li> <li>Specifies overall configuration for the platform</li> <li>Can be overridden by:<ul> <li>Changing locally .yaml file directory</li> <li>Using --deviceConfig command line switch</li> </ul> </li> <li> <p>For more details refer RAFT and example_device_config.yml</p> </li> <li> <p>componentProfile.yaml/platformProfile.yaml</p> </li> <li>Contains component-specific configurations</li> <li>Contains platform wide configuration broken down into separate components</li> <li> <p>Example configuration file dsCompositeIn_Settings</p> </li> <li> <p>testSetupConfig.yaml</p> </li> <li>This configuration file contains the list of requirements for tests to execute. Eg: Copying the streams etc.</li> <li> <p>Example configuration file dsCompositeIn_L3_testSetup.yml</p> </li> <li> <p>testConfig.yaml</p> </li> <li>This configuration file contains the list of menu items for C/C++ L3 test running on <code>DUT</code></li> <li>Example configuration file dsCompositeIn_testConfig.yml</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-L3-TestProcedure/","title":"dscompositeIn HAL L3 Python Test Procedure","text":""},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-L3-TestProcedure/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>HAL</code>     - Hardware Abstraction Layer</li> <li><code>L3</code>      - Level 3 Testing</li> <li><code>DUT</code>     - Device Under Test</li> <li><code>RAFT</code>    - Rapid Automation Framework for Testing</li> <li><code>YAML</code>    - YAML Ain't Markup Language</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-L3-TestProcedure/#setting-up-test-environment","title":"Setting Up Test Environment","text":"<p>To execute <code>HAL</code> <code>L3</code> Python test cases, need a Python environment. Follow these steps mentioned in HPK Public Documentation</p>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-L3-TestProcedure/#update-configuration-files","title":"Update Configuration Files","text":""},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-L3-TestProcedure/#rack-configuration-file","title":"Rack Configuration File","text":"<p>Example Rack configuration File: example_rack_config.yml</p> <p>For more details refer RAFT and example_rack_config.yml</p> <p>In this file, update the configuration to define the console sessions for the <code>DUT</code> and the outbound settings:</p> Console Session Description default Downloads the streams required for test cases ssh_hal_test Executes the <code>HAL</code> binary for the test case <pre><code>rackConfig:\n  - dut:\n      ip: \"XXX.XXX.XXX.XXX\"  # IP Address of the device\n      description: \"stb device under test\"\n      platform: \"stb\"\n      consoles:\n        - default:\n            type: \"ssh\"\n            port: 10022\n            username: \"root\"\n            ip: \"XXX.XXX.XXX\" # IP address of the device\n            password: ' '\n        - ssh_hal_test:\n            type: \"ssh\"\n            port: 10022\n            username: \"root\"\n            ip: \"XXX.XXX.XXX\" # IP address of the device\n            password: ' '\n      outbound:\n        download_url: \"tftp://tftp-server.com/rack1/slot1/\"    # Download location for the CPE device\n        upload_url: \"sftp://server-address/home/workspace/tftp/rack1/slot1/\" # Upload location\n        upload_url_base_dir: \"sftp://server-address/home/workspace/tftp/rack1/slot1\"\n        httpProxy:   # Local proxy if required\n        workspaceDirectory: './logs/workspace'   # Local working directory\n</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-L3-TestProcedure/#device-configuration-file","title":"Device Configuration File","text":"<p>Example Device configuration File: deviceConfig.yml</p> <p>For more details refer RAFT and example_device_config.yml</p> <p>Update below fileds in the device configuration file:</p> <ul> <li>Set the folder path for <code>target_directory</code> where <code>HAL</code> binaries will be copied onto the device.</li> <li>Specify the device profile path in <code>test/profile</code></li> <li>Ensure the <code>platform</code> should match with the <code>DUT</code> <code>platform</code> in Rack Configuration</li> </ul> <pre><code>deviceConfig:\n    cpe1:\n        platform: \"linux\"\n        model: \"uk\"\n        soc_vendor: \"intel\"\n        target_directory: \"/tmp/\"  # Target Directory on device\n        prompt: \"\" # Prompt string on console\n        test:\n            profile: \"../../../../profiles/sink/Sink_CompositeInput.yaml\"\n            streams_download_url: \"&lt;URL_Path&gt;\" #URL path from which the streams are downloaded to the device\n</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-L3-TestProcedure/#test-setup-configuration-file","title":"Test Setup Configuration File","text":"<p>Example Test Setup configuration File: dscompositeIn_L3_testSetup.yml</p> <p>Provide the streams for each test case. This path is appended with <code>streams_download_url</code> entry from Device Configuration File</p> <p>If a test case requires multiple streams or needs to be validated using several streams, ensure that all necessary streams are added sequentially for that specific test case.</p> <pre><code>dscompositeIn:\n  description: \"dscompositeIn Device Settings test setup\"\n  assets:\n    device:\n        test1_VerifyConnect_Callback:\n          streams:\n        test2_VerifyStatus_Callback:\n          streams:\n        test3_ScaleAndVerify_Video:\n          streams:\n        test4_VerifySignal_Callback:\n          streams:\n        test5_VerifyVideoMode_Callback:\n          streams:\n</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-L3-TestProcedure/#test-configuration","title":"Test Configuration","text":"<p>Example Test Setup configuration File: dsCompositeIn_testConfig.yml</p> <p>Update the execute command according to the device path where <code>HAL</code> binaries are copied.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-L3-TestProcedure/#run-test-cases","title":"Run Test Cases","text":"<p>Once the environment is set up, you can execute the test cases with the following command</p> <pre><code>python &lt;TestCaseName.py&gt; --config &lt;/PATH&gt;/ut/host/tests/configs/example_rack_config.yml --deviceConfig &lt;/PATH&gt;/ut/host/tests/configs/deviceConfig.yml\n</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-L3-TestProcedure/#test-cases","title":"Test Cases","text":""},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-L3-TestProcedure/#dscompositein_test1_verifyconnect_callbackpy","title":"dsCompositeIn_test1_VerifyConnect_Callback.py","text":""},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-L3-TestProcedure/#platform-support-test01","title":"Platform Support - test01","text":"<ul> <li>Sink</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-L3-TestProcedure/#user-input-required-test01","title":"User Input Required - test01","text":"<p>Yes: User interaction is necessary to connect/disconnect the Composite Source device (This will be automated later).</p>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-L3-TestProcedure/#acceptance-criteria-test01","title":"Acceptance Criteria - test01","text":"<p>Connect the external device and check if 'DUT' recognizes the events Disconnect the external device and check if 'DUT' recognizes the event</p>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-L3-TestProcedure/#expected-results-test01","title":"Expected Results - test01","text":"<p>The test registers the event and checks for  the event call back.</p> <p>Success Criteria</p> <ul> <li>The device should recognize the connect/Disconnect event.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-L3-TestProcedure/#test-steps-test01","title":"Test Steps - test01","text":"<ul> <li> <p>Initiate the Test:</p> </li> <li> <p>Select and execute the Python file: <code>dsCompositeIn_test1_VerifyConnect_Callback.py</code></p> </li> <li> <p>The test will automatically download all required artifacts, copying them to the designated target directory before commencing execution.</p> </li> <li> <p>Device Connect prompt:</p> <p>The test will Request the User to connect the Source device to the Composite In port:</p> </li> <li> <p>Question: \"Connect the compositeIn source device to Port port_type and press Y: \"</p> </li> <li> <p>Press Y if the user connected the device and acknowledged it. (this will mark the step as PASS).</p> </li> <li> <p>Device connect Confirmation:</p> </li> <li> <p>The test will check if the event has reached the device.</p> </li> <li>If the event is detected will mark the step as PASS</li> <li> <p>If the event is not detected will mark the step as FAIL</p> </li> <li> <p>Device Disconnect prompt:</p> <p>The test will Request the User to disconnect the Source device to the Composite In port:</p> </li> <li> <p>Question: \"Disconnect the compositeIn source device to Port port_type and press Y: \"</p> </li> <li> <p>Press Y if the user connected the device and acknowledged it. (this will mark the step as PASS).</p> </li> <li> <p>Device disconnect Confirmation:</p> </li> <li> <p>The test will check if the event has reached the device.</p> </li> <li>If the event detected will mark the step as PASS</li> <li> <p>If the event not detected will mark the step as FAIL</p> </li> <li> <p>Repeat for All Ports:</p> </li> </ul> <p>The test will iterate through all available  ports, connecting/disconnecting each one and collecting user feedback accordingly.</p> <ul> <li>Test Conclusion:</li> </ul> <p>Upon receiving user responses for all ports, the test will conclude and present a final result: PASS or FAIL based on the user inputs throughout the test execution.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-L3-TestProcedure/#dscompositein_test2_verifystatus_callbackpy","title":"dsCompositeIn_test2_VerifyStatus_Callback.py","text":""},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-L3-TestProcedure/#platform-support-test02","title":"Platform Support - test02","text":"<ul> <li>Sink</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-L3-TestProcedure/#user-input-required-test02","title":"User Input Required - test02","text":"<p>Yes: User interaction is necessary to check the connect status of the Composite Source device (This will be automated later).</p>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-L3-TestProcedure/#acceptance-criteria-test02","title":"Acceptance Criteria - test02","text":"<p>The test detects the status of the Source device connected to the Composite In port</p>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-L3-TestProcedure/#expected-results-test02","title":"Expected Results - test02","text":"<p>The test registers the event and checks for  the event call back.</p> <p>Success Criteria</p> <ul> <li>The device should recognize the status of the port connected.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-L3-TestProcedure/#test-steps-test02","title":"Test Steps - test02","text":"<ul> <li> <p>Initiate the Test:</p> </li> <li> <p>Select and execute the Python file: <code>dsCompositeIn_test2_VerifyStatus_Callback.py</code></p> </li> <li> <p>The test will automatically download all required artifacts, copying them to the designated target directory before commencing execution.</p> </li> <li> <p>Device Connect prompt:</p> <p>The test will Request the User to connect the Source device to the Composite In port:</p> </li> <li> <p>Question: \"Connect the compositeIn source device to Port port_type and press Y: \"</p> </li> <li> <p>Press Y if the user connected the device and acknowledged it. (this will mark the step as PASS).</p> </li> <li> <p>Device status Confirmation:</p> </li> <li> <p>The test will select the port and check if the device status event has reached the device.</p> </li> <li>If the event is detected will mark the step as PASS</li> <li> <p>If the event is not detected will mark the step as FAIL</p> </li> <li> <p>Repeat for All Ports:</p> </li> </ul> <p>The test will iterate through all available  ports, selecting each port and collecting user feedback accordingly.</p> <ul> <li>Test Conclusion:</li> </ul> <p>Upon receiving user responses for all the ports, the test will conclude and present a final result: PASS or FAIL based on the user inputs throughout the test execution.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-L3-TestProcedure/#dscompositein_test3_scaleandverify_videopy","title":"dsCompositeIn_test3_ScaleAndVerify_Video.py","text":""},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-L3-TestProcedure/#platform-support-test03","title":"Platform Support - test03","text":"<ul> <li>Sink</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-L3-TestProcedure/#user-input-required-test03","title":"User Input Required - test03","text":"<p>Yes: User interaction is necessary to check the composite connection with the source device and to verify the video scaling (This will be automated later).</p>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-L3-TestProcedure/#acceptance-criteria-test03","title":"Acceptance Criteria - test03","text":"<p>Test checks if video scaling happens on video from the Source device connected to the Composite In port</p>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-L3-TestProcedure/#expected-results-test03","title":"Expected Results - test03","text":"<p>The test scales the video playing from compositeIn source device</p> <p>Success Criteria</p> <ul> <li>The user should see video scaling happening in 'DUT'.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-L3-TestProcedure/#test-steps-test03","title":"Test Steps - test03","text":"<ul> <li> <p>Initiate the Test:</p> </li> <li> <p>Select and execute the Python file: <code>dsCompositeIn_test3_ScaleAndVerify_Video.py</code></p> </li> <li> <p>The test will automatically download all required artifacts, copying them to the designated target directory before commencing execution.</p> </li> <li> <p>Device Connect prompt:</p> <p>The test will Request the User to connect the Source device to the Composite In port:</p> </li> <li> <p>Question: \"Connect the compositeIn source device to Port port_type and press Y: \"</p> </li> <li> <p>Press Y if the user connected the device and acknowledged it. (this will mark the step as PASS).</p> </li> <li> <p>The device changes the scale and requests user to confirm:</p> </li> <li> <p>Question: \"Check video scaled on port_type and press (Y/N)\"</p> </li> <li>Press Y if the user sees the video scaling. (this will mark the step as PASS).</li> <li> <p>Press N if the user cannot see the video scaling. (this will mark the step as FAIL).</p> </li> <li> <p>Repeat for Scaling factor:</p> </li> </ul> <p>The test will iterate through all available scaling parameters and set scaling accordingly..</p> <ul> <li>Repeat for All Ports:</li> </ul> <p>The test will iterate through all available ports.</p> <ul> <li>Test Conclusion:</li> </ul> <p>Upon receiving user responses for all ports, the test will conclude and present a final result: PASS or FAIL based on the user inputs throughout the test execution.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-L3-TestProcedure/#dscompositein_test4_verifysignal_callbackpy","title":"dsCompositeIn_test4_VerifySignal_Callback.py","text":""},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-L3-TestProcedure/#platform-support-test04","title":"Platform Support - test04","text":"<ul> <li>Sink</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-L3-TestProcedure/#user-input-required-test04","title":"User Input Required - test04","text":"<p>Yes: User interaction is necessary to connect/Disconnect the device (This will be automated later).</p>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-L3-TestProcedure/#acceptance-criteria-test04","title":"Acceptance Criteria - test04","text":"<p>The test detects the signal status of the compositeIn signal.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-L3-TestProcedure/#expected-results-test04","title":"Expected Results - test04","text":"<p>The test checks the signal change in the composite source</p> <p>Success Criteria</p> <ul> <li>Test identifies the signal change.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-L3-TestProcedure/#test-steps-test04","title":"Test Steps - test04","text":"<ul> <li> <p>Initiate the Test:</p> </li> <li> <p>Select and execute the Python file: <code>dsCompositeIn_test4_VerifySignal_Callback.py</code></p> </li> <li> <p>The test will automatically download all required artifacts, copying them to the designated target directory before commencing execution.</p> </li> <li> <p>Device Connect prompt:</p> <p>The test will Request the User to connect the Source device to the Composite In port:</p> </li> <li> <p>Question: \"Connect the compositeIn source device to Port port_type and press Y: \"</p> </li> <li> <p>Press Y if the user connected the device and acknowledged it. (this will mark the step as PASS).</p> </li> <li> <p>Signal change confirmation:</p> </li> <li> <p>The test will check if the event has reached the device.</p> </li> <li>If the event is detected will mark the step as PASS</li> <li> <p>If the event is not detected will mark the step as FAIL</p> </li> <li> <p>Device Disconnect/Standby prompt:</p> <p>The test will Request the User to disconnect the Source device to the Composite In port or make Source device to standby mode:</p> </li> <li> <p>Question: \"Check if CompositeIn source is disconnected to port_type/set to standby and press Y: \"</p> </li> <li> <p>Press Y if the user connected the device and acknowledged it. (this will mark the step as PASS).</p> </li> <li> <p>Signal change confirmation:</p> </li> <li> <p>The test will check if the event has reached the device.</p> </li> <li>If the event is detected will mark the step as PASS</li> <li> <p>If the event is not detected will mark the step as FAIL</p> </li> <li> <p>Repeat for All Ports:</p> </li> </ul> <p>The test will iterate through all available ports.</p> <ul> <li>Test Conclusion:</li> </ul> <p>Upon receiving user responses for all ports, the test will conclude and present a final result: PASS or FAIL based on the user inputs throughout the test execution.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-L3-TestProcedure/#dscompositein_test5_verifyvideomode_callbackpy","title":"dsCompositeIn_test5_VerifyVideoMode_Callback.py","text":""},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-L3-TestProcedure/#platform-support-test05","title":"Platform Support - test05","text":"<ul> <li>Sink</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-L3-TestProcedure/#user-input-required-test05","title":"User Input Required - test05","text":"<p>Yes: User interaction is necessary to connect/Disconnect the device (This will be automated later).</p>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-L3-TestProcedure/#acceptance-criteria-test05","title":"Acceptance Criteria - test05","text":"<p>The test detects the video mode change of the compositeIn video.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-L3-TestProcedure/#expected-results-test05","title":"Expected Results - test05","text":"<p>The test checks the video mode change in the composite source</p> <p>Success Criteria</p> <ul> <li>Test identifies the video mode change.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-L3-TestProcedure/#test-steps-test05","title":"Test Steps - test05","text":"<ul> <li> <p>Initiate the Test:</p> </li> <li> <p>Select and execute the Python file: <code>dsCompositeIn_test5_VerifyVideoMode_Callback.py</code></p> </li> <li> <p>The test will automatically download all required artifacts, copying them to the designated target directory before commencing execution.</p> </li> <li> <p>Device Connect prompt:</p> <p>The test will Request the User to connect the Source device to the Composite In port:</p> </li> <li> <p>Question: \"Connect the compositeIn source device to Port port_type and press Y: \"</p> </li> <li> <p>Press Y if the user connected the device and acknowledged it. (this will mark the step as PASS).</p> </li> <li> <p>Device connect confirmation:</p> </li> <li> <p>The test will check if the event has reached the device.</p> </li> <li>If the event is detected will mark the step as PASS</li> <li> <p>If the event is not detected will mark the step as FAIL</p> </li> <li> <p>Source video resolution change prompt:</p> <p>The test will Request the User to change the resolution of video on Source device connected to the Composite In port:</p> </li> <li> <p>Question: \"Change the resolution of video played from CompositeIn source device connected to port_type and press Y: \"</p> </li> <li> <p>Press Y if the user changed the resolution and acknowledged it. (this will mark the step as PASS).</p> </li> <li> <p>Source video resolution change confirmation:</p> </li> <li> <p>The test will check if the event has reached the device.</p> </li> <li>If the event is detected will mark the step as PASS</li> <li> <p>If the event is not detected will mark the step as FAIL</p> </li> <li> <p>Repeat for All Ports:</p> </li> </ul> <p>The test will iterate through all available ports.</p> <ul> <li>Test Conclusion:</li> </ul> <p>Upon receiving user responses for all ports, the test will conclude and present a final result: PASS or FAIL based on the user inputs throughout the test execution.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsCompositeIn/ds-compositeIn-L3-TestProcedure/#dscompositein_l3_runall_sinkpy","title":"dsCompositeIn_L3_Runall_Sink.py","text":"<p>This python file runs all the tests supported by <code>sink</code> devices</p> <pre><code>python dsCompositeIn_L3_Runall_Sink.py --config &lt;/PATH&gt;/ut/host/tests/configs/example_rack_config.yml --deviceConfig &lt;/PATH&gt;/ut/host/tests/configs/deviceConfig.yml\n</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsDisplay/ds-display-L2-Low-Level_TestSpec/","title":"Device Settings Display L2 Low Level Test Specification and Procedure Documentation","text":""},{"location":"external_content/device_settings_test/docs/pages/dsDisplay/ds-display-L2-Low-Level_TestSpec/#overview","title":"Overview","text":"<p>This document describes the Low Level L2 test Specification and Procedure for the Device settings Display module.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsDisplay/ds-display-L2-Low-Level_TestSpec/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>HAL</code>     - Hardware Abstraction layer</li> <li><code>EDID</code>    - Extended Display Identification</li> <li><code>HDMI</code>    - High-Definition Multimedia Interface</li> <li><code>API</code>     - Application programming interface</li> <li><code>HAL</code>     - Hardware Abstraction Layer, may include some common components</li> <li><code>UT</code>      - Unit Test(s)</li> <li><code>OEM</code>     - Original Equipment Manufacture</li> <li><code>SoC</code>     - System on a Chip</li> <li><code>DS</code>      - Device Settings</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsDisplay/ds-display-L2-Low-Level_TestSpec/#definitions","title":"Definitions","text":"<ul> <li><code>ut-core</code> - Common Testing Framework https://github.com/rdkcentral/ut-core, which wraps a open-source framework that can be expanded to the requirements for future framework.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsDisplay/ds-display-L2-Low-Level_TestSpec/#references","title":"References","text":"<ul> <li><code>High Level Test Specification</code> - dsDisplay_TestSpecificaion.md</li> <li><code>HAL Interface file</code> - dsDisplay.h</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsDisplay/ds-display-L2-Low-Level_TestSpec/#level-2-test-procedure","title":"Level 2 Test Procedure","text":"<p>The following functions are expecting to test the module operates correctly.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsDisplay/ds-display-L2-Low-Level_TestSpec/#test-1","title":"Test 1","text":"Title Details Function Name <code>test_l2_dsDisplay_RetrieveAndValidateEDID_sink</code> Description For the sink device, retrieve EDID information for the display type 'dsVIDEOPORT_TYPE_INTERNAL' using GetEDID and GetEDIDBytes, then validate the values against the data available in the \"Panel_4K_Display.yaml\" profile file. The values to be validated are the 'EDID_Data/productCode' for GetEDID and the 'EDID_Data/edidBytes'(which stands for Manufacturer ID) at bytes 8 and 9 against the values available in the profile file for GetEDIDBytes. Test Group 02 Test Case ID 001 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsDisplay/ds-display-L2-Low-Level_TestSpec/#test-procedure-test-1","title":"Test Procedure - Test 1","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the display using <code>dsDisplayInit</code> None <code>dsERR_NONE</code> Should be successful 02 Get the display handle using <code>dsGetDisplay</code> for the <code>dsVIDEOPORT_TYPE_INTERNAL</code> type type = <code>dsVIDEOPORT_TYPE_INTERNAL</code>, index = 0 <code>dsERR_NONE</code> Should be successful 03 Retrieve EDID information using <code>dsGetEDID</code> handle = obtained from step 02 <code>dsERR_NONE</code> Should be successful 04 Validate with the product code data available in the profile file product code, <code>dsDisplay/EDID_Data/productCode</code> Value matches Should be successful 05 Retrieve EDID bytes using <code>dsGetEDIDBytes</code> handle = obtained from step 02, edidBytes = valid buffer, length = valid buffer <code>dsERR_NONE</code> Should be successful 06 Validate with the Manufacturer ID at bytes 8 and 9 against the values available in the profile file Manufacturer ID , <code>dsDisplay/EDID_Data/edidBytes</code> Value matches Should be successful 07 Terminate the display using <code>dsDisplayTerm</code> None <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\n    A[Call dsDisplayInit] --&gt;|dsERR_NONE| B[Call dsGetDisplay]\n    A --&gt;|!= dsERR_NONE| A1[Test case fail]\n    B --&gt;|dsERR_NONE and valid handle| C[Parse 'Panel_CompositeInput.yaml']\n    C--&gt; D[Call dsGetEDID]\n    B --&gt;|!= dsERR_NONE or invalid handle| B1[Test case fail]\n    D --&gt;|dsERR_NONE and valid dsDisplayEDID_t| E[Compare productcode values]\n    D --&gt;|!= dsERR_NONE or invalid dsDisplayEDID_t| D1[Test case fail]\n    E --&gt; F[Call dsGetEDIDBytes]\n    F --&gt;|dsERR_NONE and valid buffer and length &gt;= 0| G[Compare Manufacturer ID values]\n    F --&gt;|!= dsERR_NONE or invalid buffer or length &lt; 0| F1[Test case fail]\n    G --&gt; H[Call dsDisplayTerm]\n    H --&gt;|dsERR_NONE| I[Test case success]\n    H --&gt;|!= dsERR_NONE| H1[Test case fail]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsDisplay/ds-display-L2-Low-Level_TestSpec/#test-2","title":"Test 2","text":"Title Details Function Name <code>test_l2_dsDisplay_TestDefaultAspectRatio_source</code> Description Test the default aspect ratio (16:9) without any TV connected on source devices. Test Group 02 Test Case ID 002 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsDisplay/ds-display-L2-Low-Level_TestSpec/#test-procedure-test-2","title":"Test Procedure - Test 2","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the display using <code>dsDisplayInit</code> None <code>dsERR_NONE</code> Should be successful 02 Get the display handle using <code>dsGetDisplay</code> with <code>dsVIDEOPORT_TYPE_HDMI</code> and index 0 <code>dsVIDEOPORT_TYPE_HDMI</code>, 0 <code>dsERR_NONE</code> Should be successful 03 Get the display aspect ratio using <code>dsGetDisplayAspectRatio</code> with the handle obtained from <code>dsGetDisplay</code> handle obtained from <code>dsGetDisplay</code> and aspectRatio = valid buffer <code>dsERR_NONE</code>, <code>dsVIDEO_ASPECT_RATIO_16x9</code> Should be successful 04 Verify that the aspect ratio is <code>dsVIDEO_ASPECT_RATIO_16x9</code> None <code>dsVIDEO_ASPECT_RATIO_16x9</code>, <code>dsDisplay/AspectRatio</code> Should be successful 05 Terminate the display using <code>dsDisplayTerm</code> None <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\nA[Call dsDisplayInit] --&gt;|dsERR_NONE| B[Call dsGetDisplay]\nB --&gt;|dsERR_NONE| C[Call dsGetDisplayAspectRatio]\nC --&gt;|dsERR_NONE| D[Verify aspect ratio is dsVIDEO_ASPECT_RATIO_16x9]\nD --&gt;|Verified| E[Call dsDisplayTerm]\nE --&gt;|dsERR_NONE| F[Test case success]\nA --&gt;|!=dsERR_NONE| G[Test case fail]\nB --&gt;|!=dsERR_NONE| H[Test case fail]\nC --&gt;|!=dsERR_NONE| I[Test case fail]\nD --&gt;|Not Verified| J[Test case fail]\nE --&gt;|!=dsERR_NONE| K[Test case fail]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsDisplay/ds-display-high-Level_TestSpec/","title":"Device Settings Display High Level Test Specification Document","text":""},{"location":"external_content/device_settings_test/docs/pages/dsDisplay/ds-display-high-Level_TestSpec/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>HAL</code>       - Hardware Abstraction layer</li> <li><code>EDID</code>      - Extended Display Identification</li> <li><code>API</code>       - Application programming interface</li> <li><code>CPU</code>       - Central processing unit</li> <li><code>RDK</code>       - Reference Design Kit</li> <li><code>dsDisplay</code> - Device Settings Display</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsDisplay/ds-display-high-Level_TestSpec/#references","title":"References","text":"<ul> <li><code>EDID</code> Specifications - https://en.wikipedia.org/wiki/Extended_Display_Identification_Data</li> <li>Python <code>EDID</code> decoder library is available here - https://pypi.org/project/pyedid/</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsDisplay/ds-display-high-Level_TestSpec/#introduction","title":"Introduction","text":"<p>This document provides an overview of the high level testing requirements for the dsDisplay module. It outlines the scope of testing, objectives, testing levels and approaches, specific test requirements, emulator requirements, control plane requirements and expected deliverables.</p> <ul> <li>Interface of the test is available in this link - https://github.com/rdkcentral/rdk-halif-device_settings/blob/main/include/dsDisplay.h</li> <li><code>HAL</code> Specification in this link - https://github.com/rdkcentral/rdk-halif-device_settings/blob/main/docs/pages/ds-display_halSpec.md</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsDisplay/ds-display-high-Level_TestSpec/#module-description","title":"Module Description","text":"<p>High level overview:</p> <ul> <li><code>dsDisplay</code> offers a range of APIs for retrieving information about the Display Device.</li> <li>Data is retrieved from the Display Device and HDMI. This data is passed to the caller.</li> <li>In order to retrieve HDMI information, an external device must be connected.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsDisplay/ds-display-high-Level_TestSpec/#testing-scope","title":"Testing Scope","text":"# Test Functionality Test Description 1 Get EDID Information Test validates the accuracy and functionality of the display device module's functions (dsGetEDID and dsGetEDIDBytes) in retrieving the Extended Display Identification Data (EDID) from connected display devices 2 Get Aspect Ratio Test provides the aspect ratio of the display device 3 Callback Registration for Display Related Events To verify the callback registration for display related events. The display events are Display connected event, Display disconnected event, Rx Sense ON event, Rx Sense OFF event, HDCP protocol version change event -----------"},{"location":"external_content/device_settings_test/docs/pages/dsDisplay/ds-display-high-Level_TestSpec/#get-edid-information","title":"Get EDID Information","text":"Description HAL APIs L2 L3 Source Sink Control plane requirements The Get EDID Information test aims to verify the functionality of the display device module's dsGetEDID and dsGetEDIDBytes functions, which are responsible for retrieving the Extended Display Identification Data (EDID) from connected display devices. This test ensures that the module can accurately retrieve and interpret EDID information, providing essential data about the display's capabilities and characteristics. dsGetEDID(), dsGetEDIDBytes() N Y Y N N For the sink device, retrieve EDID information for the 'dsVIDEOPORT_TYPE_INTERNAL' type using GetEDID and GetEDIDBytes, then validate the values against the data available in the profile file. The values to be validated are the 'EDID_Data/productCode' for GetEDID and the 'EDID_Data/edidBytes'(which stands for Manufacturer ID) at bytes 8 and 9 against the values available in the profile file \"Panel_4K_Display.yaml\" for GetEDIDBytes. dsGetEDID(), dsGetEDIDBytes() Y N N Y N"},{"location":"external_content/device_settings_test/docs/pages/dsDisplay/ds-display-high-Level_TestSpec/#test-startup-requirement-get-edid-information","title":"Test Startup Requirement - Get EDID Information","text":"<p>Launch the test with the predefined configuration set of results.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsDisplay/ds-display-high-Level_TestSpec/#emulator-requirement-get-edid-information","title":"Emulator Requirement - Get EDID Information","text":"<p>Emulator will boot with the EDID coming from the configuration file.</p> # Description 1 EDID for a panel TV <p>TODO: Generate a list of sample list for 5 to 6 different TV's. Generate a list of TV's from the office for the different EDIDs and store the binaries of the test. It can use it as samples.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsDisplay/ds-display-high-Level_TestSpec/#control-plane-requirement-get-edid-information","title":"Control Plane Requirement - Get EDID Information","text":"<p>Switching between the EDIDs of multiple TVs controlled by the control plane</p>"},{"location":"external_content/device_settings_test/docs/pages/dsDisplay/ds-display-high-Level_TestSpec/#get-aspect-ratio","title":"Get Aspect Ratio","text":"Description HAL APIs L2 L3 Source Sink Control plane requirements Test the default aspect ratio (16:9) without any TV connected. dsGetDisplayAspectRatio() Y N Y N N Adjust and test the different aspect ratios (4:3, 16:9) to ensure they provide the expected aspect ratio. dsGetDisplayAspectRatio() N Y Y N Y"},{"location":"external_content/device_settings_test/docs/pages/dsDisplay/ds-display-high-Level_TestSpec/#emulator-requirement-get-aspect-ratio","title":"Emulator Requirement - Get Aspect Ratio","text":"<p>Emulator will boot with the Aspect ratio coming from the configuration file.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsDisplay/ds-display-high-Level_TestSpec/#control-plane-requirement-get-aspect-ratio","title":"Control Plane Requirement - Get Aspect Ratio","text":"<p>Maintains the configuration of various aspect ratios and provides them whenever a user is supposed to make a change.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsDisplay/ds-display-high-Level_TestSpec/#callback-registration-for-display-related-events","title":"Callback Registration for Display Related Events","text":"Description HAL APIs L2 L3 Source Sink Control plane requirements Test the 'Display connected' event. Upon connecting the display device, the callback should trigger the event dsRegisterDisplayEventCallback() N Y Y Y Y Test the 'Display disconnected' event. Upon disconnecting the display device, the callback should trigger the event dsRegisterDisplayEventCallback() N Y Y N Y Test the 'Rx Sense ON' event by verifying the presence of a signal from the receiving device; the callback should be triggered when the signal is detected dsRegisterDisplayEventCallback() N Y Y N Y Test the 'Rx Sense OFF' event by verifying the absense of a signal from the receiving device; the callback should be triggered when the signal is detected dsRegisterDisplayEventCallback N Y Y N Y Test the 'HDCP protocol version change' event by verifying if there is a change in the HDCP protocol version used for content protection; the callback should be triggered upon detection of the protocol change dsRegisterDisplayEventCallback() N Y Y N N"},{"location":"external_content/device_settings_test/docs/pages/dsDisplay/ds-display-high-Level_TestSpec/#test-startup-requirement-callback-registration-for-display-related-events","title":"Test Startup Requirement - Callback Registration for Display Related Events","text":"<p>Launch the test with the configured HDCP 1.x and HDCP 2.x keys.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsDisplay/ds-display-high-Level_TestSpec/#emulator-requirement-callback-registration-for-display-related-events","title":"Emulator Requirement - Callback Registration for Display Related Events","text":"<p>Emulator will boot with the predefined set of HDCP keys coming from the configuration file.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsDisplay/ds-display-high-Level_TestSpec/#control-plane-requirement-callback-registration-for-display-related-events","title":"Control Plane Requirement - Callback Registration for Display Related Events","text":"<ul> <li>The control plane will generate events for HDMI connection and disconnection. It also supplies signals to the receiving devices to initiate the Rx Sense ON/Rx Sense OFF events.</li> <li>The Control Plane will handle connection/disconnection, measuring the timing between both and ensuring it meets the expected time.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsDisplay/ds-display_L3_Low-Level_TestSpecification/","title":"Display Settings L3 Low Level Test Specification and Procedure Documentation","text":""},{"location":"external_content/device_settings_test/docs/pages/dsDisplay/ds-display_L3_Low-Level_TestSpecification/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>HAL</code>  - Hardware Abstraction Layer, may include some common components</li> <li><code>UT</code>   - Unit Test(s)</li> <li><code>OEM</code>  - Original Equipment Manufacture</li> <li><code>L3</code>   - Level 3 Testing</li> <li><code>DS</code>   - Device Settings</li> <li><code>EDID</code> - Extended Display Identification Data</li> <li><code>DUT</code>  - Device Under Test</li> <li><code>RAFT</code> - Rapid Automation Framework for Testing</li> <li><code>Y</code>    - yes supported</li> <li><code>NA</code>   - Not Supported</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsDisplay/ds-display_L3_Low-Level_TestSpecification/#overview","title":"Overview","text":"<p>This document describes the L3 Test Procedure for the Device Settings Display module.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsDisplay/ds-display_L3_Low-Level_TestSpecification/#references","title":"References","text":"<ul> <li><code>Display Interface file</code> - dsDisplay.h</li> <li><code>High Level Test Specification</code> - ds-display_High-Level_TestSpecification.md</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsDisplay/ds-display_L3_Low-Level_TestSpecification/#level-3-test-cases-high-level-overview","title":"Level 3 Test Cases High Level Overview","text":"<p>Below are the top test use cases for the display.</p> # Test-case Description HAL APIs Source Sink 1 Verify Display Events with callbacks Connect/disconnect the display device on each port and verify that the callbacks are triggered for display connected, display disconnected, Rx Sense ON, Rx Sense OFF, and HDCP protocol version change events <code>dsRegisterDisplayEventCallback()</code> <code>Y</code> <code>Y</code> 2 Retrieves and interprets EDID information Connect various pre-defined displays to the device, retrieve their EDID information, and compare it against the expected EDID data <code>dsGetEDID()</code> <code>Y</code> <code>NA</code> 3 Gets the EDID buffer and EDID length Verify that the edid buffer contains the expected EDID data, and the length is accurate <code>dsGetEDIDBytes()</code> <code>Y</code> <code>NA</code> 4 Gets Aspect Ratio Verify that the aspect ratio of the display is correctly retrieved and matches the expected value for a given configuration <code>dsGetDisplayAspectRatio()</code> <code>Y</code> <code>NA</code>"},{"location":"external_content/device_settings_test/docs/pages/dsDisplay/ds-display_L3_Low-Level_TestSpecification/#level-3-python-test-cases-high-level-overview","title":"Level 3 Python Test Cases High Level Overview","text":"<p>The class diagram below illustrates the flow of dsDisplay L3 Python test cases:</p> <pre><code>---\ntitle: dsDisplay- Python Class Flow\n---\nclassDiagram\n    testControl &lt;|-- ut_raft : inherits\n    class ut_raft{\n    }\n    ut_raft &lt;|-- L3_TestClasses : inherits\n    ut_raft &lt;|-- dsDisplayHelperClass : inherits\n    dsDisplayHelperClass &lt;|-- L3_TestClasses : inherits\n    L3_TestClasses ..&gt; dsDisplay : uses\n    note for testControl \"uses rackConfig.yaml and deviceConfig.yaml\"\n    note for dsDisplay \"uses platformProfile.yaml\"\n    note for L3_TestClasses \"uses testSetupConfig.yaml\"\n    note for ut_raft \"suite Navigator uses testConfig.yaml\"</code></pre> <ul> <li>testControl</li> <li>Test Control Module for running rack Testing. This module configures the <code>DUT</code> based on the rack configuration file provided to the test.</li> <li>This class is defined in <code>RAFT</code> framework. For more details refer RAFT</li> <li>ut_raft</li> <li>Python based testing framework for writing engineering tests.</li> <li>It provides common functionalities like menu navigation, configuration reader, reading user response etc.</li> <li>For more details ut-raft.</li> <li>dsDisplay</li> <li>This is test helper class which communicates with the <code>L3</code> C/C++ test running on the <code>DUT</code> through menu</li> <li>L3TestClasses</li> <li>These are the L3 test case classes</li> <li>Each class covers the each test use-case defined in L3 Test use-cases table</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsDisplay/ds-display_L3_Low-Level_TestSpecification/#yaml-file-inputs","title":"YAML File Inputs","text":"<ul> <li>rackConfig.yaml</li> <li>Identifies the rack configuration and platform used</li> <li>References platform-specific config from <code>deviceConfig.yaml</code></li> <li> <p>For more details refer RAFT and example_rack_config.yml</p> </li> <li> <p>deviceConfig.yaml</p> </li> <li>Specifies overall configuration for the platform</li> <li>Can be overridden by:<ul> <li>Changing locally .yaml file directory</li> <li>Using --deviceConfig command line switch</li> </ul> </li> <li> <p>For more details refer RAFT and example_device_config.yml</p> </li> <li> <p>componentProfile.yaml/platformProfile.yaml</p> </li> <li>Contains component-specific configurations</li> <li>Contains platform wide configuration broken down into separate components</li> <li> <p>Example configuration file dsDisplay_Settings</p> </li> <li> <p>testSetupConfig.yaml</p> </li> <li>This configuration file contains the list of requirements for tests to execute. Eg: Copying the streams, setting environment variables etc.</li> <li> <p>Example configuration file dsDisplay_L3_testSetup.yml</p> </li> <li> <p>testConfig.yaml</p> </li> <li>This configuration file contains the list of menu items for C/C++ L3 test running on <code>DUT</code></li> <li>Example configuration file dsDisplay_testConfig.yml</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsDisplay/ds-display_L3_TestProcedure/","title":"Device Settings Display L3 Test Case and Procedure Documentation","text":""},{"location":"external_content/device_settings_test/docs/pages/dsDisplay/ds-display_L3_TestProcedure/#overview","title":"Overview","text":"<p>This document describes the VTS Level 3 Test scenarios and the execution process for the Device Setting Display Module.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsDisplay/ds-display_L3_TestProcedure/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>HAL</code>  - Hardware Abstraction Layer, may include some common components</li> <li><code>UT</code>   - Unit Test(s)</li> <li><code>OEM</code>  - Original Equipment Manufacture</li> <li><code>SoC</code>  - System on a Chip</li> <li><code>HDMI</code> - High-Definition Multimedia Interface</li> <li><code>EDID</code> - Extended Display Identification Data</li> <li><code>RAFT</code> - Rapid Automation Framework for Testing</li> <li><code>Y</code>    - yes supported</li> <li><code>NA</code>   - Not Supported</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsDisplay/ds-display_L3_TestProcedure/#references","title":"References","text":"<ul> <li> <p><code>High Level Test Specification</code> - dsDisplay High Level TestSpec</p> </li> <li> <p><code>dsDisplay L3 Low Level Test Specification</code> - dsDisplay L3 Low Level TestSpec</p> </li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsDisplay/ds-display_L3_TestProcedure/#setting-up-test-environment","title":"Setting Up Test Environment","text":"<p>To execute <code>HAL</code> <code>L3</code> Python test cases, need a Python environment. Follow these steps mentioned in HPK Public Documentation</p>"},{"location":"external_content/device_settings_test/docs/pages/dsDisplay/ds-display_L3_TestProcedure/#update-configuration-files","title":"Update Configuration Files","text":""},{"location":"external_content/device_settings_test/docs/pages/dsDisplay/ds-display_L3_TestProcedure/#rack-configuration-file","title":"Rack Configuration File","text":"<p>Example Rack configuration File: example_rack_config.yml</p> <p>For more details refer RAFT and example_rack_config.yml</p> <p>In this file, update the configuration to define the console sessions for the <code>DUT</code> and the outbound settings:</p> Console Session Description default Downloads the streams required for test cases. ssh_hal_test Executes the HAL binary for the test case. <p>```yaml rackConfig:   - dut:       ip: \"XXX.XXX.XXX.XXX\"  # IP Address of the device       description: \"stb device under test\"       platform: \"stb\"       consoles:         - default:             type: \"ssh\"             port: 10022             username: \"root\"             ip: \"XXX.XXX.XXX\" # IP address of the device             password: ' '         - ssh_hal_test:             type: \"ssh\"             port: 10022             username: \"root\"             ip: \"XXX.XXX.XXX\" # IP address of the device             password: ' '       outbound:         download_url: \"tftp://tftp-server.com/rack1/slot1/\"    # Download location for the CPE device         upload_url: \"sftp://server-address/home/workspace/tftp/rack1/slot1/\" # Upload location         upload_url_base_dir: \"sftp://server-address/home/workspace/tftp/rack1/slot1\"         httpProxy:   # Local proxy if required         workspaceDirectory: './logs/workspace'   # Local working directory</p> <pre><code>#### Device Configuration File\n\nExample Device configuration File: [deviceConfig.yml](../../../host/tests/configs/deviceConfig.yml)\n\nFor more details refer [RAFT](https://github.com/rdkcentral/python_raft/blob/1.0.0/README.md) and [example_device_config.yml](https://github.com/rdkcentral/python_raft/blob/1.0.0/examples/configs/example_device_config.yml)\n\nUpdate the target directory where `HAL` binaries will be copied into the device. Also, map the profile to the source/sink settings `YAML` file path.\n\nEnsure the platform should match with the `DUT` platform in [Rack Configuration](#rack-configuration-file)\n\n```yaml\ndeviceConfig:\n  cpe1:\n    platform: \"stb\"    # Must match the platform in example_rack_config.yml\n    model: \"uk\"\n    target_directory: \"/tmp\"  # Path where HAL binaries are copied in device\n    test:\n      profile: \"../../../../profiles/source/Source_4K_Display.yaml\"\n      player:\n        tool: \"gstreamer\"\n        prerequisites:\n          - export xxxx    # Pre-commands required to play the stream\n</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsDisplay/ds-display_L3_TestProcedure/#test-setup-configuration-file","title":"Test Setup Configuration File","text":"<p>Update the artifact paths from which the binaries should be copied to the device.</p> <p>Set the execution paths for each test case.</p> <ul> <li>Example configuration file: dsDisplay_L3_testSetup.yml.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsDisplay/ds-display_L3_TestProcedure/#test-configuration","title":"Test Configuration","text":"<p>Update the execute command according to the device path where <code>HAL</code> binaries are copied and Update the test suite for each level test case</p> <ul> <li>Example configuration file: dsDisplay_testConfig.yml.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsDisplay/ds-display_L3_TestProcedure/#run-test-cases","title":"Run Test Cases","text":"<p>Once the environment is set up, you can execute the test cases with the following command</p> <pre><code>python &lt;TestCaseName.py&gt; --config &lt;/PATH&gt;/ut/host/tests/configs/example_rack_config.yml --deviceConfig &lt;/PATH&gt;/ut/host/tests/configs/deviceConfig.yml\n</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsDisplay/ds-display_L3_TestProcedure/#test-case-procedure","title":"Test Case Procedure","text":""},{"location":"external_content/device_settings_test/docs/pages/dsDisplay/ds-display_L3_TestProcedure/#dsdisplay_test01_verifydisplayconnectcallbacktestpy","title":"dsDisplay_test01_VerifyDisplayConnectCallBackTest.py","text":"<p>Overview:</p> <p>This test verifies display event callbacks by connecting and disconnecting a display device on each supported video port, ensuring that appropriate callbacks are triggered for display connection, disconnection, Rx Sense ON, Rx Sense OFF, and HDCP protocol version change events.</p> <p>Platform Supported:</p> <ul> <li>Source</li> <li>Sink</li> </ul> <p>User Input Required:</p> <p>Yes: User input is required to manually change the display status (connect/disconnect) during the test execution, with the prompt question <code>Change the {port} status to {event} and press Enter:</code> (This will be automated later).</p> <p>Acceptance Criteria:</p> <p>The test will pass if each display event triggers the expected callback for every supported display port.</p> <p>Expected Results:</p> <p>The test will raise events for connecting and disconnecting the display and verify that the expected callbacks are received for each event. The test will pass if all expected callbacks are detected; otherwise, it will fail.</p> <p>Test Steps:</p> <ul> <li>Run the Python file <code>dsDisplay_test01_VerifyDisplayConnectCallBackTest.py</code> with the appropriate configuration:</li> </ul> <pre><code>dsDisplay_test01_VerifyDisplayConnectCallBackTest.py --config /host/tests/configs/example_rack_config.yml --deviceConfig /host/tests/configs/deviceConfig.yml\n</code></pre> <ul> <li> <p>The test will download all required artifacts, copy them to the target directory, and start execution.</p> </li> <li> <p>Callback Event Verification:</p> </li> <li> <p>Prompting the user to change display status for each supported port (connect/disconnect)</p> </li> <li>Capture and verify the device's callback status to confirm receipt of the expected event callback.</li> <li> <p>For each event, verify the following:</p> <ul> <li>dsDISPLAY_EVENT_CONNECTED</li> <li>dsDISPLAY_EVENT_DISCONNECTED</li> <li>dsDISPLAY_RXSENSE_ON</li> <li>dsDISPLAY_RXSENSE_OFF</li> <li>dsDISPLAY_HDCPPROTOCOL_CHANGE</li> </ul> </li> <li> <p>Completion and results:</p> </li> </ul> <p>After verifying all callback statuses, the test will conclude and display the final result (PASS/FAIL).</p>"},{"location":"external_content/device_settings_test/docs/pages/dsDisplay/ds-display_L3_TestProcedure/#dsdisplay_test02_testverifydisplayedidpy","title":"dsDisplay_test02_TestVerifyDisplayEdid.py","text":"<p>Overview:</p> <p>This test case is designed for Source devices and focuses on retrieving and verifying the <code>EDID</code> by connecting various pre-defined displays to each supported video port. The test compares the <code>EDID</code> data retrieved from the connected displays against expected values to ensure accurate identification. It uses the dsDisplay_test_MonitorDetails.yml file, which contains the details of the connected monitors for verification.</p> <p>Platform Supported:</p> <ul> <li>Source</li> </ul> <p>User Input Required:</p> <p>Yes: User input is required to manually connect the display to the specified port, with the prompt question <code>Connect Device: {display} to Port: {port} and Press Enter:</code> (This will be automated later).</p> <p>Acceptance Criteria:</p> <p>This test retrieves and verifies <code>EDID</code> by connecting various pre-defined displays to each supported video port. It then compares the retrieved <code>EDID</code> data against expected values to ensure accurate display identification.</p> <p>Expected Results:</p> <p>Connect each specified display device, retrieve <code>EDID</code> data, and confirm that the retrieved monitor names match the expected values defined in dsDisplay_test_MonitorDetails.yml, returning a pass/fail status based on the comparison.</p> <p>Test Steps:</p> <ul> <li>Run the Python file <code>dsDisplay_test02_TestVerifyDisplayEdid.py</code> with the appropriate configuration:</li> </ul> <pre><code>dsDisplay_test02_TestVerifyDisplayEdid.py --config /host/tests/configs/example_rack_config.yml --deviceConfig /host/tests/configs/deviceConfig.yml\n</code></pre> <ul> <li> <p>The test will download all required artifacts, copy them to the target directory, and start execution.</p> </li> <li> <p>Display Device Verification:</p> </li> <li> <p>For each available video port, the test prompts the user to connect the specified display device (LG, Philips, Sony, Samsung).</p> </li> <li>The test will retrieve the <code>EDID</code> information from the connected display device and verify it against the expected details, such as the monitor name, for each display device.</li> <li> <p>It will confirm that the <code>monitorName</code> field in the retrieved <code>EDID</code> matches the expected monitor name specified in dsDisplay_test_MonitorDetails.yml.</p> </li> <li> <p>Completion and Results:</p> </li> </ul> <p>After verifying the <code>EDID</code> information for all connected display devices, the test will conclude and display the final result (PASS/FAIL).</p>"},{"location":"external_content/device_settings_test/docs/pages/dsDisplay/ds-display_L3_TestProcedure/#dsdisplay_test03_aspectratioverificationtestpy","title":"dsDisplay_test03_AspectRatioVerificationTest.py","text":"<p>Overview:</p> <p>This test retrieves and verifies the aspect ratio of the display on each supported video port. For each specified aspect ratio, the test checks that the retrieved aspect ratio matches the expected value, ensuring that the display correctly adapts to the given configuration.</p> <p>Platform Supported:</p> <ul> <li>Source</li> </ul> <p>User Input Required:</p> <p>Yes: User input is required to manually set the aspect ratio for the specified port, with the prompt question <code>Set the aspect ratio {aspectRatio} to Port: {port} and Press Enter:</code> (This will be automated later).</p> <p>Acceptance Criteria:</p> <p>Verify that the display\u2019s aspect ratio is correctly retrieved for each configured setting (16x9, 4x3).</p> <p>Expected Results:</p> <p>The test will set various aspect ratios, retrieve the current aspect ratio from the display, and confirm that it matches the expected value. The test will pass if all aspect ratios are correctly identified; otherwise, it will fail.</p> <p>Test Steps:</p> <ul> <li>Run the Python file <code>dsDisplay_test03_AspectRatioVerificationTest.py</code> with the appropriate configuration:</li> </ul> <pre><code>dsDisplay_test03_AspectRatioVerificationTest.py --config /host/tests/configs/example_rack_config.yml --deviceConfig /host/tests/configs/deviceConfig.yml\n</code></pre> <ul> <li> <p>The test will download the required artifacts, then copy them to the target directory.</p> </li> <li> <p>Aspect Ratio Verification</p> </li> <li>For each video port, the user will be prompted to set the specified aspect ratio on the port and confirm by pressing Enter.</li> <li>The test will retrieve the aspect ratio from the connected display device.</li> <li> <p>The retrieved aspect ratio will be compared to the expected value for each configuration.</p> </li> <li> <p>Completion and Results:</p> </li> </ul> <p>If all expected aspect ratios are verified for each port, the test will conclude and display the final result (PASS/FAIL).</p>"},{"location":"external_content/device_settings_test/docs/pages/dsDisplay/ds-display_L3_TestProcedure/#dsdisplay_test04_testverifydisplayedidbytes","title":"dsDisplay_test04_TestVerifyDisplayEdidBytes","text":"<p>Overview:</p> <p>This test case is designed for Source devices and focuses on retrieving and verifying the <code>EDID</code> bytes by connecting various pre-defined displays to each supported video port. The test parses the <code>EDID</code> bytes retrieved from the connected displays against expected values to ensure accurate identification. It uses the dsDisplay_test_MonitorDetails.yml file, which contains the details of the connected monitors for verification.</p> <p>Platform Supported:</p> <ul> <li>Source</li> </ul> <p>User Input Required:</p> <p>Yes: User input is required to manually connect the display to the specified port, with the prompt question <code>Connect Device: {display} to Port: {port} and Press Enter:</code> (This will be automated in future versions.)</p> <p>Acceptance Criteria:</p> <p>Connect each display to the supported video ports, retrieve the <code>EDID</code> bytes, and verify them against the expected <code>EDID</code> data.</p> <p>Expected Results:</p> <p>The test will retrieve and parse <code>EDID</code> bytes for each connected display. It will verify that the <code>EDID</code> information, including fields like manufacturerId and monitorName, matches the expected values for each display. The test will pass if all expected <code>EDID</code> details are retrieved and verified correctly for each display and port.</p> <p>Test Steps:</p> <ul> <li>Run the Python file <code>dsDisplay_test04_TestVerifyDisplayEdidBytes</code> with the appropriate configuration:</li> </ul> <pre><code>dsDisplay_test04_TestVerifyDisplayEdidBytes --config /host/tests/configs/example_rack_config.yml --deviceConfig /host/tests/configs/deviceConfig.yml\n</code></pre> <ul> <li> <p>The test will download the required artifacts, then copy them to the target directory.</p> </li> <li> <p>EDID Bytes Verification:</p> </li> <li>For each display, the test will prompt the user to connect the display to the specified port.</li> <li>The test will retrieve the <code>EDID</code> bytes from the connected display device.</li> <li> <p>The test will verify the retrieved <code>EDID</code> bytes against the expected details, such as manufacturer ID and monitor name, for each connected display.</p> </li> <li> <p>Completion and Results:</p> </li> </ul> <p>If all expected <code>EDID</code> bytes are verified, the test will conclude and display the final result (PASS/FAIL).</p>"},{"location":"external_content/device_settings_test/docs/pages/dsDisplay/ds-display_L3_TestProcedure/#dsdisplay_l3_runall_sourcepy","title":"dsDisplay_L3_Runall_Source.py","text":"<p>This python file runs all the tests supported by <code>source</code> devices</p> <pre><code>python dsDisplay_L3_Runall_Source.py  --config &lt;/PATH&gt;/ut/host/tests/configs/example_rack_config.yml --deviceConfig &lt;/PATH&gt;/ut/host/tests/configs/deviceConfig.yml\n</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsDisplay/ds-display_L3_TestProcedure/#dsdisplay_l3_runall_sinkpy","title":"dsDisplay_L3_Runall_Sink.py","text":"<p>This python file runs all the tests supported by <code>sink</code> devices</p> <pre><code>python dsDisplay_L3_Runall_Sink.py  --config &lt;/PATH&gt;/ut/host/tests/configs/example_rack_config.yml --deviceConfig &lt;/PATH&gt;/ut/host/tests/configs/deviceConfig.yml\n</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_High-Level_TestSpec/","title":"Device Settings Front Panel Display High Level Test Specification Documentation","text":""},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_High-Level_TestSpec/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>HAL</code>     - Hardware Abstraction layer</li> <li><code>SOC</code>     - System On a Chip</li> <li><code>FP</code>      - Front Panel</li> <li><code>FPD</code>     - Front Panel Display</li> <li><code>ds</code>      - Device Settings.</li> <li><code>LED</code>     - Light Emitting Devices</li> <li><code>dsFPD</code>   - Device Settings Front Panel Display</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_High-Level_TestSpec/#introduction","title":"Introduction","text":"<p>This document provides an overview of the High Level Test Specification requirements for the <code>dsFPD</code> module. It outlines the scope of testing, objectives, testing levels and approaches, specific test requirements, emulator requirements, control plane requirements, and expected deliverables.</p> <p>The interface of the test is available here: ds-fdp HAl Header</p> <p><code>Note: There will be no test case implemented to verify the 7-segment front panel display LEDs.</code></p>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_High-Level_TestSpec/#module-description","title":"Module Description","text":"<p>High-level overview:</p> <ul> <li><code>dsFPD</code> provides a set of APIs to control the <code>FP</code>discrete <code>LED</code>s and 7-segment <code>LED</code>s existing on a platform.</li> <li>It facilitates the communication to <code>FP</code> <code>LED</code>s, aiding in their configuration and utilization within the system. The <code>LED</code>s is controlled by the caller based on the platform requirements. Interface specification is available here: ds-fdp HAl Spec</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_High-Level_TestSpec/#testing-scope","title":"Testing Scope","text":"# Test Functionality Test Description 1 Discrete <code>LED</code> Brightness Control The test aims to set and verify the Brightness of the discrete <code>LED</code>s supported on the platform. 2 Discrete <code>LED</code> Blink Control The test aims to set and verify the blink activity of the discrete <code>LED</code>s supported on the platform 3 Discrete <code>LED</code> Color Control The test aims to set and verify the color control activities of the discrete <code>LED</code>s supported on the platform 4 Discrete Power <code>LED</code> Control The test aims to set and verify the discrete Power <code>LED</code> supported on the platform"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_High-Level_TestSpec/#discrete-led-brightness-control","title":"Discrete <code>LED</code> Brightness Control","text":"Description HAL APIs L2 L3 Source Sink Control plane requirements Iterate over supported <code>FPD</code> indicators. For each supported indicator: 1. Check the current state of the <code>FP</code>. 2. If it's OFF, set it to ON. 3. Set the brightness of the discrete <code>LED</code> within the specified range (min-max) and verify using the get function. Note: 1. For supported <code>FPD</code> indicators check profile file for Sink <code>Sink_FPD.yaml</code>(path:<code>dsFPD/SupportedFPDIndicators/[Indicator number]/Indicator_type</code>) and for Source <code>Source_FPD.yaml</code>(path:<code>dsFPD/SupportedFPDIndicators/[Indicator number]/Indicator_type</code>) 2. for Brightness range check  Sink <code>Sink_FPD.yaml</code>(path:<code>dsFPD/SupportedFPDIndicators/[Indicator number]/MAX_BRIGHTNESS and dsFPD/SupportedFPDIndicators/[Indicator number]/MIN_BRIGHTNESS</code>) and for Source <code>Source_FPD.yaml</code>(path:<code>dsFPD/SupportedFPDIndicators/[Indicator number]/MAX_BRIGHTNESS and dsFPD/SupportedFPDIndicators/[Indicator number]/MIN_BRIGHTNESS</code>) dsGetFPState(), dsSetFPState(), dsSetFPBrightness(), dsGetFPBrightness() <code>Y</code> <code>NA</code> <code>Y</code> <code>Y</code> <code>NA</code> Iterate over supported <code>FPD</code> indicators. For each supported indicator: 1. Check the current state of the <code>FP</code>. 2. If it's ON, set it to OFF. 3. Set the brightness of the discrete <code>LED</code> and check it returns <code>dsERR_OPERATION_NOT_SUPPORTED</code>.Note: For supported <code>FPD</code> indicators check profile file for Sink <code>Sink_FPD.yaml</code>(path:<code>dsFPD/SupportedFPDIndicators/[Indicator number]/Indicator_type</code>) and for Source <code>Source_FPD.yaml</code>(path:<code>dsFPD/SupportedFPDIndicators/[Indicator number]/Indicator_type</code>) dsGetFPState(), dsSetFPState(), dsSetFPBrightness() <code>Y</code> <code>NA</code> <code>Y</code> <code>Y</code> <code>NA</code> Iterate over supported <code>FPD</code> indicators. For each supported indicator: 1.Check the current state of the <code>FP</code>.2. If it's OFF, set it to ON. 3. Set the brightness of the discrete <code>LED</code> and verify brightness intensity with help of control plane.Note: 1. For supported <code>FPD</code> indicators check profile file for Sink <code>Sink_FPD.yaml</code>(path:<code>dsFPD/SupportedFPDIndicators/[Indicator number]/Indicator_type</code>) and for Source <code>Source_FPD.yaml</code>(path:<code>dsFPD/SupportedFPDIndicators/[Indicator number]/Indicator_type</code>) 2. for Brightness range check  Sink <code>Sink_FPD.yaml</code>(path:<code>dsFPD/SupportedFPDIndicators/[Indicator number]/MAX_BRIGHTNESS and dsFPD/SupportedFPDIndicators/[Indicator number]/MIN_BRIGHTNESS</code>) and for Source <code>Source_FPD.yaml</code>(path:<code>dsFPD/SupportedFPDIndicators/[Indicator number]/MAX_BRIGHTNESS and dsFPD/SupportedFPDIndicators/[Indicator number]/MIN_BRIGHTNESS</code>) dsGetFPState(), dsSetFPState(), dsSetFPBrightness() <code>NA</code> <code>Y</code> <code>Y</code> <code>Y</code> <code>Y</code>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_High-Level_TestSpec/#test-startup-requirement-discrete-led-brightness-control","title":"Test Startup Requirement-Discrete <code>LED</code> Brightness Control","text":"<p><code>NA</code></p>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_High-Level_TestSpec/#emulator-requirement-discrete-led-brightness-control","title":"Emulator Requirement-Discrete <code>LED</code> Brightness Control","text":"<p>The emulator will boot with the <code>LED</code> configurations that should include</p> <ol> <li>Number of discrete <code>LED</code>s, available</li> <li>Max and Min value of Brightness.</li> <li>Default brightness of each discrete <code>LED</code></li> </ol>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_High-Level_TestSpec/#control-plane-requirement-discrete-led-brightness-control","title":"Control Plane Requirement-Discrete <code>LED</code> Brightness Control","text":"<p>Read the brightness intensity of the <code>LED</code> when set to a different level and compare it with the previous intensity value using a <code>LED</code> detector device.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_High-Level_TestSpec/#discrete-led-blink-control","title":"Discrete <code>LED</code> blink control","text":"Description HAL APIs L2 L3 Source Sink Control plane requirements Iterate over supported <code>FPD</code> indicators. For each supported indicator: 1. Check the current state of the <code>FP</code>. 2. If it's OFF, set it to ON. 3. set the blink functionality of discrete <code>LED</code> and verify Blink interval with help of control plane.Note: For supported <code>FPD</code> indicators check profile file for Sink <code>Sink_FPD.yaml</code>(path:<code>dsFPD/SupportedFPDIndicators/[Indicator number]/Indicator_type</code>) and for Source <code>Source_FPD.yaml</code>(path:<code>dsFPD/SupportedFPDIndicators/[Indicator number]/Indicator_type</code>) dsGetFPState(), dsSetFPState(), dsSetFPBlink() <code>NA</code> <code>Y</code> <code>Y</code> <code>Y</code> <code>Y</code> Iterate over supported <code>FPD</code> indicators. For each supported indicator: 1. Check the current state of the <code>FP</code>. 2. If it's ON, set it to OFF. 3. set the blink functionality of discrete <code>LED</code> and check it returns <code>dsERR_OPERATION_NOT_SUPPORTED</code>.Note: For supported <code>FPD</code> indicators check profile file for Sink <code>Sink_FPD.yaml</code>(path:<code>dsFPD/SupportedFPDIndicators/[Indicator number]/Indicator_type</code>) and for Source <code>Source_FPD.yaml</code>(path:<code>dsFPD/SupportedFPDIndicators/[Indicator number]/Indicator_type</code>) dsGetFPState(), dsSetFPState(), dsSetFPBlink() <code>Y</code> <code>NA</code> <code>Y</code> <code>Y</code> <code>NA</code>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_High-Level_TestSpec/#test-startup-requirement-discrete-led-blink-control","title":"Test Startup Requirement-Discrete <code>LED</code> blink control","text":"<p><code>NA</code></p>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_High-Level_TestSpec/#emulator-requirement-discrete-led-blink-control","title":"Emulator Requirement-Discrete <code>LED</code> blink control","text":"<p>The emulator will boot with the <code>LED</code> configurations that should include</p> <ol> <li>Number of discrete <code>LED</code>s, available</li> </ol>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_High-Level_TestSpec/#control-plane-requirement-discrete-led-blink-control","title":"Control Plane Requirement-Discrete <code>LED</code> blink control","text":"<p>Read the Blink interval from the <code>LED</code> detector device.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_High-Level_TestSpec/#discrete-led-color-control","title":"Discrete <code>LED</code> color control","text":"Description HAL APIs L2 L3 Source Sink Control plane requirements Iterate over supported <code>FPD</code> indicators. For each supported indicator: 1. Check the current state of the <code>FP</code>. 2. If it's OFF, set it to ON. 3. Check the indicator supports multi-colored 4. set the color functionality of discrete <code>LED</code> available by setting and getting different colors supported by the discrete <code>LED</code> Note: 1. For supported <code>FPD</code> indicators check profile file for Sink <code>Sink_FPD.yaml</code>(path:<code>dsFPD/SupportedFPDIndicators/[Indicator number]/Indicator_type</code>) and for Source <code>Source_FPD.yaml</code>(path:<code>dsFPD/SupportedFPDIndicators/[Indicator number]/Indicator_type</code>) 2. for indicator color support check  Sink <code>Sink_FPD.yaml</code>(path:<code>dsFPD/SupportedFPDIndicators/[Indicator number]/DEFAULT_COLOR_MODE</code>) and for Source <code>Source_FPD.yaml</code>(path:<code>dsFPD/SupportedFPDIndicators/[Indicator number]/DEFAULT_COLOR_MODE</code>) dsGetFPState(), dsSetFPState(), dsSetFPColor(), dsGetFPColor() <code>Y</code> <code>NA</code> <code>Y</code> <code>Y</code> <code>NA</code> Iterate over supported <code>FPD</code> indicators. For each supported indicator: 1. Check the current state of the <code>FP</code>. 2. If it's ON, set it to OFF. 3. set the color functionality of discrete <code>LED</code> and check it returns <code>dsERR_OPERATION_NOT_SUPPORTED</code>.Note: For supported <code>FPD</code> indicators check profile file for Sink <code>Sink_FPD.yaml</code>(path:<code>dsFPD/SupportedFPDIndicators/[Indicator number]/Indicator_type</code>) and for Source <code>Source_FPD.yaml</code>(path:<code>dsFPD/SupportedFPDIndicators/[Indicator number]/Indicator_type</code>) dsGetFPState(), dsSetFPState(), dsSetFPColor() <code>Y</code> <code>NA</code> <code>Y</code> <code>Y</code> <code>NA</code> Iterate over supported <code>FPD</code> indicators. For each supported indicator: 1. Check the current state of the <code>FP</code>. 2. If it's ON, set it to OFF. 3. Check the indicator supports <code>single-colored</code> 4. set the color functionality of discrete <code>LED</code> and check it returns <code>dsERR_OPERATION_NOT_SUPPORTED</code>.Note: For supported <code>FPD</code> indicators check profile file for Sink <code>Sink_FPD.yaml</code>(path:<code>dsFPD/SupportedFPDIndicators/[Indicator number]/Indicator_type</code>) and for Source <code>Source_FPD.yaml</code>(path:<code>dsFPD/SupportedFPDIndicators/[Indicator number]/Indicator_type</code>) dsGetFPState(), dsSetFPState(), dsSetFPColor() <code>Y</code> <code>NA</code> <code>Y</code> <code>Y</code> <code>NA</code> Iterate over supported <code>FPD</code> indicators. For each supported indicator: 1. Check the current state of the <code>FP</code>. 2. If it's OFF, set it to ON. 3. Check the indicator supports multi-colored 4. set the color functionality of discrete <code>LED</code> available by setting and verify Blink interval with help of control plane. Note: 1. For supported <code>FPD</code> indicators check profile file for Sink <code>Sink_FPD.yaml</code>(path:<code>dsFPD/SupportedFPDIndicators/[Indicator number]/Indicator_type</code>) and for Source <code>Source_FPD.yaml</code>(path:<code>dsFPD/SupportedFPDIndicators/[Indicator number]/Indicator_type</code>) 2. for indicator color support check  Sink <code>Sink_FPD.yaml</code>(path:<code>dsFPD/SupportedFPDIndicators/[Indicator number]/DEFAULT_COLOR_MODE</code>) and for Source <code>Source_FPD.yaml</code>(path:<code>dsFPD/SupportedFPDIndicators/[Indicator number]/DEFAULT_COLOR_MODE</code>) dsGetFPState(), dsSetFPState(), dsSetFPColor() <code>NA</code> <code>Y</code> <code>Y</code> <code>Y</code> <code>Y</code>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_High-Level_TestSpec/#test-startup-requirement-discrete-led-color-control","title":"Test Startup Requirement-Discrete <code>LED</code> color control","text":"<p><code>NA</code></p>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_High-Level_TestSpec/#emulator-requirement-discrete-led-color-control","title":"Emulator Requirement-Discrete <code>LED</code> color control","text":"<p>The emulator will boot with the <code>LED</code> configurations that should include</p> <ol> <li>Number of discrete <code>LED</code>s, available</li> <li>Supported colors for each <code>LED</code></li> </ol>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_High-Level_TestSpec/#control-plane-requirement-discrete-led-color-control","title":"Control Plane Requirement-Discrete <code>LED</code> color control","text":"<p>The control panel should be able to read the color of the <code>LED</code> through the specialized devices that shall identify the <code>LED</code> color and provide the same information to the control panel.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_High-Level_TestSpec/#discrete-power-led-control","title":"Discrete Power <code>LED</code> control","text":"Description HAL APIs L2 L3 Source Sink Control plane requirements Verify the <code>LED</code> state transitions 1.Loop through all supported <code>LED</code> states. 2. For each state, set the <code>LED</code> to that state using dsFPSetLEDState(). 3. Verify the state using dsFPGetLEDState(). 4. Ensure each state transition is valid.Note: 1.For supported <code>LED</code> states check profile file for Sink <code>Sink_FPD.yaml</code>(path:<code>dsFPD/SupportedFPDIndicators/[Indicator number]/Indicator_type</code>) and for Source <code>Source_FPD.yaml</code>(path:<code>dsFPD/SupportedFPDIndicators/[Indicator number]/Indicator_type</code>) dsFPGetSupportedLEDStates(), dsFPSetLEDState(), dsFPGetLEDState() <code>Y</code> <code>NA</code> <code>Y</code> <code>Y</code> <code>NA</code> Verify the <code>LED</code> state transitions 1.Loop through all supported <code>LED</code> states. 2. For each state, set the <code>LED</code> to that state using dsFPSetLEDState(). 3. Verify the state with control plane. 4. Ensure each state transition is valid.Note: For supported <code>LED</code> states check profile file for Sink <code>Sink_FPD.yaml</code>(path:<code>dsFPD/SupportedFPDIndicators/[Indicator number]/Indicator_type</code>) and for Source <code>Source_FPD.yaml</code>(path:<code>dsFPD/SupportedFPDIndicators/[Indicator number]/Indicator_type</code>) dsFPGetSupportedLEDStates(), dsFPSetLEDState() <code>NA</code> <code>Y</code> <code>Y</code> <code>Y</code> <code>Y</code>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_High-Level_TestSpec/#test-startup-requirement-discrete-power-led-control","title":"Test Startup Requirement-Discrete Power <code>LED</code> control","text":"<p>NA</p>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_High-Level_TestSpec/#emulator-requirement-discrete-power-led-control","title":"Emulator Requirement-Discrete Power <code>LED</code> control","text":"<p>The emulator will boot with the <code>LED</code> configurations that should include</p> <ol> <li>Provide the configuration of Power <code>LED</code> states supported.</li> </ol>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_High-Level_TestSpec/#control-plane-requirement-discrete-power-led-control","title":"Control Plane Requirement-Discrete Power <code>LED</code> control","text":"<p>Due to platform-specific requirements, it may not be possible to capture the <code>LED</code> behavior in each state.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L2_Low-Level_TestSpecification/","title":"Device Setting FPD L2 Low Level Test Specification and Procedure Documentation","text":""},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L2_Low-Level_TestSpecification/#overview","title":"Overview","text":"<p>This document describes the Low level l2 Specification and Procedure Documentation for the DSFPD module.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L2_Low-Level_TestSpecification/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>HAL</code> - Hardware Abstraction Layer, may include some common components</li> <li><code>UT</code>  - Unit Test(s)</li> <li><code>OEM</code>  - Original Equipment Manufacture</li> <li><code>SoC</code>  - System on a Chip</li> <li><code>FPD</code> - Front Panel Display</li> <li><code>LED</code> - Light Emitting Diode</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L2_Low-Level_TestSpecification/#definitions","title":"Definitions","text":"<ul> <li><code>ut-core</code> - Common Testing Framework https://github.com/rdkcentral/ut-core, which wraps a open-source framework that can be expanded to the requirements for future framework.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L2_Low-Level_TestSpecification/#references","title":"References","text":"<ul> <li><code>High Level Test Specification</code> - ds-front-panel-display_High-Level_TestSpec.md</li> <li><code>HAL Interface file</code> - dsFPD Header</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L2_Low-Level_TestSpecification/#level-2-test-procedure","title":"Level 2 Test Procedure","text":"<p>The following functions are expecting to test the module operates correctly.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L2_Low-Level_TestSpecification/#test-1","title":"Test 1","text":"Title Details Function Name <code>test_l2_dsFPD_SetFPstateON_SetBrightness</code> Description Iterate over supported <code>FPD</code> indicators. For each supported indicator: 1. Check the current state of the <code>FPD</code>. 2. If it's OFF, set it to ON. 3. Set the brightness of the discrete <code>LED</code> within the specified range (min-max) and verify using the get function. Note: 1. For supported <code>FPD</code> indicators check configuration file using path <code>dsFPD/SupportedFPDIndicators/[Indicator number]/Indicator_type</code> 2. for Brightness range checking by configuration file using path:<code>dsFPD/SupportedFPDIndicators/[Indicator number]/MIN_BRIGHTNESS</code> and <code>dsFPD/SupportedFPDIndicators/[Indicator number]/MAX_BRIGHTNESS</code> Test Group 02 Test Case ID 001 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L2_Low-Level_TestSpecification/#test-procedure-test-1","title":"Test Procedure - Test 1","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the Front Panel Display (<code>FPD</code>) sub-module using <code>dsFPInit</code> None <code>dsERR_NONE</code> Should be successful 02 Iterate over the supported <code>FPD</code> indicators from configuration file and get the current state of the <code>FPD</code> using <code>dsGetFPState</code> eIndicator = list of supported FPD indicators <code>dsERR_NONE</code>, state = current state Should be successful 03 If the current state of the FP is OFF, set it to ON using <code>dsSetFPState</code> eIndicator = current indicator,  state = <code>dsFPD_STATE_ON</code> <code>dsERR_NONE</code> Should be successful 04 Set the brightness of the <code>LED</code> using <code>dsSetFPBrightness</code> eIndicator = current indicator, eBrightness = random value within minimum and maximum brightness from profile <code>dsERR_NONE</code> Should be successful 05 Verify the brightness of the <code>LED</code> using <code>dsGetFPBrightness</code> eIndicator = current indicator <code>dsERR_NONE</code>, brightness = eBrightness Should be successful 06 Terminate the Front Panel Display (<code>FPD</code>) sub-module using <code>dsFPTerm</code> None <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\n    A[Call dsFPInit API] --&gt;|Success|B{Iterate over supported &lt;br&gt;FPD indicators from profile}\n    A --&gt;|Failure|A1[Test case fail]\n    B --&gt; C[Call dsGetFPState API for each indicator]\n    C --&gt;|FP OFF|E[Call dsSetFPState API to set FP ON]\n    C --&gt;|FP ON|G[Call dsSetFPBrightness API &lt;br&gt; within min and max from profile]\n    E --&gt;|Success|G\n    G --&gt;|Success|H[Call dsGetFPBrightness API]\n    H --&gt;|Success|I[Check if brightness matches value set]\n    I --&gt;|Yes|B\n    B --&gt;|End of loop|K[Call dsFPTerm API]\n    K --&gt;|Success|L[Test case success]\n    K --&gt;|Failure|K1[Test case fail]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L2_Low-Level_TestSpecification/#test-2","title":"Test 2","text":"Title Details Function Name <code>test_l2_dsFPD_SetFPstateOFF_SetBrightness</code> Description Iterate over supported <code>FPD</code> indicators. For each supported indicator: 1. Check the current state of the <code>FPD</code>. 2. If it's ON, set it to OFF. 3. Set the brightness of the discrete <code>LED</code> and check it returns <code>dsERR_OPERATION_NOT_SUPPORTED</code>. Note: For supported <code>FPD</code> indicators check configuration file using the path:<code>dsFPD/SupportedFPDIndicators/[Indicator number]/Indicator_type</code> Test Group 02 Test Case ID 002 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L2_Low-Level_TestSpecification/#test-procedure-test-2","title":"Test Procedure - Test 2","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the Front Panel Display (FPD) sub-module using <code>dsFPInit</code> None <code>dsERR_NONE</code> Should be successful 02 Iterate over the supported <code>FPD</code> indicators from configuration file and check the current state of the <code>FPD</code> using <code>dsGetFPState</code> eIndicator = eIndicator = list of supported <code>FPD</code> indicators <code>dsERR_NONE</code>, state = current state Should be successful 03 If the state is ON, set it to OFF using <code>dsSetFPState</code> eIndicator = current indicator, state = <code>dsFPD_STATE_OFF</code> <code>dsERR_NONE</code> Should be successful 04 Set the brightness of the discrete <code>LED</code> using <code>dsSetFPBrightness</code> eIndicator = current indicator, eBrightness = random value 0-100 <code>dsERR_OPERATION_NOT_SUPPORTED</code> Should be successful 05 Terminate the Front Panel Display sub-module using <code>dsFPTerm</code> None <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\n    A[Call dsFPInit] --&gt;|Success|B{Iterate over &lt;br&gt; supported FPD &lt;br&gt; indicators}\n    A --&gt;|Failure|A1[Test case fail]\n    B --&gt; C[Call dsGetFPState]\n    C --&gt;|state is &lt;br&gt; dsFPD_STATE_ON|E[Call dsSetFPState with &lt;br&gt; dsFPD_STATE_OFF]\n    C --&gt;|state is &lt;br&gt;dsFPD_STATE_OFF|G\n    E --&gt;|Success|G[Call dsSetFPBrightness]\n    G --&gt;|dsERR_OPERATION_NOT_SUPPORTED|B\n    B --&gt;|End of loop|L[Call dsFPTerm]\n    L --&gt;|Success|M[Test case success]\n    L --&gt;|Failure|L1[Test case fail]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L2_Low-Level_TestSpecification/#test-3","title":"Test 3","text":"Title Details Function Name <code>test_l2_dsFPD_SetFPstateOFF_SetBlink</code> Description Iterate over supported <code>FPD</code> indicators. For each supported indicator: 1. Check the current state of the <code>FP</code>. 2. If it's ON, set it to OFF. 3. Set the blink functionality of discrete <code>LED</code> and check it returns <code>dsERR_OPERATION_NOT_SUPPORTED</code>. Note: For supported <code>FPD</code> indicators check configuration file using the path:<code>dsFPD/SupportedFPDIndicators/[Indicator number]/Indicator_type</code> Test Group 02 Test Case ID 003 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L2_Low-Level_TestSpecification/#test-procedure-test-3","title":"Test Procedure - Test 3","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the Front Panel Display (<code>FPD</code>) using <code>dsFPInit</code> None <code>dsERR_NONE</code> Should be successful 02 Iterate over all <code>FPD</code> indicators from profile and get the current state using <code>dsGetFPState</code> eIndicator =  list of supported <code>FPD</code> indicators <code>dsERR_NONE</code> , state = current state Should be successful 03 If the state is ON, set it to OFF using <code>dsSetFPState</code> eIndicator = current indicator, state = <code>dsFPD_STATE_OFF</code> <code>dsERR_NONE</code> Should be successful 04 Set the blink functionality of discrete <code>LED</code> using <code>dsSetFPBlink</code> eIndicator = current indicator, uBlinkDuration = 500, uBlinkIterations = 10 <code>dsERR_OPERATION_NOT_SUPPORTED</code> Should be successful 05 Terminate the <code>FPD</code> using <code>dsFPTerm</code> None <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\n    A[Call dsFPInit API] --&gt;|Success|B{Iterate over &lt;br&gt; supported FPD &lt;br&gt;indicators}\n    A --&gt;|Failure|A1[Test case fail]\n    B --&gt; C[Call dsGetFPState API]\n    C --&gt;|Success|D[Check if FP state is ON]\n    D --&gt;|State is ON|E[Call dsSetFPState API &lt;br&gt; to set it OFF]\n    D --&gt;|State is OFF|F[Call dsSetFPBlink API]\n    E --&gt;|Success|F\n    F --&gt;|Return is &lt;br&gt; dsERR_OPERATION_NOT_SUPPORTED|B\n    B --&gt;|End of loop|I[Call dsFPTerm API]\n    I --&gt;|Success|J[Test case success]\n    I --&gt;|Failure|I1[Test case fail]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L2_Low-Level_TestSpecification/#test-4","title":"Test 4","text":"Title Details Function Name <code>test_l2_dsFPD_SetFPstateON_Multi_SetColor</code> Description Iterate over supported <code>FPD</code> indicators. For each SupportedFPDIndicators: 1. Check the current state of the <code>FP</code>. 2. If it's OFF, set it to ON. 3. Check the indicator supports multi-colored 4. set the color functionality of discrete <code>LED</code> available by setting and getting different colors supported by the discrete <code>LED</code> Note: 1. For supported <code>FPD</code> indicators check configuration file using path:<code>dsFPD/SupportedFPDIndicators/[Indicator number]/Indicator_type</code> 2. for indicator color support check configuration file using the path <code>dsFPD/SupportedFPDIndicators/[Indicator number]/DEFAULT_COLOR_MODE</code>) Test Group 02 Test Case ID 004 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L2_Low-Level_TestSpecification/#test-procedure-test-4","title":"Test Procedure - Test 4","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the Front Panel Display (<code>FPD</code>) using <code>dsFPInit</code> None <code>dsERR_NONE</code> Should be successful 02 Iterate over all supported <code>FPD</code> indicators from profile eIndicator = list of supported <code>FPD</code> indicators <code>dsERR_NONE</code> Should be successful 03 Get the current state of the <code>FPD</code> indicator using <code>dsGetFPState</code> eIndicator = current indicator, state = valid buffer <code>dsERR_NONE</code>, state = current state Should be successful 04 If the state is OFF, set it to ON using <code>dsSetFPState</code> eIndicator = current indicator, state = <code>dsFPD_STATE_ON</code> <code>dsERR_NONE</code> Should be successful 05 Set the color of the <code>FPD</code> indicator that supports multi-color using <code>dsSetFPColor</code> eIndicator = current indicator, color = supported color from configuration file <code>dsERR_NONE</code> Should be successful 06 Get the color of the <code>FPD</code> indicator using <code>dsGetFPColor</code> eIndicator = current indicator, getcolor = valid buffer <code>dsERR_NONE</code>, getcolor = color Should be successful 07 Terminate the FPD using <code>dsFPTerm</code> None <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\n    A[Call dsFPInit] --&gt;|Success|B{Iterate over &lt;br&gt; the supported &lt;br&gt; FPD indicators}\n    A --&gt;|Failure|A1[Test case fail]\n    B --&gt; C[Call dsGetFPState]\n    C --&gt;|Success|D[Check if the state is OFF]\n    D --&gt;|State is OFF|E[Call dsSetFPState to set it to ON]\n    D --&gt;|State is ON|I\n    E --&gt;|Success|I[Check if the indicator &lt;br&gt; supports multi-colored]\n    I --&gt;|Multi-colored &lt;br&gt; is supported|G[Call dsSetFPColor &lt;br&gt; with supported colors]\n    I --&gt;|Multi-colored &lt;br&gt; is not supported|B\n    G --&gt;|Success|H[Call dsGetFPColor ]\n    H --&gt;|get and set matches|B\n    B --&gt;|No more indicators &lt;br&gt; to check|K[Call dsFPTerm]\n    K --&gt;|Success|L[Test case success]\n    K --&gt;|Failure|K1[Test case fail]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L2_Low-Level_TestSpecification/#test-5","title":"Test 5","text":"Title Details Function Name <code>test_l2_dsFPD_SetFPstateOFF_SetColor</code> Description Iterate over supported <code>FPD</code> indicators. For each supported indicator: 1. Check the current state of the <code>FPD</code>. 2. If it's ON, set it to OFF. 3. Set the color functionality of discrete <code>LED</code> and check it returns <code>dsERR_OPERATION_NOT_SUPPORTED</code>. Note: For supported <code>FPD</code> indicators check configuration file using the path:<code>dsFPD/SupportedFPDIndicators/[Indicator number]/Indicator_type</code> Test Group 02 Test Case ID 005 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L2_Low-Level_TestSpecification/#test-procedure-test-5","title":"Test Procedure  - Test 5","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the Front Panel Display (<code>FPD</code>) using <code>dsFPInit</code> None <code>dsERR_NONE</code> Should be successful 02 Iterate over all supported <code>FPD</code> indicators eIndicator = list of supported <code>FPD</code> indicators <code>dsERR_NONE</code> Should be successful 03 Get the current state of the <code>FPD</code> indicator using <code>dsGetFPState</code> eIndicator = current indicator, state = address of state variable <code>dsERR_NONE</code> , state = current state Should be successful 04 If the state is ON, set it to OFF using <code>dsSetFPState</code> eIndicator = current indicator, state = <code>dsFPD_STATE_OFF</code> <code>dsERR_NONE</code> Should be successful 05 Set the color functionality of the discrete <code>LED</code> using <code>dsSetFPColor</code> and check it returns <code>dsERR_OPERATION_NOT_SUPPORTED</code> eIndicator = current indicator, eColor = supported colors from configuration file <code>dsERR_OPERATION_NOT_SUPPORTED</code> Should be successful 06 Terminate the <code>FPD</code> using <code>dsFPTerm</code> None <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\n    A[Call dsFPInit API] --&gt;|Success|B{Iterate over supported &lt;br&gt; FPD indicators}\n    A --&gt;|Failure|A1[Test case fail]\n    B --&gt; C[Call dsGetFPState API]\n    C --&gt;|State is ON|E[Call dsSetFPState API &lt;br&gt; to set it OFF]\n    C --&gt;|State is OFF|F[Call dsSetFPColor API &lt;br&gt; with supported colors]\n    E --&gt;|Success|F\n    F --&gt;|Return is &lt;br&gt;dsERR_OPERATION_NOT_SUPPORTED|B\n    B --&gt; I[Call dsFPTerm API]\n    I --&gt;|Success|J[Test case success]\n    I --&gt;|Failure|I1[Test case fail]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L2_Low-Level_TestSpecification/#test-6","title":"Test 6","text":"Title Details Function Name <code>test_l2_dsFPD_SetFPstateON_Single_SetColor</code> Description Iterate over supported <code>FPD</code> indicators. For each supported indicator: 1. Check the current state of the <code>FPD</code>. 2. If it's ON, set it to OFF. 3. Check the indicator supports <code>single-colored</code> 4. set the color functionality of discrete <code>LED</code> and check it returns <code>dsERR_OPERATION_NOT_SUPPORTED</code>. Note: For supported <code>FPD</code> indicators check configuration file using the path:<code>dsFPD/SupportedFPDIndicators/[Indicator number]/Indicator_type</code> Test Group 02 Test Case ID 006 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L2_Low-Level_TestSpecification/#test-procedure-test-6","title":"Test Procedure  - Test 6","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the Front Panel Display (<code>FPD</code>) using <code>dsFPInit</code> None <code>dsERR_NONE</code> Should be successful 02 Iterate over all <code>FPD</code> indicators and check if they are supported eIndicator = list of supported <code>FPD</code> indicators <code>dsERR_NONE</code> Should be successful 03 Get the current state of the <code>FPD</code> indicator using <code>dsGetFPState</code> eIndicator = current indicator, state = valid buffer <code>dsERR_NONE</code>, state = current state Should be successful 04 If the state is OFF, set it to ON using <code>dsSetFPState</code> eIndicator = current indicator, state = <code>dsFPD_STATE_ON</code> <code>dsERR_NONE</code> Should be successful 05 Set the color of the <code>FPD</code> indicator that supports single-color using <code>dsSetFPColor</code> eIndicator = current indicator, eColor = valid color <code>dsERR_OPERATION_NOT_SUPPORTED</code> Should be successful 06 Terminate the FPD using <code>dsFPTerm</code> None <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\n    A[Call dsFPInit API] --&gt;|Success|B{Iterate over supported &lt;br&gt; FPD indicators}\n    A --&gt;|Failure|A1[Test case fail]\n    B --&gt; C[Call dsGetFPState API]\n    C --&gt;|State is OFF|E[Call dsSetFPState API &lt;br&gt; to set it ON]\n    C --&gt;|State is ON|F\n    E --&gt;|Success|F[Check if indicator &lt;br&gt; supports single-color]\n    F --&gt;|Supports single-colored|G[Call dsSetFPColor API &lt;br&gt; with supported color]\n    F --&gt;|Doesn't support &lt;br&gt; single-color|B\n    G --&gt;|Returns &lt;br&gt; dsERR_OPERATION_NOT_SUPPORTED|B\n    B --&gt;|End of loop|I[Call dsFPTerm API]\n    I --&gt;|Success|J[Test case success]\n    I --&gt;|Failure|I1[Test case fail]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L2_Low-Level_TestSpecification/#test-7","title":"Test 7","text":"Title Details Function Name <code>test_l2_dsFPD_VerifyLEDStateTransitions</code> Description Verify the <code>LED</code> state transitions 1.Loop through all supported <code>LED</code> states. 2. For each state, set the <code>LED</code> to that state using <code>dsFPSetLEDState</code>. 3. Verify the state using <code>dsFPGetLEDState</code>. 4. Ensure each state transition is valid. Test Group 02 Test Case ID 007 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L2_Low-Level_TestSpecification/#test-procedure-test-7","title":"Test Procedure - Test 7","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the device using <code>dsFPInit</code> None <code>dsERR_NONE</code> Should be successful 02 Loop through all supported <code>LED</code> states and get the supported <code>LED</code> states using <code>dsFPGetSupportedLEDStates</code> supportedLEDStates = valid buffer <code>dsERR_NONE</code>, supportedLEDStates = value from configuration file Should be successful 03 For each state, set the <code>LED</code> to that state using <code>dsFPSetLEDState</code> setState = current LedState <code>dsERR_NONE</code> Should be successful 04 Verify the state using <code>dsFPGetLEDState</code> currentState = valid buffer <code>dsERR_NONE</code>, currentState = setState Should be successful 05 After looping through all states, terminate the device using <code>dsFPTerm</code> None <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\nA[Call dsFPInit] --&gt;|Success|C[Call dsFPGetSupportedLEDStates]\nA --&gt;|Failure|A1[Test case fail]\nC --&gt;|Success|D{Loop through all &lt;br&gt; supported LED states}\nC --&gt;|Failure|C1[Test case fail]\nD --&gt; E[Call dsFPSetLEDState &lt;br&gt; with current ledstate]\nE --&gt;|Success|G[Call dsFPGetLEDState]\nG --&gt;|Success|D\nD -- End of loop--&gt; I[Call dsFPTerm]\nI --&gt;|Success|J[Test case success]\nI --&gt;|Failure|I1[Test case fail]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L3_Low-Level_TestSpecification/","title":"Device Settings Front Panel Display L3 Low Level Test Specification and Procedure Documentation","text":""},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L3_Low-Level_TestSpecification/#overview","title":"Overview","text":"<p>This document describes the L3 Low Level Test Specification and Procedure Documentation for the Device Settings Front Panel Display module.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L3_Low-Level_TestSpecification/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>HAL</code> - Hardware Abstraction Layer, may include some common components</li> <li><code>UT</code>  - Unit Test(s)</li> <li><code>OEM</code> - Original Equipment Manufacture</li> <li><code>SoC</code> - System on a Chip</li> <li><code>LED</code> - Light Emitting Diode</li> <li><code>FPD</code> - Front Panel Display</li> <li><code>Y</code>   - yes supported</li> <li><code>NA</code>  - Not Supported</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L3_Low-Level_TestSpecification/#references","title":"References","text":"<ul> <li><code>High Level Test Specification</code> - dsFrontPanelDevice High Level TestSpec</li> <li><code>Interface header [4.0.0]</code> - dsFPD HAL header</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L3_Low-Level_TestSpecification/#level-3-test-cases-high-level-overview","title":"Level 3 Test Cases High Level Overview","text":"# Test-case Description HAL APIs Source Sink 1 Verify LED can be set On and OFF Verify all the supported LED on the DUT can be powered on or off. The User to vaidate the same reflected in DUT. <code>dsSetFPState()</code> <code>Y</code> <code>Y</code> 2 Check Brightness Control Verify the brightness control for all the supported LED on the DUT by changing the brightness Settings. The User to vaidate the same reflected in DUT. <code>dsSetFPBrightness()</code> <code>Y</code> <code>Y</code> 3 Check LED Blink funciton Verify all the supported LED on the DUT can be set with supported Blink rates. The User to vaidate the same reflected in DUT. <code>dsSetFPBlink()</code> <code>Y</code> <code>Y</code> 4 Verify LED Color support Verify all the supported LED on the DUT can be set to supported colors. The User to vaidate the same reflected in DUT. <code>dsSetFPColor()</code> <code>Y</code> <code>Y</code> 5 Verify All the Supported State pattern of LED Verify the Front Panel LED can all the supported states on the DUT. The User to vaidate the same reflected in DUT. <code>dsFPSetLEDState()</code> <code>Y</code> <code>Y</code>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L3_Low-Level_TestSpecification/#level-3-python-test-cases-high-level-overview","title":"Level 3 Python Test Cases High Level Overview","text":"<p>The class diagram below illustrates the flow of dsAudio L3 Python test cases:</p> <pre><code>---\ntitle: dsFPD - Python Class Flow\n---\nclassDiagram\n    testControl &lt;|-- ut_raft : inherits\n    class ut_raft{\n    }\n    ut_raft &lt;|-- L3_TestClasses : inherits\n    L3_TestClasses ..&gt; dsFPD : uses\n    note for testControl \"uses rackConfig.yaml and deviceConfig.yaml\"\n    note for dsFPD \"uses platformProfile.yaml\"\n    note for L3_TestClasses \"uses testSetupConfig.yaml\"\n    note for ut_raft \"suite Navigator uses testSuite.yaml\"</code></pre> <ul> <li>testControl</li> <li>Test Control Module for running rack Testing. This module configures the <code>DUT</code> based on the rack configuration file provided to the test.</li> <li>This class is defined in <code>RAFT</code> framework. For more details refer RAFT</li> <li>ut_raft</li> <li>Python based testing framework for writing engineering tests.</li> <li>It provides common functionalities like menu navigation, configuration reader, reading user response etc.</li> <li>For more details ut-raft.</li> <li>dsFPD</li> <li>This is test helper class which communicates with the <code>L3</code> C/C++ test running on the <code>DUT</code> through menu</li> <li>L3_TestClasses</li> <li>These are the L3 test case classes</li> <li>Each class covers the each test use-case defined in L3 Test use-cases table</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L3_Low-Level_TestSpecification/#yaml-file-inputs","title":"YAML File Inputs","text":"<ul> <li>rackConfig.yaml</li> <li>Identifies the rack configuration and platform used</li> <li>References platform-specific config from <code>deviceConfig.yaml</code></li> <li> <p>For more details refer RAFT and example_rack_config.yml</p> </li> <li> <p>deviceConfig.yaml</p> </li> <li>Specifies overall configuration for the platform</li> <li>Can be overridden by:<ul> <li>Changing locally .yaml file directory</li> <li>Using --deviceConfig command line switch</li> </ul> </li> <li> <p>For more details refer RAFT and example_device_config.yml</p> </li> <li> <p>componentProfile.yaml/platformProfile.yaml</p> </li> <li>Contains component-specific configurations</li> <li>Contains platform wide configuration broken down into separate components</li> <li> <p>Example configuration file dsFPD_Settings</p> </li> <li> <p>testSetupConfig.yaml</p> </li> <li>This configuration file contains the list of requirements for tests to execute. Eg: Copying the streams, setting environment variables etc.</li> <li> <p>Example configuration file dsFPD_L3_testSetup.yml</p> </li> <li> <p>testConfig.yaml</p> </li> <li>This configuration file contains the list of menu items for C/C++ L3 test running on <code>DUT</code></li> <li>Example configuration file dsFPD_testConfig.yml</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L3_TestProcedure/","title":"dsFPD HAL L3 Python Test Procedure","text":""},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L3_TestProcedure/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>HAL</code>    - Hardware Abstraction Layer</li> <li><code>L3</code>     - Level 3 Testing</li> <li><code>FPD</code>    - Front Panel Display</li> <li><code>DUT</code>    - Device Under Test</li> <li><code>RAFT</code>   - Rapid Automation Framework for Testing</li> <li><code>YAML</code>   - YAML Ain't Markup Language</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L3_TestProcedure/#setting-up-test-environment","title":"Setting Up Test Environment","text":"<p>To execute <code>HAL</code> <code>L3</code> Python test cases, need a Python environment. Follow these steps mentioned in HPK Public Documentation</p>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L3_TestProcedure/#update-configuration-files","title":"Update Configuration Files","text":""},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L3_TestProcedure/#rack-configuration-file","title":"Rack Configuration File","text":"<p>Example Rack configuration File: example_rack_config.yml</p> <p>For more details refer RAFT and example_rack_config.yml</p> <p>In this file, update the configuration to define the console sessions for the <code>DUT</code> and the outbound settings:</p> Console Session Description default Downloads the artifacts required for test cases ssh_hal_test Executes the <code>HAL</code> binary for the test case <pre><code>rackConfig:\n  - dut:\n      ip: \"XXX.XXX.XXX.XXX\"  # IP Address of the device\n      description: \"stb device under test\"\n      platform: \"stb\"\n      consoles:\n        - default:\n            type: \"ssh\"\n            port: 10022\n            username: \"root\"\n            ip: \"XXX.XXX.XXX\" # IP address of the device\n            password: ' '\n        - ssh_hal_test:\n            type: \"ssh\"\n            port: 10022\n            username: \"root\"\n            ip: \"XXX.XXX.XXX\" # IP address of the device\n            password: ' '\n      outbound:\n        download_url: \"tftp://tftp-server.com/rack1/slot1/\"    # Download location for the CPE device\n        upload_url: \"sftp://server-address/home/workspace/tftp/rack1/slot1/\" # Upload location\n        upload_url_base_dir: \"sftp://server-address/home/workspace/tftp/rack1/slot1\"\n        httpProxy:   # Local proxy if required\n        workspaceDirectory: './logs/workspace'   # Local working directory\n</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L3_TestProcedure/#device-configuration-file","title":"Device Configuration File","text":"<p>Example Device configuration File: deviceConfig.yml</p> <p>For more details refer RAFT and example_device_config.yml</p> <p>Update the target directory where <code>HAL</code> binaries will be copied into the device. Also, map the profile to the source/sink settings <code>YAML</code> file path.</p> <p>Ensure the platform should match with the <code>DUT</code> platform in Rack Configuration</p> <pre><code>deviceConfig:\n  cpe1:\n    platform: \"stb\"    # Must match the platform in example_rack_config.yml\n    model: \"uk\"\n    target_directory: \"/tmp\"  # Path where HAL binaries are copied in device\n    test:\n      profile: \"../../../../profiles/sink/Sink_FPD.yaml\"\n</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L3_TestProcedure/#test-setup-configuration-file","title":"Test Setup Configuration File","text":"<p>Example Test Setup configuration File: dsFPD_L3_testSetup.yml</p> <p>Update the artifact paths from which the binaries should be copied to the device.</p> <p>Set the execution paths for each test case.</p> <pre><code>dsFPD:\n  description: \"dsFPD Device Settings test setup\"\n  assets:\n    device:\n      defaults: &amp;defaults\n        execute:\n      test01_EnableDisableAndVerifyLEDIndicators:\n        &lt;&lt;: *defaults\n      test02_SetVerifyLEDIndicatorsBrightness:\n        &lt;&lt;: *defaults\n      test03_SetVerifyLEDIndicatorsBlink:\n        &lt;&lt;: *defaults\n      test04_SetVerifyLEDIndicatorsColor:\n        &lt;&lt;: *defaults\n      test05_SetVerifyFPPattern:\n        &lt;&lt;: *defaults\n</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L3_TestProcedure/#test-suite-configuration","title":"Test Suite Configuration","text":"<p>Example Test Setup configuration File: dsFPD_testConfig.yml</p> <p>Update the execute command according to the device path where <code>HAL</code> binaries are copied.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L3_TestProcedure/#run-test-cases","title":"Run Test Cases","text":"<p>Once the environment is set up, you can execute the test cases with the following command</p> <pre><code>python &lt;TestCaseName.py&gt; --config &lt;/PATH&gt;/ut/host/tests/configs/example_rack_config.yml --deviceConfig &lt;/PATH&gt;/ut/host/tests/configs/deviceConfig.yml\n</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L3_TestProcedure/#test-cases","title":"Test Cases","text":""},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L3_TestProcedure/#dsfpd_test01_enabledisableandverifyledindicatorspy","title":"dsFPD_test01_EnableDisableAndVerifyLEDIndicators.py","text":""},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L3_TestProcedure/#overview","title":"Overview","text":"<p>This test helps to verify if the Led indicators can be switched ON and OFF using the HAL API's</p>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L3_TestProcedure/#platform-support-test01","title":"Platform Support - test01","text":"<ul> <li>Source</li> <li>Sink</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L3_TestProcedure/#user-input-required-test01","title":"User Input Required - test01","text":"<p>Yes: User interaction is necessary to confirm front panel LED status (This will be automated later).</p>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L3_TestProcedure/#acceptance-criteria-test01","title":"Acceptance Criteria - test01","text":"<p>Set supported Front panel LED State to ON and OFF and verify.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L3_TestProcedure/#expected-results-test01","title":"Expected Results - test01","text":"<p>The test enables the supported front panel LED, and subsequently disabled the LED</p> <p>Success Criteria</p> <ul> <li>User should see the supported LED turned to ON State</li> <li>User should see the supported LED turned to OFF state.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L3_TestProcedure/#test-steps-test01","title":"Test Steps - test01","text":"<ul> <li> <p>Initiate the Test:</p> </li> <li> <p>Select and execute the Python file: <code>dsFPD_test01_EnableDisableAndVerifyLEDIndicators.py</code></p> </li> <li> <p>The test will automatically download all required artifacts, copying them to the designated target directory before commencing execution.</p> </li> <li> <p>LED state Verification:</p> <p>The test will enable LED and prompt the user with the following:</p> </li> <li> <p>Question: \"Is Indicator state dsFPD_STATE_ON ? (Y/N):? (Y/N)\"</p> </li> <li>Press Y if specified LED indicator is ON  (this will mark the step as PASS).</li> <li> <p>Press N if specified LED indicator is OFF (this will mark the step as FAIL).</p> </li> <li> <p>LED status confirmation (LED indicator Disabled):</p> </li> </ul> <p>After confirming LED state, the test will disable the LED indicator and prompt the user again:</p> <ul> <li>Question: \"Is Indicator state dsFPD_STATE_OFF ? (Y/N)\"</li> <li>Press Y if specified LED indicator is OFF (this will mark the step as PASS).</li> <li> <p>Press N if specified LED indicator is ON  (this will mark the step as FAIL).</p> </li> <li> <p>Repeat for All supported LED indicators:</p> </li> </ul> <p>The test will iterate through all supported Indicators, enabling/disabling each one and collecting user feedback accordingly.</p> <ul> <li>Test Conclusion:</li> </ul> <p>Upon receiving user responses for all indicators, the test will conclude and present a final result: PASS or FAIL based on the user inputs throughout the test execution.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L3_TestProcedure/#dsfpd_test02_setverifyledindicatorsbrightnesspy","title":"dsFPD_test02_SetVerifyLEDIndicatorsBrightness.py","text":""},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L3_TestProcedure/#overview_1","title":"Overview","text":"<p>This test helps to verify if the Led indicators can be set with specified brightness.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L3_TestProcedure/#platform-support-test02","title":"Platform Support - test02","text":"<ul> <li>Source</li> <li>Sink</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L3_TestProcedure/#user-input-required-test02","title":"User Input Required - test02","text":"<p>Yes: User interaction is necessary to confirm front panel LED status and Brightness (This will be automated later).</p>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L3_TestProcedure/#acceptance-criteria-test02","title":"Acceptance Criteria - test02","text":"<p>Set supported Front panel LED can be set with different brightness, 0%, 50% and 100%</p>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L3_TestProcedure/#expected-results-test02","title":"Expected Results - test02","text":"<p>The test enables the supported front panel LED, sets brightness value to 0, 50 and 100, subsequently disables the LED indicator.</p> <p>Success Criteria</p> <ul> <li>User should see the supported LED turned to ON State</li> <li>User should see the supported LED glowing in 0% brightness</li> <li>User should see the supported LED glowing in 50% brightness</li> <li>User should see the supported LED glowing in 100% brightness</li> <li>User should see the supported LED turned to OFF state.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L3_TestProcedure/#test-steps-test02","title":"Test Steps - test02","text":"<ul> <li> <p>Initiate the Test:</p> </li> <li> <p>Select and execute the Python file: <code>dsFPD_test02_SetVerifyLEDIndicatorsBrightness.py</code></p> </li> <li> <p>The test will automatically download all required artifacts, copying them to the designated target directory before commencing execution.</p> </li> <li> <p>LED state Verification:</p> <p>The test will enable LED and prompt the user with the following:</p> </li> <li> <p>Question: \"Is Indicator state dsFPD_STATE_ON ? (Y/N):? (Y/N)\"</p> </li> <li>Press Y if specified LED indicator is ON  (this will mark the step as PASS).</li> <li> <p>Press N if specified LED indicator is OFF (this will mark the step as FAIL).</p> </li> <li> <p>LED 0% brightness Verification:</p> <p>The test will set LED brightness to 0% and prompt the user with the following:</p> </li> <li> <p>Question: \"Is Indicator brightness 0% ? (Y/N):? (Y/N)\"</p> </li> <li>Press Y if specified LED indicator brightness is 0%  (this will mark the step as PASS).</li> <li> <p>Press N if specified LED indicator brightness is not 0% (this will mark the step as FAIL).</p> </li> <li> <p>LED 50% brightness Verification:</p> <p>The test will set LED brightness to 50% and prompt the user with the following:</p> </li> <li> <p>Question: \"Is Indicator brightness 50% ? (Y/N):? (Y/N)\"</p> </li> <li>Press Y if specified LED indicator brightness is 50%  (this will mark the step as PASS).</li> <li> <p>Press N if specified LED indicator brightness is not 50% (this will mark the step as FAIL).</p> </li> <li> <p>LED 100% brightness Verification:</p> <p>The test will set LED brightness to 100% and prompt the user with the following:</p> </li> <li> <p>Question: \"Is Indicator brightness 100% ? (Y/N):? (Y/N)\"</p> </li> <li>Press Y if specified LED indicator brightness is 100%  (this will mark the step as PASS).</li> <li> <p>Press N if specified LED indicator brightness is not 100% (this will mark the step as FAIL).</p> </li> <li> <p>LED status confirmation (LED indicator Disabled):</p> </li> </ul> <p>After confirming LED state, the test will disable the LED indicator and prompt the user again:</p> <ul> <li>Question: \"Is Indicator state dsFPD_STATE_OFF ? (Y/N)\"</li> <li>Press Y if specified LED indicator is OFF (this will mark the step as PASS).</li> <li> <p>Press N if specified LED indicator is ON  (this will mark the step as FAIL).</p> </li> <li> <p>Repeat for All supported LED indicators:</p> </li> </ul> <p>The test will iterate through all supported Indicators, enabling/disabling and setting brightness to each one and collecting user feedback accordingly.</p> <ul> <li>Test Conclusion:</li> </ul> <p>Upon receiving user responses for all indicators, the test will conclude and present a final result: PASS or FAIL based on the user inputs throughout the test execution.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L3_TestProcedure/#dsfpd_test03_setverifyledindicatorsblinkpy","title":"dsFPD_test03_SetVerifyLEDIndicatorsBlink.py","text":""},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L3_TestProcedure/#overview_2","title":"Overview","text":"<p>This test helps to verify if the Led indicators can blink with specified parameter.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L3_TestProcedure/#platform-support-test03","title":"Platform Support - test03","text":"<ul> <li>Source</li> <li>Sink</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L3_TestProcedure/#user-input-required-test03","title":"User Input Required - test03","text":"<p>Yes: User interaction is necessary to confirm front panel LED status and blinking (This will be automated later).</p>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L3_TestProcedure/#acceptance-criteria-test03","title":"Acceptance Criteria - test03","text":"<p>Set supported Front panel LED with blink duration of 1000 ms and 5 iterations.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L3_TestProcedure/#expected-results-test02_1","title":"Expected Results - test02","text":"<p>The test enables the supported front panel LED, sets LED to blink with 1000ms duration and 5 iterations , subsequently disables the LED indicator.</p> <p>Success Criteria</p> <ul> <li>User should see the supported LED turned to ON State</li> <li>User should see the supported LED blinking with 1000ms duration and 5 iterations.</li> <li>User should see the supported LED turned to OFF state.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L3_TestProcedure/#test-steps-test03","title":"Test Steps - test03","text":"<ul> <li> <p>Initiate the Test:</p> </li> <li> <p>Select and execute the Python file: <code>dsFPD_test03_SetVerifyLEDIndicatorsBlink.py</code></p> </li> <li> <p>The test will automatically download all required artifacts, copying them to the designated target directory before commencing execution.</p> </li> <li> <p>LED state Verification:</p> <p>The test will enable LED and prompt the user with the following:</p> </li> <li> <p>Question: \"Is Indicator state dsFPD_STATE_ON ? (Y/N):? (Y/N)\"</p> </li> <li>Press Y if specified LED indicator is ON  (this will mark the step as PASS).</li> <li> <p>Press N if specified LED indicator is OFF (this will mark the step as FAIL).</p> </li> <li> <p>LED blink Verification:</p> <p>The test will set LED to blink with duration of 1000ms for 5 times and prompt the user with the following:</p> </li> <li> <p>Question: \"Is indicator blinking 5 times with 1 sec ? (Y/N)\"</p> </li> <li>Press Y if specified LED indicator blink with the duration specified. (this will mark the step as PASS).</li> <li> <p>Press N if specified LED indicator did not blink with duration specified. (this will mark the step as FAIL).</p> </li> <li> <p>LED status confirmation (LED indicator Disabled):</p> </li> </ul> <p>After confirming LED state, the test will disable the LED indicator and prompt the user again:</p> <ul> <li>Question: \"Is Indicator state dsFPD_STATE_OFF ? (Y/N)\"</li> <li>Press Y if specified LED indicator is OFF (this will mark the step as PASS).</li> <li> <p>Press N if specified LED indicator is ON  (this will mark the step as FAIL).</p> </li> <li> <p>Repeat for All supported LED indicators:</p> </li> </ul> <p>The test will iterate through all supported Indicators, enabling/disabling and setting blink parameter to each one and collecting user feedback accordingly.</p> <ul> <li>Test Conclusion:</li> </ul> <p>Upon receiving user responses for all indicators, the test will conclude and present a final result: PASS or FAIL based on the user inputs throughout the test execution.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L3_TestProcedure/#dsfpd_test04_setverifyledindicatorscolorpy","title":"dsFPD_test04_SetVerifyLEDIndicatorsColor.py","text":""},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L3_TestProcedure/#overview_3","title":"Overview","text":"<p>This test helps to verify if the Led indicators can set with supported colors.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L3_TestProcedure/#platform-support-test04","title":"Platform Support - test04","text":"<ul> <li>Source</li> <li>Sink</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L3_TestProcedure/#user-input-required-test04","title":"User Input Required - test04","text":"<p>Yes: User interaction is necessary to confirm front panel LED status and blinking (This will be automated later).</p>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L3_TestProcedure/#acceptance-criteria-test04","title":"Acceptance Criteria - test04","text":"<p>Set supported Front panel LED set with supported colors.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L3_TestProcedure/#expected-results-test04","title":"Expected Results - test04","text":"<p>The test enables the supported front panel LED, sets LED to its supported colors , subsequently disables the LED indicator.</p> <p>Success Criteria</p> <ul> <li>User should see the supported LED turned to ON State</li> <li>User should see the supported LED set with supported color</li> <li>User should see the supported LED turned to OFF state.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L3_TestProcedure/#test-steps-test04","title":"Test Steps - test04","text":"<ul> <li> <p>Initiate the Test:</p> </li> <li> <p>Select and execute the Python file: <code>dsFPD_test04_SetVerifyLEDIndicatorsColor.py</code></p> </li> <li> <p>The test will automatically download all required artifacts, copying them to the designated target directory before commencing execution.</p> </li> <li> <p>LED state Verification:</p> <p>The test will enable LED and prompt the user with the following:</p> </li> <li> <p>Question: \"Is Indicator state dsFPD_STATE_ON ? (Y/N):? (Y/N)\"</p> </li> <li>Press Y if specified LED indicator is ON  (this will mark the step as PASS).</li> <li> <p>Press N if specified LED indicator is OFF (this will mark the step as FAIL).</p> </li> <li> <p>LED color Verification:</p> <p>The test will set LED to supported color and prompt the user with the following:</p> </li> <li> <p>Question: \"Is indicator color ? (Y/N)\" <li>Press Y if specified LED indicator set with specified color. (this will mark the step as PASS).</li> <li> <p>Press N if specified LED indicator is not set with specified color. (this will mark the step as FAIL).</p> </li> <li> <p>Repeat for All supported color for the LED indicators:</p> </li> <p>The test will iterate through all supported colors of the indicator and collecting user feedback accordingly.</p> <ul> <li>LED status confirmation (LED indicator Disabled):</li> </ul> <p>After confirming LED state, the test will disable the LED indicator and prompt the user again:</p> <ul> <li>Question: \"Is Indicator state dsFPD_STATE_OFF ? (Y/N)\"</li> <li>Press Y if specified LED indicator is OFF (this will mark the step as PASS).</li> <li> <p>Press N if specified LED indicator is ON  (this will mark the step as FAIL).</p> </li> <li> <p>Repeat for All supported LED indicators:</p> </li> </ul> <p>The test will iterate through all supported Indicators and collecting user feedback accordingly.</p> <ul> <li>Test Conclusion:</li> </ul> <p>Upon receiving user responses for all indicators, the test will conclude and present a final result: PASS or FAIL based on the user inputs throughout the test execution.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L3_TestProcedure/#dsfpd_test05_setverifyfppatternpy","title":"dsFPD_test05_SetVerifyFPPattern.py","text":""},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L3_TestProcedure/#overview_4","title":"Overview","text":"<p>This test helps to verify if the front panel can set with different patterns.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L3_TestProcedure/#platform-support-test05","title":"Platform Support - test05","text":"<ul> <li>Source</li> <li>Sink</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L3_TestProcedure/#user-input-required-test05","title":"User Input Required - test05","text":"<p>Yes: User interaction is necessary to confirm front panel Patterns is set (This will be automated later).</p>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L3_TestProcedure/#acceptance-criteria-test05","title":"Acceptance Criteria - test05","text":"<p>Set supported Front panel pattern</p>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L3_TestProcedure/#expected-results-test05","title":"Expected Results - test05","text":"<p>The test sets all the supported Front panel patterns and verifies.</p> <p>Success Criteria</p> <ul> <li>User should see all the supported front panel patterns one buy one.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L3_TestProcedure/#test-steps-test05","title":"Test Steps - test05","text":"<ul> <li> <p>Initiate the Test:</p> </li> <li> <p>Select and execute the Python file: <code>dsFPD_test05_SetVerifyFPPattern.py</code></p> </li> <li> <p>The test will automatically download all required artifacts, copying them to the designated target directory before commencing execution.</p> </li> <li> <p>Front panel pattern verification:</p> <p>The test will set the pattern and prompt the user with the following:</p> </li> <li> <p>Question: \"Is Front panel shows  ? (Y/N):? (Y/N)\" <li>Press Y if specified pattern is shown  (this will mark the step as PASS).</li> <li> <p>Press N if specified pattern is not shown (this will mark the step as FAIL).</p> </li> <li> <p>Repeat for All supported patterns:</p> </li> <p>The test will iterate through all supported patterns of the device collecting user feedback accordingly.</p> <ul> <li>Test Conclusion:</li> </ul> <p>Upon receiving user responses for all indicators, the test will conclude and present a final result: PASS or FAIL based on the user inputs throughout the test execution.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsFPD/ds-front-panel-display_L3_TestProcedure/#dsfpd_l3_runallpy","title":"dsFPD_L3_Runall.py","text":"<p>This python file runs all the tests supported</p> <pre><code>python dsFPD_L3_Runall.py --config &lt;/PATH&gt;/ut/host/tests/configs/example_rack_config.yml --deviceConfig &lt;/PATH&gt;/ut/host/tests/configs/deviceConfig.yml\n</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-Hdmi-In_L3_Low-Level_TestSpecification/","title":"Device Settings HdmiIn L3 Low Level Test Specification and Procedure Documentation","text":""},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-Hdmi-In_L3_Low-Level_TestSpecification/#overview","title":"Overview","text":"<p>This document describes the L3 Low Level Test Specification and Procedure Documentation for the Device Settings HdmiIn module.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-Hdmi-In_L3_Low-Level_TestSpecification/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>HAL</code> - Hardware Abstraction Layer, may include some common components</li> <li><code>UT</code>  - Unit Test(s)</li> <li><code>OEM</code> - Original Equipment Manufacture</li> <li><code>SoC</code> - System on a Chip</li> <li><code>HDMI</code>- High-Definition Multimedia Interface</li> <li><code>HDR</code> - High Dynamic Range</li> <li><code>HLG</code> - Hybrid Log-Gamma</li> <li><code>SDR</code> - Standard Dynamic Range</li> <li><code>EDID</code>- Extended Display Identification Data</li> <li><code>ALLM</code>- Auto Low Latency Mode</li> <li><code>AVI</code> - Audio Video Interleave</li> <li><code>SPD</code> - Source Product Descriptor</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-Hdmi-In_L3_Low-Level_TestSpecification/#references","title":"References","text":"<ul> <li><code>High Level Test Specification</code> - dsHdmiIn High Level TestSpec</li> <li><code>Interface header</code> - dsHdmiIn HAL header</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-Hdmi-In_L3_Low-Level_TestSpecification/#level-3-test-cases-high-level-overview","title":"Level 3 Test Cases High Level Overview","text":"# Streams Name Streams description 1 vts_HDR10_stream Format: HDR10,Resolution: 3840 x 2160 (4K UHD),Color Depth: 10-bit,Color Space: Rec. 2020 2 vts_SDR_stream Format: SDR,Resolution: 1920 x 1080 3 vts_HLG_stream Format: HLG,Resolution: 3840 x 2160 or It can also be used with 1080p and 720p resolutions. 4 vts_DolbyVision_stream Format: Dolby Vision,Resolution: 3840 x 2160 (4K UHD),Color Depth: 10/12-bit,Color Space: Rec. 2020format and dynamic metadata. 5 vts_HDR10plus_stream Format: HDR10,Resolution: 3840 x 2160 (4K UHD),Color Depth: 10-bit,Color Space: Rec. 2020 and dynamic metadata capabilities. <p>Each test case need to verify with the each HdmiIn port. Below are top test use-case for the HdmiIn port.</p> # Test-case Description Focus APIs Source Sink 1 Verify the HdmiIn Connect status with callback Connect or Disconnect HdmiInput device on each of the HdmiInput ports and check the hdmiInConnectCB callback is triggered <code>dsHdmiInRegisterConnectCB()</code> <code>Y</code> <code>Y</code> 2 Verify the HdmiIn Signal change with callback Select the HdmiInput port and check the callback is triggered when the change in signal status occurs(i.e like no signal , unstable signal, stable signal <code>dsHdmiInRegisterSignalChangeCB()</code> <code>NA</code> <code>Y</code> 3 Verify the HdmiIn Status change with callback Select the HdmiInput port and check the callback is triggered when the status change occurs(i.e like isPresented, activeport) and  check the callbacks is triggered <code>dsHdmiInRegisterStatusChangeCB()</code> <code>NA</code> <code>Y</code> 4 Verify the HdmiIn Video Mode update  with callback Select the Hdminput device with different resolutions , aspect ratio  and check the callbacks is triggered and outputs the same resolution , aspect ratio <code>dsHdmiInRegisterVideoModeUpdateCB()</code> <code>NA</code> <code>Y</code> 5 Verify the HdmiIn <code>ALLM</code> change  with callback Change the <code>ALLM</code> option to TRUE/FALSE after connecting game controller on 4k supported panel and check the callbacks is triggered when the <code>ALLM</code> status change occurs <code>dsHdmiInRegisterAllmChangeCB()</code> <code>NA</code> <code>Y</code> 6 Verify the  HdmiIn Audio Video lateny with callback Select the Hdminput device with available resolutions (like <code>HDR</code>,<code>HLG</code>,<code>DolbyVision</code>,<code>SDR</code>,...) and check the callbacks is triggered when there is latency change <code>dsHdmiInRegisterAVLatencyChangeCB()</code> <code>NA</code> <code>Y</code> 7 Verify the HdmiIn <code>AVI</code> content change with callbacks Play the streams from Hdminput device with differenct formats(like <code>GRAPHICS</code>,<code>PHOTO</code>,<code>CINEMA</code>,<code>GAME</code>,...) and check the callbacks is triggered when there is <code>AVI</code> content change <code>dsHdmiInRegisterAviContentTypeChangeCB()</code> <code>NA</code> <code>Y</code> 8 Get HdmiIn status of the selected port Select the HdmiInput and verify the status whether selected port active or not <code>dsHdmiInSelectPort()</code>,<code>dsHdmiInGetStatus()</code> <code>Y</code> <code>Y</code> 9 Scale HdmiIn video of the selected port Select the HdmiInput and scale the video on the selcted port verify video scaled or not <code>dsHdmiInScaleVideo()</code> <code>Y</code> <code>Y</code> 10 Check and verify Zoom mode selected Select the Zoom mode from the available inputs and verify its set or not <code>dsHdmiInSelectZoomMode()</code> <code>Y</code> <code>NA</code> 11 Get and verify the <code>EDID</code> of selected port Select the HdmiInput and get the <code>EDID</code> for that particular Input port <code>dsGetEDIDBytesInfo()</code> <code>NA</code> <code>Y</code> 12 Get and verify the <code>SPD</code> info of selected port Select the HdmiInput and get the <code>SPD</code> info for that particular Input port <code>dsGetHDMISPDInfo()</code> <code>NA</code> <code>Y</code> 13 Set and verify the <code>EDID</code> version on selected port Set the <code>EDID</code> version and verify by retrieving the <code>EDID</code> version <code>dsSetEdidVersion()</code>,<code>dsGetEdidVersion()</code> <code>NA</code> <code>Y</code> 14 Set and verify <code>EDID</code> to <code>ALLM</code> support on selected port Set and retrieve <code>ALLM</code> on selected port connected with game controller on 4k supported panel <code>dsSetEdid2AllmSupport()</code>,<code>dsGetEdid2AllmSupport()</code> <code>NA</code> <code>Y</code>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-Hdmi-In_L3_Low-Level_TestSpecification/#level-3-python-test-cases-high-level-overview","title":"Level 3 Python Test Cases High Level Overview","text":"<p>The class diagram below illustrates the flow of dsHdmiIn L3 Python test cases:</p> <pre><code>---\ntitle: dsHdmiIn - Python Class Flow\n---\nclassDiagram\n    testControl &lt;|-- ut_raft : inherits\n    class ut_raft{\n    }\n    ut_raft &lt;|-- dsHdmiInHelperClass : inherits\n    dsHdmiInHelperClass &lt;|-- L3_TestClasses : inherits\n    L3_TestClasses ..&gt; dsHdmiIn : uses\n    note for testControl \"uses rackConfig.yaml and deviceConfig.yaml\"\n    note for dsHdmiIn \"uses platformProfile.yaml\"\n    note for L3_TestClasses \"uses testSetupConfig.yaml\"\n    note for ut_raft \"suite Navigator uses testConfig.yaml\"</code></pre> <ul> <li>testControl</li> <li>Test Control Module for running rack Testing. This module configures the <code>DUT</code> based on the rack configuration file provided to the test.</li> <li>This class is defined in <code>RAFT</code> framework. For more details refer RAFT</li> <li>ut_raft</li> <li>Python based testing framework for writing engineering tests.</li> <li>It provides common functionalities like menu navigation, configuration reader, reading user response etc.</li> <li>For more details ut-raft.</li> <li>dsHdmiIn</li> <li>This is test helper class which communicates with the <code>L3</code> C/C++ test running on the <code>DUT</code> through menu</li> <li>L3TestClasses</li> <li>These are the L3 test case classes</li> <li>Each class covers the each test use-case defined in L3 Test use-cases table</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-Hdmi-In_L3_Low-Level_TestSpecification/#yaml-file-inputs","title":"YAML File Inputs","text":"<ul> <li>rackConfig.yaml</li> <li>Identifies the rack configuration and platform used</li> <li>References platform-specific config from <code>deviceConfig.yaml</code></li> <li> <p>For more details refer RAFT and example_rack_config.yml</p> </li> <li> <p>deviceConfig.yaml</p> </li> <li>Specifies overall configuration for the platform</li> <li>Can be overridden by:<ul> <li>Changing locally .yaml file directory</li> <li>Using --deviceConfig command line switch</li> </ul> </li> <li> <p>For more details refer RAFT and example_device_config.yml</p> </li> <li> <p>componentProfile.yaml/platformProfile.yaml</p> </li> <li>Contains component-specific configurations</li> <li>Contains platform wide configuration broken down into separate components</li> <li> <p>Example configuration file dsHdmiIn_Settings</p> </li> <li> <p>testSetupConfig.yaml</p> </li> <li>This configuration file contains the list of requirements for tests to execute. Eg: Copying the streams etc.</li> <li> <p>Example configuration file dsHdmiIn_L3_testSetup.yml</p> </li> <li> <p>testSuite.yaml</p> </li> <li>This configuration file contains the list of menu items for C/C++ L3 test running on <code>DUT</code></li> <li>Example configuration file dsHdmiIn_testConfig.yml</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/","title":"HdmiIn High Level Test Specification Document","text":""},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>EDID</code>     - Extended Display Identification Data</li> <li><code>API</code>      - Application programming interface</li> <li><code>HDMI</code>     - High-Definition Multimedia Interface</li> <li><code>dsHdmiIn</code> - Device Settings High-Definition Multimedia Interface Input</li> <li><code>SPD</code>      - Source Product Descriptor</li> <li><code>ALLM</code>     - Auto Low Latency Mode</li> <li><code>AVI</code>      - Audio Video Interleave</li> <li><code>Y</code>        - Yes</li> <li><code>N</code>        - No</li> <li><code>NA</code>       - Not Applicable</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#introduction","title":"Introduction","text":"<p>This document provides an overview of the high level testing requirements for the <code>dsHdmiIn</code> module. It outlines the scope of testing, objectives, testing levels and approaches, specific test requirements, emulator requirements, control plane requirements and expected deliverables.</p> <ul> <li>Interface of the test is available in this link -  Interface header</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#module-description","title":"Module Description","text":"<p>High level overview:</p> <ul> <li><code>dsHdmiIn</code> provides a variety of <code>API</code>s for accessing information regarding the <code>HDMI</code> Inputs on sink devices and source devices that has an input port.</li> <li>It facilitates interaction with <code>HDMI</code> Input ports, aiding in their configuration and utilization within the system. This information is then passed to the caller.</li> <li> <p>For the sink and source devices, to retrieve the available <code>HDMI</code> Input information, an external device must be connected.</p> </li> <li> <p><code>HAL</code> specification : ds-hdmiIn HAL Spec</p> </li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#testing-scope","title":"Testing Scope","text":"# Test Functionality Test Description 1 Get Number of Inputs The test aims to verify and validate the number of HDMI Input ports available on the platform. 2 Set and Get the <code>HDMI</code> Input port Status The test is to verify by selecting the HDMI input and getting the status of HDMI Input ports available on the platform. 3 Scale the <code>HDMI</code> Input Video The test aims to verify and validate the video size and coordinates of the HMDI Input Video. 4 Select Zoom Mode The test aims to verify the zoom mode functionality of the module. 5 Get Current Video Mode The test is to get current HDMI input video mode from active port. 6 Callback for connection Status The test aims to verify whether it notifies applications when the HDMI input port connection status changes 7 Callback for Signal Change The test aims to verify the callback function used to inform applications about changes in the signal status of the <code>HDMI</code> In.(NoSignal/UnstableSignal/NotSupportedSignal/StableSignal) 8 Callback for Status Change The test validates the functionality of the callback function designed to notify applications of <code>HDMI</code> Input status change events.(Port,IsPresented flag status) 9 Callback for Video Mode Change The test validates the functionality of the callback function designed to notify when there is a change in the video resolution 10 Callback for <code>ALLM</code> Mode Change The test validates the functionality of the callback function designed to notify when <code>HDMI</code> input <code>ALLM</code> mode changes 11 Callback for AV Latency Change The test validates the functionality of the callback function designed to notify when <code>HDMI</code> input AV latency changes 12 Callback for <code>AVI</code> Content Type Change The test validates the functionality of the callback function designed to notify when <code>HDMI</code> input AVI content type changes 13 Check <code>HDMI</code> ARC Port The test verifies whether the given port is an <code>HDMI</code> ARC port or not 14 Set and Get <code>EDID</code> Information The test is to validate by setting and getting the <code>EDID</code> bytes information and <code>EDID</code> version 15 Get <code>HDMI</code> <code>SPD</code> Info The test is to get and verify the <code>SPD</code> information. 16 Get Supported Game Feature List The test verifies by getting the all supported game features in the list. 17 Get AV latency The test validates by getting the current av latency. 18 Get <code>ALLM</code> status The test aims to verify that <code>ALLM</code> status is enabled or disabled for the specific <code>HDMI</code> input port. 19 Get and Set <code>EDID</code> to all <code>ALLM</code> Support The test aims to verfiy by setting and getting the <code>EDID</code> <code>ALLM</code> support. 20 Get <code>HDMI</code> version The test is to validate getting the <code>HDMI</code> compatibility version -----------"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#get-number-of-inputs","title":"Get Number of Inputs","text":"Test Functionality Description HAL APIs L2 L3 Source Sink Control plane requirements Get Number of Inputs Verify that the function returns the expected <code>HDMI</code> Input ports. Compare the input port values by parsing the configuration YAML file for sink is <code>Sink_HDMIIN.yaml (HDMIIN/HdmiInputPort/numberOfPorts)</code> and source is <code>Source_HDMIIN.yaml(HDMIIN/HdmiInputPort/numberOfPorts)</code> dsHdmiInGetNumberOfInputs() <code>Y</code> <code>N</code> <code>Y</code> <code>Y</code> <code>NA</code>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#test-startup-requirement-get-number-of-inputs","title":"Test Startup Requirement - Get Number of Inputs","text":"<p>The test begins with the configured <code>HDMI</code> input port details.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#emulator-requirement-get-number-of-inputs","title":"Emulator Requirement - Get Number of Inputs","text":"<p>Emulator will boot with the port information's coming from the configuration file.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#control-plane-requirement-get-number-of-inputs","title":"Control Plane Requirement - Get Number of Inputs","text":"<p>None</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#set-and-get-the-hdmi-input-port-status","title":"Set and Get the <code>HDMI</code> Input port Status","text":"Test Functionality Description HAL APIs L2 L3 Source Sink Control plane requirements Set and Get the <code>HDMI</code> Input port Status Loop through supported <code>HDMI</code> Input port, verify that the function successfully sets the specified <code>HDMI</code> Input port without any external device connection and \"Get status\" to check the active port is false, port connected is false and presentation is false. Note:supported <code>HDMI</code> Input port, Check profile file for sink is <code>Sink_HDMIIN.yaml (HDMIIN/HdmiInputPort/numberOfPorts)</code> and source is <code>Source_HDMIIN.yaml(HDMIIN/HdmiInputPort/numberOfPorts)</code> dsHdmiInGetNumberOfInputs(), dsHdmiInSelectPort(), dsHdmiInGetStatus() <code>Y</code> <code>N</code> <code>Y</code> <code>Y</code> <code>NA</code> Loop through all <code>HDMI</code> Input port, verify that the function successfully sets the specified <code>HDMI</code> Input port as active for presentation and check the port information is valid using \"Get status\".Note:supported <code>HDMI</code> Input port, Check profile file for sink is <code>Sink_HDMIIN.yaml (HDMIIN/HdmiInputPort/numberOfPorts)</code> and source is <code>Source_HDMIIN.yaml(HDMIIN/HdmiInputPort/numberOfPorts)</code> dsHdmiInGetNumberOfInput(), dsHdmiInSelectPort(), dsHdmiInGetStatus() <code>N</code> <code>Y</code> <code>Y</code> <code>Y</code> <code>Y</code> On the active HDMI port, set the Audio Mix to be enable and disable dsHdmiInSelectPort() <code>N</code> <code>Y</code> <code>N</code> <code>Y</code> <code>Y</code> On the active HDMI port, verify the <code>HDMI</code> input with the video plane in both primary and secondary. Additionally, validate the topmost flag. dsHdmiInSelectPort() <code>N</code> <code>Y</code> <code>N</code> <code>Y</code> <code>Y</code>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#test-startup-requirement-set-and-get-the-hdmi-input-port-status","title":"Test Startup Requirement - Set and Get the <code>HDMI</code> Input port Status","text":"<ul> <li>The test begins with the configured <code>HDMI</code> input port numbers.</li> <li>Connection of the source device with the <code>HDMI</code> Input.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#emulator-requirement-set-and-get-the-hdmi-input-port-status","title":"Emulator Requirement - Set and Get the <code>HDMI</code> Input port Status","text":"<p>Emulator will boot with the port information's coming from the configuration file.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#control-plane-requirement-set-and-get-the-hdmi-input-port-status","title":"Control Plane Requirement - Set and Get the <code>HDMI</code> Input port Status","text":"<ul> <li>Connecting and disconnecting source devices in the <code>HDMI</code> Input will be handled by the Control Plane. </li> <li>Validate the Audio mix and Video plane by the analyzers.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#scale-the-hdmi-input-video","title":"Scale the <code>HDMI</code> Input Video","text":"Test Functionality Description HAL APIs L2 L3 Source Sink Control plane requirements Scale the <code>HDMI</code> Input Video Verify that the function successfully scales the <code>HDMI</code> input video when valid coordinates and dimensions are provided within the resolution limits. Based on video resolution need to check whether the coordinates are in range dsHdmiInScaleVideo() <code>N</code> <code>Y</code> <code>Y</code> <code>Y</code> <code>Y</code>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#test-startup-requirement-scale-the-hdmi-input-video","title":"Test Startup Requirement - Scale the <code>HDMI</code> Input Video","text":"<p>The test begins by setting up the video analyzer, and the video should be played.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#emulator-requirement-scale-the-hdmi-input-video","title":"Emulator Requirement - Scale the <code>HDMI</code> Input Video","text":"<p>Emulator will boot with the port information's coming from the configuration file. Predefined coordinates and dimesions to compare.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#control-plane-requirement-scale-the-hdmi-input-video","title":"Control Plane Requirement - Scale the <code>HDMI</code> Input Video","text":"<p>Control plane to validate the coordinates and dimensions by the video analyzers.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#select-zoom-mode","title":"Select Zoom Mode","text":"Test Functionality Description HAL APIs L2 L3 Source Sink Control plane requirements Select Zoom Mode Verify that the function successfully updates the video zoom on the active <code>HDMI</code> input using the provided zoom mode dsHdmiInSelectZoomMode() <code>N</code> <code>Y</code> <code>Y</code> <code>N</code> <code>Y</code>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#test-startup-requirement-select-zoom-mode","title":"Test Startup Requirement - Select Zoom Mode","text":"<p>The test begins by setting up the video analyzer, and the video should be played.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#emulator-requirement-select-zoom-mode","title":"Emulator Requirement - Select Zoom Mode","text":"<p>Emulator will boot with the zoom modes in the configuration file.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#control-plane-requirement-select-zoom-mode","title":"Control Plane Requirement - Select Zoom Mode","text":"<p>Changing the zoom modes by the Control Plane. Validates the zoom mode by analyzers.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#get-current-video-mode","title":"Get Current Video Mode","text":"Test Functionality Description HAL APIs L2 L3 Source Sink Control plane requirements Get Current Video Mode Verify that the function successfully updates the current <code>HDMI</code> input video modes like Pixel resolution, frame rate and interlaced information of the active port dsHdmiInGetCurrentVideoMode() <code>N</code> <code>Y</code> <code>Y</code> <code>Y</code> <code>Y</code>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#test-startup-requirement-get-current-video-mode","title":"Test Startup Requirement - Get Current Video Mode","text":"<p>The test begins by setting up the video analyzer, and the video should be played.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#emulator-requirement-get-current-video-mode","title":"Emulator Requirement - Get Current Video Mode","text":"<p>Emulator will boot with the all video mode related information in the configuration file.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#control-plane-requirement-get-current-video-mode","title":"Control Plane Requirement - Get Current Video Mode","text":"<p>Control plane validates the current mode by the analyzers.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#callback-for-connection-status","title":"Callback for connection Status","text":"Test Functionality Description HAL APIs L2 L3 Source Sink Control plane requirements Callback for connection Status Verify that the callback function properly updates the connection/disconnection status flag and notifies the application when a <code>HDMI</code> Input port is connected or disconnected. dsHdmiInRegisterConnectCB() <code>N</code> <code>Y</code> <code>Y</code> <code>Y</code> <code>Y</code> Callback for connection Status Verify that the callback function properly updates the isPresented status, if the connected port is active and presents video after being connected. dsHdmiInRegisterConnectCB() <code>N</code> <code>Y</code> <code>Y</code> <code>Y</code> <code>Y</code>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#test-startup-requirement-callback-for-connection-status","title":"Test Startup Requirement - Callback for connection Status","text":"<p>Connection of the source device with the <code>HDMI</code> Input.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#emulator-requirement-callback-for-connection-status","title":"Emulator Requirement - Callback for connection Status","text":"<p>Emulator will boot with the port information coming from the configuration file.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#control-plane-requirement-callback-for-connection-status","title":"Control Plane Requirement - Callback for connection Status","text":"<p>Connecting and disconnecting source devices in the <code>HDMI</code> Input will be handled by the Control Plane.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#callback-for-signal-change","title":"Callback for Signal Change","text":"Test Functionality Description HAL APIs L2 L3 Source Sink Control plane requirements Callback for Signal Change Verify that the callback function properly notifies the application whenever there is a change in the signal statuses (e.g., NoSignal, UnstableSignal, NotSupportedSignal, StableSignal) for the <code>HDMI</code> Input port. dsHdmiInRegisterSignalChangeCB() <code>N</code> <code>Y</code> <code>N</code> <code>Y</code> <code>Y</code>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#test-startup-requirement-callback-for-signal-change","title":"Test Startup Requirement - Callback for Signal Change","text":"<p>Connection of the source device with the <code>HDMI</code> Input.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#emulator-requirement-callback-for-signal-change","title":"Emulator Requirement - Callback for Signal Change","text":"<p>Emulator will boot with the port information's coming from the configuration file.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#control-plane-requirement-callback-for-signal-change","title":"Control Plane Requirement - Callback for Signal Change","text":"<ul> <li>Connecting and disconnecting source devices in the <code>HDMI</code> Input will be handled by the Control Plane.</li> <li>Provide resolution changes or configurations changes on the connected device that affects the output signal.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#callback-for-status-change","title":"Callback for Status Change","text":"Test Functionality Description HAL APIs L2 L3 Source Sink Control plane requirements Callback for Status Change Verify that the callback function properly triggers whenever the dsHdmiInStatus_t is updated and notifies the application of the <code>HDMI</code> Input status change event. dsHdmiInRegisterStatusChangeCB() <code>N</code> <code>Y</code> <code>N</code> <code>Y</code> <code>Y</code>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#test-startup-requirement-callback-for-status-change","title":"Test Startup Requirement - Callback for Status Change","text":"<p>Connection of the source device with the <code>HDMI</code> Input.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#emulator-requirement-callback-for-status-change","title":"Emulator Requirement - Callback for Status Change","text":"<p>Emulator will boot with the port information's coming from the configuration file.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#control-plane-requirement-callback-for-status-change","title":"Control Plane Requirement - Callback for Status Change","text":"<p>Connecting and disconnecting source devices in the <code>HDMI</code> Input will be handled by the Control Plane.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#callback-for-video-mode-change","title":"Callback for Video Mode Change","text":"Test Functionality Description HAL APIs L2 L3 Source Sink Control plane requirements Callback for Video Mode Change Verify that the callback function properly notifies the application whenever there is resolution and other video mode changes. dsHdmiInRegisterVideoModeUpdateCB() <code>N</code> <code>Y</code> <code>N</code> <code>Y</code> <code>Y</code>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#test-startup-requirement-callback-for-video-mode-change","title":"Test Startup Requirement - Callback for Video Mode Change","text":"<p>Connection of the source device with the <code>HDMI</code> Input.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#emulator-requirement-callback-for-video-mode-change","title":"Emulator Requirement - Callback for Video Mode Change","text":"<p>Emulator will boot with the video resolutions and other video modes from the configuration file.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#control-plane-requirement-callback-for-video-mode-change","title":"Control Plane Requirement - Callback for Video Mode Change","text":"<p>Changing of the video resolution by control Plane. </p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#callback-for-allm-mode-change","title":"Callback for <code>ALLM</code> mode change","text":"Test Functionality Description HAL APIs L2 L3 Source Sink Control plane requirements Callback for <code>ALLM</code> mode change Verify that the callback function properly notifies the application whenever there is <code>ALLM</code> mode change. dsHdmiInRegisterAllmChangeCB() <code>N</code> <code>Y</code> <code>N</code> <code>Y</code> <code>Y</code>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#test-startup-requirement-callback-for-allm-mode-change","title":"Test Startup Requirement - Callback for <code>ALLM</code> mode change","text":"<p>Connection of the source device/compatible gaming console devices with the <code>HDMI</code> Input.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#emulator-requirement-callback-for-allm-mode-change","title":"Emulator Requirement - Callback for <code>ALLM</code> mode change","text":"<p>Emulator will boot with the <code>HDMI</code> input port numbers and <code>ALLM</code> mode information.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#control-plane-requirement-callback-for-allm-mode-change","title":"Control Plane Requirement - Callback for <code>ALLM</code> mode change","text":"<p>Changing of the <code>ALLM</code> mode by control Plane.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#callback-for-av-latency-change","title":"Callback for AV Latency Change","text":"Test Functionality Description HAL APIs L2 L3 Source Sink Control plane requirements Callback for AV Latency Change Verify that the callback function notifies the application whenever there is a change in the <code>HDMI</code> input Audio and Video latency within its Max(500ms) and Min(0) ranges. dsHdmiInRegisterAVLatencyChangeCB() <code>N</code> <code>Y</code> <code>N</code> <code>Y</code> <code>Y</code>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#test-startup-requirement-callback-for-av-latency-change","title":"Test Startup Requirement - Callback for AV Latency Change","text":"<ul> <li>Connection of the source device with the <code>HDMI</code> Input. </li> <li>Test starts with the video playback with different modes ( Film Maker, Cinema mode )</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#emulator-requirement-callback-for-av-latency-change","title":"Emulator Requirement - Callback for AV Latency Change","text":"<p>Emulator will boot with the AV latency information.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#control-plane-requirement-callback-for-av-latency-change","title":"Control Plane Requirement - Callback for AV Latency Change","text":"<p>Control plane signals the source device to play the content ( Cinema mode to Film Maker mode ).</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#callback-for-avi-content-type-change","title":"Callback for <code>AVI</code> Content Type Change","text":"Test Functionality Description HAL APIs L2 L3 Source Sink Control plane requirements Callback for <code>AVI</code> Content Type Change Verify that the callback function properly notifies the application whenever there is a change in the <code>AVI</code> content type. dsHdmiInRegisterAviContentTypeChangeCB() <code>N</code> <code>Y</code> <code>N</code> <code>Y</code> <code>Y</code>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#test-startup-requirement-callback-for-avi-content-type-change","title":"Test Startup Requirement - Callback for <code>AVI</code> Content Type Change","text":"<ul> <li>Connection of the source device with the <code>HDMI</code> Input.</li> <li>Test starts with the video playback.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#emulator-requirement-callback-for-avi-content-type-change","title":"Emulator Requirement - Callback for <code>AVI</code> Content Type Change","text":"<p>Emulator will boot with the <code>AVI</code> content type information.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#control-plane-requirement-callback-for-avi-content-type-change","title":"Control Plane Requirement - Callback for <code>AVI</code> Content Type Change","text":"<p>Changing <code>AVI</code> content type by control Plane..</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#check-hdmi-arc-port","title":"Check <code>HDMI</code> ARC Port","text":"Test Functionality Description HAL APIs L2 L3 Source Sink Control plane requirements Check <code>HDMI</code> ARC Port Loop through supported <code>HDMI</code> Input port and verify whether the given port is an HDMI ARC port by comparing it with the <code>Sink_HDMIIN.yaml (HDMIIN/HdmiArcPort/portNumber)</code> configuration file.Note:supported <code>HDMI</code> Input port, Check profile file for sink is <code>Sink_HDMIIN.yaml (HDMIIN/HdmiInputPort/numberOfPorts)</code> dsIsHdmiARCPort() <code>Y</code> <code>N</code> <code>N</code> <code>Y</code> <code>NA</code>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#test-startup-requirement-check-hdmi-arc-port","title":"Test Startup Requirement - Check <code>HDMI</code> ARC Port","text":"<p>Test starts with the number of ports and ARC port from the configuration file.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#emulator-requirement-check-hdmi-arc-port","title":"Emulator Requirement - Check <code>HDMI</code> ARC Port","text":"<p>Emulator will boot with the <code>HDMI</code> ARC port information.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#control-plane-requirement-check-hdmi-arc-port","title":"Control Plane Requirement - Check <code>HDMI</code> ARC Port","text":"<p>None</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#set-and-get-edid-information","title":"Set and Get <code>EDID</code> Information","text":"Test Functionality Description HAL APIs L2 L3 Source Sink Control plane requirements Set and Get <code>EDID</code> Information Setting the <code>EDID</code> version for a given port and getting back the <code>EDID</code> version and compare with the Set value. Also, validate the EDID length for a given port. Compare the EDID length values by parsing the configuration YAML file <code>Sink_EDID_Info.yaml (HDMIIN/EDID_Data/edidBytesLength)</code> dsSetEdidVersion(), dsGetEdidVersion(), dsGetEDIDBytesInfo() <code>Y</code> <code>N</code> <code>N</code> <code>Y</code> <code>NA</code> This test ensures that the module can accurately retrieve and interpret <code>EDID</code> information, providing essential data about the display's capabilities and characteristics. dsGetEdidVersion(), dsGetEDIDBytesInfo() <code>N</code> <code>Y</code> <code>N</code> <code>Y</code> <code>Y</code>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#test-startup-requirement-set-and-get-edid-information","title":"Test Startup Requirement - Set and Get <code>EDID</code> Information","text":"<ul> <li>Connection of the source device with the <code>HDMI</code> Input and video analyzer to check the display capabilities.</li> <li>Test starts with the predefined EDID length information coming from the configuration file.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#emulator-requirement-set-and-get-edid-information","title":"Emulator Requirement - Set and Get <code>EDID</code> Information","text":"<p>Emulator will boot with the <code>EDID</code> coming from the configuration file.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#control-plane-requirement-set-and-get-edid-information","title":"Control Plane Requirement - Set and Get <code>EDID</code> Information","text":"<p>Connecting and disconnecting source devices in the <code>HDMI</code> Input will be handled by the Control Plane.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#get-hdmi-spd-info","title":"Get <code>HDMI</code> <code>SPD</code> Info","text":"Test Functionality Description HAL APIs L2 L3 Source Sink Control plane requirements Get <code>HDMI</code> <code>SPD</code> Info Test to get the <code>HDMI</code> <code>SPD</code> Info. Check whether it gets the spd info frame information properly. dsGetHDMISPDInfo() <code>N</code> <code>Y</code> <code>N</code> <code>Y</code> <code>Y</code>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#test-startup-requirement-get-hdmi-spd-info","title":"Test Startup Requirement - Get <code>HDMI</code> <code>SPD</code> Info","text":"<p>Connection of the source device with the <code>HDMI</code> Input.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#emulator-requirement-get-hdmi-spd-info","title":"Emulator Requirement - Get <code>HDMI</code> <code>SPD</code> Info","text":"<p>Emulator will boot with the <code>HDMI</code> SPD information from the configuration file.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#control-plane-requirement-get-hdmi-spd-info","title":"Control Plane Requirement - Get <code>HDMI</code> <code>SPD</code> Info","text":"<p>Connecting and disconnecting source devices in the <code>HDMI</code> Input will be handled by the Control Plane. Check the SPD info frame - Vendor name by the Analyzers.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#get-supported-game-feature-list","title":"Get Supported Game Feature List","text":"Test Functionality Description HAL APIs L2 L3 Source Sink Control plane requirements Get Supported Game Feature List Make sure that the functionality can list and get the count of all the game features that are supported. Compare the result by parsing the configuration YAML file <code>Sink_HDMIIN.yaml(HDMIIN/gameFeatures/count)</code> dsGetSupportedGameFeaturesList() <code>Y</code> <code>N</code> <code>N</code> <code>Y</code> <code>NA</code>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#test-startup-requirement-get-supported-game-feature-list","title":"Test Startup Requirement - Get Supported Game Feature List","text":"<p>Connection of the source device/game supported device with the <code>HDMI</code> Input. Test boots with the game feature list and count in the configuration file to compare the results.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#emulator-requirement-get-supported-game-feature-list","title":"Emulator Requirement - Get Supported Game Feature List","text":"<p>Emulator will boot with the game supported features in the configuration.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#control-plane-requirement-get-supported-game-feature-list","title":"Control Plane Requirement - Get Supported Game Feature List","text":"<p>None</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#get-av-latency","title":"Get AV latency","text":"Test Functionality Description HAL APIs L2 L3 Source Sink Control plane requirements Get AV latency The test gets the current AV latency connected to the source device. Also, It checks the AV latency after changing the AV content, such as switching from FilmMaker mode to any other mode. dsGetAVLatency <code>N</code> <code>Y</code> <code>N</code> <code>Y</code> <code>Y</code>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#test-startup-requirement-get-av-latency","title":"Test Startup Requirement - Get AV latency","text":"<ul> <li>Connection of the source device with the <code>HDMI</code> Input.</li> <li>Test starts up with the video playback content of different modes ( Film Maker mode, Cinema mode )</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#emulator-requirement-get-av-latency","title":"Emulator Requirement - Get AV latency","text":"<p>Emulator will boot with the av latency information in configuration file.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#control-plane-requirement-get-av-latency","title":"Control Plane Requirement - Get AV latency","text":"<ul> <li>Control plane handles the switch between the modes ( Film Maker modes and Cinema modes ). </li> <li>Control Plane to test the content with post processing and without post processing.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#get-allm-status","title":"Get <code>ALLM</code> Status","text":"Test Functionality Description HAL APIs L2 L3 Source Sink Control plane requirements Get <code>ALLM</code> Status Gets the <code>ALLM</code> status of the designated <code>HDMI</code> input port. The status information indicates whether <code>ALLM</code> is enabled or disabled dsGetAllmStatus() <code>N</code> <code>Y</code> <code>N</code> <code>Y</code> <code>NA</code>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#test-startup-requirement-get-allm-status","title":"Test Startup Requirement - Get <code>ALLM</code> status","text":"<p>Connection of the Game console source devce with the <code>HDMI</code> Input with game playback. </p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#emulator-requirement-get-allm-status","title":"Emulator Requirement - Get <code>ALLM</code> status","text":"<p>Emulator will boot with the <code>ALLM</code> configuration details.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#control-plane-requirement-get-allm-status","title":"Control Plane Requirement - Get <code>ALLM</code> status","text":"<p>None</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#get-and-set-edid-to-all-allm-support","title":"Get and Set <code>EDID</code> to all <code>ALLM</code> Support","text":"Test Functionality Description HAL APIs L2 L3 Source Sink Control plane requirements Get and Set <code>EDID</code> to all <code>ALLM</code> Support Set and Get the <code>ALLM</code> support to <code>EDID</code> version 2.0 without connecting any source devices. dsSetEdid2AllmSupport(), dsGetEdid2AllmSupport() <code>Y</code> <code>N</code> <code>N</code> <code>Y</code> <code>NA</code> Set and Get <code>ALLM</code> support to <code>EDID</code> Version 2.0 with the connected external source device dsSetEdid2AllmSupport(), dsGetEdid2AllmSupport() <code>N</code> <code>Y</code> <code>N</code> <code>Y</code> <code>Y</code>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#test-startup-requirement-get-and-set-edid-to-all-allm-support","title":"Test Startup Requirement - Get and Set <code>EDID</code> to all <code>ALLM</code> Support","text":"<p>Connection of the Game console source device with the <code>HDMI</code> Input.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#emulator-requirement-get-and-set-edid-to-all-allm-support","title":"Emulator Requirement - Get and Set <code>EDID</code> to all <code>ALLM</code> Support","text":"<p>Emulator will boot with the <code>ALLM</code> support information.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#control-plane-requirement-get-and-set-edid-to-all-allm-support","title":"Control Plane Requirement - Get and Set <code>EDID</code> to all <code>ALLM</code> Support","text":"<p>Control plane connects/ disconnects the external devices. Validates the ALLM by analyzers.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#get-hdmi-version","title":"Get <code>HDMI</code> Version","text":"Test Functionality Description HAL APIs L2 L3 Source Sink Control plane requirements Get <code>HDMI</code> Version Get <code>HDMI</code> Version and Validate with the version from profile file dsGetHdmiVersion() <code>Y</code> <code>N</code> <code>N</code> <code>Y</code> <code>NA</code>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#test-startup-requirement-get-hdmi-version","title":"Test Startup Requirement - Get <code>HDMI</code> Version","text":"<ul> <li>The test begins with the configured <code>HDMI</code> input port numbers.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#emulator-requirement-get-hdmi-version","title":"Emulator Requirement - Get <code>HDMI</code> Version","text":"<p>Emulator will boot with the <code>EDID</code> coming from the configuration file.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-High-Level_TestSpec/#control-plane-requirement-get-hdmi-version","title":"Control Plane Requirement - Get <code>HDMI</code> Version","text":"<p>None</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-L2-Low-Level_TestSpec/","title":"Device Settings HDMI Input L2 Low Level Test Specification and Procedure Documentation","text":""},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-L2-Low-Level_TestSpec/#overview","title":"Overview","text":"<p>This document describes the Low Level L2 Test Specification and Procedure Documentation for the Device Settings HDMI Input module.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-L2-Low-Level_TestSpec/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>HAL</code> - Hardware Abstraction Layer, may include some common components</li> <li><code>UT</code>  - Unit Test(s)</li> <li><code>OEM</code>  - Original Equipment Manufacture</li> <li><code>SoC</code>  - System on a Chip</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-L2-Low-Level_TestSpec/#definitions","title":"Definitions","text":"<ul> <li><code>ut-core</code> - Common Testing Framework https://github.com/rdkcentral/ut-core, which wraps a open-source framework that can be expanded to the requirements for future framework.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-L2-Low-Level_TestSpec/#references","title":"References","text":"<ul> <li><code>High Level Test Specification</code> - ds-hdmi-in-High-Level_TestSpec.md</li> <li><code>HAL Interface file</code> - dsHdmiIn.h</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-L2-Low-Level_TestSpec/#level-2-test-procedure","title":"Level 2 Test Procedure","text":"<p>The following functions are expecting to test the module operates correctly.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-L2-Low-Level_TestSpec/#test-1","title":"Test 1","text":"Title Details Function Name <code>test_l2_dsHdmiIn_GetNumberOfInputs</code> Description Verify that the function returns the expected <code>HDMI</code> Input ports. Compare the input port values by parsing the configuration YAML file <code>dsHdmiIn/numberOfPorts</code> Test Group 02 Test Case ID 001 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-L2-Low-Level_TestSpec/#test-procedure-test-1","title":"Test Procedure - Test 1","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize <code>HDMI</code> input using <code>dsHdmiInInit</code> None <code>dsERR_NONE</code> Should be successful 02 Get the number of <code>HDMI</code> input ports using <code>dsHdmiInGetNumberOfInputs</code> pNumberOfinputs = valid buffer <code>dsERR_NONE</code> Should be successful 03 Compare the number of <code>HDMI</code> input ports with the value in the configuration file pNumberOfinputs = <code>dsHdmiIn/numberOfPorts</code> <code>dsERR_NONE</code> Should be successful 04 Terminate <code>HDMI</code> input using <code>dsHdmiInTerm</code> None <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\nA[Call dsHdmiInInit API] --&gt;|dsERR_NONE| B[Parse Configuration file]\nA --&gt;|Failure| A1[Test case fail]\nB --&gt;|Success| C[Call dsHdmiInGetNumberOfInputs API]\nB --&gt;|Failure| B1[Test case fail]\nC --&gt;|Success| D[Compare pNumberOfinputs with YAML value]\nC --&gt;|Failure| C1[Test case fail]\nD --&gt;|Match| E[Call dsHdmiInTerm API]\nD --&gt;|Mismatch| D1[Test case fail]\nE --&gt;|Failure| E1[Test case fail]\nE --&gt;|dsERR_NONE| F[Test case success]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-L2-Low-Level_TestSpec/#test-2","title":"Test 2","text":"Title Details Function Name <code>test_l2_dsHdmiIn_GetStatus</code> Description Verify the HDMI port with the 'Get status' function when it is disabled, without selecting any port, and without any external devices. Test Group 02 Test Case ID 002 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-L2-Low-Level_TestSpec/#test-procedure-test-2","title":"Test Procedure - Test 2","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize <code>HDMI</code> input using <code>dsHdmiInInit</code> None <code>dsERR_NONE</code> Should be successful 02 Get the status of <code>HDMI</code> input using <code>dsHdmiInGetStatus</code> status = valid buffer <code>dsERR_NONE</code> Should be successful 03 Check if <code>HDMI</code> input is presented isPresented = false false Should be successful 04 Check if any <code>HDMI</code> input port is active activePort = <code>dsHDMI_IN_PORT_NONE</code> <code>dsHDMI_IN_PORT_NONE</code> Should be successful 05 Check if any <code>HDMI</code> input port is connected isPortConnected[i] = false for all i in range 0 to <code>dsHDMI_IN_PORT_MAX</code> false Should be successful 06 Terminate <code>HDMI</code> input using <code>dsHdmiInTerm</code> None <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\nA[Call dsHdmiInInit] --&gt;|dsERR_NONE| B[Call dsHdmiInGetStatus]\nA --&gt;|Failure| A1[Test case fail]\nB --&gt;|dsERR_NONE| C[Check pStatus]\nB --&gt;|Failure| B1[Test case fail]\nC --&gt;|isPresented=false, isPortConnected=false, &lt;br&gt; activePort=dsHDMI_IN_PORT_NONE| D[Call dsHdmiInTerm]\nC --&gt;|Failure| C1[Test case fail]\nD --&gt;|dsERR_NONE| E[Test case success]\nD --&gt;|Failure| D1[Test case fail]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-L2-Low-Level_TestSpec/#test-3","title":"Test 3","text":"Title Details Function Name <code>test_l2_dsHdmiIn_VerifyHdmiInputPortStatus</code> Description Loop through all <code>HDMI</code> Input port, verify that the function successfully sets the specified <code>HDMI</code> Input port without any external device connection and 'Get status' to check the active port is false, port connected is false and presentation is false. Test Group 02 Test Case ID 003 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-L2-Low-Level_TestSpec/#test-procedure-test-3","title":"Test Procedure - Test 3","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize HDMI input using <code>dsHdmiInInit</code> None <code>dsERR_NONE</code> Should be successful 02 Get the number of <code>HDMI</code> inputs using <code>dsHdmiInGetNumberOfInputs</code> numInputs = valid buffer <code>dsERR_NONE</code>, numInputs &gt; 0 Should be successful 03 Loop through supported <code>HDMI</code> input ports and select each port using <code>dsHdmiInSelectPort</code> port = <code>dsHDMI_IN_PORT_0</code> to numInputs-1, audioMix = false, evideoPlaneType = dsVideoPlane_PRIMARY, topMost = false <code>dsERR_NONE</code> Should be successful 04 Get the status of the selected HDMI input port using <code>dsHdmiInGetStatus</code> status = valid buffer <code>dsERR_NONE</code>, activePort = port, isPresented = false, isPortConnected[port] = false Should be successful 05 Terminate HDMI input using <code>dsHdmiInTerm</code> None <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\nA[Call dsHdmiInInit API] --&gt;|dsERR_NONE| B[Call dsHdmiInGetNumberOfInputs API]\nA --&gt;|Not dsERR_NONE| A1[Test case fail]\nB --&gt;|dsERR_NONE and&lt;br&gt; non-zero inputs| C{Loop through supported &lt;br&gt; HDMI input ports}\nB --&gt;|Not dsERR_NONE or &lt;br&gt;zero inputs| B1[Test case fail]\nC --&gt; D[Call dsHdmiInSelectPort API with current port]\nD --&gt;|dsERR_NONE| E[Call dsHdmiInGetStatus API]\nE --&gt;|!dsERR_NONE| E1[Test case fail]\nE1 --&gt; F\nE --&gt;|dsERR_NONE, activePort is current port, &lt;br&gt; isPresented is false, isPortConnected is false| F[Next port in loop]\nF --&gt; C\nC --&gt;|End of loop| G[Call dsHdmiInTerm API]\nG --&gt;|dsERR_NONE| H[Test case pass]\nG --&gt;|Not dsERR_NONE| G1[Test case fail]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-L2-Low-Level_TestSpec/#test-4","title":"Test 4","text":"Title Details Function Name <code>test_l2_dsHdmiIn_VerifyHdmiArcPort_sink</code> Description Loop through supported ports and verify whether the given port is an HDMI ARC port by comparing it with the <code>dsHdmiIn/HdmiArcPort/numberOfPorts</code> configuration file. Test Group 02 Test Case ID 004 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-L2-Low-Level_TestSpec/#test-procedure-test-4","title":"Test Procedure - Test 4","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize HDMI input using <code>dsHdmiInInit</code> None <code>dsERR_NONE</code> Should be successful 02 Loop through supported HDMI input ports iPort = <code>dsHDMI_IN_PORT_0</code> to number of Hdmi Input ports supported <code>dsERR_NONE</code> Should be successful 03 For each port, check if it is an <code>HDMI</code> ARC port using <code>dsIsHdmiARCPort</code> iPort = current port in loop, &amp;isArcPort = valid buffer <code>dsERR_NONE</code> Should be successful 04 If the port is an <code>HDMI</code> ARC port, verify it with the configuration file iPort = current port, isArcPort = <code>dsHdmiIn/HdmiArcPortID</code> from configuration file returned by <code>dsIsHdmiARCPort</code> <code>dsERR_NONE</code> Should be successful 05 Terminate <code>HDMI</code> input using <code>dsHdmiInTerm</code> None <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\n    A[Call dsHdmiInInit API] --&gt;|Success| B{Loop through &lt;br&gt; HDMI ports}\n    A --&gt;|Failure| A1[Test case fail]\n    B --&gt; C[Call dsIsHdmiARCPort API]\n    C --&gt;|Success| D[Check isArcPort flag]\n    D --&gt;|isArcPort is true| E[Compare with configuration file]\n    E --&gt; F[Is it the last HDMI port?]\n    F --&gt;|No| B\n    F --&gt;|Yes| G[Call dsHdmiInTerm API]\n    G --&gt;|Success| H[Test case pass]\n    G --&gt;|Failure| G1[Test case fail]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-L2-Low-Level_TestSpec/#test-5","title":"Test 5","text":"Title Details Function Name <code>test_l2_dsHdmiIn_SetAndGetEdidVersionAndValidateEdidLength_sink</code> Description Setting the <code>EDID</code> version for a given port and getting back the <code>EDID</code> version and compare with the Set value. Test Group 02 Test Case ID 005 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-L2-Low-Level_TestSpec/#test-procedure-test-5","title":"Test Procedure - Test 5","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize HDMI input module using <code>dsHdmiInInit</code> None <code>dsERR_NONE</code> Should be successful 02 Set <code>EDID</code> version for each HDMI port using <code>dsSetEdidVersion</code> hdmiPort = <code>dsHDMI_IN_PORT_0</code> to <code>dsHDMI_IN_PORT_2</code>, edidVersion = Supported <code>EDID</code> version from configuration file  <code>dsHdmiIn/EdidVersion/</code> <code>dsERR_NONE</code> Should be successful 03 Get  and compare the <code>EDID</code> version for each <code>HDMI</code> port using <code>dsGetEdidVersion</code> hdmiPort <code>dsERR_NONE</code> Should be successful 04 Repeat steps 2 to 4 for all <code>HDMI</code> ports and <code>EDID</code> versions <code>dsERR_NONE</code> Should be successful 05 Terminate <code>HDMI</code> input module using <code>dsHdmiInTerm</code> None <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\n    A[dsHdmiInInit] --&gt; |Success| B[dsSetEdidVersion for various ports and edid version]\n    A --&gt; |Failure| A1[Test Case Fail: dsHdmiInInit]\n    B --&gt; |Success| C[dsGetEdidVersion]\n    B --&gt; |Failure| B1[Test Case Fail: dsSetEdidVersion]\n    C --&gt; |Success &amp; get and set matches | G[dsHdmiInTerm]\n    C --&gt; |Failure| C1[Test Case Fail: dsGetEdidVersion]\n    G --&gt; |Success| H[Test Case Success]\n    G --&gt; |Failure| G1[Test Case Fail: dsHdmiInTerm]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-L2-Low-Level_TestSpec/#test-6","title":"Test 6","text":"Title Details Function Name <code>test_l2_dsHdmiIn_GetSupportedGameFeaturesList_sink</code> Description Make sure that the functionality can list and get the count of all the game features that are supported. Compare the result by parsing the configuration YAML file <code>dsHdmiIn/gameFeatures/count</code> Test Group 02 Test Case ID 006 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-L2-Low-Level_TestSpec/#test-procedure-test-6","title":"Test Procedure - Test 6","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize HDMI input using dsHdmiInInit None dsERR_NONE Should be successful 02 Get the list of supported game features using dsGetSupportedGameFeaturesList features = <code>dsHdmiIn/gameFeatures/feature</code> dsERR_NONE Should be successful 03 Compare the count of game features with the count in the configuration file features.gameFeatureCount = value from <code>dsHdmiIn/gameFeatures/count</code> dsERR_NONE Should be successful 04 Terminate HDMI input using dsHdmiInTerm None dsERR_NONE Should be successful <pre><code>graph TB\n    A[Call dsHdmiInInit API] --&gt;|dsERR_NONE| B[Call dsGetSupportedGameFeaturesList API]\n    A --&gt;|Failure| A1[Test case fail]\n    B --&gt; C[Verify gameFeatureCount field]\n    B --&gt;|Failure| B1[Test case fail]\n    C --&gt;|dsERR_NONE| D[Verify gameFeatureList field]\n    C --&gt;|Failure| C1[Test case fail]\n    D --&gt; E[Call dsHdmiInTerm API]\n    D --&gt;|Failure| D1[Test case fail]\n    E --&gt; F[Test case success]\n    E --&gt;|Failure| E1[Test case fail]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-L2-Low-Level_TestSpec/#test-7","title":"Test 7","text":"Title Details Function Name <code>test_l2_dsHdmiIn_SetAndGetAllmSupport_sink</code> Description Set and Get the <code>ALLM</code> support to <code>EDID</code> version 2.0 without connecting any source devices. Test Group 02 Test Case ID 007 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-L2-Low-Level_TestSpec/#test-procedure-test-7","title":"Test Procedure - Test 7","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize <code>HDMI</code> input using <code>dsHdmiInInit</code> None <code>dsERR_NONE</code> Should be successful 02 Set <code>EDID</code> 2.0 ALLM support to true using <code>dsSetEdid2AllmSupport</code> iHdmiPort = <code>dsHDMI_IN_PORT_0</code>, allmSupport = true <code>dsERR_NONE</code> Should be successful 03 Get <code>EDID</code> 2.0 ALLM support using <code>dsGetEdid2AllmSupport</code> iHdmiPort = <code>dsHDMI_IN_PORT_0</code>,  number of Hdmi Input ports <code>dsERR_NONE</code>, allmSupport = true Should be successful 04 Set EDID 2.0 ALLM support to false using <code>dsSetEdid2AllmSupport</code> iHdmiPort = dsHDMI_IN_PORT_0, allmSupport = false <code>dsERR_NONE</code> Should be successful 05 Get EDID 2.0 ALLM support using <code>dsGetEdid2AllmSupport</code> iHdmiPort = <code>dsHDMI_IN_PORT_0</code>, to number of Hdmi Input ports supported <code>dsERR_NONE</code>, allmSupport = false Should be successful 06 Terminate HDMI input using <code>dsHdmiInTerm</code> None <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\nA[Call dsHdmiInInit] --&gt;|Success| B[Call dsSetEdid2AllmSupport with true]\nA --&gt;|Failure| A1[Test case fail]\nB --&gt;|Success| C[Call dsGetEdid2AllmSupport]\nB --&gt;|Failure| B1[Test case fail]\nC --&gt;|Success| D[Call dsSetEdid2AllmSupport with false]\nC --&gt;|Failure| C1[Test case fail]\nD --&gt;|Success| E[Call dsGetEdid2AllmSupport]\nD --&gt;|Failure| D1[Test case fail]\nE --&gt;|Success| F[Call dsHdmiInTerm]\nE --&gt;|Failure| E1[Test case fail]\nF --&gt;|Success| G[Test case success]\nF --&gt;|Failure| F1[Test case fail]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-L2-Low-Level_TestSpec/#test-8","title":"Test 8","text":"Title Details Function Name <code>test_l2_dsHdmiIn_GetHdmiVersionAndValidate_sink</code> Description Getting the <code>HDMI</code> compatibility version for a given port version and validate it. Test Group 02 Test Case ID 008 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in-L2-Low-Level_TestSpec/#test-procedure-test-8","title":"Test Procedure - Test 8","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize HDMI input module using <code>dsHdmiInInit</code> None <code>dsERR_NONE</code> Should be successful 02 Get  and validate the <code>HDMI</code> compatibility version by comparing with the YAML file for each <code>HDMI</code> port using <code>dsGetHdmiVersion</code> hdmiPort = <code>dsHDMI_IN_PORT_0</code> to number of supported ports <code>dsERR_NONE</code> Should be successful 03 Terminate <code>HDMI</code> input module using <code>dsHdmiInTerm</code> None <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\n    A[dsHdmiInInit] --&gt; |Success| B[dsGetHdmiVersion]\n    A --&gt; |Failure| A1[Test Case Fail: dsHdmiInInit]\n    B --&gt; |Success| C[Validate with value from profile file]\n    B --&gt; |Failure| B1[Test Case Fail : dsGetHdmiVersion]\n    C --&gt; |Success| D[dsHdmiInTerm]\n    C --&gt; |Failure| C1[Test Case Fail]\n    D --&gt; |Success| E[Test Case Success]\n    D --&gt; |Failure| D1[Test Case Fail]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/","title":"dsHdmiIn HAL L3 Python Test Procedure","text":""},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>HAL</code>    - Hardware Abstraction Layer</li> <li><code>L3</code>     - Level 3 Testing</li> <li><code>OEM</code>    - Original Equipment Manufacture</li> <li><code>SoC</code>    - System on a Chip</li> <li><code>HDMI</code>   - High-Definition Multimedia Interface</li> <li><code>SDR</code>    - Standard Dynamic Range</li> <li><code>EDID</code>   - Extended Display Identification Data</li> <li><code>ALLM</code>   - Auto Low Latency Mode</li> <li><code>AVI</code>    - Audio Video Interleave</li> <li><code>SPD</code>    - Source Product Descriptor</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#setting-up-test-environment","title":"Setting Up Test Environment","text":"<p>To execute <code>HAL</code> <code>L3</code> Python test cases, need a Python environment. Follow these steps mentioned in HPK Public Documentation</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#update-configuration-files","title":"Update Configuration Files","text":""},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#rack-configuration-file","title":"Rack Configuration File","text":"<p>Example Rack configuration File: <code>ut/host/tests/configs/example_rack_config.yml</code></p> <p>For more details refer RAFT and example_rack_config.yml</p> <p>In this file, update the configuration to define the console sessions for the <code>DUT</code> and the outbound settings:</p> Console Session Description default Downloads the streams required for test cases ssh_hal_test Executes the <code>HAL</code> binary for the test case <pre><code>rackConfig:\n  - dut:\n      ip: \"XXX.XXX.XXX.XXX\"  # IP Address of the device\n      description: \"tv device under test\"\n      platform: \"tv\"\n      consoles:\n        - default:\n            type: \"ssh\"\n            port: 10022\n            username: \"root\"\n            ip: \"XXX.XXX.XXX\" # IP address of the device\n            password: ' '\n        - ssh_hal_test:\n            type: \"ssh\"\n            port: 10022\n            username: \"root\"\n            ip: \"XXX.XXX.XXX\" # IP address of the device\n            password: ' '\n      outbound:\n        download_url: \"tftp://tftp-server.com/rack1/slot1/\"    # Download location for the CPE device\n        upload_url: \"sftp://server-address/home/workspace/tftp/rack1/slot1/\" # Upload location\n        upload_url_base_dir: \"sftp://server-address/home/workspace/tftp/rack1/slot1\"\n        httpProxy:   # Local proxy if required\n        workspaceDirectory: './logs/workspace'   # Local working directory\n</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#device-configuration-file","title":"Device Configuration File","text":"<p>Example Device configuration File: <code>ut/host/tests/configs/deviceConfig.yml</code></p> <p>For more details refer RAFT and example_device_config.yml</p> <p>Update below fileds in the device configuration file: - Set the folder path for <code>target_directory</code> where <code>HAL</code> binaries will be copied onto the device. - Specify the device profile path in <code>test/profile</code> - Ensure the <code>platform</code> should match with the <code>DUT</code> <code>platform</code> in Rack Configuration</p> <pre><code>deviceConfig:\n  cpe1:\n    platform: \"linux\"    # Must match the platform in example_rack_config.yml\n    model: \"uk\"\n    soc_vendor: \"intel\"\n    target_directory: \"/tmp\"  # Path where HAL binaries are copied in device\n    prompt: \"\" # Prompt string on console\n    test:\n      profile: \"../../../../profiles/sink/Sink_HDMIIN.yaml\"\n      player:\n        tool: \"gstreamer\"\n        prerequisites:\n          - export xxxx    # Pre-commands required to play the stream\n</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#test-setup-configuration-file","title":"Test Setup Configuration File","text":"<p>Example Test Setup configuration File: <code>ut/host/tests/L3_TestCases/dsHdmiIn/dsHdmiIn_L3_testSetup.yml</code></p> <p>If need to enable any commands post test case execution update postcmd.</p> <pre><code>dsHdmiIn:\n  description: \"dsHdmiIn Device Settings test setup\"\n  assets:\n    device:\n      test1_ConnectionCallback_Verify:\n        streams:[]\n      test2_SignalChangeCallback_Verify:\n        streams:[]\n      test14_SetAndGetEDID2ALLMSupport:\n        streams:[]\n</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#test-configuration","title":"Test Configuration","text":"<p>Example Test Setup configuration File: <code>ut/host/tests/dsClasses/dsHdmiIn_testConfig.yml</code></p> <p>Update the execute command according to the device path where <code>HAL</code> binaries are copied.</p> <pre><code>dsHdmiIn:\n  description: \"dsHdmiIn Device Settings testing profile\"\n  test:\n    artifacts:\n            - \"../../../bin/\"\n    execute: \"run.sh\"\n    type: UT-C  # Cunit tests (UT-C)\n</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#run-test-cases","title":"Run Test Cases","text":"<p>Once the environment is set up, you can execute the test cases with the following command</p> <pre><code>python &lt;TestCaseName.py&gt; --config &lt;/PATH&gt;/ut/host/tests/configs/example_rack_config.yml --deviceConfig &lt;/PATH&gt;/ut/host/tests/configs/deviceConfig.yml\n</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#test-cases","title":"Test Cases","text":""},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#dshdmiin_test1_connectioncallback_verifypy","title":"dsHdmiIn_test1_ConnectionCallback_Verify.py","text":""},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#platform-support-test01","title":"Platform Support - test01","text":"<ul> <li>Sink</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#user-input-required-test01","title":"User Input Required - test01","text":"<p>Yes: User interaction is necessary to connect and Disconnect the Hdmi In device.(This will be automated later).</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#acceptance-criteria-test01","title":"Acceptance Criteria - test01","text":"<p>Connect the external device and check if dut recognize the event. Disconnect the external device and check if dut recognize the event.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#expected-results-test01","title":"Expected Results - test01","text":"<p>The test registers the event and check for  the event callback.</p> <p>Success Criteria</p> <ul> <li>Device should recognize the connect/Disconnect event.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#test-steps-test01","title":"Test Steps - test01","text":"<ul> <li> <p>Initiate the Test:</p> </li> <li> <p>Select and execute the Python file: <code>dsHdmiIn_test1_ConnectionCallback_Verify.py</code></p> </li> <li> <p>The test will automatically download all required artifacts and streams, copying them to the designated target directory before commencing execution.</p> </li> <li> <p>Device Connect prompt:</p> <p>The test will Request User to connect Source device to Hdmi In port:</p> </li> <li> <p>Question: \"Plug the HDMI cable {port} and Press Enter: (Y/N)\"</p> </li> <li>Press Y if Device is connected/disconnect (this will mark the step as PASS).</li> <li> <p>Press N if user could not connect/disconnect the device (this will mark the step as FAIL).</p> </li> <li> <p>Device Status Confirmation:</p> </li> <li> <p>Test will check if the device status event has reached the device. </p> </li> <li>If event is detected, the step will marked as PASS</li> <li> <p>If event not detected, the step will marked as FAIL</p> </li> <li> <p>Repeat for All Ports:</p> </li> </ul> <p>The test will iterate through all available Hdmi IN ports, connecting/disconnecting device on each one and collecting user feedback accordingly.</p> <ul> <li>Test Conclusion:</li> </ul> <p>Upon receiving user responses for all ports, the test will conclude and present a final result: PASS or FAIL based on the user inputs throughout the test execution.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#dshdmiin_test2_signalchangecallback_verifypy","title":"dsHdmiIn_test2_SignalChangeCallback_Verify.py","text":""},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#platform-supported-test02","title":"Platform Supported - test02","text":"<ul> <li>Sink</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#user-input-required-test02","title":"User Input Required - test02","text":"<ul> <li>Yes: User interaction is necessary to connect the Hdmi In device.(This will be automated later).</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#acceptance-criteria-test02","title":"Acceptance Criteria - test02","text":"<ul> <li>Verify the Signal status.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#expected-results-test02","title":"Expected Results - test02","text":"<ul> <li>The test registers the event and check for signal status event callback.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#test-steps-test02","title":"Test Steps - test02","text":"<ul> <li> <p>Initiate the Test:</p> </li> <li> <p>Select and execute the Python file: <code>dsHdmiIn_test2_SignalChangeCallback_Verify.py</code></p> </li> <li> <p>The test will automatically download all required artifacts and streams, copying them to the designated target directory before commencing execution.</p> </li> <li> <p>Device Connect prompt:</p> <p>The test will prompt the User to connect a Source device:</p> </li> <li> <p>Question: \"connect device to porttype and press Enter (Y/N)\"</p> </li> <li>Press Y if Device is connected (this will mark the step as PASS).</li> <li> <p>Press N if user could not connect the device (this will mark the step as FAIL).</p> </li> <li> <p>Signal Status Confirmation:</p> </li> <li> <p>Test will check if the signal status event has reached the device.</p> </li> <li>If event is detected, the step will marked as PASS</li> <li> <p>If event not detected, the step will marked as FAIL</p> </li> <li> <p>Repeat for All Ports:</p> </li> </ul> <p>The test will iterate through all available Hdmi IN ports, collects signal status accordingly.</p> <ul> <li>Test Conclusion:</li> </ul> <p>Upon receiving user responses for all ports, the test will conclude and present a final result: PASS or FAIL based on the user inputs throughout the test execution.</p> <ul> <li>Completion and Result:</li> </ul> <p>Once all necessary user actions are completed, the test will evaluate the results and display whether the test Passed or Failed.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#dshdmiin_test3_portstatuscallback_verifypy","title":"dsHdmiIn_test3_PortStatusCallback_Verify.py","text":""},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#platform-supported-test03","title":"Platform Supported - test03","text":"<ul> <li>Sink</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#user-input-required-test03","title":"User Input Required - test03","text":"<ul> <li>Yes: User interaction is necessary to connect the Hdmi In device.(This will be automated later).</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#acceptance-criteria-test03","title":"Acceptance Criteria - test03","text":"<ul> <li>Verify the Port status.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#expected-results-test03","title":"Expected Results - test03","text":"<ul> <li>The test registers the event and check for port status event callback.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#test-steps-test03","title":"Test Steps - test03","text":"<ul> <li> <p>Initiate the Test:</p> </li> <li> <p>Select and execute the Python file: <code>dsHdmiIn_test3_PortStatusCallback_Verify.py</code></p> </li> <li> <p>The test will automatically download all required artifacts and streams, copying them to the designated target directory before commencing execution.</p> </li> <li> <p>Device Connect prompt:</p> <p>The test will prompt the User to connect a Source device:</p> </li> <li> <p>Question: \"connect device to porttype and press Enter (Y/N)\"</p> </li> <li>Press Y if Device is connected (this will mark the step as PASS).</li> <li> <p>Press N if user could not connect the device (this will mark the step as FAIL).</p> </li> <li> <p>Port Status Confirmation:</p> </li> <li> <p>Test will check if the port status event has reached the device.</p> </li> <li>If event is detected, the step will marked as PASS</li> <li> <p>If event not detected, the step will marked as FAIL</p> </li> <li> <p>Repeat for All Ports:</p> </li> </ul> <p>The test will iterate through all available Hdmi IN ports, collects port status accordingly.</p> <ul> <li>Test Conclusion:</li> </ul> <p>Upon receiving user responses for all ports, the test will conclude and present a final result: PASS or FAIL based on the user inputs throughout the test execution.</p> <ul> <li>Completion and Result:</li> </ul> <p>Once all necessary user actions are completed, the test will evaluate the results and display whether the test Passed or Failed.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#dshdmiin_test4_videomodechangecallback_verifypy","title":"dsHdmiIn_test4_VideoModeChangeCallback_Verify.py","text":""},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#platform-supported-test04","title":"Platform Supported - test04","text":"<ul> <li>Sink</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#user-input-required-test04","title":"User Input Required - test04","text":"<ul> <li>Yes: User interaction is necessary to connect the Hdmi In device and to change the resolution on connected device(like Fire Tv Stick, Xbox, Hdmi Analyzer).(This will be automated later).</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#acceptance-criteria-test04","title":"Acceptance Criteria - test04","text":"<ul> <li>Verify the video mode status.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#expected-results-test04","title":"Expected Results - test04","text":"<ul> <li>The test registers the event and check for Video mode status event callback.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#test-steps-test04","title":"Test Steps - test04","text":"<ul> <li> <p>Select the test file:  </p> </li> <li> <p>Run the Python script <code>dsHdmiIn_test4_VideoModeChangeCallback_Verify.py</code></p> </li> <li> <p>The test will automatically download all required artifacts and streams, copying them to the designated target directory before commencing execution.</p> </li> <li> <p>Device Connect prompt:</p> <p>The test will prompt the User to connect a Source device:</p> </li> <li> <p>Question: \"connect device to porttype and press Enter (Y/N)\"</p> </li> <li>Press Y if Device is connected (this will mark the step as PASS).</li> <li> <p>Press N if user could not connect the device (this will mark the step as FAIL).</p> </li> <li> <p>Device resolution change prompt:</p> <p>The test will prompt the user to change the resolution on the source device connected to the HDMI In port:</p> </li> <li> <p>Question: \"Change the Resolution on device connected to port_type and then press Enter: (Y/N)\"</p> </li> <li>Press Y if user able to change resolution (this will mark the step as PASS).</li> <li> <p>Press N if user unable to change the resolution  (this will mark the step as FAIL).</p> </li> <li> <p>Video mode Status Confirmation:</p> </li> <li> <p>Test will check if the video mode status event has reached the device.</p> </li> <li>If event is detected, the step will marked as PASS</li> <li> <p>If event not detected, the step will marked as FAIL</p> </li> <li> <p>Repeat for All Ports:</p> </li> </ul> <p>The test will iterate through all available Hdmi IN ports, collects video mode status accordingly.</p> <ul> <li>Test Conclusion:</li> </ul> <p>Upon receiving user responses for all ports, the test will conclude and present a final result: PASS or FAIL based on the user inputs throughout the test execution.</p> <ul> <li>Completion and Result:</li> </ul> <p>Once all necessary user actions are completed, the test will evaluate the results and display whether the test Passed or Failed.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#dshdmiin_test5_allmchangecallback_verifypy","title":"dsHdmiIn_test5_AllmChangeCallback_Verify.py","text":""},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#platform-supported-test05","title":"Platform Supported - test05","text":"<ul> <li>Sink</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#user-input-required-test05","title":"User Input Required - test05","text":"<ul> <li>Yes: User interaction is necessary to connect the Hdmi In device and to enable/disable ALLM on connected device (like Fire Tv Stick, Xbox, Hdmi Analyzer).(This will be automated later).</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#acceptance-criteria-test05","title":"Acceptance Criteria - test05","text":"<ul> <li>Verify the ALLM status.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#expected-results-test05","title":"Expected Results - test05","text":"<ul> <li>The test registers the event and check for ALLM change event callback</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#test-steps-test05","title":"Test Steps - test05","text":"<ul> <li> <p>Select the test file:</p> </li> <li> <p>Run the Python script <code>dsHdmiIn_test5_AllmChangeCallback_Verify.py</code></p> </li> <li> <p>The test will automatically download all required artifacts and streams, copying them to the designated target directory before commencing execution.</p> </li> <li> <p>Device Connect prompt:</p> <p>The test will prompt the User to connect a Source device:</p> </li> <li> <p>Question: \"connect device to porttype and press Enter (Y/N)\"</p> </li> <li>Press Y if Device is connected (this will mark the step as PASS).</li> <li> <p>Press N if user could not connect the device (this will mark the step as FAIL).</p> </li> <li> <p>Device ALLM change prompt:</p> <p>The test will prompt the user to enable or disable ALLM:</p> </li> <li> <p>Question: \"Change ALLM mode on Hdmi In device connected to port to enable ALLM if its in OFF and press Enter: (Y/N)\"</p> </li> <li>Press Y if user able to enable the ALLM feature (this will mark the step as PASS).</li> <li> <p>Press N if user unable to enable ALLM feature  (this will mark the step as FAIL).</p> </li> <li> <p>Question: \"Change ALLM mode on Hdmi In device connected to port to disable ALLM and press Enter: (Y/N)\"</p> </li> <li>Press Y if user able to disable the ALLM feature (this will mark the step as PASS).</li> <li> <p>Press N if user unable to disable ALLM feature  (this will mark the step as FAIL).</p> </li> <li> <p>ALLM enable/disable Status Confirmation:</p> </li> <li> <p>Test will check if the ALLM change event has reached the device.</p> </li> <li>If event is detected, the step will marked as PASS</li> <li> <p>If event not detected, the step will marked as FAIL</p> </li> <li> <p>Repeat for All Ports:</p> </li> </ul> <p>The test will iterate through all available Hdmi IN ports, collects ALLM status status accordingly.</p> <ul> <li>Test Conclusion:</li> </ul> <p>Upon receiving user responses for all ports, the test will conclude and present a final result: PASS or FAIL based on the user inputs throughout the test execution.</p> <ul> <li>Completion and Result:</li> </ul> <p>Once all necessary user actions are completed, the test will evaluate the results and display whether the test Passed or Failed.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#dshdmiin_test6_avlatencycallback_verifypy","title":"dsHdmiIn_test6_AVlatencyCallback_Verify.py","text":""},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#platform-supported-test06","title":"Platform Supported - test06","text":"<ul> <li>Sink</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#user-input-required-test06","title":"User Input Required - test06","text":"<ul> <li>Yes: User interaction is necessary to connect the Hdmi In device on ports (like Xbox) and play the games.(This will be    automated later).</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#acceptance-criteria-test06","title":"Acceptance Criteria - test06","text":"<ul> <li>Verify the audio video latency.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#expected-results-test06","title":"Expected Results - test06","text":"<ul> <li>The test registers the event and check for audio video latency event callback.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#test-steps-test06","title":"Test Steps - test06","text":"<ul> <li> <p>Select the test file:</p> </li> <li> <p>Run the Python script <code>dsHdmiIn_test6_AVlatencyCallback_Verify.py</code></p> </li> <li>The test will automatically download all required artifacts and streams, copying them to the designated target directory before commencing execution.</li> <li> <p>Device Connect prompt:</p> <p>The test will prompt the User to connect a Source device:</p> </li> <li> <p>Question: \"connect device to porttype and press Enter (Y/N)\"</p> </li> <li>Press Y if Device is connected (this will mark the step as PASS).</li> <li> <p>Press N if user could not connect the device (this will mark the step as FAIL).</p> </li> <li> <p>Audio Video latency Confirmation:</p> </li> <li> <p>Test will check if the audio video latency event has reached the device.</p> </li> <li>If event is detected, the step will marked as PASS</li> <li> <p>If event not detected, the step will marked as FAIL</p> </li> <li> <p>Repeat for All Ports:</p> </li> </ul> <p>The test will iterate through all available Hdmi IN ports, collects audio video latency status accordingly.</p> <ul> <li>Test Conclusion:</li> </ul> <p>Upon receiving user responses for all ports, the test will conclude and present a final result: PASS or FAIL based on the user inputs throughout the test execution.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#dshdmiin_test7_avichangecallback_verifypy","title":"dsHdmiIn_test7_AVIChangeCallback_Verify.py","text":""},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#platform-supported-test07","title":"Platform Supported - test07","text":"<ul> <li>Sink</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#user-input-required-test07","title":"User Input Required - test07","text":"<ul> <li>Yes: User interaction is necessary to connect the Hdmi In device and to change the AVI content on connected device (lik   e Hdmi Analyzer) and change the content type like Cinema , Game , Sport.(This will be automated later).</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#acceptance-criteria-test07","title":"Acceptance Criteria - test07","text":"<ul> <li>Verify the AVI content type being played on device.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#expected-results-test07","title":"Expected Results - test07","text":"<ul> <li>The test registers the event and check for AVI content change event callback</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#test-steps-test07","title":"Test Steps - test07","text":"<ul> <li> <p>Select the test file:</p> </li> <li> <p>Run the Python script <code>dsHdmiIn_test7_AVIChangeCallback_Verify.py</code></p> </li> <li> <p>The test will automatically download all required artifacts and streams, copying them to the designated target directory before commencing execution.</p> </li> <li> <p>Device Connect prompt:</p> <p>The test will prompt the User to connect a Source device:</p> </li> <li> <p>Question: \"connect device to porttype and press Enter (Y/N)\"</p> </li> <li>Press Y if Device is connected (this will mark the step as PASS).</li> <li> <p>Press N if user could not connect the device (this will mark the step as FAIL).</p> </li> <li> <p>Device AVI content change prompt:</p> <p>The test will prompt the user to change AVI content on the source device:</p> </li> <li> <p>Question: \"Change the AVI Content on device connected to port and press Enter: (Y/N)\"</p> </li> <li>Press Y if user able to change AVI content (this will mark the step as PASS).</li> <li> <p>Press N if user unable to change the AVI content (this will mark the step as FAIL).</p> </li> <li> <p>AVI content Change Confirmation:</p> </li> <li> <p>Test will check if the AVI content change event has reached the device.</p> </li> <li>If event is detected, the step will marked as PASS</li> <li> <p>If event not detected, the step will marked as FAIL</p> </li> <li> <p>Repeat for All Ports:</p> </li> </ul> <p>The test will iterate through all available Hdmi IN ports, collects AVI content change status accordingly.</p> <ul> <li>Test Conclusion:</li> </ul> <p>Upon receiving user responses for all ports, the test will conclude and present a final result: PASS or FAIL based on the user inputs throughout the test execution.</p> <ul> <li>Completion and Result:</li> </ul> <p>Once all necessary user actions are completed, the test will evaluate the results and display whether the test Passed or Failed.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#dshdmiin_test8_selectportandverifyportstatuspy","title":"dsHdmiIn_test8_SelectPortAndVerifyPortStatus.py","text":""},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#platform-supported-test08","title":"Platform Supported - test08","text":"<ul> <li>Sink</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#user-input-required-test08","title":"User Input Required - test08","text":"<ul> <li>Yes: User interaction is necessary to connect the Hdmi In device to port.(This will be automated later)</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#acceptance-criteria-test08","title":"Acceptance Criteria - test08","text":"<ul> <li>Verify the respective port is selected.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#expected-results-test08","title":"Expected Results - test08","text":"<ul> <li>The test selects the respective port and verify the same.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#test-steps-test08","title":"Test Steps - test08","text":"<ul> <li> <p>Select the test file:</p> </li> <li> <p>Run the Python script <code>dsHdmiIn_test8_SelectPortAndVerifyPortStatus.py</code></p> </li> <li> <p>The test will automatically download all required artifacts and streams, copying them to the designated target directory before commencing execution.</p> </li> <li> <p>Device Connect prompt:</p> <p>The test will prompt the User to connect a Source device:</p> </li> <li> <p>Question: \"connect device to porttype and press Enter (Y/N)\"</p> </li> <li>Press Y if Device is connected (this will mark the step as PASS).</li> <li> <p>Press N if user could not connect the device (this will mark the step as FAIL).</p> </li> <li> <p>Port select Confirmation:</p> </li> <li> <p>Test will check the status of the port selected.</p> </li> <li>If port selected and supplied port argument are same then mark the step as PASS</li> <li> <p>If  port selected and supplied port argument are not same then  mark the step as FAIL</p> </li> <li> <p>Repeat for All Ports:</p> </li> </ul> <p>The test will iterate through all available Hdmi IN ports, verify port status accordingly.</p> <ul> <li>Test Conclusion:</li> </ul> <p>Upon receiving user responses for all ports, the test will conclude and present a final result: PASS or FAIL based on the user inputs throughout the test execution.</p> <ul> <li>Completion and Result:</li> </ul> <p>Once all necessary user actions are completed, the test will evaluate the results and display whether the test Passed or Failed.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#dshdmiin_test9_scalevideoandverifypy","title":"dsHdmiIn_test9_ScaleVideoAndVerify.py","text":""},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#platform-supported-test09","title":"Platform Supported - test09","text":"<ul> <li>Sink</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#user-input-required-test09","title":"User Input Required - test09","text":"<ul> <li>Yes: User interaction is necessary to connect the Hdmi In device and to verify the video scaling on connected device.(This will be automated later).</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#acceptance-criteria-test09","title":"Acceptance Criteria - test09","text":"<ul> <li>Verify the video scaled on selected port.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#expected-results-test09","title":"Expected Results - test09","text":"<ul> <li>The test selects the respective port and scales video.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#test-steps-test09","title":"Test Steps - test09","text":"<ul> <li> <p>Select the test file:</p> </li> <li> <p>Run the Python script <code>dsHdmiIn_test9_ScaleVideoAndVerify.py</code></p> </li> <li> <p>The test will automatically download all required artifacts and streams, copying them to the designated target directory before commencing execution.</p> </li> <li> <p>Device Connect prompt:</p> <p>The test will prompt the User to connect a Source device:</p> </li> <li> <p>Question: \"connect device to porttype and press Enter (Y/N)\"</p> </li> <li>Press Y if Device is connected (this will mark the step as PASS).</li> <li> <p>Press N if user could not connect the device (this will mark the step as FAIL).</p> </li> <li> <p>Video scaling Confirmation:     The test will Request User to check video scaled on particular port or not:</p> </li> <li> <p>Question: \"Check if video is scaled  on port port_type. Press Y/N:\"</p> </li> <li>Press Y if video scaling on the specified port is successful (this will mark the step as PASS).</li> <li> <p>Press N if video scaled on the sepcified port not successful (this will mark the step as FAIL).</p> </li> <li> <p>Repeat for All Ports:</p> </li> </ul> <p>The test will iterate through all available Hdmi IN ports, verify video scaling accordingly.</p> <ul> <li>Test Conclusion:</li> </ul> <p>Upon receiving user responses for all ports, the test will conclude and present a final result: PASS or FAIL based on the user inputs throughout the test execution.</p> <ul> <li>Completion and Result:</li> </ul> <p>Once all necessary user actions are completed, the test will evaluate the results and display whether the test Passed or Failed.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#dshdmiin_test10_zoommodeandverifypy","title":"dsHdmiIn_test10_ZoomModeAndVerify.py","text":""},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#platform-supported-test10","title":"Platform Supported - test10","text":"<ul> <li>Source </li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#user-input-required-test10","title":"User Input Required - test10","text":"<ul> <li>Yes: User interaction is necessary to connect the Hdmi In device and to verify the video scaling on connected device.(This will be automated later).</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#acceptance-criteria-test10","title":"Acceptance Criteria - test10","text":"<ul> <li>Verify the zoom mode on selected port.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#expected-results-test10","title":"Expected Results - test10","text":"<ul> <li>The test selects the respective port and sets zoom mode.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#test-steps-test10","title":"Test Steps - test10","text":"<ul> <li> <p>Select the test file:</p> </li> <li> <p>Run the Python script <code>dsHdmiIn_test10_ZoomModeAndVerify.py</code></p> </li> <li> <p>The test will automatically download all required artifacts and streams, copying them to the designated target directory before commencing execution.</p> </li> <li> <p>Device Connect prompt:</p> <p>The test will prompt the User to connect a Source device:</p> </li> <li> <p>Question: \"connect device to porttype and press Enter (Y/N)\"</p> </li> <li>Press Y if Device is connected (this will mark the step as PASS).</li> <li> <p>Press N if user could not connect the device (this will mark the step as FAIL).</p> </li> <li> <p>Zoom Mode set Confirmation:     The test will Request User to check particular zoom mode is set on particular port or not:</p> </li> <li> <p>Question: \"Verify Zoom Mode selected on port {port_type} and press Enter: Y/N\"</p> </li> <li>Press Y if zoom mode ablet to set on particular port happen (this will mark the step as PASS).</li> <li> <p>Press N if unable to set zoom mode on particular port not happen (this will mark the step as FAIL).</p> </li> <li> <p>Repeat for All Ports:</p> </li> </ul> <p>The test will iterate through all available Hdmi IN ports, verify zoom mode set accordingly.</p> <ul> <li>Test Conclusion:</li> </ul> <p>Upon receiving user responses for all ports, the test will conclude and present a final result: PASS or FAIL based on the user inputs throughout the test execution.</p> <ul> <li>Completion and Result:</li> </ul> <p>Once all necessary user actions are completed, the test will evaluate the results and display whether the test Passed or Failed.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#dshdmiin_test11_getedidinfo_verifypy","title":"dsHdmiIn_test11_GetEDIDInfo_Verify.py","text":""},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#platform-supported-test11","title":"Platform Supported - test11","text":"<ul> <li>Sink</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#user-input-required-test11","title":"User Input Required - test11","text":"<ul> <li>NO</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#acceptance-criteria-test11","title":"Acceptance Criteria - test11","text":"<ul> <li>Get and verify EDID info.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#expected-results-test11","title":"Expected Results - test11","text":"<ul> <li>The test get EDID info and verifies the info.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#test-steps-test11","title":"Test Steps - test11","text":"<ul> <li>Run the Python script <code>dsHdmiIn_test11_GetEDIDInfo_Verify.py</code></li> <li>The test will automatically download all required artifacts and streams, copying them to the designated target directory before commencing execution.</li> <li> <p>Edid Info Confirmation:</p> </li> <li> <p>Test will get the EDID info and verifies the same.</p> </li> <li>If EDID info is received, it will be compared with the YAML EDID info bytes. If they match, the step will be marked as PASS</li> <li> <p>If EDID info is received, it will be compared with the YAML EDID info bytes. If they does not match, the step will be marked as FAIL</p> </li> <li> <p>Repeat for All Ports:</p> </li> </ul> <p>The test will iterate through all available Hdmi IN ports, gets EDID and verifies.</p> <ul> <li>Test Conclusion:</li> </ul> <p>Upon receiving user responses for all ports, the test will conclude and present a final result: PASS or FAIL based on the user inputs throughout the test execution.</p> <ul> <li>Completion and Result:</li> </ul> <p>Once all necessary user actions are completed, the test will evaluate the results and display whether the test Passed or Failed.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#dshdmiin_test12_getspdinfo_verifypy","title":"dsHdmiIn_test12_GetSpdInfo_Verify.py","text":""},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#platform-supported-test12","title":"Platform Supported - test12","text":"<ul> <li>Sink</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#user-input-required-test12","title":"User Input Required - test12","text":"<ul> <li>Yes: User interaction is necessary to connect the Hdmi In device to port like Hdmi Quantum Data Analyzer.(This will be    automated later).</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#acceptance-criteria-test12","title":"Acceptance Criteria - test12","text":"<ul> <li>Gets SPD Info and verifies the same.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#expected-results-test12","title":"Expected Results - test12","text":"<p>This test evaluates the SPD Info received from connected device.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#test-steps-test12","title":"Test Steps - test12","text":"<ul> <li>Run the Python script <code>dsHdmiIn_test12_GetSpdInfo_Verify.py</code></li> <li> <p>The test will automatically download all required artifacts and streams, copying them to the designated target directory before commencing execution.</p> </li> <li> <p>Device Connect prompt:</p> <p>The test will prompt the User to connect a Source device:</p> </li> <li> <p>Question: \"connect device to porttype and press Enter (Y/N)\"</p> </li> <li>Press Y if Device is connected (this will mark the step as PASS).</li> <li> <p>Press N if user could not connect the device (this will mark the step as FAIL).</p> </li> <li> <p>SPD Info Confirmation:</p> </li> <li> <p>Test will get the SPD info and verifies the same.</p> </li> <li>If SPD info is received, it will be compared with the YAML SPD info bytes. If they match, the step will be marked as PASS</li> <li> <p>If SPD info is received, it will be compared with the YAML SPD info bytes. If they does not match, the step will be marked as FAIL</p> </li> <li> <p>Repeat for All Ports:</p> </li> </ul> <p>The test will iterate through all available Hdmi IN ports, gets spdinfo and verifies the same.</p> <ul> <li>Test Conclusion:</li> </ul> <p>Upon receiving user responses for all ports, the test will conclude and present a final result: PASS or FAIL based on the user inputs throughout the test execution.</p> <ul> <li>Completion and Result:</li> </ul> <p>Once all necessary user actions are completed, the test will evaluate the results and display whether the test Passed or Failed.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#dshdmiin_test13_setandgetedidversionpy","title":"dsHdmiIn_test13_SetAndGetEDIDVersion.py","text":""},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#platform-supported-test13","title":"Platform Supported - test13","text":"<ul> <li>Sink</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#user-input-required-test13","title":"User Input Required - test13","text":"<ul> <li>NO</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#acceptance-criteria-test13","title":"Acceptance Criteria - test13","text":"<ul> <li>Verify EDID version by retrieving.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#expected-results-test13","title":"Expected Results - test13","text":"<p>This test set EDID version and verifies the same by retrieving the EDID version.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#test-steps-test13","title":"Test Steps - test13","text":"<ul> <li>Run the Python script <code>dsHdmiIn_test13_SetAndGetEDIDVersion.py</code></li> <li>The test will automatically download all required artifacts and streams, copying them to the designated target directory before commencing execution.</li> <li> <p>EDID version Verification:</p> </li> <li> <p>Test will sets and get the EDID version.</p> </li> <li>If the set and retrieved EDID versions are the same, the test will mark the step as PASS.</li> <li> <p>If the set and retrieved EDID versions do not match, the test will mark the step as FAIL.</p> </li> <li> <p>Repeat for All Ports:</p> </li> </ul> <p>The test will iterate through all available Hdmi IN ports, sets EDID version and verifies by retrieving EDID version.</p> <ul> <li>Test Conclusion:</li> </ul> <p>Upon receiving user responses for all ports, the test will conclude and present a final result: PASS or FAIL based on the user inputs throughout the test execution.</p> <ul> <li>Completion and Result:</li> </ul> <p>Once all necessary user actions are completed, the test will evaluate the results and display whether the test Passed or Failed.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#dshdmiin_test14_setandgetedid2allmsupportpy","title":"dsHdmiIn_test14_SetAndGetEDID2ALLMSupport.py","text":""},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#platform-supported-test14","title":"Platform Supported - test14","text":"<ul> <li>Sink</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#user-input-required-test14","title":"User Input Required - test14","text":"<ul> <li>NO</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#acceptance-criteria-test14","title":"Acceptance Criteria - test14","text":"<ul> <li>Verify ALLM by retrieving.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#expected-results-test14","title":"Expected Results - test14","text":"<p>This test set ALLM and verifies the same by retrieving the ALLM.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#test-steps-test14","title":"Test Steps - test14","text":"<ul> <li>Run the Python script <code>dsHdmiIn_test14_SetAndGetEDID2ALLMSupport.py</code></li> <li>The test will automatically download all required artifacts and streams, copying them to the designated target directory before commencing execution.</li> <li> <p>ALLM version Verification:</p> </li> <li> <p>Test will sets and get the ALLM.</p> </li> <li>If the set and retrieved ALLM support statuses match, the test will mark the step as PASS.</li> <li> <p>If the set and retrieved ALLM support statuses do not match, the test will mark the step as FAIL.</p> </li> <li> <p>Repeat for All Ports:</p> </li> </ul> <p>The test will iterate through all available Hdmi IN ports, sets ALLM and verifies by retrieving ALLM.</p> <ul> <li>Test Conclusion:</li> </ul> <p>Upon receiving user responses for all ports, the test will conclude and present a final result: PASS or FAIL based on the user inputs throughout the test execution.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHDMIIn/ds-hdmi-in_L3_Test-Procedure/#dshdmiin_l3_runall_sinkpy","title":"dsHdmiIn_L3_Runall_Sink.py","text":"<p>This python file runs all the tests supported by <code>sink</code> devices</p> <p>```bash python dsHdmiIn_L3_Runall_Sink.py --config /PATH/ut/host/tests/configs/example_rack_config.yml --deviceConfig /PATH/ut/host/tests/configs/deviceConfig.yml</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHost/ds-host_High-Level_TestSpecification/","title":"Device Settings Host High Level Test Specification Document","text":""},{"location":"external_content/device_settings_test/docs/pages/dsHost/ds-host_High-Level_TestSpecification/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>SoC</code>    - System On a Chip</li> <li><code>EDID</code>   - Extended Display Identification</li> <li><code>API</code>    - Application programming interface</li> <li><code>CPU</code>    - Central processing unit</li> <li><code>dsHost</code> - Device Settings Host</li> <li><code>HDMI</code>   - High-Definition Multimedia Interface</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHost/ds-host_High-Level_TestSpecification/#references","title":"References","text":"<ul> <li><code>EDID</code> specifications - https://en.wikipedia.org/wiki/Extended_Display_Identification_Data</li> <li>Python <code>EDID</code> decoder library is available here - https://pypi.org/project/pyedid/</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHost/ds-host_High-Level_TestSpecification/#introduction","title":"Introduction","text":"<p>This document provides an overview of the testing requirements for the <code>dsHost</code> module. It outlines the scope of testing, objectives, testing levels and approaches, specific test requirements, and expected deliverables.</p> <p>Interface of the test is available in this link - https://github.com/rdkcentral/rdk-halif-device_settings/blob/main/include/dsHost.h</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHost/ds-host_High-Level_TestSpecification/#module-description","title":"Module Description","text":"<p>High level overview:</p> <ul> <li><code>dsHost</code> offers a range of <code>API</code>s for retrieving information about the platform.</li> <li>Data is retrieved from the <code>SoC</code> and <code>HDMI</code>. This data is passed to the caller.</li> <li>In order to retrieve <code>HDMI</code> information, an external device must be connected.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHost/ds-host_High-Level_TestSpecification/#testing-scope","title":"Testing Scope","text":"# Testing Scope Description 1 Retrieve CPU Temperature Test if the module correctly retrieves the <code>CPU</code> temperature. 2 Obtain SOC ID Test if the module successfully obtains the 8-byte <code>SoC</code> ID programmed to the CHIP One Time Programmable area. 3 Fetch Host EDID Test if the module fetches the host <code>EDID</code> along with its length -----------"},{"location":"external_content/device_settings_test/docs/pages/dsHost/ds-host_High-Level_TestSpecification/#retrieve-cpu-temperature","title":"Retrieve CPU Temperature","text":"Description HAL APIs L2 L3 Source Sink Control plane requirements Get the CPU temperature and check weather the temperature falls within valid operating range and ensure the <code>CPU</code> is in a normal operating state based on maximum and minimum values of <code>dsHost/cpuTemperature</code> in the configuration yaml <code>dsGetCPUTemperature</code> Y N Y Y N Invoke the module to retrieve <code>CPU</code> temperature while the device is within a heat/cold chambers to verify that the device will properly retrieve the information <code>dsGetCPUTemperature</code> N Y Y Y Y"},{"location":"external_content/device_settings_test/docs/pages/dsHost/ds-host_High-Level_TestSpecification/#test-startup-requirement-retrieve-cpu-temperature","title":"Test Startup Requirement - Retrieve CPU Temperature","text":"<p>None</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHost/ds-host_High-Level_TestSpecification/#emulator-requirement-retrieve-cpu-temperature","title":"Emulator Requirement - Retrieve CPU Temperature","text":"<p>None</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHost/ds-host_High-Level_TestSpecification/#control-plane-requirement-retrieve-cpu-temperature","title":"Control Plane Requirement - Retrieve CPU Temperature","text":"<p>Control external heat/cold chambers</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHost/ds-host_High-Level_TestSpecification/#obtain-soc-id","title":"Obtain SoC ID","text":"Description HAL APIs L2 L3 Source Sink Control plane requirements Get the <code>SoC</code> ID and verify with <code>dsHost/socID</code> value in configuration yaml file. <code>dsGetSocIDFromSDK</code> Y N Y Y N"},{"location":"external_content/device_settings_test/docs/pages/dsHost/ds-host_High-Level_TestSpecification/#test-startup-requirement-obtain-soc-id","title":"Test Startup Requirement-Obtain SoC ID","text":"<p>None</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHost/ds-host_High-Level_TestSpecification/#emulator-requirement-obtain-soc-id","title":"Emulator Requirement-Obtain SoC ID","text":"<p>None</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHost/ds-host_High-Level_TestSpecification/#control-plane-requirement-obtain-soc-id","title":"Control Plane Requirement-Obtain SoC ID","text":"<p>None</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHost/ds-host_High-Level_TestSpecification/#fetch-host-edid","title":"Fetch Host EDID","text":"Description HAL APIs L2 L3 Source Sink Control plane requirements Get the host <code>EDID</code> bytes and validate the <code>EDID</code> bytes and length with the <code>dsHost/edidBytes</code> and <code>dsHost/edidbytesLength</code> values from the configuration yaml file <code>dsGetHostEDID</code> Y N N Y N"},{"location":"external_content/device_settings_test/docs/pages/dsHost/ds-host_High-Level_TestSpecification/#test-startup-requirement-fetch-host-edid","title":"Test Startup Requirement - Fetch Host EDID","text":"<p>Launch the test with the predefined configuration set of results.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHost/ds-host_High-Level_TestSpecification/#emulator-requirement-fetch-host-edid","title":"Emulator Requirement - Fetch Host EDID","text":"<p>Emulator will boot with the <code>EDID</code> coming from the configuration file.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHost/ds-host_High-Level_TestSpecification/#control-plane-requirement-fetch-host-edid","title":"Control Plane Requirement - Fetch Host EDID","text":"<p>None</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHost/ds-host_L2_Low-Level_TestSpecification/","title":"Device Settings Host L2 Low Level Test Specification and Procedure Documentation","text":""},{"location":"external_content/device_settings_test/docs/pages/dsHost/ds-host_L2_Low-Level_TestSpecification/#overview","title":"Overview","text":"<p>This document describes the Low Level L2 Test Specification and Procedure for the Device Settings Host module.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHost/ds-host_L2_Low-Level_TestSpecification/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>HAL</code> - Hardware Abstraction Layer, may include some common components</li> <li><code>UT</code>  - Unit Test(s)</li> <li><code>SoC</code>  - System on a Chip</li> <li><code>EDID</code> - Extended Display Identification</li> <li><code>CPU</code> - Central processing unit</li> <li><code>dsHost</code> - Device Settings Host</li> <li><code>API</code> - Application programming interface</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHost/ds-host_L2_Low-Level_TestSpecification/#definitions","title":"Definitions","text":"<ul> <li><code>ut-core</code> - Common Testing Framework https://github.com/rdkcentral/ut-core, which wraps a open-source framework that can be expanded to the requirements for future framework.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHost/ds-host_L2_Low-Level_TestSpecification/#references","title":"References","text":"<ul> <li><code>High Level Test Specification</code> - dsHost_TestSpecification.md</li> <li><code>HAL Interface Header File</code> - dsHost.h</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHost/ds-host_L2_Low-Level_TestSpecification/#level-2-test-procedure","title":"Level 2 Test Procedure","text":"<p>The following functions are expecting to test the module operates correctly.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHost/ds-host_L2_Low-Level_TestSpecification/#test-1","title":"Test 1","text":"Title Details Function Name <code>test_l2_dsHost_GetCPUTemperature</code> Description Get the <code>CPU</code> temperature and check whether the temperature falls within valid operating range and ensure the <code>CPU</code> is in a normal operating state based on maximum and minimum values of <code>dsHost/cpuTemperature</code> in the configuration file Test Group 02 Test Case ID 001 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHost/ds-host_L2_Low-Level_TestSpecification/#test-procedure-test-1","title":"Test Procedure - Test 1","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the host using <code>dsHostInit</code> No input parameters <code>dsERR_NONE</code> Should be successful 02 Get the <code>CPU</code> temperature using <code>dsGetCPUTemperature</code> cpuTemperature = valid buffer <code>dsERR_NONE</code> Should be successful 03 Check the <code>CPU</code> temperature against the profile cpuTemperature = obtained value, profile temperature range = <code>dsHost/cpuTemperature</code> of configuration file Value should fall in the expected range Should be successful 04 Terminate the host using <code>dsHostTerm</code> No input parameters <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\nA[Call dsHostInit API] --&gt;|return status is dsERR_NONE|B[Call dsGetCPUTemperature API]\nA --&gt;|return status is not dsERR_NONE|A1[Test case fail]\nB --&gt;|return status is dsERR_NONE|C[Check cpuTemperature value &lt;br&gt; with profile value]\nB --&gt;|return status is not dsERR_NONE|B1[Test case fail]\nC --&gt;|cpuTemperature is within valid range|D[Call dsHostTerm API]\nC --&gt;|cpuTemperature is out of valid range|C1[Test case fail]\nD --&gt;|return status is dsERR_NONE|E[Test case success]\nD --&gt;|return status is not dsERR_NONE|D1[Test case fail]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsHost/ds-host_L2_Low-Level_TestSpecification/#test-2","title":"Test 2","text":"Title Details Function Name <code>test_l2_dsHost_GetAndVerifySocID</code> Description Get the <code>SoC</code> ID and verify with <code>dsHost/socID</code> value in configuration file Test Group 02 Test Case ID 002 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHost/ds-host_L2_Low-Level_TestSpecification/#test-procedure-test-2","title":"Test Procedure - Test 2","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the host using <code>dsHostInit</code> <code>API</code> No input parameters <code>dsERR_NONE</code> Should be successful 02 Get the <code>SoC</code> ID using <code>dsGetSocIDFromSDK</code> <code>API</code> socID = valid buffer <code>dsERR_NONE</code> Should be successful 03 Verify the <code>SoC</code> ID with the value in the configuration file socID = value from <code>dsHost/socID</code> of configuration file <code>dsERR_NONE</code> Should be successful 04 Terminate the host using <code>dsHostTerm</code> <code>API</code> No input parameters <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\nA[Call dsHostInit API] --&gt;|dsERR_NONE|B[Call dsGetSocIDFromSDK API]\nA --&gt;|Failure|A1[Test case fail]\nB --&gt;|dsERR_NONE|D[Compare SoC ID with socID &lt;br&gt; from sink configuration file]\nB --&gt;|Failure|B1[Test case fail]\nD --&gt;|Match|E[Call dsHostTerm API]\nD --&gt;|No Match|D1[Test case fail]\nE --&gt;|dsERR_NONE|F[Test case success]\nE --&gt;|Failure|E1[Test case fail]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsHost/ds-host_L2_Low-Level_TestSpecification/#test-3","title":"Test 3","text":"Title Details Function Name <code>test_l2_dsHost_ValidateHostEDID_sink</code> Description Get the host <code>EDID</code> bytes and validate the <code>EDID</code> bytes and length with the <code>dsHost/edidBytes</code> and <code>dsHost/edidbytesLength</code> values from the configuration file Test Group 02 Test Case ID 003 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHost/ds-host_L2_Low-Level_TestSpecification/#test-procedure-test-3","title":"Test Procedure - Test 3","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the host using <code>dsHostInit</code> No input parameters <code>dsERR_NONE</code> Should be successful 02 Get the host <code>EDID</code> using <code>dsGetHostEDID</code> edid = valid buffer, length = valid pointer <code>dsERR_NONE</code> Should be successful 03 Validate the <code>EDID</code> bytes and length edid = retrieved <code>EDID</code> from <code>dsHost/edidBytes</code> of configuration file, length = retrieved length from <code>dsHost/edidbytesLength</code> of configuration file edidBytes and edidbytesLength from configuration file matches Should be successful 04 Terminate the host using <code>dsHostTerm</code> No input parameters <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\nA[Call dsHostInit API] --&gt;|Success: dsERR_NONE|B[Call dsGetHostEDID API]\nA --&gt;|Failure: Not dsERR_NONE|A1[Test case fail]\nB --&gt;|Success: dsERR_NONE and &lt;br&gt; valid edid, length|C[Validate EDID bytes and length with &lt;br&gt; values from configuration file]\nB --&gt;|Failure: Not dsERR_NONE or &lt;br&gt; invalid edid, length|B1[Test case fail]\nC --&gt;|Success: Values match|D[Call dsHostTerm API]\nC --&gt;|Failure: Values don't match|C1[Test case fail]\nD --&gt;|Success: dsERR_NONE|E[Test case success]\nD --&gt;|Failure: Not dsERR_NONE|D1[Test case fail]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsHost/ds-host_L3_Low-Level_TestSpec/","title":"Device Settings Host L3 Low Level Test Specification and Procedure Documentation","text":""},{"location":"external_content/device_settings_test/docs/pages/dsHost/ds-host_L3_Low-Level_TestSpec/#overview","title":"Overview","text":"<p>This document describes the L3 Low Level Test Specification and Procedure Documentation for the Device Settings Host module.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHost/ds-host_L3_Low-Level_TestSpec/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>HAL</code> - Hardware Abstraction Layer, may include some common components</li> <li><code>UT</code>  - Unit Test(s)</li> <li><code>OEM</code> - Original Equipment Manufacture</li> <li><code>SoC</code> - System on a Chip</li> <li><code>Y</code>   - yes supported</li> <li><code>NA</code>  - Not Supported</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHost/ds-host_L3_Low-Level_TestSpec/#references","title":"References","text":"<ul> <li><code>High Level Test Specification</code> - dsHost_TestSpecification.md</li> <li><code>HAL Interface Header File</code> - dsHost.h</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHost/ds-host_L3_Low-Level_TestSpec/#level-3-test-cases-high-level-overview","title":"Level 3 Test Cases High Level Overview","text":"<p>Each test case need to verify with the each supported video port. Below are top test use-case for the video port.</p> # Test-case Description HAL APIs Source Sink 1 Verify that the get temperature function After the device is running for sometime, call getTemperature, and call it after a five minute wait. The two temperatures should not see any noticable changes in temperature <code>dsGetCPUTemperature()</code> <code>Y</code> <code>Y</code>"},{"location":"external_content/device_settings_test/docs/pages/dsHost/ds-host_L3_Low-Level_TestSpec/#level-3-python-test-cases-high-level-overview","title":"Level 3 Python Test Cases High Level Overview","text":"<p>The class diagram below illustrates the flow of dsHost L3 Python test cases:</p> <pre><code>---\ntitle: dsHost - Python Class Flow\n---\nclassDiagram\n    testControl &lt;|-- ut_raft : inherits\n    class ut_raft{\n    }\n    ut_raft &lt;|-- L3_TestClasses : inherits\n    L3_TestClasses ..&gt; dsHost : uses\n    note for testControl \"uses rackConfig.yaml and deviceConfig.yaml\"\n    note for dsHost \"uses platformProfile.yaml\"\n    note for L3_TestClasses \"uses testSetupConfig.yaml\"\n    note for ut_raft \"suite Navigator uses testSuite.yaml\"</code></pre> <ul> <li>testControl</li> <li>Test Control Module for running rack Testing. This module configures the <code>DUT</code> based on the rack configuration file provided to the test.</li> <li>This class is defined in <code>RAFT</code> framework. For more details refer RAFT</li> <li>ut_raft</li> <li>Python based testing framework for writing engineering tests.</li> <li>It provides common functionalities like menu navigation, configuration reader, reading user response etc.</li> <li>For more details ut-raft.</li> <li>dsHost</li> <li>This is test helper class which communicates with the <code>L3</code> C/C++ test running on the <code>DUT</code> through menu</li> <li>L3_TestClasses</li> <li>These are the L3 test case classes</li> <li>Each class covers the each test use-case defined in L3 Test use-cases table</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHost/ds-host_L3_Low-Level_TestSpec/#yaml-file-inputs","title":"YAML File Inputs","text":"<ul> <li>rackConfig.yaml</li> <li>Identifies the rack configuration and platform used</li> <li>References platform-specific config from <code>deviceConfig.yaml</code></li> <li> <p>For more details refer RAFT and example_rack_config.yml</p> </li> <li> <p>deviceConfig.yaml</p> </li> <li>Specifies overall configuration for the platform</li> <li>Can be overridden by:<ul> <li>Changing locally .yaml file directory</li> <li>Using --deviceConfig command line switch</li> </ul> </li> <li>For more details refer RAFT and example_device_config.yml</li> </ul> <p>componentProfile.yaml/platformProfile.yaml   - Contains component-specific configurations   - Contains platform wide configuration broken down into separate components   - Example configuration file dsHost_Settings</p> <ul> <li>testSetupConfig.yaml</li> <li>This configuration file contains the list of requirements for tests to execute. Eg: Copying the streams, setting environment variables etc.</li> <li> <p>Example configuration file dsHost_L3_testSetup.yml</p> </li> <li> <p>testSuite.yaml</p> </li> <li>This configuration file contains the list of menu items for C/C++ L3 test running on <code>DUT</code></li> <li>Example configuration file dsHost_testConfig.yml</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHost/ds-host_L3_TestProcedure/","title":"dsHost HAL L3 Python Test Procedure","text":""},{"location":"external_content/device_settings_test/docs/pages/dsHost/ds-host_L3_TestProcedure/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>HAL</code>    - Hardware Abstraction Layer</li> <li><code>L3</code>     - Level 3 Testing</li> <li><code>DUT</code>    - Device Under Test</li> <li><code>RAFT</code>   - Rapid Automation Framework for Testing</li> <li><code>YAML</code>   - YAML Ain't Markup Language</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHost/ds-host_L3_TestProcedure/#setting-up-test-environment","title":"Setting Up Test Environment","text":"<p>To execute <code>HAL</code> <code>L3</code> Python test cases, need a Python environment. Follow these steps mentioned in HPK Public Documentation</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHost/ds-host_L3_TestProcedure/#update-configuration-files","title":"Update Configuration Files","text":""},{"location":"external_content/device_settings_test/docs/pages/dsHost/ds-host_L3_TestProcedure/#rack-configuration-file","title":"Rack Configuration File","text":"<p>Example Rack configuration File: example_rack_config.yml</p> <p>For more details refer RAFT and example_rack_config.yml</p> <p>In this file, update the configuration to define the console sessions for the <code>DUT</code> and the outbound settings:</p> Console Session Description default Downloads the streams required for test cases ssh_player Plays the stream required for test case ssh_player_secondary Plays a secondary stream, if required for test case ssh_hal_test Executes the <code>HAL</code> binary for the test case <pre><code>rackConfig:\n  - dut:\n      ip: \"XXX.XXX.XXX.XXX\"  # IP Address of the device\n      description: \"stb device under test\"\n      platform: \"stb\"\n      consoles:\n        - default:\n            type: \"ssh\"\n            port: 10022\n            username: \"root\"\n            ip: \"XXX.XXX.XXX\" # IP address of the device\n            password: ' '\n        - ssh_player:\n            type: \"ssh\"\n            port: 10022\n            username: \"root\"\n            ip: \"XXX.XXX.XXX\" # IP address of the device\n            password: ' '\n        - ssh_player_secondary:\n            type: \"ssh\"\n            port: 10022\n            username: \"root\"\n            ip: \"XXX.XXX.XXX\" # IP address of the device\n            password: ' '\n        - ssh_hal_test:\n            type: \"ssh\"\n            port: 10022\n            username: \"root\"\n            ip: \"XXX.XXX.XXX\" # IP address of the device\n            password: ' '\n      outbound:\n        download_url: \"tftp://tftp-server.com/rack1/slot1/\"    # Download location for the CPE device\n        upload_url: \"sftp://server-address/home/workspace/tftp/rack1/slot1/\" # Upload location\n        upload_url_base_dir: \"sftp://server-address/home/workspace/tftp/rack1/slot1\"\n        httpProxy:   # Local proxy if required\n        workspaceDirectory: './logs/workspace'   # Local working directory\n</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsHost/ds-host_L3_TestProcedure/#device-configuration-file","title":"Device Configuration File","text":"<p>Example Device configuration File: deviceConfig.yml</p> <p>For more details refer RAFT and example_device_config.yml</p> <p>Update the target directory where <code>HAL</code> binaries will be copied into the device. Also, map the profile to the source/sink settings <code>YAML</code> file path.</p> <p>Ensure the platform should match with the <code>DUT</code> platform in Rack Configuration</p> <pre><code>deviceConfig:\n  cpe1:\n    platform: \"stb\"    # Must match the platform in example_rack_config.yml\n    model: \"uk\"\n    target_directory: \"/tmp\"  # Path where HAL binaries are copied in device\n    test:\n      profile: \"../../../../profiles/sink/Sink_HostSettings.yaml\"\n      player:\n        tool: \"gstreamer\"\n        prerequisites:\n          - export xxxx    # Pre-commands required to play the stream\n</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsHost/ds-host_L3_TestProcedure/#test-setup-configuration-file","title":"Test Setup Configuration File","text":"<p>Example Test Setup configuration File: dsHost_L3_testSetup.yml</p> <p>Update the artifact paths from which the binaries should be copied to the device.</p> <p>Set the execution paths for each test case.</p> <pre><code>dsHost:\n  description: \"dsHost Device Settings test setup\"\n  assets:\n    device:\n      defaults: &amp;defaults\n        artifacts:\n          - \"&lt;path&gt;/bin/hal_test\"\n          - \"&lt;path&gt;/bin/libut_control.so\"\n          - \"&lt;path&gt;/bin/Sink_HostSettings.yaml\"\n          - \"&lt;path&gt;/bin/run.sh\"\n        execute:\n          - \"chmod +x /opt/HAL/dshost_L3/hal_test\"\n          - \"chmod +x /opt/HAL/dshost_L3/run.sh\"\n          - cp -rf /usr/lib/libdshal.so /opt/HAL/dshost_L3/\n          - \"ln -s /usr/lib/libds-hal.so /opt/HAL/dshost_L3/libdshal.so\"\n        streams:\n        test1_VerifyConnect_Callback:\n          &lt;&lt;: *defaults\n          streams:\n</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsHost/ds-host_L3_TestProcedure/#test-suite-configuration","title":"Test Suite Configuration","text":"<p>Example Test Setup configuration File: dsHost_testConfig.yml</p> <p>Update the execute command according to the device path where <code>HAL</code> binaries are copied.</p> <pre><code>dsHost:\n  description: \"dsHost Device Settings testing profile\"\n  test:\n    execute: \"/tmp/run.sh -p /tmp/Sink_HostSettings.yaml\"\n    type: UT-C  # Cunit tests (UT-C)\n</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsHost/ds-host_L3_TestProcedure/#run-test-cases","title":"Run Test Cases","text":"<p>Once the environment is set up, you can execute the test cases with the following command</p> <pre><code>python &lt;TestCaseName.py&gt; --config &lt;/PATH&gt;/ut/host/tests/configs/example_rack_config.yml --deviceConfig &lt;/PATH&gt;/ut/host/tests/configs/deviceConfig.yml\n</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsHost/ds-host_L3_TestProcedure/#test-setup-connections","title":"Test Setup Connections","text":"<p>To verify the get temperature works as expected. For Example:</p> <ul> <li>Get the temperature, and then place the device in a heat chamber and verify the temperature increases.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHost/ds-host_L3_TestProcedure/#test-cases","title":"Test Cases","text":""},{"location":"external_content/device_settings_test/docs/pages/dsHost/ds-host_L3_TestProcedure/#dshost_test1_verifytemperaturepy","title":"dsHost_test1_VerifyTemperature.py","text":""},{"location":"external_content/device_settings_test/docs/pages/dsHost/ds-host_L3_TestProcedure/#platform-support-test01","title":"Platform Support - test01","text":"<ul> <li>Sink/Source</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsHost/ds-host_L3_TestProcedure/#user-input-required-test01","title":"User Input Required - test01","text":"<p>Yes: User interaction is necessary increase the temperature (This will be automated later).</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHost/ds-host_L3_TestProcedure/#acceptance-criteria-test01","title":"Acceptance Criteria - test01","text":"<p>The temperature is noted to be increasing once placed in the heat chamber or location to increase the temperature.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHost/ds-host_L3_TestProcedure/#expected-results-test01","title":"Expected Results - test01","text":"<p>The temperature should increase.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsHost/ds-host_L3_TestProcedure/#test-steps-test01","title":"Test Steps - test01","text":"<ul> <li> <p>Initiate the Test:</p> </li> <li> <p>Select and execute the Python file: <code>dsHost_test1_VerifyTemperature.py</code></p> </li> <li> <p>The test will automatically download all required artifacts, copying them to the designated target directory before commencing execution.</p> </li> <li> <p>Increase Temperature prompt:</p> <p>The test will request the User to place the device in a heat chamber and press enter to take the first reading, then increase the temperature and press enter to get the next reading:</p> </li> <li> <p>Question: \"Please begin to increase the temperature, and wait around one to two minutes before pressing enter to continue:\"</p> </li> <li> <p>Press Enter once the device is in a location to increase the temperature and suitable time has passed the change in temperature can be recorded.</p> </li> <li> <p>Test Conclusion:</p> </li> </ul> <p>The temperature should increase as expected.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_High-Level_TestSpec/","title":"Device Settings Video Device High Level Test Specification Documentation","text":""},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_High-Level_TestSpec/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>HAL</code>  - Hardware Abstraction Layer</li> <li><code>API</code>  - Caller Programming Interface</li> <li><code>DS</code>   - Device Settings</li> <li><code>HDR</code>  - High Dynamic Range</li> <li><code>FPS</code>  - Frames Per Second.</li> <li><code>FRF</code>  - Frame Rate Frequency</li> <li><code>HEVC</code> - High Efficiency Video Coding</li> <li><code>NA</code>   - Not Applicable</li> <li><code>Y</code>    - Yes</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_High-Level_TestSpec/#introduction","title":"Introduction","text":"<p>This document provides an overview of the High Level testing requirements for the Device Settings Video Device module. It outlines the scope of testing, objectives, testing levels and approaches, specific test requirements, and expected deliverables.</p> <p>Interface of the test is available here: dsVideoDevice HAL header</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_High-Level_TestSpec/#module-description","title":"Module Description","text":"<p><code>DS</code> Video device <code>HAL</code> provides a set of <code>APIs</code> to initialize, query and set information about about the zoom mode, <code>HDR</code> capabilities, Video encoding formats and frame rate.</p> <p>Interface specification is available here: dsVideoPort HAL Spec</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_High-Level_TestSpec/#testing-scope","title":"Testing Scope","text":"# Test Functionality Description 1 Check the Zoom Control Verify setting and getting the zoom modes 2 Check the HDR Capability Check the <code>HDR</code> Capability 3 Check Video codec and Formats Check supported video codec formats 4 Check the Display frame rate Capability Check supported Display frame rates"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_High-Level_TestSpec/#emulator-requirements","title":"Emulator Requirements","text":"<p>Boot configuration: Check video ports, encoding formats, profiles, frame rates, and device-supported zoom modes, along with the number of ports supported by each device.</p> <p>Supported Video encoding formats dsVideoCodingFormat_t link</p> <p>Supported Video <code>HEVC</code> profiles dsVideoCodecHevcProfiles_t link</p> <p>Supported Frame rates dsVideoFrameRate_t link</p> <p>Supported Video formats dsHDRStandard_t link</p> <p>Supported zoom modes dsVideoZoom_t link</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_High-Level_TestSpec/#check-the-zoom-control","title":"Check the Zoom Control","text":"Test Functionality Description HAL APIs L2 L3 Source Sink Control plane requirements Check the zoom mode status Loop through each supported video device and the zoom mode can be set using <code>Source_VideoDevice.yaml(dsVideoDevice/Device/[Device Number]/SupportedDFCs)</code> profile file and verify using get function.Note:Supported Number of VideoDevices check this profile file for source <code>Source_VideoDevice.yaml(dsVideoDevice/NumVideoDevices)</code> dsGetVideoDevice(), dsSetDFC(), dsGetDFC() <code>Y</code> <code>N</code> <code>Y</code> <code>NA</code> <code>NA</code> Loop through each supported video device and the zoom mode can be set using <code>Source_VideoDevice.yaml(dsVideoDevice/Device/[Device Number]/SupportedDFCs)</code> profile file and verify using get with Video playback &amp; connected device. Note:Supported Number of VideoDevices check this profile file for source <code>Source_VideoDevice.yaml(dsVideoDevice/NumVideoDevices)</code> dsGetVideoDevice(), dsSetDFC(), dsGetDFC() <code>NA</code> <code>Y</code> <code>Y</code> <code>NA</code> <code>Y</code>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_High-Level_TestSpec/#test-startup-requirement-check-the-zoom-control","title":"Test Startup Requirement-Check the Zoom Control","text":"<p>Playback the pre-define streams</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_High-Level_TestSpec/#emulator-requirements-check-the-zoom-control","title":"Emulator Requirements-Check the Zoom Control","text":"<p>Emulator Requirements</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_High-Level_TestSpec/#control-plane-requirements-check-the-zoom-control","title":"Control Plane Requirements-Check the Zoom Control","text":"<p>Verify the applied zoom mode during playback with analyzer.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_High-Level_TestSpec/#check-the-hdr-capability","title":"Check the HDR Capability","text":"Test Functionality Description HAL APIs L2 L3 Source Sink Control plane requirements Check <code>HDR</code> Capability Loop through each supported video device and Get the <code>HDR</code> capabilities for each video device and verify with the profile file for source use this <code>Source_VideoDevice.yaml(dsVideoDevice/Device/[Device Number]/HDRCapabilities)</code> and for the sink use this <code>Sink_VideoDevice.yaml(dsVideoDevice/Device/[Device Number]/HDRCapabilities)</code> Note:Supported Number of VideoDevices check this profile file for source <code>Source_VideoDevice.yaml(dsVideoDevice/NumVideoDevices)</code> and for the sink use this <code>Sink_VideoDevice.yaml(dsVideoDevice/NumVideoDevices)</code> dsGetHDRCapabilities() <code>Y</code> <code>NA</code> <code>Y</code> <code>Y</code> <code>NA</code>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_High-Level_TestSpec/#test-startup-requirement-check-the-hdr-capability","title":"Test Startup Requirement-Check the HDR Capability","text":"<p><code>NA</code></p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_High-Level_TestSpec/#emulator-requirements-check-the-hdr-capability","title":"Emulator Requirements-Check the HDR Capability","text":"<p>Emulator Requirements</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_High-Level_TestSpec/#control-plane-requirements-check-the-hdr-capability","title":"Control Plane Requirements-Check the HDR Capability","text":"<p><code>NA</code></p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_High-Level_TestSpec/#check-video-codec-and-formats","title":"Check Video codec and Formats","text":"Test Functionality Description HAL APIs L2 L3 Source Sink Control plane requirements Check Video coding Formats and information Loop through each supported video device and the get Video coding format for each video device and verify the with profile file for source use this file <code>Source_VideoDevice.yaml(dsVideoDevice/Device/[Device Number]/SupportedVideoCodingFormats)</code> and for the sink use this <code>Sink_VideoDevice.yaml(dsVideoDevice/Device/[Device Number]/SupportedVideoCodingFormats)</code> Note:Supported Number of VideoDevices check this profile file for source <code>Source_VideoDevice.yaml(dsVideoDevice/NumVideoDevices)</code> and for the sink use this <code>Sink_VideoDevice.yaml(dsVideoDevice/NumVideoDevices)</code> dsGetSupportedVideoCodingFormats() <code>Y</code> <code>NA</code> <code>Y</code> <code>Y</code> <code>NA</code> Loop through each supported video device and get Video codec information for each video device and verify the with <code>Source_VideoDevice.yaml(dsVideoDevice/Device/[Device Number]/VideoCodecInfo)</code> profile file.Note:Supported Number of VideoDevices check this profile file for source <code>Source_VideoDevice.yaml(dsVideoDevice/NumVideoDevices)</code>. dsGetVideoCodecInfo() <code>Y</code> <code>NA</code> <code>Y</code> <code>NA</code> <code>NA</code>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_High-Level_TestSpec/#test-startup-requirement-check-video-codec-and-formats","title":"Test Startup Requirement-Check Video codec and Formats","text":"<p><code>NA</code></p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_High-Level_TestSpec/#emulator-requirements-check-video-codec-and-formats","title":"Emulator Requirements-Check Video codec and Formats","text":"<p>Emulator Requirements</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_High-Level_TestSpec/#control-plane-requirements-check-video-codec-and-formats","title":"Control Plane Requirements-Check Video codec and Formats","text":"<p><code>NA</code></p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_High-Level_TestSpec/#check-the-display-frame-rate-capability","title":"Check the Display frame rate Capability","text":"Test Functionality Description HAL APIs L2 L3 Source Sink Control plane requirements Check the Display frame rate Capability Loop through each supported video device and Set the supported display frame rate for each video device using profile file <code>Source_VideoDevice.yaml(dsVideoDevice/Device/[Device Number]/SupportedDisplayFramerate)</code> and verify using get function. Note:Supported Number of VideoDevices check this profile file for source <code>Source_VideoDevice.yaml(dsVideoDevice/NumVideoDevices)</code>. dsSetDisplayframerate(), dsGetCurrentDisplayframerate() <code>Y</code> <code>NA</code> <code>NA</code> <code>Y</code> <code>NA</code> Loop through each supported video device and Set the supported display frame rate for each video device using profile file <code>Source_VideoDevice.yaml(dsVideoDevice/Device/[Device Number]/SupportedDisplayFramerate)</code> and check if callbacks are triggered Note:Supported Number of VideoDevices check this profile file for source <code>Source_VideoDevice.yaml(dsVideoDevice/NumVideoDevices)</code> dsSetDisplayframerate(), dsRegisterFrameratePreChangeCB(), dsRegisterFrameratePostChangeCB() <code>NA</code> <code>Y</code> <code>NA</code> <code>Y</code> <code>Y</code>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_High-Level_TestSpec/#test-startup-requirement-check-the-display-frame-rate-capability","title":"Test Startup Requirement-Check the Display frame rate Capability","text":"<p>Playback the pre-define streams</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_High-Level_TestSpec/#emulator-requirements-check-the-display-frame-rate-capability","title":"Emulator Requirements-Check the Display frame rate Capability","text":"<p>Emulator Requirements</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_High-Level_TestSpec/#control-plane-requirements-check-the-display-frame-rate-capability","title":"Control Plane Requirements-Check the Display frame rate Capability","text":"<p>Verify the frame rate with analyzer</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_L2-Low-Level_TestSpec/","title":"Device Settings Video Device L2 Low Level Test Specification and Procedure Documentation","text":""},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_L2-Low-Level_TestSpec/#overview","title":"Overview","text":"<p>This document describes the Low Level L2 Test Specification and Procedure for the Device Settings Video Device module.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_L2-Low-Level_TestSpec/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>HAL</code> - Hardware Abstraction Layer, may include some common components</li> <li><code>UT</code>  - Unit Test(s)</li> <li><code>OEM</code>  - Original Equipment Manufacture</li> <li><code>SoC</code>  - System on a Chip</li> <li><code>HDR</code> - High Dynamic Range</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_L2-Low-Level_TestSpec/#definitions","title":"Definitions","text":"<ul> <li><code>ut-core</code> - Common Testing Framework https://github.com/rdkcentral/ut-core, which wraps a open-source framework that can be expanded to the requirements for future framework.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_L2-Low-Level_TestSpec/#references","title":"References","text":"<ul> <li>High Level Test Specification ds-video-device_High-Level_TestSpec.md</li> <li>dsVideoDevice <code>HAL</code> Interface - dsVideoDevice.h</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_L2-Low-Level_TestSpec/#level-2-test-procedure","title":"Level 2 Test Procedure","text":"<p>The following functions are expecting to test the module operates correctly.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_L2-Low-Level_TestSpec/#test-1","title":"Test 1","text":"Title Details Function Name <code>test_l2_dsVideoDevice_SetAndGetDFC_source</code> Description Loop through each supported video device and the zoom mode can be set using <code>dsVideoDevice/Device/[Device Number]/SupportedDFCs</code> field of configuration file and verify using get Test Group 02 Test Case ID 001 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_L2-Low-Level_TestSpec/#test-procedure-test-1","title":"Test Procedure - Test 1","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize video device using <code>dsVideoDeviceInit</code> None <code>dsERR_NONE</code> Should be successful 02 Get video device handle using <code>dsGetVideoDevice</code> index = 0 to <code>dsVideoDevice/NumVideoDevices</code> from profile file <code>dsERR_NONE</code> Should be successful 03 Loop through each supported video device and set the zoom mode using <code>dsSetDFC</code> handle = obtained handle, dfc = <code>dsVideoDevice/Device/[Device Number]/SupportedDFCs</code> of configuration file <code>dsERR_NONE</code> Should be successful 04 Verify the set zoom mode using <code>dsGetDFC</code> handle = obtained handle, dfc_get = buffer to get dfc <code>dsERR_NONE</code>, dfc_get = dfc Should be successful 05 Terminate video device using <code>dsVideoDeviceTerm</code> None <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\nA[dsVideoDeviceInit] --&gt;|dsERR_NONE|B{Loop through &lt;br&gt; each video device}\nA --&gt;|Failure|A1[Test case fail]\nB --&gt;|dsERR_NONE|C[ dsGetVideoDevice]\nC --&gt; D[Set various zoom mode from &lt;br&gt; configuration file - dsSetDFC]\nD --&gt;|dsERR_NONE|E[Verify zoom mode -&lt;br&gt; dsGetDFC]\nE --&gt;|dsERR_NONE, &lt;br&gt; Zoom mode matches|B\nE --&gt;|!dsERR_NONE, &lt;br&gt; Zoom mode doesn't match|E1[Test case fail]\nE1 --&gt; B\nB --&gt;|End of loop|F[ dsVideoDeviceTerm]\nF --&gt;|dsERR_NONE|G[Test case success]\nF --&gt;|Failure|F1[Test case fail]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_L2-Low-Level_TestSpec/#test-2","title":"Test 2","text":"Title Details Function Name <code>test_l2_dsVideoDevice_GetHDRCapabilities</code> Description Loop through each supported video device and Get the <code>HDR</code> capabilities for each video device and verify with the configuration file Test Group 02 Test Case ID 002 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_L2-Low-Level_TestSpec/#test-procedure-test-2","title":"Test Procedure - Test 2","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the video device using <code>dsVideoDeviceInit</code> None <code>dsERR_NONE</code> Should be successful 02 Loop through each video device using <code>dsGetVideoDevice</code> index = 0 to <code>dsVideoDevice/NumVideoDevices</code> from configuration file, handle = valid pointer <code>dsERR_NONE</code> Should be successful 03 Get the <code>HDR</code> capabilities for each video device using <code>dsGetHDRCapabilities</code> handle = obtained from previous step, capabilities = valid pointer <code>dsERR_NONE</code> Should be successful 04 Verify the obtained <code>HDR</code> capabilities with the configuration file capabilities = obtained from previous step, configuration field = <code>dsVideoDevice/Device/[Device Number]/HDRCapabilities</code> Value should match with the configuration file Should be successful 05 Terminate the video device using <code>dsVideoDeviceTerm</code> None <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\nA[dsVideoDeviceInit] --&gt;|dsERR_NONE|B{Loop through each &lt;br&gt; supported video device}\nB --&gt;|dsERR_NONE and valid handle|C[dsGetVideoDevice]\nC --&gt;|dsERR_NONE and valid capabilities|D[dsGetHDRCapabilities]\nD --&gt;|Verify HDR capabilities|E{End of loop}\nD --&gt;|Verify HDR capabilities Fail|D1[Test case fail]\nD1 --&gt; E\nE --&gt; B\nE --&gt;|dsERR_NONE|F[dsVideoDeviceTerm]\nF --&gt; G[Test case success]\nA --&gt;|Failure|H[Test case fail]\nF --&gt;|Failure|J[Test case fail]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_L2-Low-Level_TestSpec/#test-3","title":"Test 3","text":"Title Details Function Name <code>test_l2_dsVideoDevice_GetSupportedVideoCodingFormats</code> Description Loop through each supported video device and get the Video coding format for each video device and verify it with the Configuration file Test Group 02 Test Case ID 003 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_L2-Low-Level_TestSpec/#test-procedure-test-3","title":"Test Procedure - Test 3","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the video device using <code>dsVideoDeviceInit</code> None <code>dsERR_NONE</code> Should be successful 02 Loop through each video device using <code>dsGetVideoDevice</code> index = 0 to <code>dsVideoDevice/NumVideoDevices</code> from the configuration file <code>dsERR_NONE</code> Should be successful 03 Get the supported video coding formats for each device using <code>dsGetSupportedVideoCodingFormats</code> handle = obtained from <code>dsGetVideoDevice</code> <code>dsERR_NONE</code> Should be successful 04 Verify the obtained supported formats with the configuration file supported_formats = from previous step, configuration field = <code>dsVideoDevice/Device/[Device Number]/SupportedVideoCodingFormats</code> <code>dsERR_NONE</code> Should be successful 05 Terminate the video device using <code>dsVideoDeviceTerm</code> None <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\nA[Call dsVideoDeviceInit] --&gt;|dsERR_NONE|B{Loop through each &lt;br&gt; supported video device}\nA --&gt;|Failure|A1[Test case fail]\nB --&gt; C[Call dsGetVideoDevice for each device]\nC --&gt;|dsERR_NONE and &lt;br&gt; handle is valid|D[Call dsGetSupportedVideoCodingFormats &lt;br&gt;for each device]\nD --&gt;|dsERR_NONE and &lt;br&gt; supported_formats is valid|E[Verify supported_formats &lt;br&gt; with configuration file]\nE --&gt;|Match|B\nE --&gt;|No Match|E1[Test case fail]\nE1 --&gt; B\nB --&gt;|End of loop|F[Call dsVideoDeviceTerm]\nF --&gt;|dsERR_NONE|G[Test case success]\nF --&gt;|Failure|F1[Test case fail]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_L2-Low-Level_TestSpec/#test-4","title":"Test 4","text":"Title Details Function Name <code>test_l2_dsVideoDevice_GetVideoCodecInfo_source</code> Description Loop through each supported video device and get Video codec information for each video device and verify the with configuration file Test Group 02 Test Case ID 004 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_L2-Low-Level_TestSpec/#test-procedure-test-4","title":"Test Procedure - Test 4","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the video device using <code>dsVideoDeviceInit</code> None <code>dsERR_NONE</code> Should be successful 02 Loop through each supported video device using <code>dsGetVideoDevice</code> index = 0 to <code>dsVideoDevice/NumVideoDevices</code> from the configuration file <code>dsERR_NONE</code> Should be successful 03 Get Video codec information for each video device using <code>dsGetVideoCodecInfo</code> handle = handle from <code>dsGetVideoDevice</code>, codec = codec <code>dsERR_NONE</code> Should be successful 04 Verify the obtained Video codec information with configuration file num_entries = <code>dsVideoDevice/Device/[Device Number]/VideoCodecInfo/num_entries</code>, level = <code>dsVideoDevice/Device/[Device Number]/VideoCodecInfo/VideoCodec[number]/level</code>, profile =  <code>dsVideoDevice/Device/[Device Number]/VideoCodecInfo/VideoCodec[number]/profile</code> <code>dsERR_NONE</code> Should be successful 05 Terminate the video device using <code>dsVideoDeviceTerm</code> None <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\nA[Call dsVideoDeviceInit] --&gt;|dsERR_NONE|B{Loop through each &lt;br&gt;supported video device}\nA --&gt;|Failure|A1[Test case fail]\nB --&gt;|dsERR_NONE and valid handle|C[Call dsGetVideoCodecInfo with handle]\nC --&gt;|dsERR_NONE and info structure populated|D[Verify video codec info &lt;br&gt; with profile file]\nD --&gt;|Success|B\nD --&gt;|Fail|D1[Test case fail]\nD1 --&gt; B\nB --&gt;|End of loop|F[Call dsVideoDeviceTerm]\nF --&gt;|dsERR_NONE|G[Test case success]\nF --&gt;|Failure|F1[Test case fail]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_L2-Low-Level_TestSpec/#test-5","title":"Test 5","text":"Title Details Function Name <code>test_l2_dsVideoDevice_SetAndVerifyDisplayframerate_sink</code> Description Loop through each supported video device and Set the supported display frame rate for each video device using configuration file and verify using get Test Group 02 Test Case ID 005 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_L2-Low-Level_TestSpec/#test-procedure-test-5","title":"Test Procedure - Test 5","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize video device using <code>dsVideoDeviceInit</code> None <code>dsERR_NONE</code> Should be successful 02 Get video device handle using <code>dsGetVideoDevice</code> with index 0 , Loop through each supported video device index = 0 to <code>dsVideoDevice/NumVideoDevices</code> from the configuration file, handle = valid pointer <code>dsERR_NONE</code> Should be successful 03 Set the supported display frame rate for each video device using <code>dsSetDisplayframerate</code> handle = obtained handle, framerate = <code>dsVideoDevice/Device/[Device Number]/SupportedDisplayframerate</code> dsERR_NONE Should be successful 04 Verify the set frame rate using <code>dsGetCurrentDisplayframerate</code> handle = obtained handle, framerate = valid pointer <code>dsERR_NONE</code> Should be successful 05 Terminate video device using <code>dsVideoDeviceTerm</code> None <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\nA[Call dsVideoDeviceInit] --&gt;|dsERR_NONE|B{Loop through each &lt;br&gt; supported video device}\nA --&gt;|Failure|A1[Test case fail]\nB --&gt; D[Read supported display frame &lt;br&gt; rate from profile file]\nD --&gt; E[Call dsSetDisplayframerate &lt;br&gt; with handle and frame rate]\nE --&gt;|dsERR_NONE|F[Call dsGetCurrentDisplayframerate ]\nF --&gt;|dsERR_NONE and frame rate matches|B\nF --&gt; |!dsERR_NONE and frame rate doesn't match|F1[Test case fail]\nF1 --&gt; B\nB --&gt;|End of loop|H[Call dsVideoDeviceTerm]\nH --&gt;|dsERR_NONE|I[Test case pass]\nH --&gt;|Failure|H1[Test case fail]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_L2-Low-Level_TestSpec/#test-6","title":"Test 6","text":"Title Details Function Name <code>test_l2_dsVideoDevice_SetAndVerifyFRFMode_sink</code> Description Loop through each supported video device and Set the display frame rate mode for each video device and verify using get Test Group 02 Test Case ID 006 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_L2-Low-Level_TestSpec/#test-procedure-test-5_1","title":"Test Procedure - Test 5","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize video device using <code>dsVideoDeviceInit</code> None <code>dsERR_NONE</code> Should be successful 02 Get video device handle using <code>dsGetVideoDevice</code> with index 0 , Loop through each supported video device index = 0 to <code>dsVideoDevice/NumVideoDevices</code> from the configuration file, handle = valid pointer <code>dsERR_NONE</code> Should be successful 03 Set the frame rate mode for each video device using <code>dsSetFRFMode</code> handle = obtained handle, frfMode = 0 and 1 dsERR_NONE Should be successful 04 Verify the set frame rate mode using <code>dsGetFRFMode</code> handle = obtained handle, frfMode = valid intiger pointer <code>dsERR_NONE</code> Should be successful 05 Terminate video device using <code>dsVideoDeviceTerm</code> None <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\nA[Call dsVideoDeviceInit] --&gt;|dsERR_NONE|B{Loop through each &lt;br&gt; supported video device}\nA --&gt;|Failure|A1[Test case fail]\nB --&gt; E[Call dsSetFRFMode with handle and frfMode 0 and 1]\nE --&gt;|dsERR_NONE|F[Call dsGetFRFMode ]\nF --&gt;|dsERR_NONE and frfMode matches|B\nF --&gt; |!dsERR_NONE and frfMode doesn't match|F1[Test case fail]\nF1 --&gt; B\nB --&gt;|End of loop|H[Call dsVideoDeviceTerm]\nH --&gt;|dsERR_NONE|I[Test case pass]\nH --&gt;|Failure|H1[Test case fail]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_L3_Low-Level_TestSpecification/","title":"Device Settings Video Device L3 Low Level Test Specification and Procedure Documentation","text":""},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_L3_Low-Level_TestSpecification/#overview","title":"Overview","text":"<p>This document describes the L3 Low Level Test Specification and Procedure Documentation for the Device Settings Video Device module.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_L3_Low-Level_TestSpecification/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>HAL</code> - Hardware Abstraction Layer, may include some common components</li> <li><code>DFC</code>  - Decoder Format Conversion</li> <li><code>OEM</code> - Original Equipment Manufacture</li> <li><code>SoC</code> - System on a Chip</li> <li><code>L3</code>   - Level 3 Testing</li> <li><code>DS</code>   - Device Settings</li> <li><code>HDR</code>  - High Dynamic Range</li> <li><code>FPS</code>  - Frames Per Second.</li> <li><code>FRF</code>  - Frame Rate Frequency</li> <li><code>HEVC</code> - High Efficiency Video Coding</li> <li><code>RAFT</code>  - Rapid Automation Framework for Testing</li> <li><code>DUT</code>   - Device Under Test</li> <li><code>NA</code>   - Not Applicable</li> <li><code>Y</code>    - Yes</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_L3_Low-Level_TestSpecification/#references","title":"References","text":"<ul> <li><code>High Level Test Specification</code> - dsVideoDevice High Level TestSpec</li> <li><code>Interface header</code> - dsVideoDevice HAL header</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_L3_Low-Level_TestSpecification/#video-streams-requirement","title":"Video Streams Requirement","text":"# Streams Name Streams description 1 scrolling_text_fast_3840x2160_23.98fps.mp4 Resolution: 3840x2160, Framerate Per Second: 23.98 2 scrolling_text_fast_3840x2160_24fps.mp4 Resolution: 3840x2160, Framerate Per Second: 24 3 scrolling_text_fast_3840x2160_25fps.mp4 Resolution: 3840x2160, Framerate Per Second: 25 4 scrolling_text_fast_3840x2160_29.97fps.mp4 Resolution: 3840x2160, Framerate Per Second: 29.97 5 scrolling_text_fast_3840x2160_30fps.mp4 Resolution: 3840x2160, Framerate Per Second: 30 6 scrolling_text_fast_3840x2160_50fps.mp4 Resolution: 3840x2160, Framerate Per Second: 50 7 scrolling_text_fast_3840x2160_59.94fps.mp4 Resolution: 3840x2160, Framerate Per Second: 59.94 8 scrolling_text_fast_3840x2160_60fps.mp4 Resolution: 3840x2160, Framerate Per Second: 60 9 scrolling_text_fast_1920x1080_60fps.mp4 Resolution: 1920x1080, Framerate Per Second: 60"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_L3_Low-Level_TestSpecification/#level-3-test-cases-high-level-overview","title":"Level 3 Test Cases High Level Overview","text":"<p>Below are top test use-case for the Video Display.</p> # Test-case Description HAL APIs Source Sink Streams Number 1 Verify the Video Display framerate change with pre and post change callback. Set the auto framerate mode and check the callback is triggered before and after when the framerate of a display changes <code>dsRegisterFrameratePreChangeCB()</code>, <code>dsRegisterFrameratePostChangeCB()</code> <code>NA</code> <code>Y</code> 1,2,3,4,5,6,7,8 2 Set and verify the Zoom mode of the source device Play any video content and Set the supported Zoom mode and verify the selected Zoom mode <code>dsSetDFC()</code>, <code>dsGetDFC()</code> <code>Y</code> <code>NA</code> 9 3 Select the Device Frame Rate of Sink device Select the Device Frame Rate of Sink device and on playing video playback verify <code>dsSetDisplayframerate()</code> <code>dsSetDisplayframerate()</code> <code>NA</code> <code>Y</code> 1,2,3,4,5,6,7,8 4 Set and verify the <code>FRF</code> mode Select the<code>FRF</code>mode and verify the selected <code>FRF</code> mode with video playback <code>dsSetFRFMode()</code> <code>NA</code> <code>Y</code> 1,2,3,4,5,6,7,8"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_L3_Low-Level_TestSpecification/#level-3-python-test-cases-high-level-overview","title":"Level 3 Python Test Cases High Level Overview","text":"<p>The class diagram below illustrates the flow of dsVideoDevice L3 Python test cases:</p> <pre><code>---\ntitle: dsVideoDevice - Python Class Flow\n---\nclassDiagram\n    testControl &lt;|-- ut_raft : inherits\n    class ut_raft{\n    }\n    ut_raft &lt;|-- dsVideoDeviceHelperClass : inherits\n    dsVideoDeviceHelperClass &lt;|-- L3_TestClasses : inherits\n    L3_TestClasses ..&gt; dsVideoDevice : uses\n    note for testControl \"uses rackConfig.yaml and deviceConfig.yaml\"\n    note for dsVideoDevice \"uses platformProfile.yaml\"\n    note for L3_TestClasses \"uses testSetupConfig.yaml\"\n    note for ut_raft \"suite Navigator uses testConfig.yaml\"</code></pre> <ul> <li>testControl</li> <li>Test Control Module for running rack Testing. This module configures the <code>DUT</code> based on the rack configuration file provided to the test.</li> <li>This class is defined in <code>RAFT</code> framework. For more details refer RAFT</li> <li>ut_raft</li> <li>Python based testing framework for writing engineering tests.</li> <li>It provides common functionalities like menu navigation, configuration reader, reading user response etc.</li> <li>For more details ut-raft.</li> <li>dsVideoDevice</li> <li>This is test helper class which communicates with the <code>L3</code> C/C++ test running on the <code>DUT</code> through menu</li> <li>L3_TestClasses</li> <li>These are the L3 test case classes</li> <li>Each class covers the each test use-case defined in L3 Test use-cases table</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_L3_Low-Level_TestSpecification/#yaml-file-inputs","title":"YAML File Inputs","text":"<ul> <li>rackConfig.yaml</li> <li>Identifies the rack configuration and platform used</li> <li>References platform-specific config from <code>deviceConfig.yaml</code></li> <li> <p>For more details refer RAFT and example_rack_config.yml</p> </li> <li> <p>deviceConfig.yaml</p> </li> <li>Specifies overall configuration for the platform</li> <li>Can be overridden by:<ul> <li>Changing locally .yaml file directory</li> <li>Using --deviceConfig command line switch</li> </ul> </li> <li> <p>For more details refer RAFT and example_device_config.yml</p> </li> <li> <p>componentProfile.yaml/platformProfile.yaml</p> </li> <li>Contains component-specific configurations</li> <li>Contains platform wide configuration broken down into separate components</li> <li> <p>Example configuration file dsVideoDevice_Settings</p> </li> <li> <p>testSetupConfig.yaml</p> </li> <li>This configuration file contains the list of requirements for tests to execute. Eg: Copying the streams, setting environment variables etc.</li> <li> <p>Example configuration file dsVideoDevice_L3_testSetup.yml</p> </li> <li> <p>testConfig.yaml</p> </li> <li>This configuration file contains the list of menu items for C/C++ L3 test running on <code>DUT</code></li> <li>Example configuration file dsVideoDevice_testConfig.yml</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_L3_TestProcedure/","title":"dsVideoDevice HAL L3 Python Test Procedure","text":""},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_L3_TestProcedure/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>HAL</code>  - Hardware Abstraction Layer</li> <li><code>L3</code>   - Level 3 Testing</li> <li><code>DUT</code>  - Device Under Test</li> <li><code>RAFT</code> - Rapid Automation Framework for Testing</li> <li><code>YAML</code> - YAML Ain't Markup Language</li> <li><code>DS</code>   - Device Settings</li> <li><code>FPS</code>  - Frames Per Second.</li> <li><code>FRF</code>  - Frame Rate Frequency</li> <li><code>HEVC</code> - High Efficiency Video Coding</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_L3_TestProcedure/#setting-up-test-environment","title":"Setting Up Test Environment","text":"<p>To execute <code>HAL</code> <code>L3</code> Python test cases, need a Python environment. Follow these steps mentioned in HPK Public Documentation</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_L3_TestProcedure/#update-configuration-files","title":"Update Configuration Files","text":""},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_L3_TestProcedure/#rack-configuration-file","title":"Rack Configuration File","text":"<p>Example Rack configuration File: example_rack_config.yml</p> <p>For more details refer RAFT and example_rack_config.yml</p> <p>In this file, update the configuration to define the console sessions for the <code>DUT</code> and the outbound settings:</p> Console Session Description default Downloads the streams required for test cases ssh_player Plays the stream required for test case ssh_hal_test Executes the <code>HAL</code> binary for the test case <pre><code>rackConfig:\n  - dut:\n      ip: \"XXX.XXX.XXX.XXX\"  # IP Address of the device\n      description: \"stb device under test\"\n      platform: \"stb\"\n      consoles:\n        - default:\n            type: \"ssh\"\n            port: 10022\n            username: \"root\"\n            ip: \"XXX.XXX.XXX\" # IP address of the device\n            password: ' '\n        - ssh_player:\n            type: \"ssh\"\n            port: 10022\n            username: \"root\"\n            ip: \"XXX.XXX.XXX\" # IP address of the device\n            password: ' '\n        - ssh_hal_test:\n            type: \"ssh\"\n            port: 10022\n            username: \"root\"\n            ip: \"XXX.XXX.XXX\" # IP address of the device\n            password: ' '\n      outbound:\n        download_url: \"tftp://tftp-server.com/rack1/slot1/\"    # Download location for the CPE device\n        upload_url: \"sftp://server-address/home/workspace/tftp/rack1/slot1/\" # Upload location\n        upload_url_base_dir: \"sftp://server-address/home/workspace/tftp/rack1/slot1\"\n        httpProxy:   # Local proxy if required\n        workspaceDirectory: './logs/workspace'   # Local working directory\n</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_L3_TestProcedure/#device-configuration-file","title":"Device Configuration File","text":"<p>Example Device configuration File: deviceConfig.yml</p> <p>For more details refer RAFT and example_device_config.yml</p> <p>Update below fileds in the device configuration file: - Set the folder path for <code>target_directory</code> where <code>HAL</code> binaries will be copied onto the device. - Specify the device profile path in <code>test/profile</code> - Ensure the <code>platform</code> should match with the <code>DUT</code> <code>platform</code> in Rack Configuration</p> <pre><code>deviceConfig:\n    cpe1:\n        platform: \"linux\"\n        model: \"uk\"\n        soc_vendor: \"intel\"\n        target_directory: \"/tmp/\"  # Target Directory on device\n        prompt: \"\" # Prompt string on console\n        test:\n            profile: \"../../../../profiles/sink/Source_VideoDevice.yaml\"\n            streams_download_url: \"&lt;URL_Path&gt;\" #URL path from which the streams are downloaded to the device\n</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_L3_TestProcedure/#test-setup-configuration-file","title":"Test Setup Configuration File","text":"<p>Example Test Setup configuration File: dsVideoDevice_L3_testSetup.yml</p> <p>Provide the streams for each test case. This path is appended with <code>streams_download_url</code> entry from Device Configuration File</p> <p>If a test case requires multiple streams or needs to be validated using several streams, ensure that all necessary streams are added sequentially for that specific test case.</p> <pre><code>dsVideoDevice:  \n  description: \"dsVideoDevice Device Settings test setup\"\n  assets:\n    device:\n      test1_FrameratePrePostChangeCallBack_Verify:\n        streams:\n      test2_ZoomMode:\n        streams:\n      test3_SetDisplayFramerate:\n        streams:\n      test4_FRFMode:\n        streams:\n</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_L3_TestProcedure/#test-configuration","title":"Test Configuration","text":"<p>Example Test Setup configuration File: dsVideoDevice_testConfig.yml</p> <p>Update the execute command according to the device path where <code>HAL</code> binaries are copied.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_L3_TestProcedure/#run-test-cases","title":"Run Test Cases","text":"<p>Once the environment is set up, you can execute the test cases with the following command</p> <pre><code>python &lt;TestCaseName.py&gt; --config &lt;/PATH&gt;/ut/host/tests/configs/example_rack_config.yml --deviceConfig &lt;/PATH&gt;/ut/host/tests/configs/deviceConfig.yml\n</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_L3_TestProcedure/#streams-required","title":"Streams Required","text":"<p>Refer ds-video-device_L3_Low-Level_TestSpecification.md for the stream details</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_L3_TestProcedure/#test-cases","title":"Test Cases","text":""},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_L3_TestProcedure/#dsvideodevice_test1_framerateprechangepostchangecallback_verifypy","title":"dsVideoDevice_test1_FrameratePreChangePostChangeCallback_Verify.py","text":""},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_L3_TestProcedure/#platform-supported-test01","title":"Platform Supported - test01","text":"<ul> <li>Sink</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_L3_TestProcedure/#user-input-required-test01","title":"User Input Required - test01","text":"<ul> <li>No</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_L3_TestProcedure/#acceptance-criteria-test01","title":"Acceptance Criteria - test01","text":"<ul> <li>Play Streams <code>#1</code> <code>#2</code> <code>#3</code> <code>#4</code> <code>#5</code> <code>#6</code> <code>#7</code> <code>#8</code> of different fps sequentially and verify whether pre and post display framerate change callbacks triggered or not.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_L3_TestProcedure/#expected-results-test01","title":"Expected Results - test01","text":"<ul> <li>This test should verify the triggered pre and post callbacks whenever there is a framerate change.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_L3_TestProcedure/#test-steps-test01","title":"Test Steps - test01","text":"<ul> <li>Run the test file: <code>dsVideoDevice_test1_FrameratePreChangePostChangeCallback_Verify.py</code></li> <li>Execution process:</li> </ul> <p>Upon execution, the test will:</p> <ul> <li>Download all the required artifacts and streams.</li> <li>Copy them to the target directory.</li> <li> <p>Automatically start the test execution.</p> </li> <li> <p>Iterating through supported display framerates and respective stream:</p> <p>The test sets the auto frame mode and verifies the pre- and post-frame rate change callbacks for different streams with varying frame rates.</p> </li> <li> <p>Completion and results:</p> </li> </ul> <p>Upon verifying the supported framerates and based on the callback responses, the test will conclude and display the final result (PASS/FAIL).</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_L3_TestProcedure/#dsvideodevice_test2_setandgetzoommodepy","title":"dsVideoDevice_test2_SetAndGetZoomMode.py","text":""},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_L3_TestProcedure/#platform-supported-test02","title":"Platform Supported - test02","text":"<ul> <li>Source</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_L3_TestProcedure/#user-input-required-test02","title":"User Input Required - test02","text":"<p>Yes (This will be automated later).</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_L3_TestProcedure/#acceptance-criteria-test02","title":"Acceptance Criteria - test02","text":"<p>Play Stream <code>#9</code> and verify the supported zoom modes on device.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_L3_TestProcedure/#expected-results-test02","title":"Expected Results - test02","text":"<p>The test will set the various zoom modes. The user should able to notice a change in device's output while different zoom modes are applied.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_L3_TestProcedure/#test-steps-test02","title":"Test Steps - test02","text":"<ul> <li> <p>Select the test file:</p> </li> <li> <p>Run the Python script <code>dsVideoDevice_test2_SetAndGetZoomMode.py</code></p> </li> <li> <p>Execution process:</p> </li> </ul> <p>The test will:</p> <ul> <li>Download all the required artifacts and video streams.</li> <li>Copy them to the target directory.</li> <li> <p>Automatically start the test execution.</p> </li> <li> <p>Play the video stream:</p> </li> </ul> <p>Test starts the video stream playback specified in the test setup configuration file.</p> <ul> <li>Iterating through supported zoom modes:</li> </ul> <p>The test will repeat for different supported zoom modes. On setting each zoom mode user need to verify whether it is applied to playback stream.</p> <ul> <li>User interaction for verification:</li> </ul> <p>For each iteration:</p> <ul> <li>The test will ask: <code>Is the Zoom mode {zoomMode} applied in the device: {device}? (Y/N):</code></li> <li> <p>The user should press Y if the zoom mode is applied correctly (this passes the step), or N if the zoom is not observed (this fails the step).</p> </li> <li> <p>Completion and results:</p> </li> </ul> <p>Once all necessary user actions are completed, the test will evaluate the results and display whether the test Passed or Failed.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_L3_TestProcedure/#dsvideodevice_test3_setdisplayframeratepy","title":"dsVideoDevice_test3_SetDisplayFramerate.py","text":""},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_L3_TestProcedure/#platform-supported-test03","title":"Platform Supported - test03","text":"<ul> <li>Sink</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_L3_TestProcedure/#user-input-required-test03","title":"User Input Required - test03","text":"<p>Yes (This will be automated later).</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_L3_TestProcedure/#acceptance-criteria-test03","title":"Acceptance Criteria - test03","text":"<p>Play Streams <code>#1</code> <code>#2</code> <code>#3</code> <code>#4</code> <code>#5</code> <code>#6</code> <code>#7</code> <code>#8</code> of different fps sequentially an verify the impact of the supported display framerates.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_L3_TestProcedure/#expected-results-test03","title":"Expected Results - test03","text":"<p>This test will evaluate the supported display framerates. The user should notice a difference in video playback when different streamrates are applied.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_L3_TestProcedure/#test-steps-test03","title":"Test Steps - test03","text":"<ul> <li> <p>Select the test file:  </p> </li> <li> <p>Run the Python script <code>dsVideoDevice_test3_SetDisplayFramerate.py</code></p> </li> <li> <p>Execution process:</p> </li> </ul> <p>The test will:</p> <ul> <li>Download all required artifacts and video streams.</li> <li>Copy them to the target directory.</li> <li> <p>Automatically begin the test execution.</p> </li> <li> <p>Stream Playback:</p> </li> <li> <p>The test will play the designated video stream.</p> </li> <li>During playback, the test will prompt the user to verify whether displayRate with a streamRate acceptable.</li> </ul> <pre><code>  For example, to verify the display frame rate for weston-gl, run the following commands to check the refresh rate set on the display:\n\n  export XDG_RUNTIME_DIR=/tmp\n  westeros-gl-console get auto-frm-mode   //auto-frm-mode 0 - Disable, auto-frm-mode 1 - Enable\n  westeros-gl-console get mode            //mode 3840x2160px60 - 60FPS\n</code></pre> <ul> <li>Iterating through supported display framerates:</li> </ul> <p>The test will repeat for different supported display framerates.</p> <ul> <li>User Interaction:</li> </ul> <p>For each prompt, the user should assess the video playback output and respond:</p> <ul> <li><code>Is a displayRate {displayFramerate} with a streamRate {StreamFrameRate} acceptable? (Y/N):</code>, the user should press Y to confirm (this will pass the step).</li> <li> <p>If not, press N (this will fail the step).</p> </li> <li> <p>Completion and results:</p> </li> </ul> <p>After receiving all user inputs, the test will conclude and provide a final result (PASS/FAIL).</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_L3_TestProcedure/#dsvideodevice_test4_setandgetfrfmodepy","title":"dsVideoDevice_test4_SetAndGetFRFMode.py","text":""},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_L3_TestProcedure/#platform-supported-test04","title":"Platform Supported - test04","text":"<ul> <li>Sink</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_L3_TestProcedure/#user-input-required-test04","title":"User Input Required - test04","text":"<p>Yes (This will be automated later).</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_L3_TestProcedure/#acceptance-criteria-test04","title":"Acceptance Criteria - test04","text":"<p>Play Streams <code>#1</code> <code>#2</code> <code>#3</code> <code>#4</code> <code>#5</code> <code>#6</code> <code>#7</code> <code>#8</code> sequentially and verify the video playback and Framerate with <code>FRF</code> mode enabled.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_L3_TestProcedure/#expected-results-test04","title":"Expected Results - test04","text":"<p>The test evaluates the effect of <code>FRF</code> mode on video playback. The user should notice a difference in video output for different frame rate streams when Auto <code>FRF</code> mode is enabled.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_L3_TestProcedure/#test-steps-test04","title":"Test Steps - test04","text":"<ul> <li> <p>Run the Test:</p> </li> <li> <p>Select and run the Python script: <code>dsVideoDevice_test4_SetAndGetFRFMode.py</code></p> </li> <li> <p>Download and Setup:</p> <p>The test will automatically download all necessary artifacts and streams, and copy them to the target directory on the device.</p> </li> <li> <p>Stream Playback:</p> </li> <li> <p>The test will play the designated video stream.</p> </li> <li> <p>During playback, the test will prompt the user to verify whether <code>FRF</code> mode is applied based on video playback.</p> </li> <li> <p>User Interaction:</p> </li> </ul> <p>For each prompt, the user should assess the video playback output and respond:</p> <ul> <li>The test will ask: <code>Has the display refresh rate been changed to match Stream Framerate:{streamFramerate} (Suggested mode is {expectedMode})? (Y/N):</code>, the user should press Y to confirm the experience (this will pass the step).</li> <li>If not, press N (this will fail the step).</li> </ul> <pre><code>  For example, to verify the display frame rate for weston-gl, run the following commands to check the refresh rate set on the display:\n\n  export XDG_RUNTIME_DIR=/tmp\n  westeros-gl-console get auto-frm-mode   //auto-frm-mode 0 - Disable, auto-frm-mode 1 - Enable\n  westeros-gl-console get mode            //mode 3840x2160px60 - 60FPS\n</code></pre> <ul> <li>Completion:</li> </ul> <p>After receiving all necessary user inputs, the test case will conclude and display the final result: PASS or FAIL.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_L3_TestProcedure/#dsvideodevice_l3_runall_sinkpy","title":"dsVideoDevice_L3_Runall_Sink.py","text":"<p>This python file runs all the tests supported by <code>sink</code> devices</p> <pre><code>python dsVideoDevice_L3_Runall_Sink.py --config &lt;/PATH&gt;/ut/host/tests/configs/example_rack_config.yml --deviceConfig &lt;/PATH&gt;/ut/host/tests/configs/deviceConfig.yml\n</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoDevice/ds-video-device_L3_TestProcedure/#dsvideodevice_l3_runall_sourcepy","title":"dsVideoDevice_L3_Runall_Source.py","text":"<p>This python file runs all the tests supported by <code>source</code> devices</p> <pre><code>python dsVideoDevice_L3_Runall_Source.py --config &lt;/PATH&gt;/ut/host/tests/configs/example_rack_config.yml --deviceConfig &lt;/PATH&gt;/ut/host/tests/configs/deviceConfig.yml\n</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_High-Level_TestSpec/","title":"Device Settings Video Port High Level Test Specification Documentation","text":""},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_High-Level_TestSpec/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>HAL</code>    - Hardware Abstraction Layer</li> <li><code>API</code>    - Caller Programming Interface</li> <li><code>DS</code>     - Device Settings</li> <li><code>HDMI</code>   - High-Definition Multimedia Interface</li> <li><code>HDCP</code>   - High-bandwidth Digital Content Protection</li> <li><code>HDR</code>    - High Dynamic Range</li> <li><code>SDR</code>    - Standard Dynamic Range</li> <li><code>EDID</code>   - Extended Display Identification Data</li> <li><code>EOTF</code>   - Electro-Optical Transfer Function</li> <li><code>NA</code>     - Not Applicable</li> <li><code>Y</code>      - Yes</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_High-Level_TestSpec/#introduction","title":"Introduction","text":"<p>This document provides an overview of the High Level testing requirements for the Device Settings Video Port module. It outlines the scope of testing, objectives, testing levels and approaches, specific test requirements, and expected deliverables.</p> <p>Interface header is available here: dsVideoPort HAL header</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_High-Level_TestSpec/#module-description","title":"Module Description","text":"<p><code>DS</code> Video Port <code>HAL</code> provides a set of <code>APIs</code> to initialize, query and set information about the Video ports like getting  video port handle, fetching connected display information such as color depth, color space, matrix coefficients, quantization range, supported video resolutions using the video port handle. It also provides <code>APIs</code> to enable or disable content protection like <code>HDCP</code>, to set the background color and preferred color depth of the video port.</p> <p>Interface specification is available here: dsVideoPort HAL Spec</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_High-Level_TestSpec/#testing-scope","title":"Testing Scope","text":"# Test Functionality Description 1 Check the Video port status Check the Video Port Access and Status 2 Check Video Content Format and Resolution Check Video content Format and Resolution 3 Check HDR Capability Check <code>HDR</code> Capability 4 HDCP Management Check <code>HDCP</code> Status 5 Color Capabilities Check the color capabilities"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_High-Level_TestSpec/#emulator-requirements","title":"Emulator Requirements","text":"<p>Boot configuration: Check video ports, formats, frame rates, and device-supported resolutions, along with the number of ports supported by each device.</p> <p>Supported Video Port dsVideoPortType_t link</p> <p>Supported Video resolutions dsTVResolution_t link</p> <p>Supported Frame rates dsVideoFrameRate_t link</p> <p>Supported Video formats dsHDRStandard_t link</p> <p>Supported Video background Color dsVideoBackgroundColor_t link</p> <p>Supported Display Color Depth dsDisplayColorDepth_t link</p> <p>Supported Display Color Space dsDisplayColorSpace_t link</p> <p>Supported Display MatrixCoefficient dsDisplayMatrixCoefficients_t link</p> <p>Supported Display QuantizationRange dsDisplayQuantizationRange_t link</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_High-Level_TestSpec/#check-the-video-port-status","title":"Check the video port status","text":"Test Functionality Description HAL APIs L2 L3 Source Sink Control plane requirements Check the each video port status Get the handle for each video port, check the status of each video port to see if it's enabled or disabled. If a port is disabled, enable it, and then verify the status of each port. dsGetVideoPort(), dsIsVideoPortEnabled(), dsEnableVideoPort() <code>Y</code> <code>NA</code> <code>Y</code> <code>Y</code> <code>NA</code> Verify the connected/disconnected status of each port's display when no video port is connected. dsIsDisplayConnected(), dsIsVideoPortActive() <code>Y</code> <code>NA</code> <code>Y</code> <code>Y</code> <code>NA</code> Verify the connected/disconnected status of each port's display by connecting/disconnecting the video port dsIsDisplayConnected(), dsIsVideoPortActive() <code>NA</code> <code>Y</code> <code>Y</code> <code>NA</code> <code>Y</code> Retrieve the surround mode capabilities of each port and verify them with the configuration YAML file. If it is a sink device, retrieve the value from 'Sink_4K_VideoPort.yaml' using the path \"dsVideoPort/Ports/[port no]/Display_surround\" since the sink device has only an INTERNAL port. It is not supported for the source devices dsIsDisplaySurround() <code>Y</code> <code>NA</code> <code>NA</code> <code>Y</code> <code>NA</code> Verify the each port surround mode capabilities of connected display and verify with configuration file. It is not supported of Sink devices. If it is a source devices, the value has to be retrieved from the \"Source_4K_VideoPort.yaml\" using the path \"dsVideoPort/Ports/[port no]/Display_surround\" supported by the <code>HDMI</code> device. dsIsDisplaySurround(), dsGetSurroundMode() <code>Y</code> <code>NA</code> <code>Y</code> <code>NA</code> <code>NA</code>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_High-Level_TestSpec/#test-startup-requirement-check-the-video-port-status","title":"Test Startup Requirement-Check the video port status","text":"<p><code>NA</code></p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_High-Level_TestSpec/#emulator-requirements-check-the-video-port-status","title":"Emulator Requirements-Check the video port status","text":"<p>Emulator Requirements</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_High-Level_TestSpec/#control-plane-requirements-check-the-video-port-status","title":"Control Plane Requirements-Check the video port status","text":"<p>plug/Unplug the Video port,Verify with edid info, is surround mode supported</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_High-Level_TestSpec/#check-video-content-format-and-resolution","title":"Check Video Content Format and Resolution","text":"Test Functionality Description HAL API's L2 L3 Source Sink Control plane requirements Check Video Format Content and Resolution Register callback for the Video Format update event,change the video formate and check whether callback is Triggered or not dsVideoFormatUpdateRegisterCB() <code>NA</code> <code>Y</code> <code>Y</code> <code>Y</code> <code>Y</code> Set properties for each video port, including pixel resolution, aspect ratio, stereoscopic modes, frame rates, and scan modes, looping through supported values. Verify the settings using the get function dsSetResolution(), dsGetResolution() <code>Y</code> <code>NA</code> <code>Y</code> <code>NA</code> <code>NA</code> Set current active Video port properties like pixel resolution, Aspect ratio, Stereo Scopic modes, frame rates &amp; scan modes and looping through with supported values and verify external Analyzer with video playback dsIsVideoPortActive(), dsSetResolution(), dsGetResolution() <code>NA</code> <code>Y</code> <code>Y</code> <code>NA</code> <code>Y</code> Gets the each port supported resolutions of TV and verify with the configuration YAML file. If it is a sink device, the value to be retrieved from the 'Sink_4K_VideoPort.yaml' by using the path \"dsVideoPort/Ports/[port no]/Supported_tv_resolutions_capabilities\", supported by INTERNAL port. For source devices, the value to be retrieved from the 'Source_4K_VideoPort.yaml' by using the path \"dsVideoPort/Ports/[port no]/Supported_tv_resolutions_capabilities\", supported by <code>HDMI</code> port. dsSupportedTvResolutions() <code>Y</code> <code>NA</code> <code>Y</code> <code>Y</code> <code>Y</code> Get the current active Video port resolution and verify with the external device dsIsVideoPortActive(), dsGetResolution() <code>NA</code> <code>Y</code> <code>Y</code> <code>Y</code> <code>Y</code>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_High-Level_TestSpec/#test-startup-requirement-check-video-content-format-and-resolution","title":"Test Startup Requirement-Check Video Content Format and Resolution","text":"<p>Playback the pre-define streams</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_High-Level_TestSpec/#emulator-requirements-check-video-content-format-and-resolution","title":"Emulator Requirements-Check Video Content Format and Resolution","text":"<p>Emulator Requirements</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_High-Level_TestSpec/#control-plane-requirements-check-video-content-format-and-resolution","title":"Control Plane Requirements-Check Video Content Format and Resolution","text":"<p>Check the each  port output resolutions and Verify the AspectRatio,video Stereo Scopic modes,video Frame rates,interlaced/progressive.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_High-Level_TestSpec/#check-hdr-capability","title":"Check HDR Capability","text":"Test Functionality Description HAL API's L2 L3 Source Sink Control plane requirements Check HDR Capability Get the each port HDR capabilities &amp; verify with the configuration YAML file YAML file. If it is a sink device, the value to be retrieved from the 'Sink_4K_VideoPort.yaml' by using the path \"dsVideoPort/Ports/[port no]/hdr_capabilities\", supported by INTERNAL port. For source devices, the value to be retrieved from the 'Source_4K_VideoPort.yaml' by using the path \"dsVideoPort/Ports/[port no]/hdr_capabilities\", supported only by <code>HDMI</code> port. dsGetTVHDRCapabilities() <code>Y</code> <code>NA</code> <code>Y</code> <code>Y</code> <code>NA</code> get the HDR format current active video port and verify with external analyzer dsIsVideoPortActive(), dsGetVideoEOTF() <code>NA</code> <code>Y</code> <code>Y</code> <code>Y</code> <code>Y</code> Checks current active video port output is HDR with different HDR/SDR streams and verify with external analyzer dsIsVideoPortActive(), dsIsOutputHDR() <code>NA</code> <code>Y</code> <code>Y</code> <code>Y</code> <code>Y</code> Set/Reset force HDR mode for the current active video port and verify with external analyzer is HDR mode is set/reset dsIsVideoPortActive(), dsSetForceHDRMode() <code>NA</code> <code>Y</code> <code>Y</code> <code>NA</code> <code>Y</code> Reset the current active video port output to SDR and verify with external analyzer dsIsVideoPortActive(), dsResetOutputToSDR() <code>NA</code> <code>Y</code> <code>Y</code> <code>NA</code> <code>Y</code> Set Force-disable 4K support for each port and verify it using the get function. dsSetForceDisable4KSupport(), dsGetForceDisable4KSupport() <code>Y</code> <code>NA</code> <code>Y</code> <code>Y</code> <code>NA</code> Set Force Disable 4KSupport for active port on playback and verify with analyzer dsIsVideoPortActive(), dsSetForceDisable4KSupport() <code>NA</code> <code>Y</code> <code>Y</code> <code>Y</code> <code>NA</code>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_High-Level_TestSpec/#test-startup-requirement-check-hdr-capability","title":"Test Startup Requirement-Check HDR Capability","text":"<p>Playback the pre-define streams</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_High-Level_TestSpec/#emulator-requirements-check-hdr-capability","title":"Emulator Requirements-Check HDR Capability","text":"<p>Emulator Requirements</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_High-Level_TestSpec/#control-plane-requirements-check-hdr-capability","title":"Control Plane Requirements-Check HDR Capability","text":"<p>Check video out is HDR or SDR and verify with analyzer</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_High-Level_TestSpec/#hdcp-management","title":"HDCP Management","text":"Test Functionality Description HAL API's L2 L3 Source Sink Control plane requirements Check HDCP status Check enable/disable the HDCP(1.x &amp; 2.x) for the current active video port with playback dsIsVideoPortActive(), dsEnableHDCP(), dsIsHDCPEnabled() <code>NA</code> <code>Y</code> <code>Y</code> <code>NA</code> <code>NA</code> Check the HDCP status of each port and verify if dsHDCP_STATUS_AUTHENTICATED is returned for sinks, and dsHDCP_STATUS_UNPOWERED/dsHDCP_STATUS_PORTDISABLED is returned for sources. dsGetHDCPStatus() <code>Y</code> <code>NA</code> <code>Y</code> <code>Y</code> <code>NA</code> Check current active port HDCP status and check with connected device dsIsVideoPortActive(), dsGetHDCPStatus() <code>NA</code> <code>Y</code> <code>Y</code> <code>NA</code> <code>NA</code> Check the HDCP protocol status of each port and verify it with the configuration YAML file. If it is a sink device, retrieve the value from the 'Sink_4K_VideoPort.yaml' file using the path \"dsVideoPort/Ports/[port no]/hdcp_protocol_version\" supported by INTERNAL port. For a source device, retrieve the value from the 'Source_4K_VideoPort.yaml' file using the path \"dsVideoPort/Ports/[port no]/hdcp_protocol_version\" supported by <code>HDMI</code> port. dsGetHDCPProtocol() <code>Y</code> <code>NA</code> <code>Y</code> <code>Y</code> <code>NA</code> Check current active port HDCP protocol Status with connected device dsIsVideoPortActive(), dsGetHDCPCurrentProtocol() <code>NA</code> <code>Y</code> <code>Y</code> <code>Y</code> <code>Y</code> Check active port HDCP Receiver protocol version with connected device dsIsVideoPortActive(), dsGetHDCPReceiverProtocol(), <code>NA</code> <code>Y</code> <code>Y</code> <code>NA</code> <code>Y</code> Ignore EDID status for active port with connected device dsIsVideoPortActive(), dsGetIgnoreEDIDStatus() <code>N</code> <code>Y</code> <code>Y</code> <code>NA</code> <code>Y</code> Set the preferred HDCP Protocol version for each valid port and verify it using the get function. dsSetHdmiPreference(), dsGetHdmiPreference() <code>Y</code> <code>NA</code> <code>Y</code> <code>Y</code> <code>NA</code> set/get preferred HDCP Protocol version for active port with connected device dsIsVideoPortActive(), dsSetHdmiPreference(), dsGetHdmiPreference() <code>NA</code> <code>Y</code> <code>Y</code> <code>NA</code> <code>NA</code> Notify event if the HDCP status change and check the timing info for hdcp authentication dsRegisterHdcpStatusCallback() <code>NA</code> <code>Y</code> <code>Y</code> <code>NA</code> <code>Y</code> Check HDCP status for active port and verify with external analyzer dsRegisterHdcpStatusCallback() <code>NA</code> <code>Y</code> <code>Y</code> <code>NA</code> <code>Y</code>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_High-Level_TestSpec/#test-startup-requirement-hdcp-management","title":"Test Startup Requirement-HDCP Management","text":"<p>Playback the pre-define streams</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_High-Level_TestSpec/#emulator-requirements-hdcp-management","title":"Emulator Requirements-HDCP Management","text":"<p>Emulator Requirements</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_High-Level_TestSpec/#control-plane-requirements-hdcp-management","title":"Control Plane Requirements-HDCP Management","text":"<p>Check the HDCP status with external analyzer</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_High-Level_TestSpec/#color-capabilities","title":"Color Capabilities","text":"Test Functionality Description HAL API's L2 L3 Source Sink Control plane requirements Check Color information Get each port Color Space, compare with the configuration YAML file. If it is a sink device, retrieve the value from the 'Sink_4K_VideoPort.yaml' file using the path \"dsVideoPort/Ports/[port no]/colorspaces\" supported by INTERNAL port. For a source device, retrieve the value from the 'Source_4K_VideoPort.yaml' file using the path \"dsVideoPort/Ports/[port no]/colorspaces\" supported by <code>HDMI</code> port. dsGetColorSpace() <code>Y</code> <code>NA</code> <code>Y</code> <code>Y</code> <code>NA</code> Get Color Space of active port with video playback dsIsVideoPortActive(), dsGetColorSpace() <code>NA</code> <code>Y</code> <code>Y</code> <code>Y</code> <code>NA</code> Check each port Color Depth Capabilities and compare with the configuration YAML file . If it is a sink device, retrieve the value from the 'Sink_4K_VideoPort.yaml' file using the pat \"dsVideoPort/Ports/[port no]/Supported_color_depth_capabilities\" supported by INTERNAL port. For a source device, retrieve the value from the 'Source_4K_VideoPort.yaml' file using the path \"dsVideoPort/Ports/[port no]/Supported_color_depth_capabilities\" supported by <code>HDMI</code> port. dsColorDepthCapabilities() <code>Y</code> <code>NA</code> <code>Y</code> <code>NA</code> <code>NA</code> Get each port Color Depth and verify with the configuration YAML file . If it is a sink device, retrieve the value from the 'Sink_4K_VideoPort.yaml' file using the path \"color_depth\" supported by INTERNAL port. For a source device, retrieve the value from the 'Source_4K_VideoPort.yaml' file using the path \"color_depth\" supported by <code>HDMI</code> port. dsGetColorDepth() <code>Y</code> <code>NA</code> <code>Y</code> <code>Y</code> <code>NA</code> Get active port Color Depth and verify with the analyzer dsIsVideoPortActive(), dsGetColorDepth() <code>NA</code> <code>Y</code> <code>Y</code> <code>Y</code> <code>Y</code> Set preferred color depth for each port and compare get function dsSetPreferredColorDepth(), dsGetPreferredColorDepth() <code>Y</code> <code>NA</code> <code>Y</code> <code>NA</code> <code>NA</code> Set preferred color depth for current active port and verify with the analyzer dsIsVideoPortActive(), dsSetPreferredColorDepth() <code>NA</code> <code>Y</code> <code>Y</code> <code>NA</code> <code>Y</code> Get each port QuantizationRange status and verify with the configuration YAML file. If it is a sink device, retrieve the value from the 'Sink_4K_VideoPort.yaml' file using the path \"dsVideoPort/Ports/[port no]/quantization_ranges\" supported only by INTERNAL port. For a source device, retrieve the value from the 'Source_4K_VideoPort.yaml' file using the path \"dsVideoPort/Ports/[port no]/quantization_ranges\" supported by <code>HDMI</code> port. dsGetQuantizationRange() <code>Y</code> <code>NA</code> <code>Y</code> <code>Y</code> <code>NA</code> Get each port MatrixCoefficients status and verify return dsDISPLAY_MATRIXCOEFFICIENT_UNKNOWN for source and with the configuration YAML file. If it is a sink device, retrieve the value from the 'Sink_4K_VideoPort.yaml' file using the path \"dsVideoPort/Ports/[port no]/matrix_coefficients\" supported only by INTERNAL port. For a source device, retrieve the value from the 'Source_4K_VideoPort.yaml' file using the path \"dsVideoPort/Ports/[port no]/matrix_coefficients\" supported by <code>HDMI</code> port. dsGetMatrixCoefficients() <code>Y</code> <code>NA</code> <code>Y</code> <code>Y</code> <code>NA</code> Check active port MatrixCoefficients status with video playback and verify with analyzer dsIsVideoPortActive(), dsGetMatrixCoefficients() <code>NA</code> <code>Y</code> <code>Y</code> <code>Y</code> <code>NA</code> Set Background Color for active port with video playback and verify with analyzer/external device dsIsVideoPortActive(), dsSetBackgroundColor() <code>N</code> <code>Y</code> <code>Y</code> <code>NA</code> <code>Y</code> Gets current color space setting, color depth, matrix coefficients, HDR type,quantization range in one call of the active video port and verify with analyzer/external device dsIsVideoPortActive(), dsGetCurrentOutputSettings() <code>NA</code> <code>Y</code> <code>Y</code> <code>Y</code> <code>Y</code>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_High-Level_TestSpec/#test-startup-requirement-color-capabilities","title":"Test Startup Requirement-Color Capabilities","text":"<p>Playback the pre-define streams</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_High-Level_TestSpec/#emulator-requirements-color-capabilities","title":"Emulator Requirements-Color Capabilities","text":"<p>Emulator Requirements</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_High-Level_TestSpec/#control-plane-requirements-color-capabilities","title":"Control Plane Requirements-Color Capabilities","text":"<p>Verify the Color Space,Color Depth,QuantizationRange,MatrixCoefficients,Background Color with analyzer/external device</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_L2_Low-Level_TestSpecification/","title":"Device Settings Video Port L2 Low Level Test Specification and Procedure Documentation","text":""},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_L2_Low-Level_TestSpecification/#overview","title":"Overview","text":"<p>This document describes the L2 Low Level Test Specification and Procedure Documentation for the Device Settings Video Port module.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_L2_Low-Level_TestSpecification/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>HAL</code> - Hardware Abstraction Layer, may include some common components</li> <li><code>UT</code>  - Unit Test(s)</li> <li><code>OEM</code>  - Original Equipment Manufacture</li> <li><code>SoC</code>  - System on a Chip</li> <li><code>HDMI</code>  - High-Definition Multimedia Interface</li> <li><code>HDCP</code>  - High-bandwidth Digital Content Protection</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_L2_Low-Level_TestSpecification/#definitions","title":"Definitions","text":"<ul> <li><code>ut-core</code> - Common Testing Framework https://github.com/rdkcentral/ut-core, which wraps a open-source framework that can be expanded to the requirements for future framework.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_L2_Low-Level_TestSpecification/#references","title":"References","text":"<ul> <li><code>High Level Test Specification</code> - dsVideoPort High Level TestSpec</li> <li><code>Interface header</code> - dsVideoPort HAL header</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_L2_Low-Level_TestSpecification/#level-2-test-procedure","title":"Level 2 Test Procedure","text":"<p>The following functions are expecting to test the module operates correctly.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_L2_Low-Level_TestSpecification/#test-1","title":"Test 1","text":"Title Details Function Name <code>test_l2_dsVideoPort_EnableDisabledVideoPorts</code> Description Get the handle for supported video port from configuration file(<code>dsVideoPort/Number_of_ports</code>), check the status of each supported video port type <code>dsVideoPort/Ports/[port no]/Typeid</code> to see if it's enabled or disabled. If a port is disabled, enable it, and then verify the status of each port. Test Group 02 Test Case ID 001 Priority High <p>Pre-Conditions : None</p> <p>Dependencies : None</p> <p>User Interaction :</p> <p>If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_L2_Low-Level_TestSpecification/#test-procedure-test-1","title":"Test Procedure - Test 1","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the video port using <code>dsVideoPortInit</code> None <code>dsERR_NONE</code> Should be successful 02 Get the handle for each supported video port using <code>dsGetVideoPort</code> type = <code>dsVideoPort/Ports/[port no]/Typeid</code> index = <code>dsVideoPort/Ports/[port no]/Index</code> <code>dsERR_NONE</code> Should be successful 03 enable the video port using <code>dsEnableVideoPort</code> handle = obtained from <code>dsGetVideoPort</code> <code>dsERR_NONE</code> Should be successful 04 Verify the status of each port using <code>dsIsVideoPortEnabled</code> handle = obtained from <code>dsGetVideoPort</code> <code>dsERR_NONE</code>, enabled = true Should be successful 05 disabled port using <code>dsEnableVideoPort</code> handle = obtained from <code>dsGetVideoPort</code>, enabled = false <code>dsERR_NONE</code> Should be successful 06 Verify the status of each port using <code>dsIsVideoPortEnabled</code> handle = obtained from <code>dsGetVideoPort</code> <code>dsERR_NONE</code>, enabled = false Should be successful 07 Terminate the video port using <code>dsVideoPortTerm</code> None <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\n    A[Call dsVideoPortInit API] --&gt;|dsERR_NONE|B{For each supported&lt;br&gt; type and index &lt;br&gt; call dsGetVideoPort}\n    A --&gt;|Not dsERR_NONE|A1[Test case fail]\n    B --&gt;|dsERR_NONE and valid handle|D[Call dsEnableVideoPort API with true]\n    D --&gt;|dsERR_NONE|E[verify the port is true with dsIsVideoPortEnabled]\n    E --&gt;|check Enabled flag is true|F[Call dsEnableVideoPort API with false]\n    F --&gt;|dsERR_NONE|G[verify the port is false with dsIsVideoPortEnabled]\n    G --&gt;|Not dsERR_NONE|A4[Test case fail]\n    G --&gt; B\n    B --&gt;|End of loop|I[Call dsVideoPortTerm API]\n    I --&gt;|dsERR_NONE|J[Test case success]\n    I --&gt;|Not dsERR_NONE|I1[Test case fail]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_L2_Low-Level_TestSpecification/#test-2","title":"Test 2","text":"Title Details Function Name <code>test_l2_dsVideoPort_VerifyDisplayAndPortStatus</code> Description Get the handle for supported video port from configuration file(<code>dsVideoPort/Number_of_ports</code>), check the status of each supported video port type <code>dsVideoPort/Ports/[port no]/Typeid</code> .Verify the connected/disconnected status of each supported port's display when no video port is connected. Test Group 02 Test Case ID 002 Priority High <p>Pre-Conditions : None</p> <p>Dependencies : None</p> <p>User Interaction : If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_L2_Low-Level_TestSpecification/#test-procedure-test-2","title":"Test Procedure - Test 2","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the video port using <code>dsVideoPortInit</code> None <code>dsERR_NONE</code> Should be successful 02 Get the video port handle for supported type of video port using <code>dsGetVideoPort</code> type = <code>dsVideoPort/Ports/[port no]/Typeid</code> index = <code>dsVideoPort/Ports/[port no]/Index</code> <code>dsERR_NONE</code> Should be successful 03 Check if the display is connected for the obtained video port handle using <code>dsIsDisplayConnected</code> handle = obtained from <code>dsGetVideoPort</code> <code>dsERR_NONE</code>, connected = false Should be successful 04 Check if the video port is active for the obtained video port handle using <code>dsIsVideoPortActive</code> handle = obtained from <code>dsGetVideoPort</code> <code>dsERR_NONE</code>, active = false Should be successful 05 Terminate the video port using <code>dsVideoPortTerm</code> None <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\n    A[Call dsVideoPortInit] --&gt;|dsERR_NONE|B{For each supported&lt;br&gt; type and index &lt;br&gt; call dsGetVideoPort}\n    A --&gt;|Not dsERR_NONE|A1[Test case fail]\n    B --&gt;|dsERR_NONE and valid handle|C[Call dsIsDisplayConnected for each handle]\n    C --&gt;|dsERR_NONE and connected is false|D[Call dsIsVideoPortActive for each handle]\n    D --&gt;|Not dsERR_NONE|A2[Test case fail]\n    D --&gt;|dsERR_NONE and enabled flag is true|B\n    B --&gt;|End of loop|I[Call dsVideoPortTerm API]\n    I --&gt;|dsERR_NONE|J[Test case success]\n    I --&gt;|Not dsERR_NONE|I1[Test case fail]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_L2_Low-Level_TestSpecification/#test-3","title":"Test 3","text":"Title Details Function Name <code>test_l2_dsVideoPort_RetrieveAndVerifySurroundModeCapabilities</code> Description Get the handle for supported video port from configuration file(<code>dsVideoPort/Number_of_ports</code>), check the status of each supported video port type <code>dsVideoPort/Ports/[port no]/Typeid</code>.Retrieve the surround mode capabilities of each supported port and verify them with the configuration file. If it is a sink device, retrieve the value from 'configuration file using the path <code>dsVideoPort/Ports/[port no]/Display_surround</code> since the sink device has only an INTERNAL port. It is not supported for the source devices. Test Group 02 Test Case ID 003 Priority High <p>Pre-Conditions : None</p> <p>Dependencies : None</p> <p>User Interaction : If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_L2_Low-Level_TestSpecification/#test-procedure-test-3","title":"Test Procedure - Test 3","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the video port using <code>dsVideoPortInit</code> None <code>dsERR_NONE</code> Should be successful 02 Get the video port handle for supported type of video port using <code>dsGetVideoPort</code> type = <code>dsVideoPort/Ports/[port no]/Typeid</code> index = <code>dsVideoPort/Ports/[port no]/Index</code> <code>dsERR_NONE</code> Should be successful 03 Check if the display is in surround mode using <code>dsIsDisplaySurround</code> with the obtained handle handle = obtained from previous step <code>dsERR_NONE</code> Should be successful 04 Verify if the surround mode from previous step matches with the configuration file get_surround = <code>dsVideoPort/Ports/[port no]/Display_surround</code> None Should be successful 05 Terminate the video port using <code>dsVideoPortTerm</code> None <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\n    Step1[Call dsVideoPortInit API]\n    Step1 --&gt;|dsERR_NONE|Step2{For each supported &lt;br&gt; type and index &lt;br&gt; call dsGetVideoPort}\n    Step1 --&gt;|Not dsERR_NONE|Fail1[Test Case Failed]\n    Step2 --&gt;|dsERR_NONE and valid handle|Step3[Call dsIsDisplaySurround API]\n    Step3 --&gt;|dsERR_NONE and boolean value|Step4[Retrieve surround mode capabilities]\n    Step4 --&gt;|Not dsERR_NONE|Step5[Verify if dsIsDisplaySurround value matches with configuration file value]\n    Step5 --&gt;|loop through |Step2\n    Step2 --&gt;|End of loop|Step6[Call dsVideoPortTerm API]\n    Step5 --&gt;|Not match|Fail6[Test Case Failed]\n    Step6 --&gt;|dsERR_NONE|End[Test Case Passed]\n    Step6 --&gt;|Not dsERR_NONE|Fail5[Test Case Failed]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_L2_Low-Level_TestSpecification/#test-4","title":"Test 4","text":"Title Details Function Name <code>test_l2_dsVideoPort_SetAndGetResolution_source</code> Description Get the handle for supported video port from configuration file(<code>dsVideoPort/Number_of_ports</code>), check the status of each supported video port type <code>dsVideoPort/Ports/[port no]/Typeid</code>.Set properties for each supported video port, including pixel resolution, aspect ratio, stereoscopic modes, frame rates, and scan modes, looping through supported values. Verify the settings using the get function. Test Group 02 Test Case ID 004 Priority High <p>Pre-Conditions : None</p> <p>Dependencies : None</p> <p>User Interaction : If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_L2_Low-Level_TestSpecification/#test-procedure-test-4","title":"Test Procedure - Test 4","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize video port using <code>dsVideoPortInit</code> None <code>dsERR_NONE</code> Should be successful 02 Get the video port handle for supported type of video port using <code>dsGetVideoPort</code> Loop through each video port and get the handle using <code>dsGetVideoPort</code> type = <code>dsVideoPort/Ports/[port no]/Typeid</code> index = <code>dsVideoPort/Ports/[port no]/Index</code>. <code>dsERR_NONE</code> Should be successful 03 Loop through all possible pixel resolutions, aspect ratios, stereoscopic modes, frame rates, and scan modes pixelResolution = <code>dsVIDEO_PIXELRES_720x480</code> to <code>dsVIDEO_PIXELRES_MAX</code>, aspectRatio = <code>dsVIDEO_ASPECT_RATIO_4x3</code> to <code>dsVIDEO_ASPECT_RATIO_MAX</code>, stereoScopicMode = <code>dsVIDEO_SSMODE_UNKNOWN</code> to <code>dsVIDEO_SSMODE_MAX</code>, frameRate = <code>dsVIDEO_FRAMERATE_UNKNOWN</code> to <code>dsVIDEO_FRAMERATE_MAX</code>, interlaced = false <code>dsERR_NONE</code> Should be successful 04 Set resolution using <code>dsSetResolution</code> with handle and setResolution handle, &amp;setResolution <code>dsERR_NONE</code> Should be successful 05 Get resolution using <code>dsGetResolution</code> with handle and getResolution handle, &amp;getResolution <code>dsERR_NONE</code> Should be successful 06 Compare setResolution and getResolution setResolution, getResolution Equal values for all properties Should be successful 07 Terminate video port using <code>dsVideoPortTerm</code> None <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\n    A[Call dsVideoPortInit] --&gt;|dsERR_NONE|B{For each supported&lt;br&gt; type and index &lt;br&gt; call dsGetVideoPort}\n    A --&gt;|Not dsERR_NONE|A1[Test case Fail]\n    B --&gt;|Not dsERR_NONE|E[Set supported values&lt;br&gt; using dsSetResolution API]\n    E --&gt;|Not dsERR_NONE| F[Get values using dsGetResolution API]\n    F --&gt;|Not dsERR_NONE|G[Compare returned and set resolution]\n    G --&gt;|loop through | B\n    G --&gt;|Not dsERR_NONE|I1[Test case Fail]\n    B --&gt;|End of Iteration| I[Call dsVideoPortTerm]\n    I --&gt;|dsERR_NONE|J[Test case Success]\n    I --&gt;|Not dsERR_NONE|I2[Test case Fail]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_L2_Low-Level_TestSpecification/#test-5","title":"Test 5","text":"Title Details Function Name <code>test_l2_dsVideoPort_VerifySupportedTvResolutions</code> Description Get the handle for supported video port from configuration file(<code>dsVideoPort/Number_of_ports</code>), check the status of each supported video port type <code>dsVideoPort/Ports/[port no]/Typeid</code>.Gets the supported port Resolutions of TV and verify with the configuration file <code>dsVideoPort/Ports/[port no]/Supported_tv_resolutions_capabilities</code> Test Group 02 Test Case ID 005 Priority High <p>Pre-Conditions : None</p> <p>Dependencies : None</p> <p>User Interaction : If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_L2_Low-Level_TestSpecification/#test-procedure-test-5","title":"Test Procedure - Test 5","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the video port using <code>dsVideoPortInit</code> None <code>dsERR_NONE</code> Should be successful 02 Get the video port handle for supported type of video port using <code>dsGetVideoPort</code> Loop through each video port and get the handle using <code>dsGetVideoPort</code> type = <code>dsVideoPort/Ports/[port no]/Typeid</code> index = <code>dsVideoPort/Ports/[port no]/Index</code>. <code>dsERR_NONE</code> Should be successful 03 Get the supported TV resolutions using <code>dsSupportedTvResolutions</code> with the obtained handle handle = obtained from previous step <code>dsERR_NONE</code> Should be successful 04 Verify the obtained resolutions with the expected resolutions from the configuration file resolutions = value in <code>dsVideoPort/Ports/[port no]/Supported_tv_resolutions_capabilities</code> <code>dsERR_NONE</code> Should be successful 05 Terminate the video port using <code>dsVideoPortTerm</code> None <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\n    Step1[Call dsVideoPortInit API]\n    Step1 -- dsERR_NONE --&gt; Step2{For each supported&lt;br&gt; type and index &lt;br&gt; call dsGetVideoPort}\n    Step1 -- Not dsERR_NONE --&gt; Fail1[Test case fail]\n    Step2 -- dsERR_NONE and valid handle --&gt; Step3[Call dsSupportedTvResolutions API]\n    Step3 -- dsERR_NONE and valid resolutions --&gt; Step4[Verify if resolutions match with configuration file value]\n    Step4 --&gt;|loop through | Step2\n    Step4 -- Not Match --&gt; Fail2[Test case fail]\n    Step2 --&gt;|End of Iteration| Step5[Call dsVideoPortTerm API]\n    Step5 -- dsERR_NONE --&gt; End[Test Case Passed]\n    Step5 -- Not dsERR_NONE --&gt; Fail5[Test Case Failed]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_L2_Low-Level_TestSpecification/#test-6","title":"Test 6","text":"Title Details Function Name <code>test_l2_dsVideoPort_GetHDRCapabilities</code> Description Get the handle for supported video port from configuration file(<code>dsVideoPort/Number_of_ports</code>), check the status of each supported video port type <code>dsVideoPort/Ports/[port no]/Typeid</code>.Get the each supported port HDR capabilities &amp; verify with the configuration file <code>dsVideoPort/Ports/[port no]/hdr_capabilities</code> Test Group 02 Test Case ID 006 Priority High <p>Pre-Conditions : None</p> <p>Dependencies : None</p> <p>User Interaction : If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_L2_Low-Level_TestSpecification/#test-procedure-test-6","title":"Test Procedure - Test 6","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the video port using <code>dsVideoPortInit</code> None <code>dsERR_NONE</code> Should be successful 02 Get the video port handle for supported type of video port using dsGetVideoPort Loop through each video port and get the handle using <code>dsGetVideoPort</code> type = <code>dsVideoPort/Ports/[port no]/Typeid</code> index = <code>dsVideoPort/Ports/[port no]/Index</code>. <code>dsERR_NONE</code> Should be successful 03 Get the HDR capabilities of the TV using <code>dsGetTVHDRCapabilities</code> with the obtained handle handle = obtained from previous step <code>dsERR_NONE</code> Should be successful 04 Verify the obtained capabilities with the configuration file <code>dsVideoPort/Ports/[port no]/hdr_capabilities</code> Values should match capabilities = value in <code>dsVideoPort/Ports/[port no]/hdr_capabilities</code> Should be successful 05 Terminate the video port using <code>dsVideoPortTerm</code> None <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\n    A[Call dsVideoPortInit API] --&gt;|dsERR_NONE|B{For each supported&lt;br&gt; type and index &lt;br&gt; call dsGetVideoPort}\n    A --&gt;|Not dsERR_NONE|A1[Test case fail]\n    B --&gt;|dsERR_NONE and valid handle|C[Call dsGetTVHDRCapabilities API with handle]\n    C --&gt;|dsERR_NONE|D[Verify if output matches with value from configuration file]\n    D --&gt;|Not dsERR_NONE|A2[Test case fail]\n    D --&gt;|loop through | B\n    B --&gt;|End of Iteration| E[Call dsVideoPortTerm API]\n    E --&gt;|dsERR_NONE|F[Test case success]\n    E --&gt;|Not dsERR_NONE|E1[Test case fail]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_L2_Low-Level_TestSpecification/#test-7","title":"Test 7","text":"Title Details Function Name <code>test_l2_dsVideoPort_GetHDCPStatus</code> Description Get the handle for supported video port from configuration file(<code>dsVideoPort/Number_of_ports</code>), check the status of each supported video port type <code>dsVideoPort/Ports/[port no]/Typeid</code>.Check the <code>HDCP</code> status of each supported port and verify if <code>dsHDCP_STATUS_AUTHENTICATED</code> is returned for sinks and <code>dsHDCP_STATUS_UNPOWERED</code>/<code>dsHDCP_STATUS_PORTDISABLED</code> is returned for sources. Test Group 02 Test Case ID 007 Priority High <p>Pre-Conditions : None</p> <p>Dependencies : None</p> <p>User Interaction : If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_L2_Low-Level_TestSpecification/#test-procedure-test-7","title":"Test Procedure - Test 7","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the video port using <code>dsVideoPortInit</code> None <code>dsERR_NONE</code> Should be successful 02 Get the video port handle for supported type of video port using <code>dsGetVideoPort</code> Loop through each video port and get the handle using <code>dsGetVideoPort</code> type = <code>dsVideoPort/Ports/[port no]/Typeid</code> index = <code>dsVideoPort/Ports/[port no]/Index</code>. <code>dsERR_NONE</code> Should be successful 03 Get the <code>HDCP</code> status for each handle using <code>dsGetHDCPStatus</code> handle = obtained from dsGetVideoPort() <code>dsERR_NONE</code> Should be successful 04 Check if the <code>HDCP</code> status is authenticated status = obtained from <code>dsGetHDCPStatus</code> <code>dsHDCP_STATUS_AUTHENTICATED</code> Should be successful 05 Terminate the video port using <code>dsVideoPortTerm</code> None <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\n    A[Call dsVideoPortInit API] --&gt;|dsERR_NONE|B{For each supported&lt;br&gt; type and index &lt;br&gt; call dsGetVideoPort}\n    A --&gt;|Not dsERR_NONE|A1[Test Case Fail]\n    B --&gt;|dsERR_NONE and valid handle|C[Call dsGetHDCPStatus API with handle]\n    C --&gt;|dsERR_NONE and HDCP status|D[Verify HDCP status is dsHDCP_STATUS_AUTHENTICATED]\n    D --&gt;|Not dsERR_NONE|E2[Test Case Fail]\n    D --&gt;|Iterate through all possible values|B\n    B --&gt;|End of loop|E[Call dsVideoPortTerm API]\n    E --&gt;|dsERR_NONE|F[Test Case Success]\n    E --&gt;|Not dsERR_NONE|E1[Test Case Fail]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_L2_Low-Level_TestSpecification/#test-8","title":"Test 8","text":"Title Details Function Name <code>test_l2_dsVideoPort_VerifyHDCPProtocolStatus</code> Description Get the handle for supported video port from configuration file(<code>dsVideoPort/Number_of_ports</code>), check the status of each supported video port type <code>dsVideoPort/Ports/[port no]/Typeid</code>.Check the <code>HDCP</code> protocol status of each supported port and verify it with the configuration file <code>dsVideoPort/Ports/[port no]/hdcp_protocol_version</code> supported by <code>HDMI</code> port. Test Group 02 Test Case ID 008 Priority High <p>Pre-Conditions : None</p> <p>Dependencies : None</p> <p>User Interaction : If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_L2_Low-Level_TestSpecification/#test-procedure-test-8","title":"Test Procedure - Test 8","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the video port using <code>dsVideoPortInit</code> None <code>dsERR_NONE</code> Should be successful 02 Get the video port handle for supported type of video port using <code>dsGetVideoPort</code> Loop through each video port and get the handle using <code>dsGetVideoPort</code> type = <code>dsVideoPort/Ports/[port no]/Typeid</code> index = <code>dsVideoPort/Ports/[port no]/Index</code>. <code>dsERR_NONE</code> Should be successful 03 Get the HDCP protocol version using <code>dsGetHDCPProtocol</code> with the obtained handle handle = obtained from previous step <code>dsERR_NONE</code> Should be successful 04 Verify the obtained protocol version with the value from the configuration file protocolVersion = <code>dsVideoPort/Ports/[port no]/hdcp_protocol_version</code> <code>dsERR_NONE</code> Should be successful 05 Terminate the video port using <code>dsVideoPortTerm</code> None <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\n    Step1[Call dsVideoPortInit API]\n    Step1 -- dsERR_NONE --&gt; Step2{For each supported&lt;br&gt; type and index &lt;br&gt; call dsGetVideoPort}\n    Step1 -- Not dsERR_NONE --&gt; Fail1[Test Case Failed]\n    Step2 -- dsERR_NONE and valid handle --&gt; Step3[Call dsGetHDCPProtocol API and get HDCP protocol version]\n    Step3 -- dsERR_NONE --&gt; Step5[Compare the version with the value from configuration file ]\n    Step5 --&gt;|loop through | Step2\n    Step5 -- Not dsERR_NONE --&gt; Fail3[Test Case Failed]\n    Step2 --&gt;|End of Iteration| Step6[Call dsVideoPortTerm API]\n    Step6 -- dsERR_NONE --&gt; End[Test Case Passed]\n    Step6 -- Not dsERR_NONE --&gt; Fail6[Test Case Failed]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_L2_Low-Level_TestSpecification/#test-9","title":"Test 9","text":"Title Details Function Name <code>test_l2_dsVideoPort_SetAndGetHdmiPreference</code> Description Get the handle for supported video port from configuration file(<code>dsVideoPort/Number_of_ports</code>), check the status of each supported video port type <code>dsVideoPort/Ports/[port no]/Typeid</code>.Set the HDMI preference    for each valid port and verify it using the get function. Test Group 02 Test Case ID 009 Priority High <p>Pre-Conditions : None</p> <p>Dependencies : None</p> <p>User Interaction : If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_L2_Low-Level_TestSpecification/#test-procedure-test-9","title":"Test Procedure - Test 9","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the video port using <code>dsVideoPortInit</code> None <code>dsERR_NONE</code> Should be successful 02 Get the video port handle for supported type of video port using <code>dsGetVideoPort</code> Loop through each video port and get the handle using <code>dsGetVideoPort</code> type = <code>dsVideoPort/Ports/[port no]/Typeid</code> index = <code>dsVideoPort/Ports/[port no]/Index</code>. <code>dsERR_NONE</code> Should be successful 03 Get the <code>HDCP</code> protocol version using <code>dsGetHDCPProtocol</code> with the obtained handle handle = obtained from <code>dsGetVideoPort</code> <code>dsERR_NONE</code> Should be successful 04 Verify the <code>HDCP</code> protocol version with the value from the configuration file protocolVersion = value <code>dsVideoPort/Ports/[port no]/hdcp_protocol_version</code> <code>dsERR_NONE</code> Should be successful 05 Terminate the video port using <code>dsVideoPortTerm</code> None <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\n    A[Call dsVideoPortInit] --&gt;|return dsERR_NONE|B{For each supported&lt;br&gt; type and index &lt;br&gt; call dsGetVideoPort}\n    B --&gt;|return dsERR_NONE and valid handle|D[Call dsSetHdmiPreference&lt;br&gt; to set supported protocol version]\n    A --&gt;|Not dsERR_NONE|C[Test case fail]\n    D --&gt;|dsERR_NONE|F[Call dsGetHdmiPreference API]\n    F --&gt;|Not dsERR_NONE|A2[Test case fail]\n    F --&gt;|loop through | B\n    B --&gt;|End of Iteration|J[Call dsVideoPortTerm API]\n    J --&gt;|dsERR_NONE|K[Test case success]\n    J --&gt;|Not dsERR_NONE|L[Test case fail]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_L2_Low-Level_TestSpecification/#test-10","title":"Test 10","text":"Title Details Function Name <code>test_l2_dsVideoPort_GetColorSpace</code> Description Get each port Color Space, compare with the configuration file. Test Group 02 Test Case ID 010 Priority High <p>Pre-Conditions : None</p> <p>Dependencies : None</p> <p>User Interaction : If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_L2_Low-Level_TestSpecification/#test-procedure-test-10","title":"Test Procedure - Test 10","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize video port using <code>dsVideoPortInit</code> None <code>dsERR_NONE</code> Should be successful 02 Get video port handle using <code>dsGetVideoPort</code> with type as <code>dsVIDEOPORT_TYPE_INTERNAL</code> and index as 0 type = <code>dsVIDEOPORT_TYPE_INTERNAL</code>, index = 0 <code>dsERR_NONE</code> Should be successful 03 Get color space using <code>dsGetColorSpace</code> with handle obtained from previous step handle = handle obtained from step 02 <code>dsERR_NONE</code> Should be successful 04 Compare the obtained color space with the value from the configuration file color_space = value in <code>dsVideoPort/Ports/[port no]/colorspaces</code> Value from the configuration file Should be successful 05 Terminate video port using <code>dsVideoPortTerm</code> None <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\nA[Call dsVideoPortInit] --&gt;|dsERR_NONE|B{For each supported&lt;br&gt; type and index &lt;br&gt; call dsGetVideoPort}\nA --&gt;|Not dsERR_NONE|A1[Test case fail]\nB --&gt;|dsERR_NONE and valid handle|C[Call dsGetColorSpace API]\nC --&gt;|dsERR_NONE|D[Compare color space &lt;br&gt;with value from profile file]\nD --&gt;|loop through | B\nD --&gt;|dsERR_NONE|E2[Test case fail]\nB --&gt;|End of Iteration| E[Call dsVideoPortTerm]\nE --&gt;|dsERR_NONE|F[Test case success]\nE --&gt;|dsERR_NONE|E1[Test case fail]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_L2_Low-Level_TestSpecification/#test-11","title":"Test 11","text":"Title Details Function Name <code>test_l2_dsVideoPort_CheckColorDepthCapabilities_source</code> Description Check each port Color Depth Capabilities and compare with the configuration file. Test Group 02 Test Case ID 011 Priority High <p>Pre-Conditions : None</p> <p>Dependencies : None</p> <p>User Interaction : If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_L2_Low-Level_TestSpecification/#test-procedure-test-11","title":"Test Procedure - Test 11","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the video port using <code>dsVideoPortInit</code> None <code>dsERR_NONE</code> Should be successful 02 Get the video port handle using <code>dsGetVideoPort</code> with <code>dsVIDEOPORT_TYPE_HDMI</code> and index 0 <code>dsVIDEOPORT_TYPE_HDMI</code>, 0 <code>dsERR_NONE</code> Should be successful 03 Check the color depth capabilities using <code>dsColorDepthCapabilities</code> with the obtained handle handle <code>dsERR_NONE</code> Should be successful 04 Compare the obtained color depth capability with the value from the configuration file colorDepthCapability = value in <code>dsVideoPort/Ports/[port no]/Supported_color_depth_capabilities</code> Check if equal Should be successful 05 Terminate the video port using <code>dsVideoPortTerm</code> None <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\n    Step1[Call dsVideoPortInit] --&gt;|dsERR_NONE| Step2{For each supported&lt;br&gt; type and index &lt;br&gt; call dsGetVideoPort}\n    Step1 -- \"Not dsERR_NONE\" --&gt; Fail1[Test Case Failed]\n    Step2 -- \"dsERR_NONE and valid handle\" --&gt; Step3[Call dsColorDepthCapabilities API with handle]\n    Step3 -- \"dsERR_NONE\" --&gt; Step4[Compare if value retrieved &lt;br&gt;from API and configuration file matches]\n    Step4 --&gt;|loop through | Step2\n    Step4 -- \"dsERR_NONE\" --&gt; Fail6[Test Case Failed]\n    Step2 --&gt;|End of Iteration| Step6[Call dsVideoPortTerm API]\n    Step6 -- \"dsERR_NONE\" --&gt; End[Test Case Passed]\n    Step6 -- \"Not dsERR_NONE\" --&gt; Fail4[Test Case Failed]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_L2_Low-Level_TestSpecification/#test-12","title":"Test 12","text":"Title Details Function Name <code>test_l2_dsVideoPort_GetColorDepth</code> Description Get each port Color Depth and verify with the configuration file. Test Group 02 Test Case ID 012 Priority High <p>Pre-Conditions : None</p> <p>Dependencies : None</p> <p>User Interaction : If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_L2_Low-Level_TestSpecification/#test-procedure-test-12","title":"Test Procedure - Test 12","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the video port using <code>dsVideoPortInit</code> None <code>dsERR_NONE</code> Should be successful 02 Get the video port handle using <code>dsGetVideoPort</code> with type=<code>dsVIDEOPORT_TYPE_INTERNAL</code> and index=0 type=<code>dsVIDEOPORT_TYPE_INTERNAL</code>, index=0 <code>dsERR_NONE</code> Should be successful 03 Get the color depth using <code>dsGetColorDepth</code> with the obtained handle handle=obtained handle <code>dsERR_NONE</code> Should be successful 04 Verify the obtained color depth with the value from the configuration file color_depth=value in <code>dsVideoPort/Ports/[port no]/Supported_color_depth_capabilities</code> Should be equal Should be successful 05 Terminate the video port using <code>dsVideoPortTerm</code> None <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\n    A[Call dsVideoPortInit] --&gt;|dsERR_NONE|B{For each supported&lt;br&gt; type and index &lt;br&gt; call dsGetVideoPort}\n    A --&gt;|Not dsERR_NONE|A1[Test case fail]\n    B --&gt;|dsERR_NONE and valid handle|C[Call dsGetColorDepth with handle from previous step]\n    C --&gt;|dsERR_NONE|D[Compare the color depth &lt;br&gt;values from API and configuration file]\n    D --&gt;|loop through | B\n    D --&gt;|dsERR_NONE|E2[Test case fail]\n    B --&gt;|End of Iteration| F[Call dsVideoPortTerm]\n    F --&gt;|dsERR_NONE|G[Test case success]\n    F --&gt;|Not dsERR_NONE|F1[Test case fail]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_L2_Low-Level_TestSpecification/#test-13","title":"Test 13","text":"Title Details Function Name <code>test_l2_dsVideoPort_SetAndGetPreferredColorDepth_source</code> Description Set preferred color depth for each port and compare get function Test Group 02 Test Case ID 013 Priority High <p>Pre-Conditions : None</p> <p>Dependencies : None</p> <p>User Interaction : If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_L2_Low-Level_TestSpecification/#test-procedure-test-13","title":"Test Procedure - Test 13","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize video port using <code>dsVideoPortInit</code> None <code>dsERR_NONE</code> Should be successful 02 Get video port handle for each port type using <code>dsGetVideoPort</code> type = <code>dsVIDEOPORT_TYPE_RF</code> to <code>dsVIDEOPORT_TYPE_MAX</code>, index = 0 <code>dsERR_NONE</code> Should be successful 03 Set preferred color depth for each color depth type using <code>dsSetPreferredColorDepth</code> handle = from step 02, colorDepthSet = <code>dsDISPLAY_COLORDEPTH_8BIT</code> to <code>dsDISPLAY_COLORDEPTH_AUTO</code> <code>dsERR_NONE</code> Should be successful 04 Get preferred color depth using <code>dsGetPreferredColorDepth</code> handle = from step 02, colorDepthGet <code>dsERR_NONE</code> Should be successful 05 Compare set and get color depth colorDepthSet = colorDepthGet colorDepthSet should be equal to colorDepthGet Should be successful 06 Terminate video port using <code>dsVideoPortTerm</code> None <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\n    Step1[Call dsVideoPortInit] --&gt;|dsERR_NONE| Step2{For each supported&lt;br&gt; type and index &lt;br&gt; call dsGetVideoPort}\n    Step1 -- \"Not dsERR_NONE\" --&gt; Fail1[Test Case Failed]\n    Step2 --&gt;|dsERR_NONE and valid handle|Step3[Call dsSetPreferredColorDepth API]\n    Step3 --&gt;|dsERR_NONE|Step4[Call dsGetPreferredColorDepth API]\n    Step4 --&gt;|dsERR_NONE|Step5[Compare color depth values]\n    Step5 --&gt;|loop through | Step2\n    Step5 -- \"dsERR_NONE\" --&gt; Fail6[Test Case Failed]\n    Step2 --&gt;|End of Iteration|Step7[Call dsVideoPortTerm API]\n    Step7 --&gt;|dsERR_NONE|End[Test Case success]\n    Step7 --&gt;|Failure|TestcaseFail6[Testcase Fail]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_L2_Low-Level_TestSpecification/#test-14","title":"Test 14","text":"Title Details Function Name <code>test_l2_dsVideoPort_GetQuantizationRange</code> Description Get each port QuantizationRange status and verify with the configuration file. Test Group 02 Test Case ID 014 Priority High <p>Pre-Conditions : None</p> <p>Dependencies : None</p> <p>User Interaction : If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_L2_Low-Level_TestSpecification/#test-procedure-test-14","title":"Test Procedure - Test 14","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the video port using <code>dsVideoPortInit</code> None <code>dsERR_NONE</code> Should be successful 02 Get the video port handle using <code>dsGetVideoPort</code> with <code>dsVIDEOPORT_TYPE_INTERNAL</code> as type and 0 as index type = <code>dsVIDEOPORT_TYPE_INTERNAL</code>, index = 0 <code>dsERR_NONE</code> Should be successful 03 Get the Quantization Range using <code>dsGetQuantizationRange</code> with the handle obtained from previous step handle = obtained from step 02 <code>dsERR_NONE</code> Should be successful 04 Verify the Quantization Range with the value from the configuration file quantization_range = value in <code>dsVideoPort/Ports/[port no]/quantization_ranges</code> Should be equal Should be successful 05 Terminate the video port using <code>dsVideoPortTerm</code> None <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\n    Start(Start) --&gt; Step1[Call dsVideoPortInit]\n    Step1 -- dsERR_NONE --&gt; Step2{For each supported&lt;br&gt; type and index &lt;br&gt; call dsGetVideoPort}\n    Step1 -- Not dsERR_NONE --&gt; TestcaseFail1[Test case fail]\n    Step2 -- dsERR_NONE and valid handle --&gt; Step3[Call dsGetQuantizationRange with handle]\n    Step3 -- dsERR_NONE and valid quantization range --&gt; Step4[Compare quantization &lt;br&gt;range with configuration file]\n    Step4 --&gt;|loop through | Step2\n    Step4 -- Not dsERR_NONE --&gt; TestcaseFail5[Test case fail]\n    Step2  --&gt; |End of Iteration|Step5[Call dsVideoPortTerm]\n    Step5 -- dsERR_NONE --&gt; End[Test case success]\n    Step5 -- Not dsERR_NONE --&gt; TestcaseFail6[Test case fail]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_L2_Low-Level_TestSpecification/#test-15","title":"Test 15","text":"Title Details Function Name <code>test_l2_dsVideoPort_GetMatrixCoefficients</code> Description Get each port MatrixCoefficients status and verify return <code>dsDISPLAY_MATRIXCOEFFICIENT_UNKNOWN</code> for source and with the configuration file. Test Group 02 Test Case ID 015 Priority High <p>Pre-Conditions : None</p> <p>Dependencies : None</p> <p>User Interaction : If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_L2_Low-Level_TestSpecification/#test-procedure-test-15","title":"Test Procedure - Test 15","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the video port using <code>dsVideoPortInit</code> None <code>dsERR_NONE</code> Should be successful 02 Get the video port with type=<code>dsVIDEOPORT_TYPE_INTERNAL</code> and index=1 using <code>dsGetVideoPort</code> type=<code>dsVIDEOPORT_TYPE_INTERNAL</code>, index=1 <code>dsERR_NONE</code> Should be successful 03 Get the Matrix Coefficients with handle obtained from <code>dsGetVideoPort</code> using <code>dsGetMatrixCoefficients</code> handle=handle obtained from <code>dsGetVideoPort</code> <code>dsERR_NONE</code> Should be successful 04 Verify the Matrix Coefficients with the value from the configuration file matrix_coefficients=<code>dsVideoPort/Ports/[port no]/matrix_coefficients</code> Should be equal Should be successful 05 Terminate the video port using <code>dsVideoPortTerm</code> None <code>dsERR_NONE</code> Should be successful <pre><code>graph TB\n    Start(Start) --&gt; Step1[Call dsVideoPortInit]\n    Step1 -- dsERR_NONE --&gt; Step2{For each supported&lt;br&gt; type and index &lt;br&gt; call dsGetVideoPort}\n    Step1 -- Not dsERR_NONE --&gt; TestcaseFail1[Test case fail]\n    Step2 -- dsERR_NONE and valid handle --&gt; Step3[Call dsGetMatrixCoefficients with handle]\n    Step3 -- dsERR_NONE --&gt; Step4[Compare the retrieved matrix_coefficients&lt;br&gt; with value from configuration file]\n    Step4 --&gt;|loop through | Step2\n    Step4 -- Not dsERR_NONE --&gt; Fail7[Test Case Fail]\n    Step2 --&gt;|End of Iteration| Step6[Call dsVideoPortTerm]\n    Step6 -- dsERR_NONE --&gt; End[Test Case Success]\n    Step6 -- Not dsERR_NONE --&gt; Fail6[Test Case Fail]</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_L3_Low-Level_TestSpecification/","title":"Device Settings Video Port L3 Low Level Test Specification and Procedure Documentation","text":""},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_L3_Low-Level_TestSpecification/#overview","title":"Overview","text":"<p>This document describes the L3 Low Level Test Specification and Procedure Documentation for the Device Settings Video Port module.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_L3_Low-Level_TestSpecification/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>HAL</code> - Hardware Abstraction Layer, may include some common components</li> <li><code>UT</code>  - Unit Test(s)</li> <li><code>OEM</code> - Original Equipment Manufacture</li> <li><code>SoC</code> - System on a Chip</li> <li><code>HDMI</code>- High-Definition Multimedia Interface</li> <li><code>HDCP</code>- High-bandwidth Digital Content Protection</li> <li><code>HDR</code> - High Dynamic Range</li> <li><code>HLG</code> - Hybrid Log-Gamma</li> <li><code>SDR</code> - Standard Dynamic Range</li> <li><code>Y</code>   - yes supported</li> <li><code>NA</code>  - Not Supported</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_L3_Low-Level_TestSpecification/#references","title":"References","text":"<ul> <li><code>High Level Test Specification</code> - dsVideoPort High Level TestSpec</li> <li><code>Interface header</code> - dsVideoPort HAL header</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_L3_Low-Level_TestSpecification/#level-3-test-cases-high-level-overview","title":"Level 3 Test Cases High Level Overview","text":"# Streams Name Streams description 1 vts_HDR10_stream Format: HDR10,Resolution: 3840 x 2160 (4K UHD),Color Depth: 10-bit,Color Space: Rec. 2020 2 vts_SDR_stream Format: SDR,Resolution: 1920 x 1080 3 vts_HLG_stream Format: HLG,Resolution: 3840 x 2160 or It can also be used with 1080p and 720p resolutions. 4 vts_DolbyVision_stream Format: Dolby Vision,Resolution: 3840 x 2160 (4K UHD),Color Depth: 10/12-bit,Color Space: Rec. 2020format and dynamic metadata. 5 vts_HDR10plus_stream Format: HDR10,Resolution: 3840 x 2160 (4K UHD),Color Depth: 10-bit,Color Space: Rec. 2020 and dynamic metadata capabilities. <p>Each test case need to verify with the each supported video port. Below are top test use-case for the video port.</p> # Test-case Description HAL APIs Source Sink Streams Number 1 Verify the Video content Formats with callbacks Play the pre-defined streams with different video content format(<code>HDR</code>,<code>HLG</code>,DolbyVision,..) and check the callbacks is triggered when the video content format changes <code>dsVideoFormatUpdateRegisterCB()</code> <code>dsGetVideoEOTF()</code> <code>NA</code> <code>Y</code> 1,2,3,4,5 2 Check DisplayConnected Verify the Display by enabling and disable each supported video port <code>dsEnableVideoPort()</code> <code>dsIsDisplayConnected()</code> <code>dsIsVideoPortActive()</code> <code>Y</code> <code>Y</code> 1 3 Select the <code>HDCP</code> Version Select the Supported <code>HDCP</code> version and verify <code>dsSetHdmiPreference()</code> <code>Y</code> <code>Y</code> <code>NA</code> 4 Verify the Resolution for source Play the pre-defined stream and set supported resolution and verify the resolution of the TV <code>dsSetResolution()</code> <code>Y</code> <code>NA</code> <code>NA</code> 5 Verify the <code>HDCP</code> status using callbacks for Source Power off and power on TV or pug/unplug <code>HDMI</code> and Check the <code>HDCP</code> status using callbacks(i.e.UNPOWERED,AUTHENTICATED,..) <code>dsEnableHDCP()</code> <code>Y</code> <code>NA</code> <code>NA</code> 6 Select video content formats for Source Select the Supported <code>HDR</code> modes &amp; Verify the video content formats using callbacks <code>dsSetForceHDRMode()</code> <code>Y</code> <code>NA</code> 1,2,3,4,5 7 Resets the video output to <code>SDR</code> for Source Play the <code>HDR</code> stream and verify the video content formats <code>dsResetOutputToSDR()</code> <code>Y</code> <code>NA</code> 1 8 Select preferred color depth for Source Select the Color depth from Supported list &amp; verify <code>dsSetPreferredColorDepth()</code> <code>Y</code> <code>NA</code> <code>NA</code> 9 sets the background color for Source Select the background color form supported list &amp; verify <code>dsSetBackgroundColor()</code> <code>Y</code> <code>NA</code> <code>NA</code>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_L3_Low-Level_TestSpecification/#level-3-python-test-cases-high-level-overview","title":"Level 3 Python Test Cases High Level Overview","text":"<p>The class diagram below illustrates the flow of dsVideoPort L3 Python test cases:</p> <pre><code>---\ntitle: dsVideoPort - Python Class Flow\n---\nclassDiagram\n    testControl &lt;|-- ut_raft : inherits\n    class ut_raft{\n    }\n    ut_raft &lt;|-- L3_TestHelperClass : inherits\n    L3_TestHelperClass ..&gt; dsVideoPort : uses\n    note for testControl \"uses rackConfig.yaml and deviceConfig.yaml\"\n    note for dsVideoPort \"uses platformProfile.yaml\"\n    note for L3_TestHelperClass \"uses testSetupConfig.yaml\"\n    note for ut_raft \"suite Navigator uses testSuite.yaml\"</code></pre> <ul> <li>testControl</li> <li>Test Control Module for running rack Testing. This module configures the <code>DUT</code> based on the rack configuration file provided to the test.</li> <li>This class is defined in <code>RAFT</code> framework. For more details refer RAFT</li> <li>ut_raft</li> <li>Python based testing framework for writing engineering tests.</li> <li>It provides common functionalities like menu navigation, configuration reader, reading user response etc.</li> <li>For more details ut-raft.</li> <li>dsVideoPort</li> <li>This is test helper class which communicates with the <code>L3</code> C/C++ test running on the <code>DUT</code> through menu</li> <li>L3_TestHelperClass</li> <li>Each test class uses HelperClass to write a test case define in L3 Test use-cases.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_L3_Low-Level_TestSpecification/#yaml-file-inputs","title":"YAML File Inputs","text":"<ul> <li>rackConfig.yaml</li> <li>Identifies the rack configuration and platform used</li> <li>References platform-specific config from <code>deviceConfig.yaml</code></li> <li> <p>For more details refer RAFT and example_rack_config.yml</p> </li> <li> <p>deviceConfig.yaml</p> </li> <li>Specifies overall configuration for the platform</li> <li>Can be overridden by:<ul> <li>Changing locally .yaml file directory</li> <li>Using --deviceConfig command line switch</li> </ul> </li> <li> <p>For more details refer RAFT and example_device_config.yml</p> </li> <li> <p>componentProfile.yaml/platformProfile.yaml</p> </li> <li>Contains component-specific configurations</li> <li>Contains platform wide configuration broken down into separate components</li> <li> <p>Example configuration file dsVidePort Profile</p> </li> <li> <p>testSetupConfig.yaml</p> </li> <li>This configuration file contains the list of requirements for tests to execute. Eg: Copying the streams, setting environment variables etc.</li> <li> <p>Example configuration file dsVideoPort_L3_testSetup.yml</p> </li> <li> <p>testSuite.yaml</p> </li> <li>This configuration file contains the list of menu items for C/C++ L3 test running on <code>DUT</code></li> <li>Example configuration file dsVideoPort_testConfig.yml</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_L3_Low-Level_TestSpecification/#l3-test-procedure-documentation","title":"L3 Test Procedure Documentation","text":"<ul> <li>L3 test procedure doc</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_L3_Test-Procedure/","title":"Device Settings Video Port L3 Test Case and Procedure Documentation","text":""},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_L3_Test-Procedure/#overview","title":"Overview","text":"<p>This document describes the L3 Test case Procedure Documentation for the Device Settings Video Port module.</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_L3_Test-Procedure/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>HAL</code> - Hardware Abstraction Layer, may include some common components</li> <li><code>UT</code>  - Unit Test(s)</li> <li><code>OEM</code> - Original Equipment Manufacture</li> <li><code>SoC</code> - System on a Chip</li> <li><code>HDMI</code>- High-Definition Multimedia Interface</li> <li><code>HDCP</code>- High-bandwidth Digital Content Protection</li> <li><code>HDR</code> - High Dynamic Range</li> <li><code>HLG</code> - Hybrid Log-Gamma</li> <li><code>SDR</code> - Standard Dynamic Range</li> <li><code>Y</code>   - yes supported</li> <li><code>NA</code>  - Not Supported</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_L3_Test-Procedure/#references","title":"References","text":"<ul> <li><code>High Level Test Specification</code> - dsVideoPort High Level TestSpec</li> <li><code>dsVideoPort L3 Low Level Test Specification</code> - dsVideoPort L3 LowLevel TestSpec</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_L3_Test-Procedure/#setting-up-test-environment","title":"Setting Up Test Environment","text":"<p>To execute <code>HAL</code> <code>L3</code> Python test cases, need a Python environment. Follow these steps mentioned in HPK Public Documentation</p>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_L3_Test-Procedure/#update-configuration-files","title":"Update Configuration Files","text":""},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_L3_Test-Procedure/#rack-configuration-file","title":"Rack Configuration File","text":"<ul> <li>It identifies the rack configuration and platform used. We need to update our target device specif information in the rackconfig.yaml. In this file, update the configuration to define the console sessions for the device under test (DUT) Example Rack configuration File: <code>ut/host/tests/configs/example_rack_config.yml</code></li> <li>For more details refer RAFT and example_rack_config.yml</li> </ul> <p>In this file, update the configuration to define the console sessions for the <code>DUT</code> and the outbound settings:</p> Console Session Description default Downloads the streams required for test cases. ssh_player Plays the stream required for test case. ssh_hal_test Executes the HAL binary for the test case. <p>```yaml rackConfig:   - dut:       ip: \"XXX.XXX.XXX.XXX\"  # IP Address of the device       description: \"stb device under test\"       platform: \"stb\"       consoles:         - default:             type: \"ssh\"             port: 10022             username: \"root\"             ip: \"XXX.XXX.XXX\" # IP address of the device             password: ' '         - ssh_player:             type: \"ssh\"             port: 10022             username: \"root\"             ip: \"XXX.XXX.XXX\" # IP address of the device             password: ' '         - ssh_hal_test:             type: \"ssh\"             port: 10022             username: \"root\"             ip: \"XXX.XXX.XXX\" # IP address of the device             password: ' '       outbound:         download_url: \"tftp://tftp-server.com/rack1/slot1/\"    # Download location for the CPE device         upload_url: \"sftp://server-address/home/workspace/tftp/rack1/slot1/\" # Upload location         upload_url_base_dir: \"sftp://server-address/home/workspace/tftp/rack1/slot1\"         httpProxy:   # Local proxy if required         workspaceDirectory: './logs/workspace'   # Local working directory</p> <pre><code>#### Device Configuration File\n\n  Example Device configuration File: `ut/host/tests/configs/deviceConfig.yml`\n\nFor more details refer [RAFT](https://github.com/rdkcentral/python_raft/blob/1.0.0/README.md) and [example_device_config.yml](https://github.com/rdkcentral/python_raft/blob/1.0.0/examples/configs/example_device_config.yml)\n\nUpdate the target directory where `HAL` binaries will be copied into the device. Also, map the profile to the source/sink settings `YAML` file path.\n\nEnsure the platform should match with the `DUT` platform in [Rack Configuration](#rack-configuration-file)\n\n```yaml\ndeviceConfig:\n    cpe1:\n        platform: \"xi-one\"\n        model: \"uk\"\n        soc_vendor: \"realtek\"\n        target_directory: \"/opt/\"  # Target Directory on device\n        prompt: \"\" # Prompt string on console\n        test:\n            #TODO: Use the single profile file which contains all details (ds, hdmi, etc)\n            profile: \"../../../../profiles/source/Source_4K_VideoPort.yaml\"\n            streams_download_url: \"\" #URL path from which the streams are downloaded to the device\n</code></pre> <ul> <li>Example Device Config file: deviceConfig.yml.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_L3_Test-Procedure/#test-setup-configuration-file","title":"Test Setup Configuration File","text":"<p>Each test case requires a stream name to be provided if required. If a test case involves multiple streams or requires validation using several streams, ensure that all necessary streams are added sequentially under the specific test case.</p> <p>The URL paths for the streams are defined in the deviceConfig.yml file, under the parameter <code>streams_download_url</code></p> <ul> <li>Example configuration file dsVideoPort_L3_testSetup.yml.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_L3_Test-Procedure/#test-suite-configuration","title":"Test Suite Configuration","text":"<p>Update the execute command according to the device path where <code>HAL</code> binaries are copied and Update the test suite for each level test case</p> <ul> <li>Example configuration file: dsVideoPort_testConfig.yml.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_L3_Test-Procedure/#run-test-cases","title":"Run Test Cases","text":"<p>Once the environment is set up, you can execute the test cases with the following command</p> <pre><code>python &lt;TestCaseName.py&gt; --config &lt;/PATH&gt;/ut/host/tests/configs/example_rack_config.yml --deviceConfig &lt;/PATH&gt;/ut/host/tests/configs/deviceConfig.yml\n</code></pre>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_L3_Test-Procedure/#test-case-procedure","title":"Test Case Procedure","text":""},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_L3_Test-Procedure/#dsvideoport_test1_verifyvideocontent_format_callbackpy","title":"dsVideoPort_test1_VerifyVideoContent_Format_Callback.py","text":"<p>Overview:</p> <p>This test plays pre-defined streams in various video content formats (HDR, HLG, Dolby Vision, etc.) and checks if the appropriate callbacks are triggered when the video format changes.</p> <p>Platform Supported:</p> <p>Sink</p> <p>User Input Required:</p> <p>No</p> <p>Acceptance Criteria:</p> <p>Play the pre-defined streams with different video content formats (HDR, HLG, Dolby Vision, etc.) and check that the callbacks are triggered when the video content format changes.</p> <p>Expected Results:</p> <p>The test will download and play multiple streams, each corresponding to a specific video format, and verify that the expected callbacks are triggered. After playback, the streams will be removed, and the test will pass if all expected callbacks are received.</p> <p>Test Steps:</p> <ul> <li>Run the Python file dsVideoPort_test1_VerifyVideoContent_Format_Callback.py with the required configuration:</li> </ul> <pre><code>dsVideoPort_test1_VerifyVideoContent_Format_Callback.py --config /host/tests/configs/example_rack_config.yml --deviceConfig /host/tests/configs/deviceConfig.yml\n</code></pre> <ul> <li>The test will download the required assets and begin execution, playing streams in various formats.</li> <li>For each video format, the test will verify that the appropriate callbacks are triggered:</li> <li>NONE Video Format Callback</li> <li><code>HDR10</code> Video Format Callback</li> <li><code>HLG</code> Video Format Callback</li> <li><code>Dolby Vision</code> Video Format Callback</li> <li><code>HDR10PLUS</code> Video Format Callback</li> <li><code>SDR</code> Video Format Callback</li> <li>The test will pass if all the required callbacks are detected; otherwise, it will fail.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_L3_Test-Procedure/#dsvideoport_test2_enabledisableandverifyportstatuspy","title":"dsVideoPort_test2_EnableDisableAndVerifyPortStatus.py","text":"<p>Overview:</p> <p>This test enables and disables video ports, requiring manual user interaction to verify if the video is displayed when the port is enabled, and if the display is blank when the port is disabled. The user is asked to confirm the video playback status.</p> <p>Platform Supported:</p> <p>Source, Sink</p> <p>User Input Required:</p> <p>Yes:User input is required to verify whether the video is playing or not with prompt question <code>Is Video Display on the port? (Y/N)</code> (This will be automated later).</p> <p>Acceptance Criteria:</p> <p>Verify the Display by enabling and disable each supported video port.</p> <p>Expected Results:</p> <p>The video is visible when the port is enabled and goes blank when the port is disabled. User responses (Y/N) will determine if the test passes.</p> <p>Test Steps:</p> <ul> <li>Run the Python file <code>dsVideoPort_test2_EnableDisableAndVerifyPortStatus.py</code> with the appropriate configuration:</li> </ul> <pre><code>dsVideoPort_test2_EnableDisableAndVerifyPortStatus.py --config /host/tests/configs/example_rack_config.yml --deviceConfig /host/tests/configs/deviceConfig.yml\n</code></pre> <ul> <li>The test will download all required artifacts and streams, copy them to the target directory, and start execution.</li> <li>The test will play the stream, enable the video port, and ask the user to confirm the video playback status. It will then disable the port and ask the user to confirm that the display is blank.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_L3_Test-Procedure/#dsvideoport_test3_verifyhdcp_versionpy","title":"dsVideoPort_test3_VerifyHDCP_Version.py","text":"<p>Overview:</p> <p>This test is designed to verify the correct <code>HDCP</code> version used during video playback. The test will specifically enable <code>HDCP</code> 2.2 encryption and ask the user to confirm the version displayed using an AV analyzer connected to the video output. The user must verify if the correct <code>HDCP</code> version is being used.</p> <p>Platform Supported:</p> <p>Source, Sink</p> <p>User Input Required:</p> <p>Yes: The user is required to verify the <code>HDCP</code> version on an external AV analyzer connected to the device. (This will be automated later).</p> <p>Acceptance Criteria:</p> <p>The test must successfully enable HDCP 2.2 encryption, and the user must confirm that HDCP 2.X is displayed on the AV analyzer for the test to pass.</p> <p>Expected Results:</p> <p>The test will enable HDCP 2.2 encryption on the video output. The user will confirm the correct HDCP version using a supported AV analyzer, ensuring proper encryption is applied.</p> <p>Test Steps:</p> <ul> <li>Run the Python file <code>dsVideoPort_test3_VerifyHDCP_Version.py</code> with the appropriate configuration:</li> </ul> <pre><code>dsVideoPort_test3_VerifyHDCP_Version.py --config /host/tests/configs/example_rack_config.yml --deviceConfig /host/tests/configs/deviceConfig.yml\n</code></pre> <ul> <li>Download and copy all required assets to the target directory.</li> <li>Enable HDCP 2.2 encryption on the video output.</li> <li>Prompt the user to verify that HDCP 2.X is displayed on the AV analyzer.</li> <li>The test will pass if the user confirms that the correct HDCP version is being used.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_L3_Test-Procedure/#dsvideoport_test4_verifyresolutionpy","title":"dsVideoPort_test4_VerifyResolution.py","text":"<p>Overview:</p> <p>This test verifies the resolution settings supported by the source device. It sets different resolutions and checks additional parameters, including aspect ratio, SS mode, frame rate, and scan mode. The user must confirm the accuracy of these settings using an AV analyzer connected to the video output. The test involves manual verification of video parameters displayed on the AV analyzer.</p> <p>Platform Supported:</p> <p>Source</p> <p>User Input Required:</p> <p>Yes: The user must verify the video resolution and other attributes (aspect ratio, SS mode, frame rate, scan mode) using a connected AV analyzer. (This will be automated later).</p> <p>Acceptance Criteria:</p> <p>The user verifies that the correct resolution, aspect ratio, SS mode, frame rate, and scan mode are displayed on the AV analyzer for each tested video resolution.</p> <p>Expected Results:</p> <p>The test sets various resolutions on the video output and prompts the user to confirm the correctness of the settings via an AV analyzer. If all settings match, the test will pass</p> <p>Test Steps:</p> <ul> <li>Run the Python file <code>dsVideoPort_test4_VerifyResolution.py</code> with the appropriate configuration:</li> </ul> <pre><code>dsVideoPort_test4_VerifyResolution.py --config /host/tests/configs/example_rack_config.yml --deviceConfig /host/tests/configs/deviceConfig.yml\n</code></pre> <ul> <li>The test will download the required artifacts and streams, then copy them to the target directory.</li> <li>For each supported resolution, the test will set the following parameters and prompt the user for confirmation using an AV analyzer:</li> <li>Resolution (e.g., 720x480, 1920x1080)</li> <li>Aspect Ratio (e.g., 4:3, 16:9)</li> <li>SS Mode (e.g., 2D, 3D)</li> <li>Frame Rate (e.g., 29.97, 60 Hz)</li> <li>Scan Mode (e.g., Interlaced, Progressive)</li> <li>The test will repeat step 3 for all supported resolutions.</li> <li>If the user confirms the correct settings for all resolutions and parameters, the test will pass.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_L3_Test-Procedure/#dsvideoport_test5_verifyhdcp_callbackpy","title":"dsVideoPort_test5_VerifyHDCP_Callback.py","text":"<p>Overview:</p> <p>This test verifies <code>HDCP</code> status using callbacks during HDMI plug and unplug events. The test will ask the user to physically disconnect and reconnect the <code>HDMI</code> cable and then verify whether the appropriate <code>HDCP</code> callbacks for \"plug\" and \"unplug\" events are received and logged.</p> <p>Platform Supported:</p> <p>Source</p> <p>User Input Required:</p> <p>Yes: The user is required to unplug and plug the <code>HDMI</code> cable and confirm actions using the AV analyzer. (This will be automated in future versions.)</p> <p>Acceptance Criteria:</p> <ul> <li>The user successfully unplugs and plugs the <code>HDMI</code> cable.</li> <li>The system receives the appropriate <code>HDCP</code> status callbacks: \"HDMI Unplug Callback found\" and \"HDMI Plug Callback found.\"</li> </ul> <p>Expected Results:</p> <ul> <li>The test prompts the user to physically disconnect and reconnect the HDMI cable.</li> <li>The system detects the HDMI plug/unplug events and verifies the corresponding HDCP callbacks.</li> </ul> <p>Test Steps:</p> <ul> <li>Run the Python file <code>dsVideoPort_test5_VerifyHDCP_Callback.py</code> with the appropriate configuration:</li> </ul> <pre><code>dsVideoPort_test5_VerifyHDCP_Callback.py --config /host/tests/configs/example_rack_config.yml --deviceConfig /host/tests/configs/deviceConfig.yml\n</code></pre> <ul> <li>The test will automatically download the necessary artifacts and streams, copy them to the target directory, and begin execution.</li> <li>The test prompts the user to perform the following actions:</li> <li>Unplug the <code>HDMI</code> cable when prompted with:<ul> <li><code>UnPlug the HDMI Cable? (Y/N):</code></li> <li>The user must unplug the <code>HDMI</code> cable and confirm by entering 'y'.</li> </ul> </li> <li>Plug the HDMI cable back in when prompted with:<ul> <li><code>Plug the HDMI Cable? (Y/N):</code></li> <li>The user must plug the <code>HDMI</code> cable and confirm by entering 'y'.</li> </ul> </li> <li>The user must also confirm that the following HDCP callbacks are received and logged:</li> <li><code>HDMI Unplug Callback found</code></li> <li><code>HDMI Plug Callback found</code></li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_L3_Test-Procedure/#dsvideoport_test6_verifyvideocontentformatspy","title":"dsVideoPort_test6_VerifyVideoContentFormats.py","text":"<p>Overview:</p> <p>This test verifies the supported <code>HDR</code> (High Dynamic Range) video content formats by playing various predefined streams and checking their formats via callbacks. The user will confirm the displayed formats using an AV analyzer.</p> <p>Platform Supported:</p> <p>Source</p> <p>User Input Required:</p> <p>Yes: The user needs to verify HDR formats using an AV analyzer(This will be automated in future versions with callbacks.)</p> <p>Acceptance Criteria:</p> <ul> <li>The test will play streams in different HDR formats.</li> <li>The user must verify and confirm the video content format displayed on the analyzer for each HDR mode.</li> </ul> <p>Expected Results:</p> <ul> <li>The test will automatically download and play predefined video streams in different HDR content formats.</li> <li>The user must confirm the displayed format using an AV analyzer for formats like HDR10, HLG, Dolby Vision, and HDR10+.</li> <li>The test passes if the user confirms all HDR formats were displayed correctly.</li> </ul> <p>Test Steps:</p> <ul> <li>Run the Python file <code>dsVideoPort_test6_VerifyVideoContentFormats.py</code> with the appropriate configuration:</li> </ul> <pre><code>dsVideoPort_test6_VerifyVideoContentFormats.py --config /host/tests/configs/example_rack_config.yml --deviceConfig /host/tests/configs/deviceConfig.yml\n</code></pre> <ul> <li>The test will automatically download the necessary artifacts and streams, copy them to the target directory, and begin execution.</li> <li> <p>The test will play streams in various HDR content formats and prompt the user to confirm the format displayed on the analyzer:</p> </li> <li> <p>Is dsHDRSTANDARD_HDR10 displayed on the analyzer? (Y/N)</p> </li> <li>Is dsHDRSTANDARD_HLG displayed on the analyzer? (Y/N)</li> <li>Is dsHDRSTANDARD_DolbyVision displayed on the analyzer? (Y/N)</li> <li>Is dsHDRSTANDARD_HDR10PLUS displayed on the analyzer? (Y/N)</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_L3_Test-Procedure/#dsvideoport_test7_resettosdrmodepy","title":"dsVideoPort_test7_ResetToSDRMode.py","text":"<p>Overview:</p> <p>This test verifies the ability to reset the video output from <code>HDR</code> to <code>SDR</code> . The user will confirm if the video format has changed successfully from <code>HDR</code> to <code>SDR</code> using a display analyzer.</p> <p>Platform Supported:</p> <p>Source</p> <p>User Input Required:</p> <p>Yes: The user will verify whether the video playback has switched from HDR to SDR. (This will be automated in future versions.)</p> <p>Acceptance Criteria:</p> <ul> <li>The test will play an HDR stream, and the video content format will be reset to SDR.</li> <li>The user must verify that the playback format changes from HDR to SDR.</li> <li>The test will query the user with: \"Is Video Display on the port?\" to confirm if SDR mode is enabled.</li> </ul> <p>Expected Results:</p> <ul> <li>The test will download and play an HDR stream.</li> <li>It will switch the playback from HDR to SDR mode.</li> <li>The user must confirm that the video display is now in SDR mode using an analyzer or visual confirmation.</li> </ul> <p>Test Steps:</p> <ul> <li>Run the Python file <code>dsVideoPort_test7_ResetToSDRMode.py</code> with the appropriate configuration:</li> </ul> <pre><code>dsVideoPort_test7_ResetToSDRMode.py --config /host/tests/configs/example_rack_config.yml --deviceConfig /host/tests/configs/deviceConfig.yml\n</code></pre> <ul> <li>The test will automatically download the necessary artifacts and streams, copy them to the target directory, and begin execution.</li> <li>The test will play <code>HDR</code> video content and switch the playback output to <code>SDR</code> mode. The user must verify that the output has changed to <code>SDR</code>:</li> <li>Is Video Playback in <code>HDR</code>on the port? (Y/N):</li> <li>If the answer is \"Yes\", the test passes.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_L3_Test-Procedure/#dsvideoport_test8_verifycolordepthpy","title":"dsVideoPort_test8_VerifyColorDepth.py","text":"<p>Overview:</p> <p>This test verifies that the video output color depth on supported video ports can be correctly set and confirmed by the user using an AV analyzer or through command-line verification. The test focuses on verifying the 8-bit color depth configuration, which the source device supports.</p> <p>Platform Supported:</p> <p>Source</p> <p>User Input Required:</p> <p>Yes: The user will verify if the color depth has been correctly set using an AV analyzer or command-line output. (This will be automated in future versions.)</p> <p>Acceptance Criteria:</p> <ul> <li>The test will set the color depth to 8-bit, and the user will confirm if the output has been set correctly.</li> <li>The user can verify this by inspecting the AV analyzer or running the command HdmiClient get-res to check the color depth.</li> </ul> <p>Expected Results:</p> <ul> <li>The test will set the color depth to 8-bit (supported by the source device).</li> <li>The user will confirm if the video output matches the set color depth:</li> <li>Is dsDISPLAY_COLORDEPTH_10BIT displayed on the Analyzer (Y/N)?</li> </ul> <p>Test Steps:</p> <ul> <li>Run the Python file <code>dsVideoPort_test8_VerifyColorDepth.py</code> with the appropriate configuration:</li> </ul> <pre><code>dsVideoPort_test8_VerifyColorDepth.py --config /host/tests/configs/example_rack_config.yml --deviceConfig /host/tests/configs/deviceConfig.yml\n</code></pre> <ul> <li>The test will automatically download the necessary artifacts and streams, copy them to the target directory, and begin execution.</li> <li>The test will configure the color depth to 8-bit, which is supported by the source device.</li> <li>The user will be asked to confirm if the color depth has been correctly set by checking the AV analyzer or running the command:</li> <li><code>Is dsVIDEO_BGCOLOR_BLUE displayed on the Analyzer (Y/N)?</code></li> <li>If the answer is <code>Yes,</code> the test will pass.</li> </ul>"},{"location":"external_content/device_settings_test/docs/pages/dsVideoPort/ds-video-port_L3_Test-Procedure/#dsvideoport_test9_verifybackgroundcolorpy","title":"dsVideoPort_test9_VerifyBackgroundColor.py","text":"<p>Overview:</p> <p>This test verifies that the video output background color on supported video ports can be correctly set and confirmed by the user. The test allows the user to select a background color from a supported list and asks for confirmation of the color setting via an AV analyzer.</p> <p>Platform Supported:</p> <p>Source</p> <p>User Input Required:</p> <p>Yes: The user will verify if the background color has been correctly set using an AV analyzer.(This will be automated in future versions.)</p> <p>Acceptance Criteria:</p> <p>he test will set the background color from the supported list and ask the user to confirm whether the color is displayed correctly.</p> <p>Expected Results:</p> <ul> <li>The test will set the background color from the supported list and ask the user to verify each color:</li> <li>Is dsVIDEO_BGCOLOR_BLUE displayed on the Analyzer (Y/N)?</li> <li>Is dsVIDEO_BGCOLOR_BLACK displayed on the Analyzer (Y/N)?</li> <li>Is dsVIDEO_BGCOLOR_NONE displayed on the Analyzer (Y/N)?</li> <li>If the user answers \"Yes\" to all three questions, the test will pass.</li> </ul> <p>Test Steps:</p> <ul> <li>Run the Python file <code>dsVideoPort_test9_VerifyBackgroundColor.py</code> with the appropriate configuration:</li> </ul> <pre><code>dsVideoPort_test9_VerifyBackgroundColor.py --config /host/tests/configs/example_rack_config.yml --deviceConfig /host/tests/configs/deviceConfig.yml\n</code></pre> <ul> <li>The test will automatically download the necessary artifacts and streams, copy them to the target directory, and begin execution.</li> <li>The test will set the background color from the supported list and prompt the user for confirmation. The user will be asked to verify the following colors:</li> <li>Is dsVIDEO_BGCOLOR_BLUE displayed on the Analyzer (Y/N)?</li> <li>Is dsVIDEO_BGCOLOR_BLACK displayed on the Analyzer (Y/N)?</li> <li>Is dsVIDEO_BGCOLOR_NONE displayed on the Analyzer (Y/N)?</li> <li>If the answers to all three questions are \"Yes,\" the test will pass.</li> </ul>"},{"location":"external_content/hdmi_cec/","title":"HDMI CEC HAL Documentation","text":""},{"location":"external_content/hdmi_cec/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>HDMI</code>   - High-Definition Multimedia Interface</li> <li><code>CEC</code>    - Consumer Electronics Control</li> <li><code>HAL</code>    - Hardware Abstraction Layer</li> <li><code>API</code>    - Application Programming Interface</li> <li><code>Caller</code> - Any user of the interface via the <code>APIs</code></li> </ul>"},{"location":"external_content/hdmi_cec/#references","title":"References","text":"<ul> <li><code>HDMI-CEC Specification</code> - High-Definition Multimedia Interface, Specification Version 1.4b, (https://www.hdmi.org/)</li> <li>Downloadable via this link</li> <li>refer to Supplement 1 - Consumer Electronics Control (CEC) </li> </ul>"},{"location":"external_content/hdmi_cec/#description","title":"Description","text":"<p>The diagram below describes a high-level software architecture of the module stack.</p> <pre><code>%%{ init : { \"theme\" : \"forest\", \"flowchart\" : { \"curve\" : \"linear\" }}}%%\nflowchart TD\ny[Caller]--&gt;x[HDMI CEC HAL];\nx[HDMI CEC HAL]--&gt;z[HDMI CEC SOC Driver];\nstyle y fill:#99CCFF,stroke:#333,stroke-width:0.3px,align:left\nstyle z fill:#fcc,stroke:#333,stroke-width:0.3px,align:left\nstyle x fill:#9f9,stroke:#333,stroke-width:0.3px,align:left</code></pre> <p>This interface provides a set of <code>APIs</code> to facilitate communication through the driver for <code>CEC</code> messages with other <code>CEC</code> devices connected with HDMI cable.</p> <p>The interface retrieves and discovers logical and physical address of the host device, it is responsibile for transmitting and receiving messages with remote device(s) synchronously / asynchronously.</p> <p>The <code>CEC</code> protocol responsibilities will lie between the <code>caller</code> and the <code>HAL</code>.</p> <ul> <li>The <code>caller</code> must be responsible for <code>CEC</code> higher level protocol as defined in <code>HDMI-CEC Specification</code> Section <code>CEC 12</code>.</li> <li>The <code>caller</code> must pass fully formed <code>CEC</code> messages to the <code>HAL</code> for the transmission.</li> <li>The <code>HAL</code> must be responsible for physical device discovery and announcements on the <code>CEC</code> network as defined in the <code>HDMI-CEC Specification</code> Section <code>CEC 10</code>.</li> <li>The driver layer is responsible for the physical layer as defined in the Section <code>CEC 4</code> (Electrical Specification) and Section <code>CEC 5</code> (Signalling and Bit Timings). The driver layer is out-of-scope for this document.</li> </ul>"},{"location":"external_content/hdmi_cec/#component-runtime-execution-requirements","title":"Component Runtime Execution Requirements","text":"<p><code>CEC</code> message transmit operation must complete within one second. Desired <code>CEC</code> response time is 200 milliseconds and maximum response time must be 1 second as provided in the <code>CEC</code> specifications (<code>HDMI-CEC Specification</code>). <code>Caller</code> is responsible to perform retry operations as per the <code>CEC</code> specification requirements. <code>Caller</code> will retry each transmission in line with a requirement as specified in Section <code>CEC 7.1</code> of the HMDI-CEC specification.</p>"},{"location":"external_content/hdmi_cec/#initialization-and-startup","title":"Initialization and Startup","text":"<p><code>Caller</code> must initialize by calling <code>HdmiCecOpen()</code> before calling any other <code>API</code>.</p>"},{"location":"external_content/hdmi_cec/#threading-model","title":"Threading Model","text":"<p>This interface is not required to be thread safe. Any caller invoking the <code>APIs</code> must ensure calls are made in a thread safe manner.</p>"},{"location":"external_content/hdmi_cec/#process-model","title":"Process Model","text":"<p>This interface is required to support a single instantiation with a single process.</p>"},{"location":"external_content/hdmi_cec/#memory-model","title":"Memory Model","text":"<p>For transmit messages, it is upto the caller to allocate and free the memory for the message buffer. For receive messages, the <code>HAL</code> is responsible for memory management. The memory allocated cannot exceed 20 bytes (<code>HDMI-CEC Specification</code> Section <code>CEC 6</code>).</p>"},{"location":"external_content/hdmi_cec/#power-management-requirements","title":"Power Management Requirements","text":"<p>Although this interface is not required to be involved in any of the power management operations, the state transitions MUST not affect its operation. e.g. on resumption from a low power state, the interface must operate as if no transition has occurred.</p>"},{"location":"external_content/hdmi_cec/#asynchronous-notification-model","title":"Asynchronous Notification Model","text":"<p>For asynchronous transmit and receive operations, the following <code>APIs</code> and callback registrations are used:</p> <ol> <li>For async transmit use: <code>HdmiCecTxAsync()</code></li> <li>For async receive call back use: <code>HdmiCecSetRxCallback()</code></li> <li>For async transmit ack use: <code>HdmiCecSetTxCallback()</code></li> </ol> <p>The caller is required to return the callback context as fast as possible.</p>"},{"location":"external_content/hdmi_cec/#blocking-calls","title":"Blocking calls","text":"<p>There are no blocking calls. Synchronous calls must complete within a reasonable time period in accordance with any relevant <code>CEC</code> specification. Any call that can fail due to the lack of response from the connected device must have a timeout period in accordance with any relevant <code>CEC</code> specification and the function must return the relevant error code.</p>"},{"location":"external_content/hdmi_cec/#internal-error-handling","title":"Internal Error Handling","text":"<p>All the <code>APIs</code> must return error synchronously as a return argument. <code>HAL</code> is responsible for handling system errors (e.g. out of memory) internally.</p>"},{"location":"external_content/hdmi_cec/#persistence-model","title":"Persistence Model","text":"<p>There is no requirement for the interface to persist any setting information. <code>Caller</code> is responsible to persist any settings related to the <code>HAL</code>.</p>"},{"location":"external_content/hdmi_cec/#non-functional-requirements","title":"Non-functional requirements","text":""},{"location":"external_content/hdmi_cec/#logging-and-debugging-requirements","title":"Logging and debugging requirements","text":"<p>This interface is required to support DEBUG, INFO and ERROR messages. DEBUG and INFO must be disabled by default and enabled when required.</p>"},{"location":"external_content/hdmi_cec/#memory-and-performance-requirements","title":"Memory and performance requirements","text":"<p>This interface is required to not cause excessive memory and CPU utilization.</p>"},{"location":"external_content/hdmi_cec/#quality-control","title":"Quality Control","text":"<ul> <li>This interface is required to perform static analysis, our preferred tool is Coverity.</li> <li>Have a zero-warning policy with regards to compiling. All warnings are required to be treated as error.</li> <li>Copyright validation is required to be performed, e.g.: Black duck, FossID.</li> <li>Use of memory analysis tools like Valgrind are encouraged, to identify leaks/corruptions.</li> <li><code>HAL</code> Tests will endeavour to create worst case scenarios to assist investigations.</li> <li>Improvements by any party to the testing suite are required to be fed back.</li> </ul>"},{"location":"external_content/hdmi_cec/#licensing","title":"Licensing","text":"<p>The <code>HAL</code> implementation is expected to released under the Apache License 2.0. </p>"},{"location":"external_content/hdmi_cec/#build-requirements","title":"Build Requirements","text":"<p>The source code must build into a shared library and must be named as <code>libRCECHal.so</code>. The build mechanism must be independent of Yocto.</p>"},{"location":"external_content/hdmi_cec/#variability-management","title":"Variability Management","text":"<p>Any changes in the <code>APIs</code> must be reviewed and approved by the component architects.</p>"},{"location":"external_content/hdmi_cec/#platform-or-product-customization","title":"Platform or Product Customization","text":"<p>None</p>"},{"location":"external_content/hdmi_cec/#interface-api-documentation","title":"Interface API Documentation","text":"<p><code>API</code> documentation will be provided by Doxygen which will be generated from the header files.</p>"},{"location":"external_content/hdmi_cec/#theory-of-operation-and-key-concepts","title":"Theory of operation and key concepts","text":"<p>The caller is expected to have complete control over the life cycle of the <code>HAL</code>.</p> <ol> <li> <p>Initialize the <code>HAL</code> using function: <code>HdmiCecOpen()</code> before making any other <code>API</code> calls. This call also discovers the physical address based on the connection topology. In case of source devices, <code>HdmiCecOpen()</code> must initiate the logical address discovery as part of this routine. In case of sink devices, logical address will be fixed and set using the <code>HdmiCecAddLogicalAddress()</code>. If <code>HdmiCecOpen()</code> call fails, the <code>HAL</code> must return the respective error code, so that the caller can retry the operation.</p> </li> <li> <p>Once logical address and physical address are assigned, the caller will be able to send and receive the respective <code>CEC</code> messages.</p> </li> <li> <p>For asynchronous receive operations, use the callback function: <code>HdmiCecSetRxCallback()</code>. the caller must register a callback after initialisation.</p> </li> <li> <p>For synchronous transmit, use the function: <code>HdmiCecTx()</code>.</p> </li> <li> <p>For asynchronous transmit, use the function: <code>HdmiCecTxAsync()</code>. The caller must register a callback via <code>HdmiCecSetTxCallback()</code> in order to receive the status or acknowledgement.</p> </li> </ol> <p>3.De-intialise the <code>HAL</code> using the function: <code>HdmiCecClose()</code>.</p> <p>NOTE: The module would operate deterministically if the above call sequence is followed.</p>"},{"location":"external_content/hdmi_cec/#diagrams","title":"Diagrams","text":""},{"location":"external_content/hdmi_cec/#operational-call-sequence","title":"Operational Call Sequence","text":"<pre><code>%%{ init : { \"theme\" : \"default\", \"flowchart\" : { \"curve\" : \"stepBefore\" }}}%%\n   sequenceDiagram\n    participant Caller as Caller\n    participant HAL as HDMI CEC HAL\n    participant Driver as HDMI Device Control/Driver\n    Caller-&gt;&gt;HAL:HdmiCecOpen()\n    Note over HAL: SOC intialises and discovers &lt;br&gt; physical address based on the connection topology &lt;br&gt; source devices discovers logical address internally  based on device type.\n    HAL-&gt;&gt;Driver: soc intialises\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:HdmiCecSetRxCallback()\n    HAL-&gt;&gt;Driver: Setting a receiver callback in soc\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:HdmiCecSetTxCallback()\n    HAL-&gt;&gt;Driver:Setting a transmit callback in soc\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    Caller -&gt;&gt;HAL:HdmiCecAddLogicalAddress()\n    Note over Caller: Sink devices must set the logical address using the API &lt;br&gt; HdmiCecAddLogicalAddress (Only for sink devices)\n    HAL-&gt;&gt;Driver: add logical address in soc\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    Caller -&gt;&gt;HAL:HdmiCecGetLogicalAddress()\n    HAL-&gt;&gt;Driver:Get logical address from soc\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    Caller -&gt;&gt;HAL:HdmiCecGetPhysicalAddress()\n    HAL-&gt;&gt;Driver:Get physical address in soc\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    Caller -&gt;&gt;HAL:HdmiCecTx()\n    Note over Caller,HAL: sync CEC transmit message\n    HAL-&gt;&gt;Driver: Transmit packet in soc side\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    Driver--&gt;&gt;HAL:RxCallback()\n    Note over HAL: For CEC message received from the remote device, HdmiCecSetRxCallback() will be triggered\n    HAL--&gt;&gt;Caller:HdmiCecRxCallback() triggered\n    Caller -&gt;&gt;HAL:HdmiCecClose()\n    Note over Caller,HAL: SOC Un-initialises \n    HAL-&gt;&gt;Driver: Soc Un-initialises\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return</code></pre>"},{"location":"external_content/hdmi_cec/CHANGELOG/","title":"Changelog","text":""},{"location":"external_content/hdmi_cec/CHANGELOG/#changelog","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file. Dates are displayed in UTC.</p> <p>Generated by <code>auto-changelog</code>.</p>"},{"location":"external_content/hdmi_cec/CHANGELOG/#1310","title":"1.3.10","text":"<ul> <li>gh #11 Modified the description of result param in HdmiCecTx <code>#12</code></li> </ul>"},{"location":"external_content/hdmi_cec/CHANGELOG/#139","title":"1.3.9","text":"<p>28 June 2024</p> <ul> <li>gh #4 HDMI Spec Version update <code>#10</code></li> <li>Bumped CHANGELOG.md - 1.3.9 <code>4af0a90</code></li> <li>Merge tag '1.3.8' into develop <code>7fd9b82</code></li> </ul>"},{"location":"external_content/hdmi_cec/CHANGELOG/#138","title":"1.3.8","text":"<p>22 May 2024</p> <ul> <li>gh #6 Update HDMI CEC Interface <code>#7</code></li> <li>gh #6 CEC Architecture Review comment addressal <code>5a770e1</code></li> <li>gh #6 HdmiCecRemoveLogicalAddress Update &amp; HdmiCecTxAsync deprecation <code>deed402</code></li> <li>Bumped CHANGELOG.md - 1.3.8 <code>406ee58</code></li> </ul>"},{"location":"external_content/hdmi_cec/CHANGELOG/#137","title":"1.3.7","text":"<p>14 November 2023</p> <ul> <li>Updated build_ut.sh, generate_docs.sh and gitignore <code>#3</code></li> <li>Baseline version <code>55c1046</code></li> <li>Updated CHANGELOG.md - 1.3.7 <code>a9daa8d</code></li> <li>Updated LICENSE file name in header <code>aebaa51</code></li> </ul>"},{"location":"external_content/hdmi_cec/CHANGELOG/#020","title":"0.2.0","text":"<p>21 March 2024</p> <ul> <li>RDK6 Changes <code>3d03b3c</code></li> <li>Added CHANGELOG.md - 0.2.0 <code>196b3e8</code></li> <li>Initial commit <code>67e87e9</code></li> </ul>"},{"location":"external_content/hdmi_cec/CONTRIBUTING/","title":"Contributing","text":"<ul> <li>If you wish to make code contributions to this project, the source is hosted at github.com/rdkcentral.</li> </ul> <p>You can submit your changes for review via that site, by raising an issue in github, (https://github.com/rdkcentral/xxxx/issues), and following the sequence below.</p> <ul> <li>create a branch with a name follow the guidelines gh(x)_(synopsis)</li> <li>where x is the ticket number</li> <li>where synopsis is a short synopsis for the reason for the branch.</li> <li>create a pull request (https://github.com/rdkcentral/xxxx/compare) when the code changes are ready for review.</li> <li> <p>The team will review, and if accepted your changes will be merged to the mainline.</p> </li> <li> <p>In order to contribute code, first-time users are requested to agree to the license.</p> </li> <li> <p>where <code>xxxx</code> is your module name</p> </li> </ul>"},{"location":"external_content/hdmi_cec/docs/pages/CONTRIBUTING/","title":"Contributing","text":"<ul> <li>If you wish to make code contributions to this project, the source is hosted at github.com/rdkcentral.</li> </ul> <p>You can submit your changes for review via that site, by raising an issue in github, (https://github.com/rdkcentral/xxxx/issues), and following the sequence below.</p> <ul> <li>create a branch with a name follow the guidelines gh(x)_(synopsis)</li> <li>where x is the ticket number</li> <li>where synopsis is a short synopsis for the reason for the branch.</li> <li>create a pull request (https://github.com/rdkcentral/xxxx/compare) when the code changes are ready for review.</li> <li> <p>The team will review, and if accepted your changes will be merged to the mainline.</p> </li> <li> <p>In order to contribute code, first-time users are requested to agree to the license.</p> </li> <li> <p>where <code>xxxx</code> is your module name</p> </li> </ul>"},{"location":"external_content/hdmi_cec/docs/pages/hdmi-cec_halSpec/","title":"HDMI CEC HAL Documentation","text":""},{"location":"external_content/hdmi_cec/docs/pages/hdmi-cec_halSpec/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>HDMI</code>   - High-Definition Multimedia Interface</li> <li><code>CEC</code>    - Consumer Electronics Control</li> <li><code>HAL</code>    - Hardware Abstraction Layer</li> <li><code>API</code>    - Application Programming Interface</li> <li><code>Caller</code> - Any user of the interface via the <code>APIs</code></li> </ul>"},{"location":"external_content/hdmi_cec/docs/pages/hdmi-cec_halSpec/#references","title":"References","text":"<ul> <li><code>HDMI-CEC Specification</code> - High-Definition Multimedia Interface, Specification Version 1.4b, (https://www.hdmi.org/)</li> <li>Downloadable via this link</li> <li>refer to Supplement 1 - Consumer Electronics Control (CEC) </li> </ul>"},{"location":"external_content/hdmi_cec/docs/pages/hdmi-cec_halSpec/#description","title":"Description","text":"<p>The diagram below describes a high-level software architecture of the module stack.</p> <pre><code>%%{ init : { \"theme\" : \"forest\", \"flowchart\" : { \"curve\" : \"linear\" }}}%%\nflowchart TD\ny[Caller]--&gt;x[HDMI CEC HAL];\nx[HDMI CEC HAL]--&gt;z[HDMI CEC SOC Driver];\nstyle y fill:#99CCFF,stroke:#333,stroke-width:0.3px,align:left\nstyle z fill:#fcc,stroke:#333,stroke-width:0.3px,align:left\nstyle x fill:#9f9,stroke:#333,stroke-width:0.3px,align:left</code></pre> <p>This interface provides a set of <code>APIs</code> to facilitate communication through the driver for <code>CEC</code> messages with other <code>CEC</code> devices connected with HDMI cable.</p> <p>The interface retrieves and discovers logical and physical address of the host device, it is responsibile for transmitting and receiving messages with remote device(s) synchronously / asynchronously.</p> <p>The <code>CEC</code> protocol responsibilities will lie between the <code>caller</code> and the <code>HAL</code>.</p> <ul> <li>The <code>caller</code> must be responsible for <code>CEC</code> higher level protocol as defined in <code>HDMI-CEC Specification</code> Section <code>CEC 12</code>.</li> <li>The <code>caller</code> must pass fully formed <code>CEC</code> messages to the <code>HAL</code> for the transmission.</li> <li>The <code>HAL</code> must be responsible for physical device discovery and announcements on the <code>CEC</code> network as defined in the <code>HDMI-CEC Specification</code> Section <code>CEC 10</code>.</li> <li>The driver layer is responsible for the physical layer as defined in the Section <code>CEC 4</code> (Electrical Specification) and Section <code>CEC 5</code> (Signalling and Bit Timings). The driver layer is out-of-scope for this document.</li> </ul>"},{"location":"external_content/hdmi_cec/docs/pages/hdmi-cec_halSpec/#component-runtime-execution-requirements","title":"Component Runtime Execution Requirements","text":"<p><code>CEC</code> message transmit operation must complete within one second. Desired <code>CEC</code> response time is 200 milliseconds and maximum response time must be 1 second as provided in the <code>CEC</code> specifications (<code>HDMI-CEC Specification</code>). <code>Caller</code> is responsible to perform retry operations as per the <code>CEC</code> specification requirements. <code>Caller</code> will retry each transmission in line with a requirement as specified in Section <code>CEC 7.1</code> of the HMDI-CEC specification.</p>"},{"location":"external_content/hdmi_cec/docs/pages/hdmi-cec_halSpec/#initialization-and-startup","title":"Initialization and Startup","text":"<p><code>Caller</code> must initialize by calling <code>HdmiCecOpen()</code> before calling any other <code>API</code>.</p>"},{"location":"external_content/hdmi_cec/docs/pages/hdmi-cec_halSpec/#threading-model","title":"Threading Model","text":"<p>This interface is not required to be thread safe. Any caller invoking the <code>APIs</code> must ensure calls are made in a thread safe manner.</p>"},{"location":"external_content/hdmi_cec/docs/pages/hdmi-cec_halSpec/#process-model","title":"Process Model","text":"<p>This interface is required to support a single instantiation with a single process.</p>"},{"location":"external_content/hdmi_cec/docs/pages/hdmi-cec_halSpec/#memory-model","title":"Memory Model","text":"<p>For transmit messages, it is upto the caller to allocate and free the memory for the message buffer. For receive messages, the <code>HAL</code> is responsible for memory management. The memory allocated cannot exceed 20 bytes (<code>HDMI-CEC Specification</code> Section <code>CEC 6</code>).</p>"},{"location":"external_content/hdmi_cec/docs/pages/hdmi-cec_halSpec/#power-management-requirements","title":"Power Management Requirements","text":"<p>Although this interface is not required to be involved in any of the power management operations, the state transitions MUST not affect its operation. e.g. on resumption from a low power state, the interface must operate as if no transition has occurred.</p>"},{"location":"external_content/hdmi_cec/docs/pages/hdmi-cec_halSpec/#asynchronous-notification-model","title":"Asynchronous Notification Model","text":"<p>For asynchronous transmit and receive operations, the following <code>APIs</code> and callback registrations are used:</p> <ol> <li>For async transmit use: <code>HdmiCecTxAsync()</code></li> <li>For async receive call back use: <code>HdmiCecSetRxCallback()</code></li> <li>For async transmit ack use: <code>HdmiCecSetTxCallback()</code></li> </ol> <p>The caller is required to return the callback context as fast as possible.</p>"},{"location":"external_content/hdmi_cec/docs/pages/hdmi-cec_halSpec/#blocking-calls","title":"Blocking calls","text":"<p>There are no blocking calls. Synchronous calls must complete within a reasonable time period in accordance with any relevant <code>CEC</code> specification. Any call that can fail due to the lack of response from the connected device must have a timeout period in accordance with any relevant <code>CEC</code> specification and the function must return the relevant error code.</p>"},{"location":"external_content/hdmi_cec/docs/pages/hdmi-cec_halSpec/#internal-error-handling","title":"Internal Error Handling","text":"<p>All the <code>APIs</code> must return error synchronously as a return argument. <code>HAL</code> is responsible for handling system errors (e.g. out of memory) internally.</p>"},{"location":"external_content/hdmi_cec/docs/pages/hdmi-cec_halSpec/#persistence-model","title":"Persistence Model","text":"<p>There is no requirement for the interface to persist any setting information. <code>Caller</code> is responsible to persist any settings related to the <code>HAL</code>.</p>"},{"location":"external_content/hdmi_cec/docs/pages/hdmi-cec_halSpec/#non-functional-requirements","title":"Non-functional requirements","text":""},{"location":"external_content/hdmi_cec/docs/pages/hdmi-cec_halSpec/#logging-and-debugging-requirements","title":"Logging and debugging requirements","text":"<p>This interface is required to support DEBUG, INFO and ERROR messages. DEBUG and INFO must be disabled by default and enabled when required.</p>"},{"location":"external_content/hdmi_cec/docs/pages/hdmi-cec_halSpec/#memory-and-performance-requirements","title":"Memory and performance requirements","text":"<p>This interface is required to not cause excessive memory and CPU utilization.</p>"},{"location":"external_content/hdmi_cec/docs/pages/hdmi-cec_halSpec/#quality-control","title":"Quality Control","text":"<ul> <li>This interface is required to perform static analysis, our preferred tool is Coverity.</li> <li>Have a zero-warning policy with regards to compiling. All warnings are required to be treated as error.</li> <li>Copyright validation is required to be performed, e.g.: Black duck, FossID.</li> <li>Use of memory analysis tools like Valgrind are encouraged, to identify leaks/corruptions.</li> <li><code>HAL</code> Tests will endeavour to create worst case scenarios to assist investigations.</li> <li>Improvements by any party to the testing suite are required to be fed back.</li> </ul>"},{"location":"external_content/hdmi_cec/docs/pages/hdmi-cec_halSpec/#licensing","title":"Licensing","text":"<p>The <code>HAL</code> implementation is expected to released under the Apache License 2.0. </p>"},{"location":"external_content/hdmi_cec/docs/pages/hdmi-cec_halSpec/#build-requirements","title":"Build Requirements","text":"<p>The source code must build into a shared library and must be named as <code>libRCECHal.so</code>. The build mechanism must be independent of Yocto.</p>"},{"location":"external_content/hdmi_cec/docs/pages/hdmi-cec_halSpec/#variability-management","title":"Variability Management","text":"<p>Any changes in the <code>APIs</code> must be reviewed and approved by the component architects.</p>"},{"location":"external_content/hdmi_cec/docs/pages/hdmi-cec_halSpec/#platform-or-product-customization","title":"Platform or Product Customization","text":"<p>None</p>"},{"location":"external_content/hdmi_cec/docs/pages/hdmi-cec_halSpec/#interface-api-documentation","title":"Interface API Documentation","text":"<p><code>API</code> documentation will be provided by Doxygen which will be generated from the header files.</p>"},{"location":"external_content/hdmi_cec/docs/pages/hdmi-cec_halSpec/#theory-of-operation-and-key-concepts","title":"Theory of operation and key concepts","text":"<p>The caller is expected to have complete control over the life cycle of the <code>HAL</code>.</p> <ol> <li> <p>Initialize the <code>HAL</code> using function: <code>HdmiCecOpen()</code> before making any other <code>API</code> calls. This call also discovers the physical address based on the connection topology. In case of source devices, <code>HdmiCecOpen()</code> must initiate the logical address discovery as part of this routine. In case of sink devices, logical address will be fixed and set using the <code>HdmiCecAddLogicalAddress()</code>. If <code>HdmiCecOpen()</code> call fails, the <code>HAL</code> must return the respective error code, so that the caller can retry the operation.</p> </li> <li> <p>Once logical address and physical address are assigned, the caller will be able to send and receive the respective <code>CEC</code> messages.</p> </li> <li> <p>For asynchronous receive operations, use the callback function: <code>HdmiCecSetRxCallback()</code>. the caller must register a callback after initialisation.</p> </li> <li> <p>For synchronous transmit, use the function: <code>HdmiCecTx()</code>.</p> </li> <li> <p>For asynchronous transmit, use the function: <code>HdmiCecTxAsync()</code>. The caller must register a callback via <code>HdmiCecSetTxCallback()</code> in order to receive the status or acknowledgement.</p> </li> </ol> <p>3.De-intialise the <code>HAL</code> using the function: <code>HdmiCecClose()</code>.</p> <p>NOTE: The module would operate deterministically if the above call sequence is followed.</p>"},{"location":"external_content/hdmi_cec/docs/pages/hdmi-cec_halSpec/#diagrams","title":"Diagrams","text":""},{"location":"external_content/hdmi_cec/docs/pages/hdmi-cec_halSpec/#operational-call-sequence","title":"Operational Call Sequence","text":"<pre><code>%%{ init : { \"theme\" : \"default\", \"flowchart\" : { \"curve\" : \"stepBefore\" }}}%%\n   sequenceDiagram\n    participant Caller as Caller\n    participant HAL as HDMI CEC HAL\n    participant Driver as HDMI Device Control/Driver\n    Caller-&gt;&gt;HAL:HdmiCecOpen()\n    Note over HAL: SOC intialises and discovers &lt;br&gt; physical address based on the connection topology &lt;br&gt; source devices discovers logical address internally  based on device type.\n    HAL-&gt;&gt;Driver: soc intialises\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:HdmiCecSetRxCallback()\n    HAL-&gt;&gt;Driver: Setting a receiver callback in soc\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:HdmiCecSetTxCallback()\n    HAL-&gt;&gt;Driver:Setting a transmit callback in soc\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    Caller -&gt;&gt;HAL:HdmiCecAddLogicalAddress()\n    Note over Caller: Sink devices must set the logical address using the API &lt;br&gt; HdmiCecAddLogicalAddress (Only for sink devices)\n    HAL-&gt;&gt;Driver: add logical address in soc\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    Caller -&gt;&gt;HAL:HdmiCecGetLogicalAddress()\n    HAL-&gt;&gt;Driver:Get logical address from soc\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    Caller -&gt;&gt;HAL:HdmiCecGetPhysicalAddress()\n    HAL-&gt;&gt;Driver:Get physical address in soc\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    Caller -&gt;&gt;HAL:HdmiCecTx()\n    Note over Caller,HAL: sync CEC transmit message\n    HAL-&gt;&gt;Driver: Transmit packet in soc side\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    Driver--&gt;&gt;HAL:RxCallback()\n    Note over HAL: For CEC message received from the remote device, HdmiCecSetRxCallback() will be triggered\n    HAL--&gt;&gt;Caller:HdmiCecRxCallback() triggered\n    Caller -&gt;&gt;HAL:HdmiCecClose()\n    Note over Caller,HAL: SOC Un-initialises \n    HAL-&gt;&gt;Driver: Soc Un-initialises\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return</code></pre>"},{"location":"external_content/hdmi_cec_test/","title":"Unit Testing Suite For HDMI CEC HAL","text":""},{"location":"external_content/hdmi_cec_test/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Acronyms, Terms and Abbreviations</li> <li>Description</li> <li>Reference Documents</li> <li>Notes</li> </ul>"},{"location":"external_content/hdmi_cec_test/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>HAL</code>- Hardware Abstraction Layer</li> <li><code>HDMI</code> - High Definition Multimedia Interface</li> <li><code>CEC</code> - Consumer Electronics Control</li> <li><code>L1</code> - Functional Tests</li> <li><code>L2</code> - Module functional Testing</li> <li><code>L3</code> - Module testing with External Stimulus is required to validate and control device</li> <li><code>API</code> - Application Programming Interface</li> </ul>"},{"location":"external_content/hdmi_cec_test/#description","title":"Description","text":"<p>This repository contains the Unit Test Suites(L1 &amp; L2) for HDMI CEC <code>HAL</code>.</p>"},{"location":"external_content/hdmi_cec_test/#reference-documents","title":"Reference Documents","text":"SNo Document Name Document Description Document Link 1 <code>HAL</code> Specification Document This document provides specific information on the APIs for which tests are written in this module hdmi-cec_halSpec.md 2 High Level Test Spec for sink device High Level Test Specification Documentation for the <code>HDMI</code> <code>CEC</code> Sink device hdmi-cec-sink_High-Level_TestSpec.md 3 <code>L2</code> Low Level Test Spec for sink device <code>L2</code> Low Level Test Specification and Procedure Documentation for the <code>HDMI</code> <code>CEC</code> Sink device hdmi-cec-sink_L2_Low-Level_TestSpec.md 4 High Level Test Spec for Source device High Level Test Specification Documentation for the <code>HDMI</code> <code>CEC</code> Source device hdmi-cec-source_High-Level_TestSpec.md 5 <code>L2</code> Low Level Test Spec for Source device <code>L2</code> Low Level Test Specification and Procedure Documentation for the <code>HDMI</code> <code>CEC</code> Source device hdmi-cec-source_L2_Low-Level_TestSpec.md 6 <code>L3</code> Low Level Test Specification <code>L3</code> Low Level Test Specification for the <code>HDMI</code> <code>CEC</code> hdmi-cec-L3-Low-Level_TestSpec.md 7 <code>L3</code> Test procedure document <code>L3</code> Test procedure document for the <code>HDMI</code> <code>CEC</code> hdmi-cec-L3_TestProcedure.md"},{"location":"external_content/hdmi_cec_test/#notes","title":"Notes","text":"<ul> <li>All APIs need to be implemented in this current version. If any API is not supported, please add stub implementation with return type HDMI_CEC_IO_OPERATION_NOT_SUPPORTED for the same.</li> <li>Building against the actual library may introduce SOC dependencies. Hence, a template SKELETON library is created without SOC dependencies. On the real platform (target), it can be mounted, copied and bound with the actual library.</li> <li>When running the binary, remember to include a profile file as an argument for designated test cases. The following example illustrates this:</li> </ul> <pre><code>./hal_test -p sink_hdmiCEC.yml\n</code></pre> <p>Alternatively, use the run.sh script with the profile file:</p> <pre><code>./run.sh -p /absolute/path/to/profile/file\n</code></pre> <ul> <li>Profile files define the configuration for the platform available at sink HDMI CEC, source HDMI CEC, stb source device, tv panel</li> <li>vcomponent is an alpha release.</li> <li>Install Python Environment and Activation Scripts please check theHPK Documentation</li> </ul>"},{"location":"external_content/hdmi_cec_test/CHANGELOG/","title":"Changelog","text":""},{"location":"external_content/hdmi_cec_test/CHANGELOG/#changelog","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file. Dates are displayed in UTC.</p> <p>Generated by <code>auto-changelog</code>.</p>"},{"location":"external_content/hdmi_cec_test/CHANGELOG/#140","title":"1.4.0","text":"<ul> <li>gh #44 Initial L3 C-Test Code generation. <code>#45</code></li> </ul>"},{"location":"external_content/hdmi_cec_test/CHANGELOG/#133","title":"1.3.3","text":"<p>7 November 2024</p> <ul> <li>gh #58 l1 logic update fix <code>#60</code></li> <li>gh #61 updated the intiator and destination address in the log <code>cd92f1c</code></li> <li>gh #61 L1 Fix on Logical address update <code>d76034e</code></li> <li>gh #61 L1 logical address update <code>bb0ea75</code></li> </ul>"},{"location":"external_content/hdmi_cec_test/CHANGELOG/#132","title":"1.3.2","text":"<p>5 November 2024</p> <ul> <li>gh #58 Issue fix L1 and L2 <code>#59</code></li> <li>gh #41 Support State commands (AddDevice, RemoveDevice, PrintStatus) <code>#46</code></li> <li>Fixed #50 : updated activate &amp; added test_helper <code>#50</code></li> <li>Baseline #50 setup layout <code>28aa818</code></li> <li>Added #50 baseline requirements <code>d119127</code></li> <li>Added example config #50 <code>1d972fd</code></li> </ul>"},{"location":"external_content/hdmi_cec_test/CHANGELOG/#131","title":"1.3.1","text":"<p>4 September 2024</p> <ul> <li>gh #53 Update L1 and L2 according to new pre post condition. <code>#55</code></li> <li>gh #52 Update L1 and L2 for pre post condition update <code>7910ceb</code></li> <li>gh #53 Update L1 and L2 for pre and post condition <code>0afa1da</code></li> <li>gh #53 Update L1 L2 with post and pre condition. <code>30f601c</code></li> </ul>"},{"location":"external_content/hdmi_cec_test/CHANGELOG/#130","title":"1.3.0","text":"<p>13 August 2024</p> <ul> <li>gh #47 L1 Test code cleanup <code>#49</code></li> <li>gh #30 VTS L1 Enhancement - Test Profile Changes - HDMI CEC <code>#33</code></li> <li>gh #36 Update L1 suite with specification 1.3.9 <code>#38</code></li> <li>Document the control plane commands that will be supported <code>#40</code></li> <li>Feature/issue18 control plane integration <code>#37</code></li> <li>Feature/issues9: Support emulating a cec network <code>#29</code></li> <li>gh #47 L1 cod cleanup <code>ffdb87a</code></li> <li>gh #36 Addressing review comments <code>91ee018</code></li> <li>gh #36 Update L1 with specification 1.3.9 <code>ab12bd6</code></li> </ul>"},{"location":"external_content/hdmi_cec_test/CHANGELOG/#120","title":"1.2.0","text":"<p>28 June 2024</p> <ul> <li>gh #24 hdmicec source &amp; sink l2 tests  <code>#28</code></li> <li>Feature/issues15 emulator startup <code>#21</code></li> <li>Update <code>#19</code></li> <li>Update with Sink tests <code>9655adf</code></li> <li>Update based on review discussion <code>ab6f668</code></li> <li>Update with generated L2 code and specification document <code>769045a</code></li> </ul>"},{"location":"external_content/hdmi_cec_test/CHANGELOG/#110","title":"1.1.0","text":"<p>5 June 2024</p> <ul> <li>gh #11 hdmi_cec: Test Profile: Adding MACRO ENABLE_ENHANCED_ERROR_CODE to enalbe/disable the enhanced error code tests <code>#12</code></li> <li>Capture the YAML Template and design for CEC Emulator <code>#8</code></li> <li>Create hdmi_cec_emulator_design.md <code>84741c3</code></li> <li>Handling Enhanced error code with kvp profile <code>117c8d4</code></li> <li>Adding MACRO ENABLE_ENHANCED_ERROR_CODE <code>a77ad32</code></li> </ul>"},{"location":"external_content/hdmi_cec_test/CHANGELOG/#104","title":"1.0.4","text":"<p>11 May 2024</p> <ul> <li>fixing the usage of UT core functions  <code>#10</code></li> <li>gh #1 Updated UT version2 and removed unnecessary clean up <code>284ac93</code></li> <li>gh #1 replace UT fatal to non fatal &amp; updated the test suite <code>bb6bc68</code></li> <li>gh #1 Updated the ut assert true <code>febc59d</code></li> </ul>"},{"location":"external_content/hdmi_cec_test/CHANGELOG/#103","title":"1.0.3","text":"<p>12 December 2023</p> <ul> <li>Updated README.md with hal &amp; haltest supported version <code>2150135</code></li> <li>Bumped CHANGELOG.md - 1.0.3 <code>c948d2a</code></li> <li>Merge tag '1.0.2' into develop <code>4bf3988</code></li> </ul>"},{"location":"external_content/hdmi_cec_test/CHANGELOG/#102","title":"1.0.2","text":"<p>5 December 2023</p> <ul> <li>baseline version <code>9f45b9e</code></li> <li>Added CHANGELOG.md - 1.0.2 <code>1c8f1c3</code></li> <li>minior fix for doxgen warning <code>8e7777a</code></li> </ul>"},{"location":"external_content/hdmi_cec_test/CONTRIBUTING/","title":"Contributing","text":"<ul> <li>If you wish to make code contributions to this project, the source is hosted at github.com/rdkcentral.</li> </ul> <p>You can submit your changes for review via that site, by raising an issue in github, (https://github.com/rdkcentral/xxxx/issues), and following the sequence below.</p> <ul> <li>create a branch with a name follow the guidelines gh(x)_(synopsis)</li> <li>where x is the ticket number</li> <li>where synopsis is a short synopsis for the reason for the branch.</li> <li>create a pull request (https://github.com/rdkcentral/xxxx/compare) when the code changes are ready for review.</li> <li> <p>The team will review, and if accepted your changes will be merged to the mainline.</p> </li> <li> <p>In order to contribute code, first-time users are requested to agree to the license.</p> </li> <li> <p>where <code>xxxx</code> is your module name</p> </li> </ul>"},{"location":"external_content/hdmi_cec_test/docs/pages/CONTRIBUTING/","title":"Contributing","text":"<ul> <li>If you wish to make code contributions to this project, the source is hosted at github.com/rdkcentral.</li> </ul> <p>You can submit your changes for review via that site, by raising an issue in github, (https://github.com/rdkcentral/xxxx/issues), and following the sequence below.</p> <ul> <li>create a branch with a name follow the guidelines gh(x)_(synopsis)</li> <li>where x is the ticket number</li> <li>where synopsis is a short synopsis for the reason for the branch.</li> <li>create a pull request (https://github.com/rdkcentral/xxxx/compare) when the code changes are ready for review.</li> <li> <p>The team will review, and if accepted your changes will be merged to the mainline.</p> </li> <li> <p>In order to contribute code, first-time users are requested to agree to the license.</p> </li> <li> <p>where <code>xxxx</code> is your module name</p> </li> </ul>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-L3-Low-Level_TestSpec/","title":"HDMI CEC L3 Test Document","text":""},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-L3-Low-Level_TestSpec/#overview","title":"Overview","text":"<p>This document describes the L3 Test Procedure for the HDMI CEC module.</p>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-L3-Low-Level_TestSpec/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>CEC</code>    -  Consumer Electronics Control</li> <li><code>HAL</code>    -  Hardware Abstraction layer</li> <li><code>HDMI</code>   -  High Definition Multimedia Interface</li> <li><code>API</code>    -  Application Program Interface</li> <li><code>SoC</code>    -  System on Chip</li> <li><code>DUT</code>    -  Device Under Test</li> <li><code>LA</code>     -  Logical Address</li> <li><code>PA</code>     -  Physical Address</li> </ul>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-L3-Low-Level_TestSpec/#references","title":"References","text":"<ul> <li>CEC Adaptor: Pulse Eight</li> <li><code>HAL</code> interface file: hdmi_cec_driver.h</li> </ul>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-L3-Low-Level_TestSpec/#level-3-test-cases-high-level-overview","title":"Level 3 Test Cases High Level Overview","text":"# Test-case Description HAL APIs Source Sink 1 Transmit CEC Commands Send predefined <code>CEC</code> commands from the DUT and verify if the command is successfully transmitted using the CEC adapter <code>HdmiCecTx()</code> <code>Y</code> <code>Y</code> 2 Receive CEC commands Send predefined <code>CEC</code> commands from the CEC adapter, verify if the <code>DUT</code> successfully receives the command, and check the response through call-backs. <code>HdmiCecTx()</code> <code>Y</code> <code>Y</code>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-L3-Low-Level_TestSpec/#level-3-python-test-cases-high-level-overview","title":"Level 3 Python Test Cases High Level Overview","text":"<p>The class diagram below illustrates the flow of HDMI CEC Python test cases:</p> <pre><code>---\ntitle: HDMI-CEC - Python Class Flow\n---\nclassDiagram\n    testControl &lt;|-- ut_raft : inherits\n    class ut_raft{\n    }\n    ut_raft &lt;|-- hdmiCECHelperClass : inherits\n    hdmiCECHelperClass &lt;|-- L3_TestClasses : inherits\n    L3_TestClasses ..&gt; hdmiCEC : uses\n    note for testControl \"uses rackConfig.yml and deviceConfig.yml\"\n    note for hdmiCEC \"uses platformProfile.yml\"\n    note for L3_TestClasses \"uses hdmiCECTestCommands.yml\"\n    note for ut_raft \"suite Navigator uses testSuite.yml\"</code></pre> <ul> <li>testControl</li> <li>Test Control Module for running rack Testing. This module configures the <code>DUT</code> based on the rack configuration file provided to the test.</li> <li>This class is defined in <code>RAFT</code> framework. For more details refer RAFT</li> <li>ut_raft</li> <li>Python based testing framework for writing engineering tests.</li> <li>It provides common functionalities like menu navigation, configuration reader, reading user response etc.</li> <li>For more details ut-raft</li> <li>hdmiCEC</li> <li>This is test helper class which communicates with the <code>L3</code> C/C++ test running on the <code>DUT</code> through menu</li> <li>L3_TestClasses</li> <li>These are the L3 test case classes</li> <li>Each class covers the each test use-case defined in L3 Test use-cases table</li> </ul>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-L3-Low-Level_TestSpec/#yaml-file-inputs","title":"YAML File Inputs","text":"<ul> <li>rackConfig.yaml</li> <li>Identifies the rack configuration and platform used</li> <li>References platform-specific config from <code>deviceConfig.yaml</code></li> <li> <p>For more details refer RAFT and example_rack_config.yml</p> </li> <li> <p>deviceConfig.yaml</p> </li> <li>Specifies overall configuration for the platform</li> <li>Can be overridden by:<ul> <li>Changing locally .yaml file directory</li> <li>Using --deviceConfig command line switch</li> </ul> </li> <li> <p>For more details refer RAFT and example_device_config.yml</p> </li> <li> <p>componentProfile.yaml/platformProfile.yaml</p> </li> <li>Contains component-specific configurations</li> <li>Contains platform wide configuration broken down into separate components</li> <li> <p>Example configuration file sink_hdmiCEC</p> </li> <li> <p>hdmiCECTestCommands.yaml</p> </li> <li>This configuration file contains the list of <code>CEC</code> commands.</li> <li> <p>Example configuration file hdmiCECTestCommands.yml</p> </li> <li> <p>testConfig.yaml</p> </li> <li>This configuration file contains the list of menu items for C/C++ L3 test running on <code>DUT</code></li> <li>Example configuration file hdmiCEC_testConfig.yml</li> </ul>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-L3_TestProcedure/","title":"HDMI CEC HAL L3 Python Test Procedure","text":""},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-L3_TestProcedure/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>HAL</code>    - Hardware Abstraction Layer</li> <li><code>L3</code>     - Level 3 Testing</li> <li><code>DUT</code>    - Device Under Test</li> <li><code>RAFT</code>   - Rapid Automation Framework for Testing</li> <li><code>YAML</code>   - YAML Ain't Markup Language</li> <li><code>HDMI</code>   -  High Definition Multimedia Interface</li> <li><code>API</code>    -  Application Program Interface</li> <li><code>SoC</code>    -  System on Chip</li> <li><code>DUT</code>    -  Device Under Test</li> <li><code>LA</code>     -  Logical Address</li> <li><code>PA</code>     -  Physical Address</li> </ul>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-L3_TestProcedure/#setting-up-test-environment","title":"Setting Up Test Environment","text":"<p>The picture below depicts the HDMI CEC L3 Test Functionality Setup. This simple setup has an HDMI CEC Pulse-eight USB adaptor, which acts as a source device and can send the required commands (using libcec tool commands) and respond to the received CEC Commands.</p>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-L3_TestProcedure/#prerequisites","title":"Prerequisites","text":"<ul> <li>Ensure all devices in the test setup support the <code>HDMI</code> <code>CEC</code> feature for the test duration.</li> <li>HDMI drivers must be properly installed and active on the platform before initiating the test.</li> </ul> <pre><code>graph TB\nC[PC] &lt;--&gt; |USB| A\nA[Pulse-Eight CEC Adaptor ] &lt;--&gt; |HDMI| B[DUT]\nA[Pulse-Eight CEC Adaptor ] &lt;--&gt; |HDMI| D[Other Test Device]</code></pre>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-L3_TestProcedure/#pulse-eight-cec-adaptor-tool","title":"Pulse-Eight CEC Adaptor tool","text":"<p>The Pulse-Eight CEC adaptor is used to frame and send commands to the DUT. It utilizes the libCEC library for HDMI CEC activities, and the cec-client tool plays a key role in test automation within RAFT.</p> <ul> <li>Adaptor Details: Pulse Eight</li> </ul>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-L3_TestProcedure/#installation-instructions","title":"Installation Instructions","text":"<ul> <li>Linux</li> </ul> <pre><code>sudo apt update\nsudo apt upgrade\nsudo apt install cec-utils\n</code></pre> <ul> <li>Windows</li> </ul> <p>Download the libcec Tool and follow installation steps.</p>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-L3_TestProcedure/#example-cec-client-commands","title":"Example <code>cec-client</code> Commands","text":"<ul> <li>List Device Details:</li> </ul> <pre><code>cec-client -l\n</code></pre> <ul> <li>Scan for Connected Devices:</li> </ul> <pre><code>echo 'scan' | cec-client -s -d 1\n</code></pre> <ul> <li>Send CEC Commands:</li> </ul> <pre><code>echo 'tx 10:8F' | cec-client -s -d 1\n\nCommand Format:\ntx &lt;source Logical address&gt;&lt;Destination logical Address&gt;:&lt;Opcode&gt;:&lt;Payload bytes&gt;\n</code></pre>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-L3_TestProcedure/#python-environment","title":"Python Environment","text":"<p>To execute <code>HAL</code> <code>L3</code> Python test cases, need a Python environment. Follow these steps mentioned in HPK Public Documentation</p>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-L3_TestProcedure/#update-configuration-files","title":"Update Configuration Files","text":""},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-L3_TestProcedure/#rack-configuration-file","title":"Rack Configuration File","text":"<p>Example Rack configuration File: example_rack_config.yml</p> <p>Refer to the following resources for more details:</p> <ul> <li>RAFT</li> <li>example_rack_config.yml</li> </ul> <p>Update the configuration to define the console sessions for the DUT, cec-client details, and outbound settings.</p>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-L3_TestProcedure/#console-sessions","title":"Console Sessions","text":"Console Session Description default Downloads the bins required for test cases ssh_hal_test Executes the <code>HAL</code> binary for the test case"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-L3_TestProcedure/#cec-controller","title":"CEC Controller","text":"<p><code>RAFT</code> supports two types of cec controllers:</p>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-L3_TestProcedure/#remote-controller","title":"Remote controller","text":"<p>For adaptors connected to a remote server, use the configuration below:</p> <pre><code>      hdmiCECController:\n        type: remote-cec-client    # Use remote cec controller\n        adaptor: /dev/ttyACM0      # Adaptor port\n        address: XXX.XXX.XXX.XXX   # IP address of the server\n        username: root             # Login username\n        password: ' '              # Login password\n</code></pre>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-L3_TestProcedure/#local-controller","title":"Local controller","text":"<p>For adaptors connected directly to the server running the tests, use the configuration below:</p> <pre><code>      hdmiCECController:\n        type: cec-client           # Use local cec controller\n        adaptor: /dev/ttyACM0      # adaptor port\n</code></pre>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-L3_TestProcedure/#example-rack-configuration","title":"Example Rack Configuration","text":"<pre><code>rackConfig:\n  - dut:\n      ip: \"XXX.XXX.XXX.XXX\"  # IP Address of the device\n      description: \"stb device under test\"\n      platform: \"stb\"\n      consoles:\n        - default:\n            type: \"ssh\"\n            port: 10022\n            username: \"root\"\n            ip: \"XXX.XXX.XXX\" # IP address of the device\n            password: ' '\n        - ssh_hal_test:\n            type: \"ssh\"\n            port: 10022\n            username: \"root\"\n            ip: \"XXX.XXX.XXX\" # IP address of the device\n            password: ' '\n      outbound:\n        download_url: \"http://localhost:8000/\"    # download location for the CPE device\n        httpProxy:   # Local Proxy if required\n        workspaceDirectory: './logs/workspace'   # Local working directory\n      hdmiCECController:\n        type: remote-cec-client\n        adaptor: /dev/ttyACM0\n        address: XXX.XXX.XXX.XXX\n        username: root\n        password: ' '\n</code></pre>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-L3_TestProcedure/#device-configuration-file","title":"Device Configuration File","text":"<p>Example Device configuration File: deviceConfig.yml</p> <p>Refer to the following resources for more details:</p> <ul> <li>RAFT</li> <li>example_device_config.yml</li> </ul> <p>Update the following fields:</p> <ul> <li>Target Directory: Specify the <code>target_directory</code> path where HAL binaries will be copied.</li> <li>Device Profile: Provide the path and profile file for the <code>test/profile</code>.</li> <li>Platform: Ensure the platform matches the <code>dut</code> platform in the Rack Configuration</li> </ul> <pre><code>deviceConfig:\n    cpe1:\n        platform: \"tv\"\n        model: \"uk\"\n        soc_vendor: \"soc\"\n        target_directory: \"/tmp/\"  # Target Directory on device\n        prompt: \"\"\n        test:\n            profile: \"../../../profiles/sink/sink_hdmiCEC.yml\"\n</code></pre>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-L3_TestProcedure/#test-configuration","title":"Test Configuration","text":"<p>Example Test Setup configuration File: hdmiCEC_testConfig.yml</p> <p>Specify the command to run the HAL binary within this file.</p> <pre><code>hdmicec:\n    description: \"hdmi CEC testing profile / menu system for UT\"\n    test:\n        artifacts:\n        #List of artifacts folders, test class copies the content of folder to the target device workspace\n          - \"../../../bin/\"\n        # exectute command, this will appended with the target device workspace path\n        execute: \"run.sh\"\n        type: UT-C # C (UT-C Cunit) / C++ (UT-G (g++ ut-core gtest backend))\n</code></pre>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-L3_TestProcedure/#run-test-cases","title":"Run Test Cases","text":"<p>Once the environment is set up, you can execute the test cases with the following command</p> <pre><code>python &lt;TestCaseName.py&gt; --config &lt;/PATH&gt;/ut/host/tests/configs/example_rack_config.yml --deviceConfig &lt;/PATH&gt;/ut/host/tests/configs/deviceConfig.yml\n</code></pre>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-L3_TestProcedure/#test-cases","title":"Test Cases","text":""},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-L3_TestProcedure/#hdmicec_l3_runallpy","title":"hdmiCEC_L3_Runall.py","text":"<p>This python file runs all the tests</p> <pre><code>python hdmiCEC_L3_Runall.py --config &lt;/PATH&gt;/ut/host/tests/configs/example_rack_config.yml --deviceConfig &lt;/PATH&gt;/ut/host/tests/configs/deviceConfig.yml\n</code></pre>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-L3_TestProcedure/#hdmicec_test01_transmitceccommandspy","title":"hdmiCEC_test01_TransmitCECCommands.py","text":""},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-L3_TestProcedure/#platform-support-test01","title":"Platform Support - test01","text":"<ul> <li>Source</li> <li>Sink</li> </ul>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-L3_TestProcedure/#user-input-required-test01","title":"User Input Required - test01","text":"<p>No - (This is a automated case)</p>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-L3_TestProcedure/#acceptance-criteria-test01","title":"Acceptance Criteria - test01","text":"<ul> <li>The test verifies that the device under test (DUT) can successfully transmit HDMI-CEC commands to connected devices as defined in the test profile.</li> <li>Transmission should be correctly initiated and logged by the HDMI-CEC controller.</li> </ul>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-L3_TestProcedure/#expected-results-test01","title":"Expected Results - test01","text":"<p>The test is considered successful if:</p> <ul> <li>All HDMI-CEC commands listed in the <code>YAML</code> profile are transmitted without errors.</li> <li>The test script validates that the transmission is initiated and logged correctly by the HDMI-CEC controller.</li> </ul>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-L3_TestProcedure/#test-steps-test01","title":"Test Steps - test01","text":"<p>Preparation:</p> <ul> <li>Ensure the <code>DUT</code> is connected to the HDMI-CEC controller devices via HDMI cables.</li> <li>Verify that configuration files for the test environment are correctly set up.</li> </ul> <p>Execution:</p> <p>Run the Python script with the following command:</p> <pre><code>python hdmiCEC_test01_TransmitCECCommands.py --config &lt;/PATH&gt;/ut/host/tests/configs/example_rack_config.yml --deviceConfig &lt;/PATH&gt;/ut/host/tests/configs/deviceConfig.yml\n</code></pre> <p>Functionality:</p> <ul> <li>The script initializes the HDMI-CEC controller session.</li> <li>It transmits HDMI-CEC commands from the DUT to the connected devices.</li> </ul> <p>Validation:</p> <ul> <li>The script checks if the HDMI-CEC controller logs confirm the transmission of each command.</li> <li>Transmission status is logged with details such as source, destination, opcode, and payload.</li> </ul>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-L3_TestProcedure/#test-logs-and-artifacts-test01","title":"Test Logs and Artifacts - test01","text":"<p>Summary Logs:</p> <ul> <li>A comprehensive log file is generated, detailing the execution status of each command.</li> <li> <p>Log file path: &lt;\"PATH\"&gt;/ut/logs/rack&lt;#&gt;/slot&lt;#&gt;/&lt;\"DATE-TIME\"&gt;/test_summary.log.</p> </li> <li> <p>Transmission Status:</p> </li> <li>Logs include information about the success or failure of each transmitted command.</li> </ul>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-L3_TestProcedure/#test-conclusion-test01","title":"Test Conclusion - test01","text":"<p>The test script will display a final PASS/FAIL result based on the following conditions:</p> <ul> <li>PASS: All CEC commands are successfully transmitted as listed in the YAML profile, and transmission logs confirm initiation by the HDMI-CEC controller.</li> <li>FAIL: Any transmission error or failure to initiate commands.</li> </ul> <p>Summary logs are saved for further review and debugging.</p>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-L3_TestProcedure/#hdmicec_test02_receivececcommandspy","title":"hdmiCEC_test02_ReceiveCECCommands.py","text":""},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-L3_TestProcedure/#platform-support-test02","title":"Platform Support - test02","text":"<ul> <li>Source</li> <li>Sink</li> </ul>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-L3_TestProcedure/#user-input-required-test02","title":"User Input Required - test02","text":"<p>No -  (This is a automated case)</p>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-L3_TestProcedure/#acceptance-criteria-test02","title":"Acceptance Criteria - test02","text":"<ul> <li>The test verifies whether the device under test (DUT) can reliably receive HDMI-CEC commands.</li> <li>The received callback data must match the expected values, including:</li> <li>Source logical address</li> <li>Destination logical address</li> <li>Opcode</li> <li>Payload</li> </ul>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-L3_TestProcedure/#expected-results-test02","title":"Expected Results - test02","text":"<p>The test is considered successful if:</p> <ul> <li>All transmitted HDMI-CEC commands are successfully received by the DUT.</li> <li>The callback data accurately reflects the transmitted command parameters (source, destination, opcode, and payload).</li> </ul>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-L3_TestProcedure/#test-steps-test02","title":"Test Steps - test02","text":"<p>Preparation:</p> <ul> <li>Ensure the DUT is powered on and connected to the HDMI-CEC controller.</li> <li>Verify the configuration files for the test environment are properly set up.</li> </ul> <p>Execution:</p> <p>Run the Python script with the following command:</p> <pre><code>python hdmiCEC_test02_ReceiveCECCommands.py --config &lt;/PATH&gt;/ut/host/tests/configs/example_rack_config.yml --deviceConfig &lt;/PATH&gt;/ut/host/tests/configs/deviceConfig.yml\n</code></pre> <p>Functionality:</p> <ul> <li>The script initializes the HDMI-CEC controller.</li> <li>It sends HDMI-CEC commands to the DUT's logical address, including directed and broadcast messages.</li> <li>The DUT processes these commands, and the script reads the callback data.</li> </ul> <p>Verification:</p> <ul> <li>The script validates the callback data received by the DUT against the transmitted parameters (source, destination, opcode, payload).</li> </ul>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-L3_TestProcedure/#test-logs-and-artifacts-test02","title":"Test Logs and Artifacts - test02","text":"<p>Summary Logs:</p> <ul> <li>The script generates a detailed log file summarizing the test execution.</li> <li>Log file path: &lt;\"PATH\"&gt;/ut/logs/rack&lt;#&gt;/slot&lt;#&gt;/&lt;\"DATE-TIME\"&gt;/test_summary.log</li> <li>Logs include information on received commands, validation results, and any discrepancies.</li> </ul>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-L3_TestProcedure/#test-conclusion-test02","title":"Test Conclusion - test02","text":"<p>The test script will display a final PASS/FAIL result based on the following conditions:</p> <ul> <li>PASS: All received HDMI-CEC commands and callback data match the expected values.</li> <li>FAIL: Any mismatch in the callback data or failure to receive commands.</li> </ul> <p>Summary logs are saved for review and troubleshooting</p>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-sink_High-Level_TestSpec/","title":"HDMI CEC Sink High-Level Test Specification Document","text":""},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-sink_High-Level_TestSpec/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>CEC</code>  - Consumer Electronics Control</li> <li><code>HAL</code>  - Hardware Abstraction layer</li> <li><code>HDMI</code> - High Definition Multimedia Interface</li> <li><code>DUT</code>  - Device Under Test</li> <li><code>L2</code>   - Level 2 Testing ()</li> <li><code>L3</code>   - Level 3 Testing ()</li> </ul>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-sink_High-Level_TestSpec/#scope","title":"Scope","text":"<p>This document defines the requirements for testing the HDMI CEC device from a level 2/3 based on being a sink device.</p>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-sink_High-Level_TestSpec/#overview","title":"Overview","text":"<p>Consumer Electronics Control (CEC) is a single-wire bidirectional bus within an HDMI system, facilitating communication among interconnected products. HDMI-CEC establishes a protocol enabling high-level control functions between audiovisual devices linked via an HDMI network, facilitating communication and control among them. Communication can occur in either Direct messaging mode or Broadcast mode.</p>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-sink_High-Level_TestSpec/#hdmi-cec-rdk-hal-functionality","title":"HDMI-CEC RDK HAL Functionality","text":"<p>The HAL layers within RDK serve as a bridge between the underlying low-level SoC drivers and the higher-level RDK layers that utilize the functionality offered by these HAL functions. Caller will manage the discovery of logical addresses in sink devices, while HAL needs to facilitate sending and receiving the CEC commands on the network. Specifically concerning the CEC Module, the HAL layers facilitate the following functionalities on sink devices:</p> <ol> <li>Provision to set, get, and remove the logical address</li> <li>Provision to get the Physical address</li> <li>Provision to Tx and Rx the CEC data</li> </ol>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-sink_High-Level_TestSpec/#test-scenarios","title":"Test scenarios","text":"<p>The HAL CEC layer enables the transmission and reception of CEC frames on the CEC bus. However, it does not manage or validate any particular CEC opcode commands to confirm the supported HAL CEC opcodes for transmission or reception.</p> <p>Managing the opcodes is the responsibility of the caller. The existing test cases will validate responses from connected devices for a subset of opcodes as part of the testing procedure.</p> S.No. Test Functionality Description 1 Logical address Facilitating the Discovery of logical addresses, Setting, getting, and removing the logical address of the device (for sink devices) 2 Physical Address Retrieving the physical address 3 CEC Synchronous Transmission Transmitting CEC frames and reporting on their acknowledgement 4 CEC Receive functionality Receiving CEC Information from other devices and passing it to the layer above through registered callback function 5 CEC HotPlug Functionality Managing CEC during Hotplug and HotUnplug events"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-sink_High-Level_TestSpec/#logical-address-discovery","title":"Logical Address Discovery","text":"S.No. Test Functionality Description HAL APIs L2 L3 Control plane requirements 1 Logical address Get the logical address of the <code>DUT</code> without actually adding the Logical Address and the API should return 0x0F as the default logical address. HdmiCecGetLogicalAddress <code>Y</code> <code>NA</code> <code>NA</code> a Setup all valid logical addresses b/w 0x00 to 0x0F for the <code>DUT</code> and retrieve each to ensure proper functionality, using HAL APIs. HdmiCecAddLogicalAddress, HdmiCecGetLogicalAddress, HdmiCecRemoveLogicalAddress <code>Y</code> <code>NA</code> <code>NA</code> b Invoke the HAL API to delete the <code>DUT</code> logical address and verify that it is removed successfully. HdmiCecAddLogicalAddress, HdmiCecRemoveLogicalAddress, HdmiCecGetLogicalAddress <code>Y</code> <code>NA</code> <code>NA</code> c After deleting the <code>DUT</code> logical address, try to send a broadcast CEC Command (as per 1.4b HDMI CEC spec) and confirm transmission is successful. HdmiCecAddLogicalAddress, HdmiCecRemoveLogicalAddress, HdmiCecTx <code>Y</code> <code>NA</code> <code>NA</code>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-sink_High-Level_TestSpec/#emulator-requirements","title":"Emulator Requirements","text":"<ul> <li>Boot with control configuration with various configurations having a predefined set of nodes:</li> <li>configuration to support the discovery of logical addresses. The caller provides the logical address, and HAL checks the availability of this address and feedback the same to the caller.</li> <li>Verify for the valid logical address and return the appropriate error code based on the logical address availability.</li> </ul>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-sink_High-Level_TestSpec/#physical-address","title":"Physical Address","text":"S.No. Test Functionality Description HAL APIs L2 L3 Control plane requirements 2 Physical Address Verify the physical address allocated through the HAL function. HdmiCecGetPhysicalAddress Y NA Verify the physical addresses allocated by connecting two sink devices through an HDMI switch. HdmiCecGetPhysicalAddress NA Y Enable the television connected to <code>DUT</code> to declare its physical address first before <code>DUT</code>."},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-sink_High-Level_TestSpec/#emulator-requirements-physical-address","title":"Emulator Requirements - Physical Address","text":"<ul> <li>Boot control configuration to setup the CEC network nodes</li> <li>Scenario to have two sink devices on the network</li> </ul>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-sink_High-Level_TestSpec/#control-plane-requirements-physical-address","title":"Control Plane Requirements - Physical Address","text":"<ul> <li>The control plane will allow removing or adding a node to the network.</li> <li>allowing add sink node before the <code>DUT</code> switched ON.</li> </ul>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-sink_High-Level_TestSpec/#cec-synchronous-transmission","title":"CEC Synchronous Transmission","text":"S.No. Test Functionality Description HAL APIs L2 L3 Control plane requirements 3 CEC Transmission Verify the correct transmission of the supported CEC commands (as per 1.4b HDMI CEC spec) to the connected device and ensure it is acknowledged properly. HdmiCecAddLogicalAddress, HdmiCecTx, HdmiCecRemoveLogicalAddress NA Y Control plane to switch ON a CEC-supported device on the HDMI network so that it shall respond to the basic commands Broadcast a supported CEC Command to all the devices connected to the network without any error HdmiCecAddLogicalAddress, HdmiCecTx, HdmiCecRemoveLogicalAddress NA Y Control plane to switch ON a CEC-supported device on the HDMI network to act on the broadcasted command Transmit a CEC Command (as per 1.4b HDMI CEC spec) to put the connected device into standby mode and await the device's response. Monitoring the behaviour of the connected device accordingly. HdmiCecAddLogicalAddress, HdmiCecTx, HdmiCecRemoveLogicalAddress NA Y Control plane to monitor the behaviour of the connected devices. Transmit a HDMI CEC Command (as per 1.4b HDMI CEC spec) to get the CEC Version of a device that doesn't exist. HdmiCecAddLogicalAddress, HdmiCecTx, HdmiCecRemoveLogicalAddress Y NA Control plane can unplug or switch off a previously existing CEC device"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-sink_High-Level_TestSpec/#emulator-requirements-cec-transmission","title":"Emulator Requirements - CEC Transmission","text":"<ul> <li>Boot configuration</li> <li>Min case scenario multiple network nodes</li> <li>Max case scenario multiple cec nodes</li> </ul>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-sink_High-Level_TestSpec/#control-plane-requirements-cec-transmission","title":"Control Plane Requirements - CEC Transmission","text":"<ul> <li>The control plane will allow adding a device that can respond to the CEC Frames sent by <code>DUT</code></li> </ul>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-sink_High-Level_TestSpec/#cec-receive-functionality","title":"CEC Receive functionality","text":"S.No. Test Functionality Description HAL APIs L2 L3 Control plane requirements 5 CEC Receive functionality Transmit a CEC Command that expects a response (Eg. GetCECVersion) to a connected device and see the response is received correctly. Set the Rx Callback before sending the data. Validate the received CEC Version. HdmiCecAddLogicalAddress, HdmiCecSetRxCallback, HdmiCecTx, HdmiCecRemoveLogicalAddress NA Y Control plane to switch ON a CEC device that can respond to the Transmitted CEC Command Transmit a CEC command from the connected devices and consider the Acknowledgement and responses are received correctly from the host device (<code>DUT</code> TV here) HdmiCecAddLogicalAddress, HdmiCecSetRxCallback, HdmiCecRemoveLogicalAddress NA Y Control panel to control the third-party devices to Transmit the required commands to  <code>DUT</code> Transmit an OSD CEC command from the connected devices and consider the Acknowledgement and responses are received correctly from the host device (<code>DUT</code> TV here). Make the OSD String to max length HdmiCecAddLogicalAddress, HdmiCecSetRxCallback, HdmiCecRemoveLogicalAddress NA Y Control panel to control the third-party devices to Transmit the required commands to  <code>DUT</code> Transmit an OSD CEC command from the connected devices continuously for 30 seconds changing the patterns in the payload and considering the Acknowledgement and responses are received correctly from the host device (<code>DUT</code> TV here). Make the OSD String to max length HdmiCecAddLogicalAddress, HdmiCecSetRxCallback, HdmiCecRemoveLogicalAddress NA Y Control panel to control the third-party devices to Transmit the required commands to  <code>DUT</code>. Also, Control plane to detect the OSD Display on the Sink device to validate Set the Logical address to 0 on <code>DUT</code> and make sure that it doesn't receive the messages sent to devices with different logical address. HdmiCecAddLogicalAddress, HdmiCecSetRxCallback, HdmiCecRemoveLogicalAddress NA Y Control Plane to initiate a command to send CEC frames from CEC adaptor with a different logical address other than zero"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-sink_High-Level_TestSpec/#emulator-requirements-cec-receive-functionality","title":"Emulator Requirements - CEC Receive functionality","text":"<ol> <li>Emulate the Tx and Rx HAL functionalities with the required responses.</li> </ol>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-sink_High-Level_TestSpec/#control-plane-requirements-cec-receive-transmission","title":"Control Plane Requirements - CEC Receive Transmission","text":"<ul> <li>The control plane will allow adding a device that can respond to the CEC Frames sent by <code>DUT</code></li> <li>The control plane to initiate CEC Transmissions from the connected devices as expected by the <code>DUT</code></li> </ul>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-sink_High-Level_TestSpec/#cec-hotplug-functionality","title":"CEC HotPlug Functionality","text":"S.No. Test Functionality Description HAL APIs L2 L3 Control plane requirements 6 CEC HotPlug Functionality Generate a Hotplug event by disconnecting the device connected to the HDMI port of the Sink Platform. Validating whether the CEC Transmission (use Polling command) works when the HDMI port is disconnected should result in ACK not being received while the TX still works as expected. HdmiCecAddLogicalAddress, HdmiCecTx, HdmiCecRemoveLogicalAddress NA Y Control Panel to control the Hotplug activities Check the behaviour when a device has been remove from the network which is not directly connected to the TV device.  Send a CEC Tx command with acknowledgement using HAL Interface and check the behaviour. The Tx command should succeed, but the message should not be Acknowledged. HdmiCecAddLogicalAddress, HdmiCecTx, HdmiCecRemoveLogicalAddress NA Y Control Panel to control the external devices connected."},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-sink_High-Level_TestSpec/#emulator-requirements-cec-hotplug-functionality","title":"Emulator Requirements - CEC HotPlug Functionality","text":""},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-sink_High-Level_TestSpec/#control-plane-requirements-cec-hotplug-functionality","title":"Control Plane Requirements - CEC HotPlug Functionality","text":"<ol> <li>Control plane to initiate the HotPlug activity by commanding an IP power switch to the OFF State to which the Node device is connected.</li> </ol>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-sink_High-Level_TestSpec/#-","title":"-----------","text":""},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-sink_High-Level_TestSpec/#hardware-verification-testing-requirements","title":"Hardware Verification Testing Requirements","text":"S.No. Test Functionality Description HAL APIs L2 L3 Control plane requirements 7 Introduce fault in the CEC Bus Observe the behaviour when the CEC line is pulled high during the CEC Transmission using a CEC Adaptor that provision to keep the CEC line pulled high HdmiCecAddLogicalAddress, HdmiCecTx, HdmiCecRemoveLogicalAddress NA Y CEC Adaptor used shall have a provision to introduce the fault. The control plane should be able to command to pull the CEC line high, else it should follow a manual process 8 Overloading the CEC bus. Overload the CEC bus with too many messages  (by connecting more devices in the network) and observe the behaviour HdmiCecAddLogicalAddress, HdmiCecTx, HdmiCecRemoveLogicalAddress NA Y Control plane to initiate the CEC Transmission through all the connected devices continuously with a command that expects the response as well to overload the CEC Network."},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-sink_High-Level_TestSpec/#emulator-requirements-hardware-verification","title":"Emulator Requirements - Hardware verification","text":"<ol> <li>Emulator to support the HDMI_CEC_IO_SENT_FAILED during the above scenarios</li> </ol>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-sink_High-Level_TestSpec/#control-plane-requirements","title":"Control Plane Requirements","text":"<ol> <li> <p>Control Plane to control the external devices to pull the CEC line high.</p> </li> <li> <p>Control Plan to initiate multiple CEC commands from the different devices connected to the network.</p> </li> </ol>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-sink_High-Level_TestSpec/#-_1","title":"-----------","text":""},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-sink_High-Level_TestSpec/#boot-configuartion","title":"Boot configuartion","text":""},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-sink_High-Level_TestSpec/#module-configuration-requirements","title":"Module Configuration Requirements","text":"<p>The module must be configured during the boot sequence in the case of emulation as if it were a real hardware device with or without multiple connected HDMI nodes.</p>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-sink_High-Level_TestSpec/#test-configuration-for-sink-devices","title":"Test Configuration for Sink Devices","text":"<p>The following information shall be helpful for further running the Automation Rack Test for this specific module and further configuration will help for the Design and Development of Virtual Device.</p> <p>Configurations:</p> <pre><code>  Device:\n    Type: Source / Sink\n    Platform_Manufacturer: sony/Samsung etc.\n    Platform_Model:  xyz\n    Port: 3, 4\n    HDMI Node: 1-3 etc.\n    CEC_Ports: 1, x, y\n</code></pre>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-sink_L2_Low-Level_TestSpec/","title":"HDMI CEC Sink L2 Low-Level Test Specification and Procedure Documentation","text":""},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-sink_L2_Low-Level_TestSpec/#overview","title":"Overview","text":"<p>This document describes the level 2 Low-Level Test Specification and Procedure Documentation for the HDMI CEC Sink module.</p>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-sink_L2_Low-Level_TestSpec/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>HAL</code>  - Hardware Abstraction Layer, may include some common components</li> <li><code>UT</code>   - Unit Test(s)</li> <li><code>HDMI</code> - High-Definition Multimedia Interface</li> <li><code>CEC</code>  - Consumer Electronics Control</li> <li><code>DUT</code>  - Device Under Test</li> <li><code>API</code>  - Application Program Interface</li> </ul>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-sink_L2_Low-Level_TestSpec/#definitions","title":"Definitions","text":"<ul> <li><code>ut-core</code> - Common Testing Framework https://github.com/rdkcentral/ut-core, which wraps an open-source framework that can be expanded to the requirements for future frameworks.</li> </ul>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-sink_L2_Low-Level_TestSpec/#references","title":"References","text":"<ul> <li><code>High Level Test Specification</code> - hdmi-cec-sink_High-Level_TestSpec.md</li> <li><code>HDMI CEC HAL Interface file</code> - hdmi_cec_driver.h</li> </ul>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-sink_L2_Low-Level_TestSpec/#level-2-test-procedure","title":"Level 2 Test Procedure","text":"<p>The following functions are intended to test the HDMI CEC HAL module's operation on sink devices according to the L2 Test specification.</p>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-sink_L2_Low-Level_TestSpec/#test-1","title":"Test 1","text":"Title Details Function Name <code>test_l2_hdmi_cec_sink_hal_GetDefaultLogicalAddress</code> Description Get the logical address of the <code>DUT</code> without actually adding the Logical Address and the API should return 0x0F as the default logical address. Test Group 02 Test Case ID 001 Priority High <p>Pre-Conditions: None</p> <p>Dependencies: None</p> <p>User Interaction: If the user chooses to run the test in interactive mode, then the test case has to be selected via the console.</p>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-sink_L2_Low-Level_TestSpec/#test-procedure-test-1","title":"Test Procedure Test 1","text":"Variation / Steps Description Test Data Expected Result Notes 01 Call the pre-requisite API HdmiCecOpen() handle = 0 HDMI_CEC_IO_SUCCESS Should be successful 02 Call the API HdmiCecGetLogicalAddress() handle = valid handle, logicalAddress = 0 HDMI_CEC_IO_SUCCESS Should be successful 03 Check the logical address logicalAddress = 0x0F Should be successful 04 Call the post-requisite API HdmiCecClose() handle = valid handle HDMI_CEC_IO_SUCCESS Should be successful <pre><code>graph TB\nA[Call HdmiCecOpen] --&gt;|HDMI_CEC_IO_SUCCESS| B[Call HdmiCecGetLogicalAddress]\nA --&gt;|Failure| A1[Test case fail]\nB --&gt;|HDMI_CEC_IO_SUCCESS| C[Check logical address]\nB --&gt;|Failure| B1[Test case fail]\nC --&gt;|Logical address is 0x0F| D[Call HdmiCecClose]\nC --&gt;|Logical address is not 0x0F| C1[Test case fail]\nD --&gt;|HDMI_CEC_IO_SUCCESS| E[Test case pass]\nD --&gt;|Failure| D1[Test case fail]</code></pre>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-sink_L2_Low-Level_TestSpec/#test-2","title":"Test 2","text":"Title Details Function Name <code>test_l2_hdmi_cec_sink_hal_AddAndGetLogicalAddress</code> Description Setup all valid logical addresses b/w 0x00 to 0x0F for the <code>DUT</code> and retrieve each to ensure proper functionality, using HAL APIs. Test Group 02 Test Case ID 002 Priority High <p>Pre-Conditions: None</p> <p>Dependencies: None</p> <p>User Interaction: If the user chooses to run the test in interactive mode, then the test case has to be selected via the console.</p>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-sink_L2_Low-Level_TestSpec/#test-procedure-test-2","title":"Test Procedure Test 2","text":"Variation / Steps Description Test Data Expected Result Notes 01 Open HDMI CEC HAL using HdmiCecOpen API handle = valid pointer HDMI_CEC_IO_SUCCESS Should be successful 02 Loop over the range of valid logical addresses (0x00 to 0x0F) i = 0 to 0x0F N/A N/A 03 Add logical address using HdmiCecAddLogicalAddress API handle = valid handle, logicalAddress = i HDMI_CEC_IO_SUCCESS Should be successful 04 Retrieve logical address using HdmiCecGetLogicalAddress API handle = valid handle, logicalAddress = valid pointer HDMI_CEC_IO_SUCCESS, logicalAddress = i Should be successful 05 Remove logical address using HdmiCecRemoveLogicalAddress API handle = valid handle, logicalAddress = i HDMI_CEC_IO_SUCCESS Should be successful 06 Close HDMI CEC HAL using HdmiCecClose API handle = valid handle HDMI_CEC_IO_SUCCESS Should be successful <pre><code>graph TB\nA[HdmiCecOpen] --&gt;|HDMI_CEC_IO_SUCCESS| B{Loop 0x00 to 0x0F}\nB --&gt; |HDMI_CEC_IO_SUCCESS| C[HdmiCecAddLogicalAddress]\nC --&gt; |HDMI_CEC_IO_SUCCESS| D[HdmiCecGetLogicalAddress]\nD --&gt; |HDMI_CEC_IO_SUCCESS &amp; Address Match| E[HdmiCecRemoveLogicalAddress]\nE --&gt; |HDMI_CEC_IO_SUCCESS| B\nB --&gt; |End of Loop| F[HdmiCecClose]\nA --&gt;|Failure| G[Test case fail]\nF --&gt;|Failure| K[Test case fail]\nF --&gt;|HDMI_CEC_IO_SUCCESS| L[Test case success]</code></pre>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-sink_L2_Low-Level_TestSpec/#test-3","title":"Test 3","text":"Title Details Function Name <code>test_l2_hdmi_cec_sink_hal_RemoveLogicalAddress</code> Description Invoke the HAL API to delete the <code>DUT</code> logical address and verify that it is removed successfully. Test Group 02 Test Case ID 003 Priority High <p>Pre-Conditions: None</p> <p>Dependencies: None</p> <p>User Interaction: If the user chooses to run the test in interactive mode, then the test case has to be selected via the console.</p>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-sink_L2_Low-Level_TestSpec/#test-procedure-test-3","title":"Test Procedure Test 3","text":"Variation / Steps Description Test Data Expected Result Notes 01 Open the HDMI CEC HAL using HdmiCecOpen API handle = valid handle HDMI_CEC_IO_SUCCESS Should be successful 02 Add a logical address using HdmiCecAddLogicalAddress API handle = valid handle, logicalAddress = 0x00 HDMI_CEC_IO_SUCCESS Should be successful 03 Get the logical address using HdmiCecGetLogicalAddress API handle = valid handle, logicalAddress = valid buffer HDMI_CEC_IO_SUCCESS , logicalAddress = 0x00 Should be successful 04 Remove the logical address using HdmiCecRemoveLogicalAddress API handle = valid handle, logicalAddress = 0x00 HDMI_CEC_IO_SUCCESS Should be successful 05 Get the logical address using HdmiCecGetLogicalAddress API handle = valid handle, logicalAddress = valid buffer HDMI_CEC_IO_SUCCESS , logicalAddress = 0x0F Should be successful 06 Close the HDMI CEC HAL using HdmiCecClose API handle = valid handle HDMI_CEC_IO_SUCCESS Should be successful <pre><code>graph TB\nA[HdmiCecOpen] -- \"HDMI_CEC_IO_SUCCESS\" --&gt; B[HdmiCecAddLogicalAddress]\nA -- \"Failure\" --&gt; A1[Test case fail]\nB -- \"HDMI_CEC_IO_SUCCESS\" --&gt; C[HdmiCecGetLogicalAddress]\nB -- \"Failure\" --&gt; B1[Test case fail]\nC -- \"HDMI_CEC_IO_SUCCESS &amp; Logical Address = current logical address\" --&gt; D[HdmiCecRemoveLogicalAddress]\nC -- \"Failure\" --&gt; C1[Test case fail]\nD --\"HDMI_CEC_IO_SUCCESS\" --&gt;E[HdmiCecGetLogicalAddress]\nD -- \"Failure\" --&gt; D1[Test case fail]\nE -- \"HDMI_CEC_IO_SUCCESS &amp; Logical Address = 0x0F\" --&gt; F[HdmiCecClose]\nE -- \"Failure\" --&gt; E1[Test case fail]\nF -- \"HDMI_CEC_IO_SUCCESS\" --&gt; G[Test case pass]\nF -- \"Failure\" --&gt; F1[Test case fail]</code></pre>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-sink_L2_Low-Level_TestSpec/#test-4","title":"Test 4","text":"Title Details Function Name <code>test_l2_hdmi_cec_sink_hal_BroadcastHdmiCecCommand</code> Description After deleting the <code>DUT</code> logical address, try to send a broadcast CEC Command (as per 1.4b HDMI CEC spec) and confirm transmission is successful. Test Group 02 Test Case ID 004 Priority High <p>Pre-Conditions: None</p> <p>Dependencies: None</p> <p>User Interaction: If the user chooses to run the test in interactive mode, then the test case has to be selected via the console.</p>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-sink_L2_Low-Level_TestSpec/#test-procedure-test-4","title":"Test Procedure Test 4","text":"Variation / Steps Description Test Data Expected Result Notes 01 Open HDMI CEC using HdmiCecOpen handle = valid buffer HDMI_CEC_IO_SUCCESS Should be successful 02 Add logical address using HdmiCecAddLogicalAddress handle = valid handle, logicalAddresses = 0x0 HDMI_CEC_IO_SUCCESS Should be successful 03 Remove logical address using HdmiCecRemoveLogicalAddress handle = valid handle, logicalAddresses = 0x0 HDMI_CEC_IO_SUCCESS Should be successful 04 Broadast CEC message using HdmiCecTx handle = valid handle, buf = {0x0F, 0x84, 0x00, 0x00}, len = sizeof(buf), result = valid buffer HDMI_CEC_IO_SUCCESS Should be successful 05 Check the result of transmission result = valid buffer HDMI_CEC_IO_SENT_BUT_NOT_ACKD Should be successful 06 Close HDMI CEC using HdmiCecClose handle = valid handle HDMI_CEC_IO_SUCCESS Should be successful <pre><code>graph TB\nA[HdmiCecOpen] -- \"HDMI_CEC_IO_SUCCESS\" --&gt; B[HdmiCecAddLogicalAddress]\nA -- \"Failure\" --&gt; A1[Test case fail]\nB -- \"HDMI_CEC_IO_SUCCESS\" --&gt; C[HdmiCecRemoveLogicalAddress]\nB -- \"Failure\" --&gt; B1[Test case fail]\nC -- \"HDMI_CEC_IO_SUCCESS\" --&gt; D[HdmiCecTx]\nC -- \"Failure\" --&gt; C1[Test case fail]\nD -- \"HDMI_CEC_IO_SUCCESS\" --&gt; E[Check HdmiCecTx result]\nD -- \"Failure\" --&gt; D1[Test case fail]\nE -- \"HDMI_CEC_IO_SENT_AND_ACKD\" --&gt; F[HdmiCecClose]\nE -- \"Failure\" --&gt; E1[Test case fail]\nF -- \"HDMI_CEC_IO_SUCCESS\" --&gt; G[Test case success]\nF -- \"Failure\" --&gt; F1[Test case fail]</code></pre>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-sink_L2_Low-Level_TestSpec/#test-5","title":"Test 5","text":"Title Details Function Name <code>test_l2_hdmi_cec_sink_hal_VerifyPhysicalAddress</code> Description Verify the valid physical address allocated through the HAL function. Test Group 02 Test Case ID 005 Priority High <p>Pre-Conditions: None</p> <p>Dependencies: None</p> <p>User Interaction: If the user chooses to run the test in interactive mode, then the test case has to be selected via the console.</p>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-sink_L2_Low-Level_TestSpec/#test-procedure-test-5","title":"Test Procedure Test 5","text":"Variation / Steps Description Test Data Expected Result Notes 01 Call the pre-requisite API HdmiCecOpen() handle = valid handle HDMI_CEC_IO_SUCCESS Should be successful 02 Call the API HdmiCecGetPhysicalAddress() handle = valid handle, physicalAddress = valid address HDMI_CEC_IO_SUCCESS Should be successful 03 Check the return status of HdmiCecGetPhysicalAddress() status = return status of HdmiCecGetPhysicalAddress() HDMI_CEC_IO_SUCCESS Should be successful 04 Verify that the physical address obtained is equal to 0.0.0.0 physicalAddress = obtained physical address physicalAddress == 0x0000 (as per HDMI Spec 1.4b and section 8.7.2) Should be successful 05 Call the post-requisite API HdmiCecClose() handle = valid handle HDMI_CEC_IO_SUCCESS Should be successful <pre><code>graph TB\nA[HdmiCecOpen] --&gt;|HDMI_CEC_IO_SUCCESS| B[HdmiCecGetPhysicalAddress]\nB --&gt;|HDMI_CEC_IO_SUCCESS| C{Verify Physical Address == 0.0.0.0}\nB --&gt;|Failure| B1[Test case fail]\nC --&gt;|Success| D[HdmiCecClose]\nC --&gt;|Failure| C1[Test case fail]\nD --&gt;|HDMI_CEC_IO_SUCCESS| E[Test case success]\nD --&gt;|Failure| D1[Test case fail]\nA --&gt;|Failure| A1[Test case fail]</code></pre>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-sink_L2_Low-Level_TestSpec/#test-6","title":"Test 6","text":"Title Details Function Name <code>test_l2_hdmi_cec_sink_hal_TransmitCECCommand</code> Description DUT transmits a CEC Command (as per 1.4b HDMI CEC spec) to get the CEC version of the device that doesn't exist. Test Group 02 Test Case ID 006 Priority High <p>Pre-Conditions: None</p> <p>Dependencies: None</p> <p>User Interaction: If the user chooses to run the test in interactive mode, then the test case has to be selected via the console.</p>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-sink_L2_Low-Level_TestSpec/#test-procedure-test-6","title":"Test Procedure Test 6","text":"Variation / Steps Description Test Data Expected Result Notes 01 Open HDMI CEC HAL using HdmiCecOpen handle = valid buffer HDMI_CEC_IO_SUCCESS Should be successful 02 Add logical address using HdmiCecAddLogicalAddress handle = valid handle, logicalAddresses = 0x0 HDMI_CEC_IO_SUCCESS Should be successful 03 Transmit CEC command using HdmiCecTx for a non existing device handle = valid handle, buf = {0x47, 0x9F}, len = sizeof(buf), result = valid buffer HDMI_CEC_IO_SUCCESS, result = HDMI_CEC_IO_SENT_BUT_NOT_ACKD Should be successful 04 Remove logical address using HdmiCecRemoveLogicalAddress handle = valid handle, logicalAddresses = 0x4 HDMI_CEC_IO_SUCCESS Should be successful 05 Close HDMI CEC HAL using HdmiCecClose handle = valid handle HDMI_CEC_IO_SUCCESS Should be successful <pre><code>graph TB\nA[HdmiCecOpen] -- \"HDMI_CEC_IO_SUCCESS\" --&gt; B[HdmiCecAddLogicalAddress]\nA -- \"Not HDMI_CEC_IO_SUCCESS\" --&gt; A1[Test case fail]\nB -- \"HDMI_CEC_IO_SUCCESS\" --&gt; C[Prepare CEC message]\nB -- \"Not HDMI_CEC_IO_SUCCESS\" --&gt; B1[Test case fail]\nC --&gt; D[HdmiCecTx]\nD -- \"HDMI_CEC_IO_SENT_BUT_NOT_ACKD\" --&gt; E[HdmiCecRemoveLogicalAddress]\nD -- \"Not HDMI_CEC_IO_SENT_BUT_NOT_ACKD\" --&gt; D1[Test case fail]\nE -- \"HDMI_CEC_IO_SUCCESS\" --&gt; F[HdmiCecClose]\nE -- \"Not HDMI_CEC_IO_SUCCESS\" --&gt; E1[Test case fail]\nF -- \"HDMI_CEC_IO_SUCCESS\" --&gt; G[Test case success]\nF -- \"Not HDMI_CEC_IO_SUCCESS\" --&gt; F1[Test case fail]</code></pre>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-source_High-Level_TestSpec/","title":"HDMI CEC Test Document","text":""},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-source_High-Level_TestSpec/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>CEC</code>  - Consumer Electronics Control</li> <li><code>HAL</code>  - Hardware Abstraction layer</li> <li><code>HDMI</code> - High Definition Multimedia Interface</li> <li><code>L2</code>   - Level 2 Testing ()</li> <li><code>L3</code>   - Level 3 Testing ()</li> <li><code>DUT</code>  - Device Under Test</li> <li><code>Sink device</code> - An equipment or technology that receives an input signal or data from another device or system.</li> <li><code>Source Device</code> - An equipment or technology that provides an input signal or data to another device or system.</li> </ul>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-source_High-Level_TestSpec/#scope","title":"Scope","text":"<p>This document defines the requirements for testing the HDMI CEC device from a level 2/3 based on being a source device.</p>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-source_High-Level_TestSpec/#overview","title":"Overview","text":"<p>Consumer Electronics Control (CEC) is a single-wire bidirectional bus within an HDMI system, facilitating communication among interconnected products. HDMI-CEC establishes a protocol enabling high-level control functions between audiovisual devices linked via an HDMI network, facilitating communication and control among them. Communication can occur in either Direct messaging mode or Broadcast mode. </p>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-source_High-Level_TestSpec/#hdmi-cec-rdk-hal-functionality","title":"HDMI-CEC RDK HAL Functionality","text":"<p>The HAL layers within RDK serve as a bridge between the underlying low-level SoC drivers and the higher-level RDK layers that utilize the functionality offered by these HAL functions. Specifically concerning the CEC Module, the HAL layers facilitate the following functionalities:</p> <ul> <li>Logical Address discovery </li> <li>Get a Logical address</li> <li>Get a Physical address</li> <li>Synchronous transmission, and communication via hotplug connectivity</li> </ul> <p>The interface of the test is available here: Hdmicec HAL header</p> <p>The Hdmicec Hal Spec document: Hdmicec HAL Spec</p>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-source_High-Level_TestSpec/#test-scenarios","title":"Test scenarios","text":"<p>The HAL CEC layer facilitates the transmission and reception of CEC information on the CEC bus. It does not handle any specific opcode commands, nor does it validate supported HAL CEC opcodes for sending or receiving.</p> <p>The caller is responsible for managing the opcodes. The current test cases will verify responses from connected devices for a subset of opcodes as part of the testing process.</p> S.No. Test Functionality Description 1 Logical address Facilitating the Discovery of logical addresses by getting the logical address of the device (for source devices) 2 Physical Address Retrieving the physical address 3 CEC Synchronous Transmission Transmitting CEC frames and reporting on their acknowledgement 4 CEC Receive functionality Receiving CEC information from other devices and passing it to the layer above through a registered callback function 5 CEC HotPlug Functionality Managing CEC during Hotplug and HotUnplug events"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-source_High-Level_TestSpec/#logical-address-discovery","title":"Logical Address Discovery","text":"Description HAL APIs L2 L3 Control plane requirements Trying to get a logical address discovered during CEC open, and validate the return value when the <code>DUT</code> is not connected to a Sink device. It should return HDMI_CEC_IO_LOGICALADDRESS_UNAVAILABLE. HdmiCecOpen Y N Get the logical address discovered during CEC open and validate the address for a proper playback/tuner device. This will add the logical address, as per source functionality. As the connected device will be a playback device, the valid logical address would be 4, 8, and 11. HdmiCecOpen HdmiCecGetLogicalAddress N Y Connect 5 playback devices using a switch, and attempt to discover a logical address with the fifth device, which exceeds the number of logical ports for playback devices. It should return HDMI_CEC_IO_LOGICALADDRESS_UNAVAILABLE HdmiCecOpen N Y Rapidly connect and disconnect HDMI connection in 100ms connection and 100ms disconnection cycle. HdmiCecOpen  HdmiCecGetLogicalAddress N Y"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-source_High-Level_TestSpec/#emulator-requirements","title":"Emulator Requirements","text":"<ul> <li>Boot with control configuration with various configurations having a predefined set of nodes:</li> <li>configuration to support the discovery of logical addresses. The caller creates a proper logical address during Open and that should be provided when HdmiCecOpen is used.</li> <li>Verify for the valid logical address and return the appropriate error code based on the logical address availability.  </li> <li>The emulator should simulate the logical address that a source device can provide.</li> </ul>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-source_High-Level_TestSpec/#control-plane-requirements","title":"Control Plane Requirements","text":"<ul> <li>The control plane will allow removing or adding a node to the network.</li> <li>allowing adding/removing source node</li> <li>Allow adding/removing of sink node</li> <li>allow the use of multiple source nodes</li> <li>Support the CEC commands from the external devices on L3 Test Cases. </li> </ul>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-source_High-Level_TestSpec/#physical-address","title":"Physical Address","text":"Description HAL APIs L2 L3 Control plane requirements Enable a sink device connected to the DUT first to get the valid physical address allocated through the HAL function. The physical address should be 1.0.0.0 HdmiCecGetPhysicalAddress N Y Verify the physical addresses allocated by connecting a source and sink device through an HDMI switch. The physical address should 1.1.0.0 HdmiCecGetPhysicalAddress N Y Enable the television connected to <code>DUT</code> to declare its physical address first before <code>DUT</code>. Connect a sink device to the source device, get the physical address. Disconnect the sink device and attempt to get the physical address again HdmiCecGetPhysicalAddress N Y <p>@note Calling HdmiCecGetPhysicalAddress when no device is connected to <code>DUT</code> is not a valid test because HdmiCecOpen has not been initiated.</p>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-source_High-Level_TestSpec/#emulator-requirements-physical-address","title":"Emulator Requirements - Physical Address","text":"<ul> <li>Boot control configuration to setup the CEC network nodes<ul> <li>Emulator to provide a valid physical address when requested.</li> </ul> </li> </ul>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-source_High-Level_TestSpec/#control-plane-requirements-physical-address","title":"Control Plane Requirements - Physical Address","text":"<ul> <li>The control plane will allow removing or adding a node to the network.</li> <li>allowing add source node before the <code>DUT</code> switched ON.  </li> <li>allowing add sink node before the <code>DUT</code> switched ON.    </li> </ul>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-source_High-Level_TestSpec/#cec-synchronous-transmission","title":"CEC Synchronous Transmission","text":"Description HAL APIs L2 L3 Control plane requirements Transmit a CEC Command (as per 1.4b HDMI CEC spec) to get the CEC Version for a logical address that doesn't exist after the connected device is disconnected. Result should return HDMI_CEC_IO_SENT_BUT_NOT_ACKD. HdmiCecTx N Y Control plane can unplug or switch off a previously existing CEC device Transmit a CEC Command (as per 1.4b HDMI CEC spec) to get the CEC Version for supported CEC commands (as per 1.4b HDMI CEC spec) after the connected device is disconnected. Result should return HDMI_CEC_IO_SENT_BUT_NOT_ACKD. HdmiCecTx N Y Control plane can unplug or switch off a previously existing CEC device Verify the correct transmission of the supported CEC commands (as per 1.4b HDMI CEC spec) to the connected device and ensure it is acknowledged properly. The result should return HDMI_CEC_IO_SENT_AND_ACKD. HdmiCecTx N Y Control plane to switch ON a CEC-supported device on the HDMI network so that it shall respond to the basic commands Broadcast a supported CEC Command to all the devices connected to the network without any error. The result should return HDMI_CEC_IO_SENT_AND_ACKD HdmiCecTx N Y Control plane to switch ON a CEC-supported device on the HDMI network to act on the broadcasted command Transmit a CEC Command (as per 1.4b HDMI CEC spec) to put the connected device into standby mode and await the device's response. Monitoring the behavior of the connected device accordingly. The result should return HDMI_CEC_IO_SENT_AND_ACKD. HdmiCecTx N Y Control plane to monitor the behavior of the connected devices."},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-source_High-Level_TestSpec/#emulator-requirements-cec-transmission","title":"Emulator Requirements - CEC Transmission","text":"<ul> <li>Boot configuration</li> <li>Min case scenario multiple network nodes</li> <li>Max case scenario multiple cec nodes</li> </ul>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-source_High-Level_TestSpec/#control-plane-requirements-cec-transmission","title":"Control Plane Requirements - CEC Transmission","text":"<ul> <li>The control plane will allow adding a device that can respond to the CEC Frames sent by <code>DUT</code></li> </ul>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-source_High-Level_TestSpec/#cec-receive-functionality","title":"CEC Receive functionality","text":"S.No. Test Functionality Description HAL APIs L2 L3 Control plane requirements 5 CEC Receive functionality Transmit a CEC Command that expects a response (Eg. GetCECVersion) to a connected device and see the response is received correctly. Set the Rx Callback before sending the data. Validate the received CEC Version. HdmiCecSetRxCallback HdmiCecTx N Y Control plane to switch ON a CEC device that can respond to the Transmitted CEC Command Transmit a CEC command from the connected devices and consider the Acknowledgement and responses are received correctly from the host device (<code>DUT</code> TV here) HdmiCecSetRxCallback N Y Control panel to control the third-party devices to Transmit the required commands to  <code>DUT</code> Transmit an OSD CEC command from the connected devices and consider the Acknowledgement and responses are received correctly from the host device (<code>DUT</code> TV here). Make the OSD String to max length HdmiCecSetRxCallback N Y Control panel to control the third-party devices to Transmit the required commands to  <code>DUT</code> Transmit an OSD CEC command from the connected devices continuously for 30 seconds changing the patterns in the payload and considering the Acknowledgement and responses are received correctly from the host device (<code>DUT</code> TV here). Make the OSD String to max length HdmiCecSetRxCallback N Y Control panel to control the third-party devices to Transmit the required commands to  <code>DUT</code>. Also, Control plane to detect the OSD Display on the Sink device to validate Set the Logical address to 0 on <code>DUT</code> and make sure that it doesn't receive the messages sent to devices with different logical address. HdmiCecSetRxCallback N Y Control Plane to initiate a command to send CEC frames from CEC adaptor with a different logical address other than zero"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-source_High-Level_TestSpec/#emulator-requirements-cec-receive-functionality","title":"Emulator Requirements - CEC Receive functionality","text":"<ol> <li>Emulate the Tx and Rx HAL functionalities with the required responses.</li> </ol>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-source_High-Level_TestSpec/#control-plane-requirements-cec-transmission_1","title":"Control Plane Requirements - CEC Transmission","text":"<ul> <li>The control plane will allow adding a device that can respond to the CEC Frames sent by <code>DUT</code></li> <li>The control plane to initiate CEC Transmissions from the connected devices as expected by the <code>DUT</code></li> </ul>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-source_High-Level_TestSpec/#cec-hotplug-functionality","title":"CEC HotPlug Functionality","text":"S.No. Test Functionality Description HAL APIs L2 L3 Control plane requirements 6 CEC HotPlug Functionality Generate a Hotplug event by disconnecting the device connected to the HDMI port of the Source Platform. Validating whether the CEC Transmission (use Polling command) works when the HDMI port is disconnected should result in ACK not being received while the TX still works as expected. HdmiCecTx N Y Control Panel to control the Hotplug activities Check the behaviour when a device has been remove from the network which is not directly connected to the TV device.  Send a CEC Tx command with acknowledgment using HAL Interface and check the behaviour. The Tx command should succeed, but the message should not be Acknowledged. HdmiCecTx N Y Control Panel to control the external devices connected."},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-source_High-Level_TestSpec/#emulator-requirements-cec-hotplug-functionality","title":"Emulator Requirements - CEC HotPlug Functionality","text":""},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-source_High-Level_TestSpec/#control-plane-requirements-cec-hotplug-functionality","title":"Control Plane Requirements - CEC HotPlug Functionality","text":"<ol> <li>Control plane to initiate the HotPlug activity by commanding an IP power switch to the OFF State to which the Node device is connected.</li> </ol>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-source_High-Level_TestSpec/#-","title":"-----------","text":""},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-source_High-Level_TestSpec/#hardware-verification-testing-requirements","title":"Hardware Verification Testing Requirements","text":"S.No. Test Functionality Description HAL APIs L2 L3 Control plane requirements 7 Introduce fault in the CEC Bus Observe the behaviour when the CEC line is pulled high during the CEC Transmission using a CEC Adaptor that provision to keep the CEC line pulled high HdmiCecTx N Y CEC Adaptor used shall have a provision to introduce the fault. The control plane should be able to command to pull the CEC line high, else it should follow a manual process 8 Overloading the CEC bus. Overload the CEC bus with too many messages  (by connecting more devices in the network) and observe the behaviour HdmiCecTx N Y Control plane to initiate the CEC Transmission through all the connected devices continuously with a command that expects the response as well to overload the CEC Network."},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-source_High-Level_TestSpec/#emulator-requirements_1","title":"Emulator Requirements","text":"<ol> <li>Emulator to support the HDMI_CEC_IO_SENT_FAILED during the above scenarios</li> </ol>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-source_High-Level_TestSpec/#control-plane-requirements_1","title":"Control Plane Requirements","text":"<ol> <li>Control Plane to control the external devices to pull the CEC line high.</li> <li>Control Plan to initiate multiple CEC commands from the different devices connected to the network. </li> </ol>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-source_High-Level_TestSpec/#boot-configuartion","title":"Boot configuartion","text":""},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-source_High-Level_TestSpec/#module-configuration-requirements","title":"Module Configuration Requirements","text":"<p>The module must be configured during the boot sequence in the case of emulation as if it were a real hardware device with or without multiple connected HDMI nodes.</p>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-source_High-Level_TestSpec/#test-configuration-for-source-devices","title":"Test Configuration for Source Devices","text":"<p>The following information shall be helpful for further running the Automation Rack Test for this specific module and further configuration will help for the Design and Development of Virtual Device.</p> <p>Configurations:</p> <pre><code>  Device:\n    Type: Source / Sink\n    Platform_Manufacturer: sony/Samsung etc.\n    Platform_Model:  xyz\n    Port: 3, 4\n    HDMI Node: 1-3 etc.\n    CEC_Ports: 1, x, y\n</code></pre>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-source_L2_Low-Level_TestSpec/","title":"HDMI CEC Source L2 Low Level Test Specification and Procedure Documentation","text":""},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-source_L2_Low-Level_TestSpec/#overview","title":"Overview","text":"<p>This document describes the Source level 2 Low Level Test Specification and Procedure Documentation for the HDMI CEC HAL module Source.</p>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-source_L2_Low-Level_TestSpec/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>HAL</code> - Hardware Abstraction Layer, may include some common components</li> <li><code>UT</code>  - Unit Test(s)</li> <li><code>OEM</code>  - Original Equipment Manufacture</li> <li><code>SoC</code>  - System on a Chip</li> </ul>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-source_L2_Low-Level_TestSpec/#definitions","title":"Definitions","text":"<ul> <li><code>ut-core</code> - Common Testing Framework https://github.com/rdkcentral/ut-core, which wraps a open-source framework that can be expanded to the requirements for future framework.</li> </ul>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-source_L2_Low-Level_TestSpec/#references","title":"References","text":"<ul> <li><code>High Level Test Specification</code> - hdmi-cec-source_High-Level_TestSpec.md</li> <li><code>HDMI CEC HAL Interface file</code> - hdmi_cec_driver.h</li> </ul>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-source_L2_Low-Level_TestSpec/#level-2-test-procedure","title":"Level 2 Test Procedure","text":"<p>The following functions are expecting to test the module operates correctly.</p>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-source_L2_Low-Level_TestSpec/#test-1","title":"Test 1","text":"Title Details Function Name <code>test_l2_hdmi_cec_source_hal_ValidateLogicalAddressUnavailability_source</code> Description Trying to get a logical address discovered during CEC open and validate the return value when the <code>DUT</code> is not connected to a Sink device. It should return HDMI_CEC_IO_LOGICALADDRESS_UNAVAILABLE. Test Group 02 Test Case ID 001 Priority High <p>Pre-Conditions : None</p> <p>Dependencies : None</p> <p>User Interaction : If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi-cec-source_L2_Low-Level_TestSpec/#test-procedure","title":"Test Procedure","text":"Variation / Steps Description Test Data Expected Result Notes 01 Invoke HdmiCecOpen with a valid handle when the <code>DUT</code> is not connected to a Sink device handle = valid handle HDMI_CEC_IO_LOGICALADDRESS_UNAVAILABLE Should be successful 02 If the status is HDMI_CEC_IO_SUCCESS, invoke HdmiCecClose with the handle handle = valid handle HDMI_CEC_IO_SUCCESS Should be successful <pre><code>graph TB\n    Step1[Call HdmiCecOpen] --&gt;|Success| Step2[Check returned status]\n    Step1 --&gt;|Failure| TestFail1[Test Case Failed: HdmiCecOpen failed]\n    Step2 --&gt;|Status is &lt;br&gt; HDMI_CEC_IO_LOGICALADDRESS_UNAVAILABLE| Step4[TestCase Success]\n    Step2 --&gt;|Status is &lt;br&gt; HDMI_CEC_IO_SUCCESS or HDMI_CEC_IO_ALREADY_OPEN| TestFail2[Test Case Failed]\n    TestFail2 --&gt;|Status is HDMI_CEC_IO_SUCCESS| Step3[Call HdmiCecClose]\n    Step3 --&gt;|Success| Step5[HdmiCecClose success]\n    Step3 --&gt;|Failure| TestFail3[Test Case Failed: HdmiCecClose failed]</code></pre>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi_cec_VirtualComponent_ControlPlaneCommands/","title":"Virtual Component ControlPlane Commands","text":""},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi_cec_VirtualComponent_ControlPlaneCommands/#overview-of-hdmi-cec-virtual-component-control-plane-commands","title":"Overview of HDMI-CEC Virtual Component Control Plane Commands","text":"<p>The HDMI-CEC virtual component enables comprehensive testing of HDMI-CEC functionalities through the control plane. Testers can interact with the virtual component using four primary types of commands, each serving a distinct purpose:</p> <p>Command: Directly trigger specific HDMI-CEC commands between devices, simulating real-world user interactions.</p> <p>Event: Simulate HDMI-CEC events like hotplug (device connection/disconnection) to test how devices react.</p> <p>Config: Modify the virtual CEC network configuration, changing device types, connections, and capabilities.</p> <p>State: Dynamically add or remove devices during testing and print the current status for debugging.</p> <p>Each command type is structured as a YAML payload, which is outlined in detail in the following sections. These payloads allow testers to precisely control the virtual HDMI-CEC environment, replicating various scenarios and edge cases.</p>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi_cec_VirtualComponent_ControlPlaneCommands/#1-command","title":"1. Command","text":"<p>HDMI Consumer Electronics Control (CEC) commands are designed to allow control of multiple devices through a single remote control and enable devices to communicate with each other. These commands are categorized based on their functionalities and the end-user features they support.</p>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi_cec_VirtualComponent_ControlPlaneCommands/#example-yaml-cec-command","title":"Example YAML CEC Command","text":"<pre><code>---\nhdmicec:\n  command: SetOsdName\n  initiator: Sony HomeTheatre\n  destination: IPSTB\n  parameters:\n    osd_name: IPSTB\n</code></pre>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi_cec_VirtualComponent_ControlPlaneCommands/#2-event","title":"2. Event","text":"<p>This category of messages allow the test user to trigger changes in the virtual component state machine.</p>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi_cec_VirtualComponent_ControlPlaneCommands/#example-event","title":"Example Event","text":"<p>Command to trigger a hotplug event from device connected in Port 2: <pre><code>hdmicec:\n    command: hotplug\n    port: 2\n    connected: false\n</code></pre></p>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi_cec_VirtualComponent_ControlPlaneCommands/#3-config","title":"3. Config","text":"<p>Test user can also trigger a re-configuration of the initial profile with which the emulator state machine was set up, like the device type (Sink or Source) and the list of devices in the network etc.</p>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi_cec_VirtualComponent_ControlPlaneCommands/#example-config-change-trigger","title":"Example config change trigger","text":"<pre><code>---\nhdmicec:\n  config:\n    emulated_device: IPSTB\n    number_ports: 1\n    ports:\n      - id: 1\n        type: out\n        cec_supported: true\n        arc_supported: false\n    number_devices: 3\n    device_map:\n      - name: Sony TV\n        type: TV\n        version: 4\n        active_source: false\n        vendor_info: SONY\n        pwr_status: on\n        number_chlidren: 2\n        children:\n         -  name: IPSTB\n            type: PlaybackDevice\n            version: 4 \n            active_source: true\n            vendor: TEST_VENDOR\n            pwr_status: on\n            port_id: 1\n            num_children: 0\n\n         -  name: Chromecast\n            type: PlaybackDevice\n            version: 4\n            active_source: false\n            vendor: GOOGLE\n            pwr_status: on\n            port_id: 1\n            num_children: 0\n</code></pre>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi_cec_VirtualComponent_ControlPlaneCommands/#4-state","title":"4. State","text":"<p>Test user can trigger state changes by dynamically adding or removing device(s). Debug printing of the current status of virtual component in logs can also be triggered.</p> Status YAML Payload Action <code>AddDevice</code> <pre>---\rhdmicec:\r  state: AddDevice\r  parameters:\r    parent: TV\r   name: TestDevice\r    type: PlaybackDevice\r    version: 4\r    active_source: false\r    vendor: TEST_VENDOR\r    pwr_status: on\r    port_id: 2\r    number_children: 0</pre> Adds the new device as a child to given parent <code>RemoveDevice</code> <pre>---\rhdmicec:\r  state: RemoveDevice\r  parameters:\r    name: TestDevice\r</pre> Removes a device and its children from the Virtual Component state. <code>PrintStatus</code> <pre>---\rhdmicec:\r  state: PrintStatus\r  parameters:\r    status: Devices</pre> Prints the current network of devices"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi_cec_VirtualComponent_ControlPlaneCommands/#parameters-for-printstatus","title":"Parameters for <code>PrintStatus</code>","text":"Parameter Description Values <code>status</code> Specific status <code>Devices</code>, <code>Ports</code>, <code>General</code>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi_cec_VirtualComponent_ControlPlaneCommands/#example-state-trigger-to-add-a-new-device-to-a-parent-port","title":"Example state trigger to add a new device to a parent port.","text":"<pre><code>hdmicec:\n    state: AddDevice\n    prameters:\n       parent: TV\n       name: TestDevice\n       type: PlaybackDevice\n       version: 4\n       active_source: false\n       vendor: TEST_VENDOR\n       pwr_status: on\n       port_id: 2\n       number_children: 0\n</code></pre>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi_cec_VirtualComponent_ControlPlaneCommands/#example-state-trigger-to-print-status-of-devices-connected","title":"Example state trigger to print status of devices connected","text":"<pre><code>hdmicec:\n    state: PrintStatus\n    parameters:\n       status: Devices\n</code></pre>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi_cec_VirtualComponent_ControlPlaneCommands/#anatomy-of-the-yaml-cec-command","title":"Anatomy of the YAML CEC Command","text":"<p>The YAML representation of CEC commands provides a structured and human-readable format for defining and triggering HDMI-CEC commands. These YAML commands closely follow the CEC specifications but are more descriptive in nature.</p> <pre><code>---\nhdmicec:\n  command: # The CEC command to be executed (e.g., SetOsdName, ActiveSource, UserControlPressed, etc.)\n  initiator: # The device sending the command (e.g., Sony HomeTheatre, IPSTB, TV, etc.)\n  destination: # The device receiving the command (e.g., TV, IPSTB, Broadcast, etc.)\n  parameters: # Optional: Additional parameters required for the command\n    # Add specific parameters below as needed for the command\n    osd_name: # Example: OSD name to be set (for SetOsdName command)\n    device_name: # Example: Physical address of the device (for ActiveSource or ReportPhysicalAddress commands)\n    ui_command: # Example: User interface command (for UserControlPressed command)\n    device_type: # Example: Device type (for ReportPhysicalAddress command)\n    deck_info: # Example: Deck status information (for DeckStatus command)\n    tuner_info: # Example: Tuner status information\n</code></pre>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi_cec_VirtualComponent_ControlPlaneCommands/#components-of-the-yaml-cec-command","title":"Components of the YAML CEC Command","text":""},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi_cec_VirtualComponent_ControlPlaneCommands/#root-element-hdmicec","title":"Root Element (hdmicec):","text":"<p>The root element of the YAML file, indicating that this is a CEC command.</p>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi_cec_VirtualComponent_ControlPlaneCommands/#command","title":"Command:","text":"<p>The command key specifies the CEC command to be executed. Example: SetOsdName is the command to set the On-Screen Display name of a device.</p>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi_cec_VirtualComponent_ControlPlaneCommands/#initiator","title":"Initiator:","text":"<p>The initiator key indicates the device that is sending the command. All devices are identified by its unique name that is configured in the profile YAML. The virtual component takes care of converting the device names into physical and logical addresses internaly.</p> <p>Example: Sony HomeTheatre is the device initiating the command.</p>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi_cec_VirtualComponent_ControlPlaneCommands/#destination","title":"Destination:","text":"<p>The destination key specifies the target device that will receive the command. Example: IPSTB is the device receiving the command.</p>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi_cec_VirtualComponent_ControlPlaneCommands/#parameters","title":"Parameters:","text":"<p>The parameters key holds a dictionary of additional data required for the command. Example: For the SetOsdName command, the parameters section includes an osd_name key with the value IPSTB.</p>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi_cec_VirtualComponent_ControlPlaneCommands/#using-the-parameters-section-in-different-cec-commands","title":"Using the Parameters Section in Different CEC Commands","text":"<p>The <code>parameters</code> section in the YAML CEC command is used to provide additional data required for executing specific CEC commands. The parameters vary depending on the command being issued. Below are examples and descriptions of how the <code>parameters</code> section can be used in different CEC commands.</p>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi_cec_VirtualComponent_ControlPlaneCommands/#example-1-setosdname","title":"Example 1: SetOsdName","text":"<p>The <code>SetOsdName</code> command sets the On-Screen Display (OSD) name for a device. This command requires an <code>osd_name</code> parameter to specify the name to be set.</p> <pre><code>---\nhdmicec:\n  command: SetOsdName\n  initiator: Sony HomeTheatre\n  destination: IPSTB\n  parameters:\n    osd_name: IPSTB\n</code></pre>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi_cec_VirtualComponent_ControlPlaneCommands/#example-2-activesource","title":"Example 2: ActiveSource","text":"<p>The ActiveSource command is used to indicate which device is currently the active source. This command requires a physical_address parameter. <pre><code>---\nhdmicec:\n  command: ActiveSource\n  initiator: IPSTB\n  destination: TV\n  parameters:\n    physical_address: 0x1000\n</code></pre></p>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi_cec_VirtualComponent_ControlPlaneCommands/#example-3-usercontrolpressed","title":"Example 3: UserControlPressed","text":"<p>The UserControlPressed command simulates a button press on the remote control. This command requires a ui_command parameter to specify the user interface command. <pre><code>---\nhdmicec:\n  command: UserControlPressed\n  initiator: TV\n  destination: IPSTB\n  parameters:\n    ui_command: Select\n</code></pre></p>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi_cec_VirtualComponent_ControlPlaneCommands/#hdmi-cec-command-categories-based-on-end-user-features","title":"HDMI-CEC Command Categories Based on End User Features","text":"<p>HDMI CEC commands are categorized based on their functionalities and the end-user features they support.</p> <p>Below are some of the commonly used categories of CEC commands:</p>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi_cec_VirtualComponent_ControlPlaneCommands/#1-one-touch-play","title":"1. One Touch Play","text":"<p>Commands in this category are used to turn on devices and switch them to the correct input automatically.</p> Command YAML Payload Action How to Trigger in Real Setup <code>ActiveSource</code> <pre>---\rhdmicec:\r  command: \"ActiveSource\"\r  initiator: \"IPSTB\"\r  destination: \"Broadcast\"\r  parameters:\r    device_name: \"TV\"</pre> Announces that the initiator is the active source Automatically triggered when a device becomes active <code>ImageViewOn</code> <pre>---\rhdmicec:\r  command: \"ImageViewOn\"\r  initiator: \"DVD Player\"\r  destination: \"TV\"</pre> Switches the TV to the initiator's input Using a DVD player remote control to turn on the TV <code>TextViewOn</code> <pre>---\rhdmicec:\r  command: \"TextViewOn\"\r  initiator: \"DVD Player\"\r  destination: \"TV\"</pre> Switches the TV to the initiator's input with text display Using a DVD player remote control to turn on the TV"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi_cec_VirtualComponent_ControlPlaneCommands/#example-yaml-payloads","title":"Example YAML Payloads","text":"<p>Active Source:</p> <pre>\n---\nhdmicec:\n  command: \"ActiveSource\"\n  initiator: \"IPSTB\"\n  destination: \"Broadcast\"\n  parameters:\n    device_name: \"TV\"\n</pre> <p>Image View On:</p> <pre>\n---\nhdmicec:\n  command: \"ImageViewOn\"\n  initiator: \"DVD Player\"\n  destination: \"TV\"\n</pre> <p>Text View On:</p> <pre>\n---\nhdmicec:\n  command: \"TextViewOn\"\n  initiator: \"DVD Player\"\n  destination: \"TV\"\n</pre>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi_cec_VirtualComponent_ControlPlaneCommands/#2-one-touch-record","title":"2. One Touch Record","text":"<p>Allows whatever is shown on the TV screen to be recorded on a selected Recording Device.</p> Command YAML Payload Action How to Trigger in Real Setup <code>RecordOn</code> <pre>---\rhdmicec:\r  command: RecordOn\r  initiator: TV\r  destination: RecordingDevice\r  parameters:\r    source: Tuner</pre> Starts recording on the specified recording device Using a TV remote control to start recording on a DVR <code>RecordOff</code> <pre>---\rhdmicec:\r  command: RecordOff\r  initiator: TV\r  destination: RecordingDevice</pre> Stops recording on the specified recording device Using a TV remote control to stop recording on a DVR <code>RecordStatus</code> <pre>---\rhdmicec:\r  command: RecordStatus\r  initiator: RecordingDevice\r  destination: TV\r  parameters:\r    status: Recording</pre> Reports the current recording status of the device Automatically triggered by the recording device to inform status"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi_cec_VirtualComponent_ControlPlaneCommands/#parameters-for-recordon","title":"Parameters for <code>RecordOn</code>","text":"Parameter Description Values <code>source</code> Source of the recording <code>Tuner</code>, <code>ExternalInput</code>, <code>Auxiliary</code>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi_cec_VirtualComponent_ControlPlaneCommands/#parameters-for-recordstatus","title":"Parameters for <code>RecordStatus</code>","text":"Parameter Description Values <code>status</code> Indicates the current recording status <code>Recording</code>, <code>NoRecording</code>, <code>InsufficientSpace</code>, <code>AlreadyRecording</code>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi_cec_VirtualComponent_ControlPlaneCommands/#example-yaml-payloads_1","title":"Example YAML Payloads","text":"<p>Record On - Tuner Source:</p> <pre>\n---\nhdmicec:\n  command: RecordOn\n  initiator: TV\n  destination: RecordingDevice\n  parameters:\n    source: Tuner\n</pre> <p>Record Off:</p> <pre>\n---\nhdmicec:\n  command: RecordOff\n  initiator: TV\n  destination: RecordingDevice\n</pre> <p>Record Status - Recording:</p> <pre>\n---\nhdmicec:\n  command: RecordStatus\n  initiator: RecordingDevice\n  destination: TV\n  parameters:\n    status: Recording\n</pre>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi_cec_VirtualComponent_ControlPlaneCommands/#3-routing-control","title":"3. Routing Control","text":"<p>These commands manage the routing of signals between devices, ensuring the correct source is displayed on the TV.</p> Command YAML Payload Action How to Trigger in Real Setup <code>RoutingChange</code> <pre>---\rhdmicec:\r  command: \"RoutingChange\"\r  initiator: \"AV Receiver\"\r  destination: \"Broadcast\"\r  parameters:\r    from_device: \"DVD Player\"\r    to_device: \"TV\"</pre> Notifies that the source device has changed from one to another Automatically triggered when the AV Receiver changes the input source <code>RoutingInformation</code> <pre>---\rhdmicec:\r  command: \"RoutingInformation\"\r  initiator: \"AV Receiver\"\r  destination: \"Broadcast\"\r  parameters:\r    device_name: \"TV\"</pre> Provides information about the current routing path Automatically triggered to inform the routing path change <code>RequestActiveSource</code> <pre>---\rhdmicec:\r  command: \"RequestActiveSource\"\r  initiator: \"TV\"\r  destination: \"Broadcast\"</pre> Requests the active source device to identify itself Using a TV remote control to switch inputs <code>SetStreamPath</code> <pre>---\rhdmicec:\r  command: \"SetStreamPath\"\r  initiator: \"TV\"\r  destination: \"Broadcast\"\r  parameters:\r    device_name: \"AV Receiver\"</pre> Sets the stream path to the specified device Using a TV remote control to select the AV Receiver <code>InactiveSource</code> <pre>---\rhdmicec:\r  command: \"InactiveSource\"\r  initiator: \"DVD Player\"\r  destination: \"TV\"</pre> Notifies that the initiator device is no longer the active source Automatically triggered when the DVD Player is turned off <code>ReportPhysicalAddress</code> <pre>---\rhdmicec:\r  command: \"ReportPhysicalAddress\"\r  initiator: \"AV Receiver\"\r  destination: \"Broadcast\"\r  parameters:\r    device_name: \"TV\"</pre> Provides the physical address of the device Automatically triggered when a device is connected <code>GivePhysicalAddress</code> <pre>---\rhdmicec:\r  command: \"GivePhysicalAddress\"\r  initiator: \"TV\"\r  destination: \"AV Receiver\"</pre> Requests the physical address of the destination device Using a TV remote control to identify the AV Receiver"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi_cec_VirtualComponent_ControlPlaneCommands/#example-yaml-payloads_2","title":"Example YAML Payloads","text":"<p>Routing Change:</p> <pre>\n---\nhdmicec:\n  command: \"RoutingChange\"\n  initiator: \"AV Receiver\"\n  destination: \"Broadcast\"\n  parameters:\n    from_device: \"DVD Player\"\n    to_device: \"TV\"\n</pre> <p>Routing Information:</p> <pre>\n---\nhdmicec:\n  command: \"RoutingInformation\"\n  initiator: \"AV Receiver\"\n  destination: \"Broadcast\"\n  parameters:\n    device_name: \"TV\"\n</pre> <p>Request Active Source:</p> <pre>\n---\nhdmicec:\n  command: \"RequestActiveSource\"\n  initiator: \"TV\"\n  destination: \"Broadcast\"\n</pre> <p>Set Stream Path:</p> <pre>\n---\nhdmicec:\n  command: \"SetStreamPath\"\n  initiator: \"TV\"\n  destination: \"Broadcast\"\n  parameters:\n    device_name: \"AV Receiver\"\n</pre> <p>Inactive Source:</p> <pre>\n---\nhdmicec:\n  command: \"InactiveSource\"\n  initiator: \"DVD Player\"\n  destination: \"TV\"\n</pre>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi_cec_VirtualComponent_ControlPlaneCommands/#4-deck-control","title":"4. Deck Control","text":"<p>These commands control the playback devices, such as recorders and players.</p> Command YAML Payload Action How to Trigger in Real Setup <code>DeckControl</code> <pre>---\rhdmicec:\r  command: DeckControl\r  initiator: TV\r  destination: PlaybackDevice1\r  parameters:\r    deck_info: Play</pre> Controls deck functions such as play, pause, etc. Using a TV remote control to control playback functions <code>GiveDeckStatus</code> <pre>---\rhdmicec:\r  command: GiveDeckStatus\r  initiator: TV\r  destination: PlaybackDevice1\r  parameters:\r    status_request: On</pre> Requests the current status of the playback device Automatically triggered by TV to get the status of the playback device <code>Play</code> <pre>---\rhdmicec:\r  command: Play\r  initiator: TV\r  destination: PlaybackDevice1\r  parameters:\r    play_mode: PlayForward</pre> Starts playback on the specified playback device Using a TV remote control to play content <code>DeckStatus</code> <pre>---\rhdmicec:\r  command: DeckStatus\r  initiator: PlaybackDevice1\r  destination: TV\r  parameters:\r    deck_info: Play</pre> Reports the current status of the playback device Automatically triggered by the playback device to inform its status"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi_cec_VirtualComponent_ControlPlaneCommands/#parameters-for-deckcontrol","title":"Parameters for <code>DeckControl</code>","text":"Parameter Description Values <code>deck_info</code> Indicates the deck control mode <code>Play</code>, <code>Pause</code>, <code>Stop</code>, <code>Rewind</code>, <code>FastForward</code>, <code>Eject</code>, <code>Seek</code> <code>seek_time</code> Time to seek to in milliseconds <code>0</code> to <code>n</code> (where <code>n</code> is the duration of the content in ms)"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi_cec_VirtualComponent_ControlPlaneCommands/#possible-values-for-status_request","title":"Possible Values for <code>status_request</code>","text":"Prameter Possible Values Description <code>status_request</code> <code>\"On\"</code>, <code>\"Off\"</code>, <code>\"Once\"</code> Requests status information from the device. \"On\" requests continuous updates, \"Off\" stops updates, \"Once\" requests a single update."},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi_cec_VirtualComponent_ControlPlaneCommands/#parameters-for-play","title":"Parameters for <code>Play</code>","text":"Parameter Description Values <code>play_mode</code> Indicates the play mode <code>PlayForward</code>, <code>PlayReverse</code>, <code>Still</code>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi_cec_VirtualComponent_ControlPlaneCommands/#parameters-for-deckstatus","title":"Parameters for <code>DeckStatus</code>","text":"Parameter Description Values <code>deck_info</code> Indicates the current status of the deck <code>Play</code>, <code>Pause</code>, <code>Stop</code>, <code>Rewind</code>, <code>FastForward</code>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi_cec_VirtualComponent_ControlPlaneCommands/#example-yaml-payloads_3","title":"Example YAML Payloads","text":"<p>Deck Control - Play Command:</p> <pre>\n---\nhdmicec:\n  command: DeckControl\n  initiator: TV\n  destination: PlaybackDevice1\n  parameters:\n    deck_info: Play\n</pre> <p>Give Deck Status Command:</p> <pre>\n---\nhdmicec:\n  command: GiveDeckStatus\n  initiator: TV\n  destination: PlaybackDevice1\n  parameters:\n    status_request: 1\n</pre> <p>Play Command:</p> <pre>\n---\nhdmicec:\n  command: Play\n  initiator: TV\n  destination: PlaybackDevice1\n  parameters:\n    play_mode: PlayForward\n</pre> <p>Deck Status - Playing:</p> <pre>\n---\nhdmicec:\n  command: DeckStatus\n  initiator: PlaybackDevice1\n  destination: TV\n  parameters:\n    deck_info: Play\n</pre>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi_cec_VirtualComponent_ControlPlaneCommands/#5-osd-display","title":"5. OSD Display","text":"<p>These commands manage the On-Screen Display settings and information.</p> Command YAML Payload Action How to Trigger in Real Setup <code>SetOsdString</code> <pre>---\rhdmicec:\r  command: \"SetOsdString\"\r  initiator: \"PlaybackDevice1\"\r  destination: \"TV\"\r  parameters:\r    osd_string: \"IPSTB\"</pre> Sets the OSD (On-Screen Display) string on the TV Automatically triggered when the playback device sets the OSD string <code>SetOsdName</code> <pre>---\rhdmicec:\r  command: \"SetOsdName\"\r  initiator: \"TV\"\r  destination: \"Broadcast\"\r  parameters:\r    osd_name: \"IPSTB\"</pre> Sets the OSD (On-Screen Display) name on all devices Automatically triggered when the TV sets the OSD name <code>GiveOSDName</code> <pre>---\rhdmicec:\r  command: \"GiveOSDName\"\r  initiator: \"TV\"\r  destination: \"Broadcast\"</pre> Requests the OSD (On-Screen Display) name from all devices Using a TV remote control to request OSD name from all devices"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi_cec_VirtualComponent_ControlPlaneCommands/#example-yaml-payloads_4","title":"Example YAML Payloads","text":"<p>Set OSD String (\"IPSTB\") on TV:</p> <pre>\n---\nhdmicec:\n  command: \"SetOsdString\"\n  initiator: \"PlaybackDevice1\"\n  destination: \"TV\"\n  parameters:\n    osd_string: \"IPSTB\"\n</pre> <p>Set OSD Name (\"IPSTB\") on all devices:</p> <pre>\n---\nhdmicec:\n  command: \"SetOsdName\"\n  initiator: \"TV\"\n  destination: \"Broadcast\"\n  parameters:\n    osd_name: \"IPSTB\"\n</pre> <p>Give OSD Name (Request from TV):</p> <pre>\n---\nhdmicec:\n  command: \"GiveOSDName\"\n  initiator: \"TV\"\n  destination: \"Broadcast\"\n</pre>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi_cec_VirtualComponent_ControlPlaneCommands/#6-device-menu-control","title":"6. Device Menu Control","text":"<p>Commands to control the device's menu interface, enabling navigation and selection of menu items.</p> Command YAML Payload Action How to Trigger in Real Setup <code>MenuRequest</code> <pre>---\rhdmicec:\r  command: \"MenuRequest\"\r  initiator: \"TV\"\r  destination: \"PlaybackDevice1\"</pre> Requests the menu from the playback device Using a TV remote control to request the menu from the device <code>MenuStatus</code> <pre>---\rhdmicec:\r  command: \"MenuStatus\"\r  initiator: \"PlaybackDevice1\"\r  destination: \"TV\"\r  parameters:\r    status: \"activated\"</pre> Provides the status of the menu Automatically triggered to inform the TV of the menu status <code>UserControlPressed</code> <pre>---\rhdmicec:\r  command: \"UserControlPressed\"\r  initiator: \"TV\"\r  destination: \"PlaybackDevice1\"\r  parameters:\r    ui_command: \"Select\"</pre> Sends a user control command (Select) to the playback device Using a TV remote control to send a select command to the device"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi_cec_VirtualComponent_ControlPlaneCommands/#example-yaml-payloads_5","title":"Example YAML Payloads","text":"<p>Menu Request:</p> <pre>\n---\nhdmicec:\n  command: \"MenuRequest\"\n  initiator: \"TV\"\n  destination: \"PlaybackDevice1\"\n</pre> <p>Menu Status:</p> <pre>\n---\nhdmicec:\n  command: \"MenuStatus\"\n  initiator: \"PlaybackDevice1\"\n  destination: \"TV\"\n  parameters:\n    status: \"activated\"\n</pre> <p>User Control Pressed (Select):</p> <pre>\n---\nhdmicec:\n  command: \"UserControlPressed\"\n  initiator: \"TV\"\n  destination: \"PlaybackDevice1\"\n  parameters:\n    ui_command: \"Select\"\n</pre>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi_cec_VirtualComponent_ControlPlaneCommands/#7-remote-control-passthrough","title":"7. Remote Control Passthrough","text":"<p>Allows remote control commands to be sent directly to devices.</p> Command YAML Payload Action How to Trigger in Real Setup <code>UserControlPressed</code> <pre>---\rhdmicec:\r  command: \"UserControlPressed\"\r  initiator: \"TV\"\r  destination: \"PlaybackDevice1\"\r  parameters:\r    ui_command: \"Play\"</pre> Sends a user control command (Play) to the playback device Using a TV remote control to send a play command to the device <code>UserControlReleased</code> <pre>---\rhdmicec:\r  command: \"UserControlReleased\"\r  initiator: \"TV\"\r  destination: \"PlaybackDevice1\"\r  parameters:\r    ui_command: \"Play\"</pre> Sends a user control command (Play release) to the playback device Using a TV remote control to release the play command on the device"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi_cec_VirtualComponent_ControlPlaneCommands/#example-yaml-payloads_6","title":"Example YAML Payloads","text":"<p>User Control Pressed (Play):</p> <pre>\n---\nhdmicec:\n  command: \"UserControlPressed\"\n  initiator: \"TV\"\n  destination: \"PlaybackDevice1\"\n  parameters:\n    ui_command: \"Play\"\n</pre> <p>User Control Released (Play):</p> <pre>\n---\nhdmicec:\n  command: \"UserControlReleased\"\n  initiator: \"TV\"\n  destination: \"PlaybackDevice1\"\n  parameters:\n    ui_command: \"Play\"\n</pre>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi_cec_VirtualComponent_ControlPlaneCommands/#8-power-status","title":"8. Power Status","text":"<p>These commands manage the power state of devices, such as putting them into standby mode.</p> Command YAML Payload Action How to Trigger in Real Setup <code>GiveDevicePowerStatus</code> <pre>---\rhdmicec:\r  command: \"GiveDevicePowerStatus\"\r  initiator: \"TV\"\r  destination: \"AudioSystem\"</pre> Requests the power status of the audio system Using a TV remote control to request power status from the audio system <code>ReportPowerStatus</code> <pre>---\rhdmicec:\r  command: \"ReportPowerStatus\"\r  initiator: \"AudioSystem\"\r  destination: \"TV\"\r  parameters:\r    power_status: \"on\"</pre> Provides the power status of the audio system Automatically triggered to inform the TV of the audio system power status <code>Standby</code> <pre>---\rhdmicec:\r  command: \"Standby\"\r  initiator: \"TV\"\r  destination: \"AudioSystem\"</pre> Puts the audio system into standby mode Using a TV remote control to send a standby command to the audio system"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi_cec_VirtualComponent_ControlPlaneCommands/#example-yaml-payloads_7","title":"Example YAML Payloads","text":"<p>Give Device Power Status:</p> <pre>\n---\nhdmicec:\n  command: \"GiveDevicePowerStatus\"\n  initiator: \"TV\"\n  destination: \"AudioSystem\"\n</pre> <p>Report Power Status (On):</p> <pre>\n---\nhdmicec:\n  command: \"ReportPowerStatus\"\n  initiator: \"AudioSystem\"\n  destination: \"TV\"\n  parameters:\n    power_status: \"on\"\n</pre> <p>Standby:</p> <pre>\n---\nhdmicec:\n  command: \"Standby\"\n  initiator: \"TV\"\n  destination: \"AudioSystem\"\n</pre>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi_cec_VirtualComponent_ControlPlaneCommands/#9-system-audio-control","title":"9. System Audio Control","text":"<p>When an Audio Amplifier / Receiver is connected with the TV, functionality like volume can be controlled using any of the remote controls of any cec enabled devices in the system.</p> Command YAML Payload Action How to Trigger in Real Setup <code>GiveAudioStatus</code> <pre>---\rhdmicec:\r  command: \"GiveAudioStatus\"\r  initiator: \"TV\"\r  destination: \"AudioSystem\"</pre> Requests the audio system status Using a TV remote control to get the status of the audio system <code>GiveSystemAudioModeStatus</code> <pre>---\rhdmicec:\r  command: \"GiveSystemAudioModeStatus\"\r  initiator: \"TV\"\r  destination: \"AudioSystem\"</pre> Requests the audio system mode status Using a TV remote control to get the current audio system mode <code>ReportAudioStatus</code> <pre>---\rhdmicec:\r  command: \"ReportAudioStatus\"\r  initiator: \"AudioSystem\"\r  destination: \"TV\"</pre> Provides the audio system status Automatically triggered to inform the TV of the audio system status <code>ReportShortAudioDescriptor</code> <pre>---\rhdmicec:\r  command: \"ReportShortAudioDescriptor\"\r  initiator: \"AudioSystem\"\r  destination: \"TV\"</pre> Provides the audio capabilities of the audio system Automatically triggered to inform the TV of the audio capabilities <code>RequestAudioDescriptor</code> <pre>---\rhdmicec:\r  command: \"RequestAudioDescriptor\"\r  initiator: \"TV\"\r  destination: \"AudioSystem\"</pre> Requests the audio capabilities from the audio system Using a TV remote control to request audio capabilities from the audio system"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi_cec_VirtualComponent_ControlPlaneCommands/#example-yaml-payloads_8","title":"Example YAML Payloads","text":"<p>Give Audio Status:</p> <pre>\n---\nhdmicec:\n  command: \"GiveAudioStatus\"\n  initiator: \"TV\"\n  destination: \"AudioSystem\"\n</pre> <p>Give System Audio Mode Status:</p> <pre>\n---\nhdmicec:\n  command: \"GiveSystemAudioModeStatus\"\n  initiator: \"TV\"\n  destination: \"AudioSystem\"\n</pre> <p>Report Audio Status:</p> <pre>\n---\nhdmicec:\n  command: \"ReportAudioStatus\"\n  initiator: \"AudioSystem\"\n  destination: \"TV\"\n</pre> <p>Report Short Audio Descriptor:</p> <pre>\n---\nhdmicec:\n  command: \"ReportShortAudioDescriptor\"\n  initiator: \"AudioSystem\"\n  destination: \"TV\"\n</pre> <p>Request Audio Descriptor:</p> <pre>\n---\nhdmicec:\n  command: \"RequestAudioDescriptor\"\n  initiator: \"TV\"\n  destination: \"AudioSystem\"\n</pre>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi_cec_VirtualComponent_ControlPlaneCommands/#10-system-information","title":"10. System Information","text":"Command YAML Payload Action How to Trigger in Real Setup <code>GetCECVersion</code> <pre>---\rhdmicec:\r  command: \"GetCECVersion\"\r  initiator: \"TV\"\r  destination: \"Broadcast\"</pre> Requests the CEC version from all devices Automatically triggered to get the CEC version <code>GetMenuLanguage</code> <pre>---\rhdmicec:\r  command: \"GetMenuLanguage\"\r  initiator: \"TV\"\r  destination: \"AudioSystem\"</pre> Requests the menu language from the audio system Using TV remote control to request menu language from audio system <code>SetMenuLanguage</code> <pre>---\rhdmicec:\r  command: \"SetMenuLanguage\"\r  initiator: \"TV\"\r  destination: \"AudioSystem\"\r  parameters:\r    menu_language: \"ENG\"</pre> Sets the menu language on the audio system Automatically triggered to set the menu language on the audio system <code>ReportPhysicalAddress</code> <pre>---\rhdmicec:\r  command: \"ReportPhysicalAddress\"\r  initiator: \"AudioSystem\"\r  destination: \"TV\"\r  parameters:\r    physical_address: [16, 0]</pre> Reports the physical address of the audio system to the TV Automatically triggered to report physical address to the TV"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi_cec_VirtualComponent_ControlPlaneCommands/#example-yaml-payloads_9","title":"Example YAML Payloads","text":"<p>Get CEC Version (Request from TV):</p> <pre>\n---\nhdmicec:\n  command: \"GetCECVersion\"\n  initiator: \"TV\"\n  destination: \"Broadcast\"\n</pre> <p>Get Menu Language (Request from TV):</p> <pre>\n---\nhdmicec:\n  command: \"GetMenuLanguage\"\n  initiator: \"TV\"\n  destination: \"AudioSystem\"\n</pre> <p>Set Menu Language (\"ENG\") on AudioSystem:</p> <pre>\n---\nhdmicec:\n  command: \"SetMenuLanguage\"\n  initiator: \"TV\"\n  destination: \"AudioSystem\"\n  parameters:\n    menu_language: \"ENG\"\n</pre> <p>Report Physical Address (AudioSystem to TV):</p> <pre>\n---\nhdmicec:\n  command: \"ReportPhysicalAddress\"\n  initiator: \"AudioSystem\"\n  destination: \"TV\"\n  parameters:\n    physical_address: [16, 0]\n</pre>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi_cec_virtual_component_design/","title":"Virtual Component for HDMI CEC HAL","text":"<ul> <li>The HDMI CEC HAL interface test shall be enhanced to support a virtual component that can be used inside a Virtual device to emulate a real device that supports HDMI CEC.</li> <li>Currently, rdk-halif-test-hdmi_cec supports a skeleton (stubbed out) implementation of the interface defined in rdk-halif-hdmi_cec. This shall be enhanced to support a virtual component that mimics operations of a real device.</li> <li>The Virtual Component (vComponent) implementation shall replace the Skeleton implementation as the default.</li> <li>A Common Virtual Component interface with Intitialize and Deinitialize methods shall be defined.</li> <li>Virtual Component shall be built as a separate binary (shared lib).</li> <li>A Virtual device (vDevice) shall include one or more vComponents to cater a test setup.</li> </ul> <p>When the vComponent process is started, vComponent_HdmiCec_Initialize shall be called with YAML configuration file passed into it using the '-p' parameter.</p> <pre><code>`./run -p tv_panel_5_devices.yaml`\n</code></pre>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi_cec_virtual_component_design/#yaml-template-for-profile","title":"YAML Template for Profile","text":"<p>Below is the YAML template for the vComponent profile defintion. This YAML template intends to provide a blueprint of a profile config through anchor references. An actual profile would be a derivation of this template. The profile config provides a way to represent a CEC bus with a number of devices connected in a parent/children hierarchy starting from the root device. The <code>emulated_device</code> attribute defines the friendly name of the emulated vDevice. An emulated devcie can either be a Sink Device (TV) like or a Source Device like Settop boxes. The <code>device_map</code> list is a representation of the CEC bus and its networked devices. Each device can have a number of children and the <code>children</code> array lists the devices.</p> <pre><code>---\nhdmicec:\n  #Device logical types - Hints for emulator to auto allocate logical address\n  device_type: &amp;device_type \n    - TV\n    - PlaybackDevice\n    - AudioSystem\n    - RecordingDevice\n    - Tuner\n    - Reserved\n    - Unregistered\n\n  #Port ID - Integer [1 to 15]\n  port_id: &amp;port_id \n    !!int\n\n  #Enum specifying port type\n  #All references shown in the configuration templates are intended to provide possible values for the given type.\n  #In practice, the below field would be defined as,\n  # port_type: in\n  port_type: &amp;port_type\n    - in\n    - out\n\n  #Vendor Info - Name and IEEE RAC vendor code\n  vendor: &amp;vendor\n    - TOSHIBA\n    - SAMSUNG\n    - DENON\n    - MARANTZ\n    - LOEWE\n    - ONKYO\n    - MEDION\n    - TOSHIBA2\n    - APPLE\n    - HARMAN_KARDON2\n    - GOOGLE\n    - AKAI\n    - AOC\n    - PANASONIC\n    - PHILIPS\n    - DAEWOO\n    - YAMAHA\n    - GRUNDIG\n    - PIONEER\n    - LG\n    - SHARP\n    - SONY\n    - BROADCOM\n    - SHARP2\n    - VIZIO\n    - BENQ\n    - HARMAN_KARDON\n    - TEST_VENDOR\n    - UNKNOWN\n\n  #HDMI CEC Version supported by device\n  cec_version: &amp;cec_version \n    - 0  #Unknown\n    - 1  #1.2\n    - 2  #1.2A\n    - 3  #1.3\n    - 4  #1.3A\n    - 5  #1.4\n    - 6  #2.0\n\n  #Power Status of the device\n  power_status: &amp;power_status \n    - on\n    - off\n    - standby\n\n  # Emulated Device's Information\n  emulated_device: !!str # e.g, TVPanel \n  number_ports: !!int\n  ports: #Variable sized array of Ports belonging to Emulated device\n    - id: *port_id\n  #All references shown in the configuration templates are intended to provide possible values for the given type.\n  #In practice, the below field would be defined as,\n  # port_type: in\n      type: *port_type  # Type of Port from &amp;port_type\n      cec_supported: !!bool\n      arc_supported: !!bool\n    - id: *port_id\n      type: *port_type\n      cec_supported: !!bool\n      arc_supported: !!bool\n\n  number_devices: !!int # Total number of devices in the network\n  device_map: # Map of devices starting from the Root Device (A TV) and multiple levels of children\n    - name: !!str  #Unique name identifying the device.\n      type: *device_type  #Type of device from device_type list. The top parent must be a root device (TV)\n      version: *cec_version\n      active_source: !!bool\n      vendor_info: *vendor\n      pwr_status: *power_status\n      port_id: !!int  #Port id of the parent to which this device is connected. For root device, this will be 0.\n      number_children: !!int  #Number of children connected to this device\n      children:   #Array of devices that are connected to this parent\n      - name: !!str\n        type: *device_type\n        version: *cec_version\n        active_source: !!bool\n        vendor_info: *vendor\n        pwr_status: *power_status\n        port_id: !!int  #Port id of the parent to which this device is connected\n        number_children: !!int # 0, If no devices are connected. This parameter must be present for all devices\n\n      - name: !!str\n        type: *device_type\n        version: *cec_version\n        active_source: !!bool\n        vendor_info: *vendor\n        pwr_status: *power_status\n        port_id: !!int  #Port id of the parent to which this device is connected\n        number_children: !!int # 0, If no devices are connected.\n        children:\n          - name: !!str\n            type: *device_type\n            version: *cec_version\n            active_source: !!bool\n            vendor_info: *vendor\n            pwr_status: *power_status\n            port_id: !!int  #Port id of the parent to which this device is connected\n            number_children: !!int # 0, If no devices are connected.\n</code></pre>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi_cec_virtual_component_design/#an-example-sink-profile","title":"An example Sink profile","text":"<p>Below is an example profile for a virtual TV Device emulating a TV Panel with a few devices connected to it on the CEC bus. A Sample profile config in YAML with a network of devices representing a TV as the root device (Sink), connected with an Audio System connected on the HDMI port 1 and a Sony PS3 connected on its HDMI port 2. The Audio system has a IPSTB box connected on its HDMI port 2 and a chromecast connected on its port 1.</p> <pre><code>---\nhdmicec:\n    emulated_device: TVPanel\n    number_ports: 3\n    ports:\n      - id: 1\n        type: in\n        cec_supported: true\n        arc_supported: true\n      - id: 2\n        type: in\n        cec_supported: true\n        arc_supported: true\n      - id: 3\n        type: in\n        cec_supported: true\n        arc_supported: false\n\n    number_devices: 5\n    device_map:\n      - name: TVPanel\n        type: TV\n        version: 4\n        active_source: false\n        vendor: TEST_VENDOR\n        pwr_status: on\n        port_id: 0\n        number_children: 2\n        children:\n        - name: Sony HomeTheatre\n          type: AudioSystem\n          version: 4\n          active_source: false\n          vendor: SONY\n          pwr_status: on\n          port_id: 1\n          number_children: 2\n          children: \n            - name: Chromecast\n              type: PlaybackDevice\n              version: 4\n              active_source: false\n              vendor: GOOGLE\n              pwr_status: on\n              port_id: 1\n              number_children: 0\n            - name: IPSTB\n              type: PlaybackDevice\n              version: 4\n              active_source: false\n              vendor: TEST_VENDOR\n              pwr_status: on\n              port_id: 2\n              number_children: 0\n        - name: SONY PS3\n          type: PlaybackDevice\n          version: 4\n          active_source: false\n          vendor: SONY\n          pwr_status: on\n          port_id: 2\n          number_children: 0\n</code></pre> <p>The vComponent on loading the profile, creates an internal map for the device network and auto allocate HDMI CEC physical and logical addresses. This makes it easier to manage user triggers using the Friendly Name of the device.</p> <p>For the above example sink profile, the expected physical and logical address allocation would be as below.</p> Device Type Physical Address Logical Address TVPanel TV 0.0.0.0 0 SONY HomeTheatre AudioSystem 1.0.0.0 5 SONY PS3 PlaybackDevice 2.0.0.0 4 IPSTB PlaybackDevice 1.2.0.0 8 Chromecast PlaybackDevice 1.1.0.0 11"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi_cec_virtual_component_design/#vcomponent-interface","title":"vComponent Interface","text":"<p>The vComponent will have a common interface that needs to be implemented along with the HAL driver interface functions in hdmi_cec_driver.h.</p> <p><code>vcHdmiCec.h</code></p> <pre><code>vcHdmiCec_t* vcHdmiCec_Initialize( void );\n\nvcHdmiCec_Status_t vcHdmiCec_Open( vcHdmiCec_t* pVCHdmiCec, char* pProfilePath, bool enableCPMsgs );\n\nvcHdmiCec_Status_t vcHdmiCec_Close( vcHdmiCec_t* pVCHdmiCec );\n\nvcHdmiCec_Status_t vcHdmiCec_Deinitialize( vcHdmiCec_t *pvComponent );\n</code></pre> <p>vcHdmiCec_Open will use the YAML decoding functionality via the Key-Value Pair (KVP) module available currently as part of the ut_core to read the profile parameters and create the initial state machine with number of HDMI Ports and the network of devices attached on the CEC bus. In addition, vComponent will also intialise the control plane with the websocket port.</p> <p>The control plane inititialise function may look like this. This will setup the websocket server.</p> <pre><code>ut_controlPlane_instance_t instance = UT_ControlPlane_Init(port);\n</code></pre> <p>The vComponent will also register with the control plane to receive callbacks when there is a command trigger from the Test user. These are YAML messages over Websocket. The register mechanism shall look like below,</p> <pre><code>UT_ControlPlane_RegisterCallbackOnMessage(instance, \"hdmicec.command\", &amp;myCallback);\n</code></pre> <p>The state machine of the Hdmi CEC hal is setup by populating its data structures by retreiving from the profile config. Below is an example of information about HDMI ports populated. The info on devices connected to the CEC bus is populated in a similar way to set up the initial state machine.</p> <pre><code>#define MAX_OSD_NAME_LENGTH 16\n\ntypedef enum {\n    INPUT,\n    OUTPUT\n} port_type_t;\n\ntyedef enum {\n  ON,\n  STANDBY,\n  OFF\n}power_status_t;\n\ntypedef struct port_info {\n  uint8_t id;\n  uint16_t physical_address;\n  port_type_t type;\n  bool cec_supported;\n  bool arc_supported;\n} port_info_t;\n\ntypedef struct device {\n   uint32_t version;\n   uint16_t physical_address;\n   uint8_t logical_address;\n   bool active_source;\n   uint32_t vendor_id;\n   power_status_t power_status;\n   char osd_name[MAX_OSD_NAME_LENGTH];\n}\n\n\n\n---\nut_kvp_instance_t kvp_instance = ut_kvp_createInstance();\nut_kvp_status_t status = ut_kvp_read(&amp;kvp_instance, profile);\nuint32_t num_ports = ut_kvp_getUInt32Field(&amp;kvp_instance, \"hdmicec.num_ports\");\n\nport_info_t *ports = (port_info_t*)malloc(size(port_info_t) * num_ports);\n\nchar prefix_name[] = \"hdmicec.ports.\";\nfor(int i = 0; i &lt; ports; i++)\n{\n.......\n}\n---\n</code></pre>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi_cec_virtual_component_design/#control-plane-message-flow","title":"Control Plane Message flow","text":"<p>The emulator also sets up the data structures to manage HdmiCec Tx and Rx callbacks when the respective interface function is called. This includes the threading mechanisms required to trigger callbacks to caller of HdmiCec driver. Below diagram depicts a typical call sequence with emulator handling commands from Test user and triggering HdmiCec Rx callback.</p> <pre><code>sequenceDiagram\n    vcomponent_main-&gt;&gt;+vcomponent_lib: vComponent_HdmiCec_Initialize(profile)\n    vcomponent_lib-&gt;&gt;+control_plane: UT_ControlPlane_Init(port)\n    control_plane--&gt;&gt;-vcomponent_lib: return\n    vcomponent_lib--&gt;&gt;-vcomponent_main: return\n    Note over control_plane: Setup Websocket server\n    vcomponent_lib-&gt;&gt;+control_plane: UT_ControlPlane_RegisterCallbackOnMessage\n    control_plane--&gt;&gt;-vcomponent_lib: return\n    Note over vcomponent_lib: Get KVP parameters, Setup device network\n    hal_user-&gt;&gt;+vcomponent_lib: HdmiCecOpen\n    vcomponent_lib--&gt;&gt;-hal_user: return\n    hal_user-&gt;&gt;+vcomponent_lib: HdmiCecSetRxCallback\n    vcomponent_lib--&gt;&gt;-hal_user: return\n    hal_user-&gt;&gt;+vcomponent_lib: HdmiCecGetLogicalAddress\n    vcomponent_lib--&gt;&gt;-hal_user: return\n    hal_user-&gt;+vcomponent_lib: HdmiCecGetPhysicalAddress\n    vcomponent_lib--&gt;&gt;-hal_user: return\n    hal_user-&gt;&gt;+vcomponent_lib: HdmiCeTx\n    vcomponent_lib--&gt;&gt;-hal_user: return\n      Note over Test User: hdmicec: &lt;br&gt; command: hotplug &lt;br&gt; port:1 &lt;br&gt; connected: true\n    Test User-&gt;&gt;control_plane: YAML Message with Command\n    control_plane-&gt;&gt;+vcomponent_lib: Command Callback\n    vcomponent_lib-&gt;&gt;+hal_user: HdmiCecRxCallback triggered\n      hal_user--&gt;-vcomponent_lib: return\n      vcomponent_lib--&gt;-control_plane: return\n\n</code></pre> <p>Some sample commands from control plane</p> <p>Command to trigger a hotplug event from device connected in Port 2:</p> <pre><code>hdmicec:\n    command: hotplug\n    port: 2\n    connected: false\n</code></pre> <p>User presses power on button in PS3 to come out of standby and makes the PS3 the active source. Command to make virtual component, a TV, to switch to Power on:</p> <pre><code>---\nhdmicec:\n    command: ImageViewOn\n    initiator: SONY PS3\n    destination: TVPanel\n</code></pre> <p>The above command should trigger 2 call backs from the emulator to hal user. The emulator should be able to translate the commands received from test user into CEC message payload and trigger the call back.</p> <p>With the above setup, user trigger messages shall be as in the table below.</p> User Trigger Yaml Message RX Callback Data Action ImageViewOn <pre>---  \rhdmicec:  \r  command: ImageViewOn  \r  initiator: SONY PS3  \r  destination: TVPanel</pre> 40:04 TV Powers On and enters display state SetOSDName <pre>---  \rhdmicec:  \r  command: SetOSDName  \r  initiator: IPSTB  \r  destination: TVPanel \r  osd_name: osd_name: IPSTB</pre> 80:04:49:50:53:54:42 TV Powers On and enters display state ActiveSource <pre>---  \rhdmicec:  \r  command: ActiveSource  \r  initiator: IPSTB  \r  destination: TVPanel</pre> 80:47:12:00 Switches to relevant HDMI port Standby <pre>---  \rhdmicec:  \r  command: Standby  \r  initiator: TVPanel  \r  destination: Broadcast</pre> 0F:36 Broadcasts all devices to go to standby Hotplug <pre>---  \rhdmicec:  \r  command: hotplug  \r  port: 1  \r  connected: false</pre> None Reset logical address and change power state Give Physical address <pre>---  \rhdmicec:  \r  command: GivePhysicalAddress  \r  initiator: Sony HomeTheatre  \r  destination: IPSTB</pre> 54:83 HdmiCecTx should be triggered with ReportPhysicalAddress"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi_cec_virtual_component_design/#one-touch-play-feature","title":"One Touch Play Feature","text":"<p>The One touch play feature allows a source device to become the active source with a single button press. Typically, in a real home setup, when the user presses play on a playback device that is connected to the TV, CEC messages are sent to the TV and the CEC bus to inform that the playback device has started streaming content. The TV on receiving the ImageViewOn message, will come out of the standby if needed and enters the display state. Subsequently, the playback device also broadcasts an ActiveSource message which allows the TV to switch to the relevant HDMI port that the playback device is connected on. The below sequence diagram shows how this senario can be emulated using the control plane to trigger the CEC messages. Here the Test user sends the YAML messages over websocket or http to the control plane.</p> <pre><code>sequenceDiagram\nNote over Test User: hdmicec: &lt;br&gt; command: ImageViewOn &lt;br&gt; initiator: SONY PS3 &lt;br&gt; destination: TVPanel\nTest User-&gt;&gt;+control_plane: command\ncontrol_plane-&gt;&gt;+vcomponent_lib: command callback\nvcomponent_lib-&gt;&gt;+hal_user: HdmiCecRxCallback (IMAGE_VIEW_ON msg)\nhal_user--&gt;&gt;-vcomponent_lib: return\nNote over Test User: hdmicec: &lt;br&gt; command: ActiveSource &lt;br&gt; initiator: SONY PS3 &lt;br&gt; destination: Broadcast\nTest User-&gt;&gt;+control_plane: command\ncontrol_plane-&gt;&gt;+vcomponent_lib: command callback\nvcomponent_lib-&gt;&gt;+hal_user: HdmiCecRxCallback (ACTIVE_SOURCE msg)\nhal_user--&gt;&gt;-vcomponent_lib: return\n\n</code></pre>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi_cec_virtual_component_design/#standby-feature","title":"Standby Feature","text":"<p>Command to trigger a Broadcast message from Playback Device 1 to put all devices to standby (toggle)</p> <pre><code>---\nhdmicec:\n    command: Standby\n    initiator: IPSTB\n    destination: Broadcast\n</code></pre>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi_cec_virtual_component_design/#device-menu-control","title":"Device Menu Control","text":"<p>Command to trigger a Device Menu Control command from Playback Device 2 to mute.</p> <pre><code>---\nhdmicec:\n    command: UserControl\n    initiator: SONY PS3\n    destination: TVPanel\n    ui_command: Mute\n</code></pre>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi_cec_virtual_component_design/#validating-l3-tests-using-validation-profile","title":"Validating L3 Tests using validation profile","text":"<p>Level 3 tests validate end-to-end functionality for a specific feature. In case of HDMI CEC L3 tests, when user triggers a command message the test can vaildate the callback data that is received through the HdmiCec Receive callback. For this, the validation profile and the actual profile shall be linked in a way they can be used to validate a particular test. For e.g, when the user triggers ActiveSource command through control plane, the yaml payload consists of Device Names as the primary handles, but the Receive callbacks that are generated as response for the commands contain raw cec data buffer that follow the HDMI CEC Specifications. This means, the L3 test will only have logical and physical addresses. The validation profile yaml can contain specific payload information to calidate against for a particualar test which corresponds to a selected main profile. In other words, tv_panel_5_devices.yaml profile will have a corresponding tv_panel_5_devices_vp.yaml.</p> <p>An example validation yaml for a particular profile.</p> <pre><code>---\nhdmicec:\n  ActiveSource:\n    input:\n      initiator: SONY PS3\n      destination: TVPanel\n    result:\n      initiator: 4\n      destination: 0\n      opcode: 0x82   # Opcode as defined in HDMI CEC Specification\n      parameters:\n        size: 2\n        data: [20, 0] # Physical address 2.0.0.0\n  SetOSDName:\n     input:\n      initiator: IPSTB\n      destination: TVPanel\n      osd_name: IPSTB\n     result:\n      initiator: 4\n      destination: 0\n      opcode: 0x49 # Opcode as defined in HDMI CEC Specification\n      parameters:\n        size:\n        data: [0x49,0x50,0x53,0x54,0x42] # \"IPSTB\" in hex ascii\n</code></pre>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi_cec_virtual_component_design/#reconfiguring-the-vcomponent","title":"Reconfiguring the vComponent","text":"<p>Test user can also trigger a re-configuration of the initial profile with which the emulator state machine was set up, like the device type (Sink or Source) and the list of devices in the network etc.</p> <p>Command to trigger a re-configuration of the initial state. The following config represents that the emulated device is Playback Device 1 and is connected to a TV on its Port. The TV also has a Chromecast connected to it on port 2.</p> <pre><code>---\nhdmicec:\n  config:\n    emulated_device: IPSTB\n    number_ports: 1\n    ports:\n      - id: 1\n        type: out\n        cec_supported: true\n        arc_supported: false\n    number_devices: 3\n    device_map:\n      - name: Sony TV\n        type: TV\n        version: 4\n        active_source: false\n        vendor_info: SONY\n        pwr_status: on\n        number_chlidren: 2\n        children:\n         -  name: IPSTB\n            type: PlaybackDevice\n            version: 4 \n            active_source: true\n            vendor: TEST_VENDOR\n            pwr_status: on\n            port_id: 1\n            num_children: 0\n\n         -  name: Chromecast\n            type: PlaybackDevice\n            version: 4\n            active_source: false\n            vendor: GOOGLE\n            pwr_status: on\n            port_id: 1\n            num_children: 0\n</code></pre> <p>The above configuration yaml instructs the emulator about the following devices connected.</p> <pre><code>mindmap\n  root[Sony TV - 0.0.0.0]\n    id[IPSTB - 1.0.0.0]\n    id[Chromecast - 2.0.0.0]\n</code></pre> <p>This will trigger a complete reconfiguration of the emulator state machine by deleting and reconstructing its internal data base.</p>"},{"location":"external_content/hdmi_cec_test/docs/pages/hdmi_cec_virtual_component_design/#tasks-breakdown-for-mvp","title":"Tasks Breakdown for MVP","text":"<pre><code>mindmap\n  root((HDMI CEC Emulator))\n    Library\n      Init/Deinit\n      Load values from Profile config\n        KVP\n      Makery - Build/Install\n      ::icon(fa fa-wrench)\n      Setup State machine\n        Local data structures\n            Build device network topology\n        Threading for callbacks\n    Process\n      Main driver to start Emulator\n      Makery - Build/Install\n      ::icon(fa fa-wrench)\n      Sample Profile config YAMLs\n      Test Menus - Emulator init and basic CEC\n    User Triggers\n    ::icon(fa fa-user)\n      Initialize control plane with endpoint\n      id)User Commands(\n        Active Source Request\n        Add/Remove devices\n        Catalogue of Commands\n        Dynamic base config change\n</code></pre>"},{"location":"external_content/power_manager/","title":"Power Manager HAL Documentation","text":""},{"location":"external_content/power_manager/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>HAL</code>:    Hardware Abstraction Layer</li> <li><code>CPE</code>:    Customer Premises Equipment</li> <li><code>CPU</code>:    Central Processing Unit</li> <li><code>IR</code>:     Infra-red</li> <li><code>HDMI</code>:   High-Definition Multimedia Interface</li> <li><code>A/V</code>:    Audio/Video</li> <li><code>HDD</code>:    Hard Drive Disk</li> </ul>"},{"location":"external_content/power_manager/#references","title":"References","text":""},{"location":"external_content/power_manager/#description","title":"Description","text":"<p>The diagram below describes a high-level software architecture of the module stack.</p> <pre><code>%%{ init : { \"theme\" : \"forest\", \"flowchart\" : { \"curve\" : \"linear\" }}}%%\nflowchart TD\ny[Caller]&lt;--&gt;x[Power Manager HAL];\nx[Power Manager HAL]&lt;--&gt;z[SOC Drivers];\nstyle y fill:#99CCFF,stroke:#333,stroke-width:0.3px,align:left\nstyle z fill:#fcc,stroke:#333,stroke-width:0.3px,align:left\nstyle x fill:#9f9,stroke:#333,stroke-width:0.3px,align:left</code></pre> <p>This interface provides a set of <code>APIs</code> to facilitate communication through the <code>caller</code> and <code>HAL</code>.</p> <p>The Power manger <code>HAL</code> provides a set of <code>APIs</code> to initialize, query and set the power state, and query and set the wake up source.</p>"},{"location":"external_content/power_manager/#component-runtime-execution-requirements","title":"Component Runtime Execution Requirements","text":""},{"location":"external_content/power_manager/#initialization-and-startup","title":"Initialization and Startup","text":"<p><code>Caller</code> must initialize by calling <code>PLAT_INIT()</code> before calling any other <code>API</code>.</p>"},{"location":"external_content/power_manager/#threading-model","title":"Threading Model","text":"<p>This interface is not required to be thread safe. Any <code>caller</code> invoking the <code>APIs</code> must ensure calls are made in a thread safe manner.</p>"},{"location":"external_content/power_manager/#process-model","title":"Process Model","text":"<p>This interface is required to support a single instantiation with a single process.</p>"},{"location":"external_content/power_manager/#memory-model","title":"Memory Model","text":"<p>The <code>caller</code> is responsible to pass message buffer and free it for transmit request.</p>"},{"location":"external_content/power_manager/#power-management-requirements","title":"Power Management Requirements","text":"<p>The Power Manager <code>HAL</code> is involved to set the power management states ON, OFF, STANDBY, and LIGHT_SLEEP. </p>"},{"location":"external_content/power_manager/#asynchronous-notification-model","title":"Asynchronous Notification Model","text":"<p>This interface is not required to support asynchronous notification.</p>"},{"location":"external_content/power_manager/#blocking-calls","title":"Blocking calls","text":"<p>There are no blocking calls. Synchronous calls must complete within a reasonable time period. Any call that can fail due to the lack of response from the connected device must have a timeout period and the function must return the relevant error code.</p>"},{"location":"external_content/power_manager/#internal-error-handling","title":"Internal Error Handling","text":"<p>All the <code>APIs</code> must return error synchronously as a return argument. <code>HAL</code> is responsible for handling system errors (e.g. out of memory) internally.</p>"},{"location":"external_content/power_manager/#persistence-model","title":"Persistence Model","text":"<p>There is no requirement for the interface to persist any setting information. <code>Caller</code> is responsible to persist any settings related to the <code>HAL</code>.</p>"},{"location":"external_content/power_manager/#non-functional-requirements","title":"Non functional requirements","text":""},{"location":"external_content/power_manager/#logging-and-debugging-requirements","title":"Logging and debugging requirements","text":"<p>This interface is required to support DEBUG, INFO and ERROR messages. INFO and DEBUG must be disabled by default and enabled when required.</p>"},{"location":"external_content/power_manager/#memory-and-performance-requirements","title":"Memory and performance requirements","text":"<p>This interface is required to not cause excessive memory and CPU utilization.</p>"},{"location":"external_content/power_manager/#quality-control","title":"Quality Control","text":"<ul> <li>This interface is required to perform static analysis, our preferred tool is Coverity.</li> <li>Have a zero-warning policy with regards to compiling. All warnings are required to be treated as errors.</li> <li>Copyright validation is required to be performed, e.g.: Black duck, FossID.</li> <li>Use of memory analysis tools like Valgrind are encouraged to identify leaks/corruptions.</li> <li><code>HAL</code> Tests will endeavour to create worst case scenarios to assist investigations.</li> <li>Improvements by any party to the testing suite are required to be fed back.</li> </ul>"},{"location":"external_content/power_manager/#licensing","title":"Licensing","text":"<p>The <code>HAL</code> implementation is expected to released under the Apache License 2.0.</p>"},{"location":"external_content/power_manager/#build-requirements","title":"Build Requirements","text":"<p>The source code must build into a shared library and must be named as <code>libiarmmgrs-power-hal.so</code>. The build mechanism must be independent of Yocto.</p>"},{"location":"external_content/power_manager/#variability-management","title":"Variability Management","text":"<p>Any changes in the <code>APIs</code> must be reviewed and approved by the component architects.</p>"},{"location":"external_content/power_manager/#platform-or-product-customization","title":"Platform or Product Customization","text":"<p>This interface is not required to have any platform or product customizations.</p>"},{"location":"external_content/power_manager/#interface-api-documentation","title":"Interface API Documentation","text":"<p><code>API</code> documentation will be provided by Doxygen which will be generated from the header file.</p>"},{"location":"external_content/power_manager/#theory-of-operation-and-key-concepts","title":"Theory of operation and key concepts","text":"<p>The <code>caller</code> is expected to have complete control over the life cycle of the <code>HAL</code>.</p> <ul> <li> <p>Initialize the <code>HAL</code> using function: <code>PLAT_INIT()</code> before making any other <code>API</code> calls.  If <code>PLAT_INIT()</code> call fails, the <code>HAL</code> must return the respective error code, so that the <code>caller</code> can retry the operation.</p> </li> <li> <p>Power status settings can be controlled using the functions <code>PLAT_API_SetPowerState()</code> and <code>PLAT_API_SetWakeupSrc()</code> and existing status can be queried using the functions <code>PLAT_API_GetPowerState()</code> and <code>PLAT_API_GetWakeupSrc()</code>.</p> </li> <li> <p>De-initialize the <code>HAL</code> using the function: <code>PLAT_TERM()</code>.</p> </li> </ul>"},{"location":"external_content/power_manager/#sequence-diagram","title":"Sequence Diagram","text":"<pre><code>%%{ init : { \"theme\" : \"default\", \"flowchart\" : { \"curve\" : \"stepBefore\" }}}%%\n   sequenceDiagram\n    participant Caller as Caller\n    participant HAL as Power Manager HAL\n    participant Device as HAL Device Control/Driver\n    Caller-&gt;&gt;HAL:PLAT_INIT()\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:PLAT_API_SetPowerState()\n    Note over HAL: Sets the current power state.\n    HAL-&gt;&gt;Device:Setting power mode.\n    Device--&gt;&gt;HAL:Return\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:PLAT_API_GetPowerState()\n    Note over HAL: Gets the current power state.\n    HAL-&gt;&gt;Device:Getting current Power Mode\n    Device--&gt;&gt;HAL:Return\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:PLAT_API_SetWakeupSrc()\n    Note over HAL: Sets the wake-up source.\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:PLAT_API_GetWakeupSrc()\n    Note over HAL: Gets the current wake-up source.\n    HAL--&gt;&gt;Caller:return\n    Caller -&gt;&gt;HAL:PLAT_TERM()\n    HAL--&gt;&gt;Caller:return</code></pre>"},{"location":"external_content/power_manager/#state-diagram","title":"State Diagram","text":"<pre><code>flowchart TD\n    PO[Powered On]\n    POF[Powered Off]\n    SB[Standby]\n    LS[Light Sleep]\n    DS[DeepSleep]\n    PO --&gt;|Application Initiated, State: Standby, User Inaction, Power Off| SB\n    PO --&gt;|Crash/Pysical Power OFF| POF\n    SB --&gt;|Application Initiated, State: Deep Sleep, User Inaction/Time Out| DS\n    SB --&gt;|Application Initiated, State: ON, Key Pressed/CEC/MD/FFV| PO\n    SB --&gt;|Reboot / Reboot/Physical Power Off| POF\n    LS --&gt;|Application Initiated, State: Deep Sleep, User Inaction/Time Out| DS\n    LS --&gt;|Application Initiated, State: ON, Key Pressed/CEC/MD/FFV| PO\n    LS --&gt;|Reboot / Physical Power Off| POF\n    DS --&gt;|DS Timeout/MD/FFV, Key Pressed/CEC, WoL/WoWL| LS\n    DS --&gt;|DS Timeout/MD/FFV, Key Pressed/CEC, WoL/WoWL, When Light Sleep is not available| SB\n    DS --&gt;|Physical Power Off| POF\n    POF --&gt;|Cold boot / Plugin / Reset / Reboot| SB</code></pre>"},{"location":"external_content/power_manager/CHANGELOG/","title":"Changelog","text":""},{"location":"external_content/power_manager/CHANGELOG/#changelog","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file. Dates are displayed in UTC.</p> <p>Generated by <code>auto-changelog</code>.</p>"},{"location":"external_content/power_manager/CHANGELOG/#103","title":"1.0.3","text":"<ul> <li>gh #3 Update based on review comments <code>#9</code></li> <li>post condation is added for plat_init in the interface file <code>aa60776</code></li> <li>Merge tag '1.0.2' into develop <code>f726b45</code></li> </ul>"},{"location":"external_content/power_manager/CHANGELOG/#102","title":"1.0.2","text":"<p>13 November 2023</p> <ul> <li>Bumped CHANGELOG.md - 1.0.2 <code>a1c1f09</code></li> <li>Updated License file name in header <code>578e520</code></li> <li>Merge tag '1.0.1' into develop <code>c3b2470</code></li> </ul>"},{"location":"external_content/power_manager/CHANGELOG/#101","title":"1.0.1","text":"<p>9 November 2023</p> <ul> <li>updated build_ut.sh generate_doc gitignore <code>#1</code></li> <li>Base files added <code>f2b93e7</code></li> <li>Added CHANGELOG.md - 1.0.1 <code>dbd5eb9</code></li> <li>Initial commit <code>ea4de5b</code></li> </ul>"},{"location":"external_content/power_manager/CONTRIBUTING/","title":"Contributing","text":"<ul> <li>If you wish to make code contributions to this project, the source is hosted at github.com/rdkcentral.</li> </ul> <p>You can submit your changes for review via that site, by raising an issue in github, (https://github.com/rdkcentral/xxxx/issues), and following the sequence below.</p> <ul> <li>create a branch with a name follow the guidelines gh(x)_(synopsis)</li> <li>where x is the ticket number</li> <li>where synopsis is a short synopsis for the reason for the branch.</li> <li>create a pull request (https://github.com/rdkcentral/xxxx/compare) when the code changes are ready for review.</li> <li> <p>The team will review, and if accepted your changes will be merged to the mainline.</p> </li> <li> <p>In order to contribute code, first-time users are requested to agree to the license.</p> </li> <li> <p>where <code>xxxx</code> is your module name</p> </li> </ul>"},{"location":"external_content/power_manager/docs/pages/CONTRIBUTING/","title":"Contributing","text":"<ul> <li>If you wish to make code contributions to this project, the source is hosted at github.com/rdkcentral.</li> </ul> <p>You can submit your changes for review via that site, by raising an issue in github, (https://github.com/rdkcentral/xxxx/issues), and following the sequence below.</p> <ul> <li>create a branch with a name follow the guidelines gh(x)_(synopsis)</li> <li>where x is the ticket number</li> <li>where synopsis is a short synopsis for the reason for the branch.</li> <li>create a pull request (https://github.com/rdkcentral/xxxx/compare) when the code changes are ready for review.</li> <li> <p>The team will review, and if accepted your changes will be merged to the mainline.</p> </li> <li> <p>In order to contribute code, first-time users are requested to agree to the license.</p> </li> <li> <p>where <code>xxxx</code> is your module name</p> </li> </ul>"},{"location":"external_content/power_manager/docs/pages/power-manager_halSpec/","title":"Power Manager HAL Documentation","text":""},{"location":"external_content/power_manager/docs/pages/power-manager_halSpec/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>HAL</code>:    Hardware Abstraction Layer</li> <li><code>CPE</code>:    Customer Premises Equipment</li> <li><code>CPU</code>:    Central Processing Unit</li> <li><code>IR</code>:     Infra-red</li> <li><code>HDMI</code>:   High-Definition Multimedia Interface</li> <li><code>A/V</code>:    Audio/Video</li> <li><code>HDD</code>:    Hard Drive Disk</li> </ul>"},{"location":"external_content/power_manager/docs/pages/power-manager_halSpec/#references","title":"References","text":""},{"location":"external_content/power_manager/docs/pages/power-manager_halSpec/#description","title":"Description","text":"<p>The diagram below describes a high-level software architecture of the module stack.</p> <pre><code>%%{ init : { \"theme\" : \"forest\", \"flowchart\" : { \"curve\" : \"linear\" }}}%%\nflowchart TD\ny[Caller]&lt;--&gt;x[Power Manager HAL];\nx[Power Manager HAL]&lt;--&gt;z[SOC Drivers];\nstyle y fill:#99CCFF,stroke:#333,stroke-width:0.3px,align:left\nstyle z fill:#fcc,stroke:#333,stroke-width:0.3px,align:left\nstyle x fill:#9f9,stroke:#333,stroke-width:0.3px,align:left</code></pre> <p>This interface provides a set of <code>APIs</code> to facilitate communication through the <code>caller</code> and <code>HAL</code>.</p> <p>The Power manger <code>HAL</code> provides a set of <code>APIs</code> to initialize, query and set the power state, and query and set the wake up source.</p>"},{"location":"external_content/power_manager/docs/pages/power-manager_halSpec/#component-runtime-execution-requirements","title":"Component Runtime Execution Requirements","text":""},{"location":"external_content/power_manager/docs/pages/power-manager_halSpec/#initialization-and-startup","title":"Initialization and Startup","text":"<p><code>Caller</code> must initialize by calling <code>PLAT_INIT()</code> before calling any other <code>API</code>.</p>"},{"location":"external_content/power_manager/docs/pages/power-manager_halSpec/#threading-model","title":"Threading Model","text":"<p>This interface is not required to be thread safe. Any <code>caller</code> invoking the <code>APIs</code> must ensure calls are made in a thread safe manner.</p>"},{"location":"external_content/power_manager/docs/pages/power-manager_halSpec/#process-model","title":"Process Model","text":"<p>This interface is required to support a single instantiation with a single process.</p>"},{"location":"external_content/power_manager/docs/pages/power-manager_halSpec/#memory-model","title":"Memory Model","text":"<p>The <code>caller</code> is responsible to pass message buffer and free it for transmit request.</p>"},{"location":"external_content/power_manager/docs/pages/power-manager_halSpec/#power-management-requirements","title":"Power Management Requirements","text":"<p>The Power Manager <code>HAL</code> is involved to set the power management states ON, OFF, STANDBY, and LIGHT_SLEEP. </p>"},{"location":"external_content/power_manager/docs/pages/power-manager_halSpec/#asynchronous-notification-model","title":"Asynchronous Notification Model","text":"<p>This interface is not required to support asynchronous notification.</p>"},{"location":"external_content/power_manager/docs/pages/power-manager_halSpec/#blocking-calls","title":"Blocking calls","text":"<p>There are no blocking calls. Synchronous calls must complete within a reasonable time period. Any call that can fail due to the lack of response from the connected device must have a timeout period and the function must return the relevant error code.</p>"},{"location":"external_content/power_manager/docs/pages/power-manager_halSpec/#internal-error-handling","title":"Internal Error Handling","text":"<p>All the <code>APIs</code> must return error synchronously as a return argument. <code>HAL</code> is responsible for handling system errors (e.g. out of memory) internally.</p>"},{"location":"external_content/power_manager/docs/pages/power-manager_halSpec/#persistence-model","title":"Persistence Model","text":"<p>There is no requirement for the interface to persist any setting information. <code>Caller</code> is responsible to persist any settings related to the <code>HAL</code>.</p>"},{"location":"external_content/power_manager/docs/pages/power-manager_halSpec/#non-functional-requirements","title":"Non functional requirements","text":""},{"location":"external_content/power_manager/docs/pages/power-manager_halSpec/#logging-and-debugging-requirements","title":"Logging and debugging requirements","text":"<p>This interface is required to support DEBUG, INFO and ERROR messages. INFO and DEBUG must be disabled by default and enabled when required.</p>"},{"location":"external_content/power_manager/docs/pages/power-manager_halSpec/#memory-and-performance-requirements","title":"Memory and performance requirements","text":"<p>This interface is required to not cause excessive memory and CPU utilization.</p>"},{"location":"external_content/power_manager/docs/pages/power-manager_halSpec/#quality-control","title":"Quality Control","text":"<ul> <li>This interface is required to perform static analysis, our preferred tool is Coverity.</li> <li>Have a zero-warning policy with regards to compiling. All warnings are required to be treated as errors.</li> <li>Copyright validation is required to be performed, e.g.: Black duck, FossID.</li> <li>Use of memory analysis tools like Valgrind are encouraged to identify leaks/corruptions.</li> <li><code>HAL</code> Tests will endeavour to create worst case scenarios to assist investigations.</li> <li>Improvements by any party to the testing suite are required to be fed back.</li> </ul>"},{"location":"external_content/power_manager/docs/pages/power-manager_halSpec/#licensing","title":"Licensing","text":"<p>The <code>HAL</code> implementation is expected to released under the Apache License 2.0.</p>"},{"location":"external_content/power_manager/docs/pages/power-manager_halSpec/#build-requirements","title":"Build Requirements","text":"<p>The source code must build into a shared library and must be named as <code>libiarmmgrs-power-hal.so</code>. The build mechanism must be independent of Yocto.</p>"},{"location":"external_content/power_manager/docs/pages/power-manager_halSpec/#variability-management","title":"Variability Management","text":"<p>Any changes in the <code>APIs</code> must be reviewed and approved by the component architects.</p>"},{"location":"external_content/power_manager/docs/pages/power-manager_halSpec/#platform-or-product-customization","title":"Platform or Product Customization","text":"<p>This interface is not required to have any platform or product customizations.</p>"},{"location":"external_content/power_manager/docs/pages/power-manager_halSpec/#interface-api-documentation","title":"Interface API Documentation","text":"<p><code>API</code> documentation will be provided by Doxygen which will be generated from the header file.</p>"},{"location":"external_content/power_manager/docs/pages/power-manager_halSpec/#theory-of-operation-and-key-concepts","title":"Theory of operation and key concepts","text":"<p>The <code>caller</code> is expected to have complete control over the life cycle of the <code>HAL</code>.</p> <ul> <li> <p>Initialize the <code>HAL</code> using function: <code>PLAT_INIT()</code> before making any other <code>API</code> calls.  If <code>PLAT_INIT()</code> call fails, the <code>HAL</code> must return the respective error code, so that the <code>caller</code> can retry the operation.</p> </li> <li> <p>Power status settings can be controlled using the functions <code>PLAT_API_SetPowerState()</code> and <code>PLAT_API_SetWakeupSrc()</code> and existing status can be queried using the functions <code>PLAT_API_GetPowerState()</code> and <code>PLAT_API_GetWakeupSrc()</code>.</p> </li> <li> <p>De-initialize the <code>HAL</code> using the function: <code>PLAT_TERM()</code>.</p> </li> </ul>"},{"location":"external_content/power_manager/docs/pages/power-manager_halSpec/#sequence-diagram","title":"Sequence Diagram","text":"<pre><code>%%{ init : { \"theme\" : \"default\", \"flowchart\" : { \"curve\" : \"stepBefore\" }}}%%\n   sequenceDiagram\n    participant Caller as Caller\n    participant HAL as Power Manager HAL\n    participant Device as HAL Device Control/Driver\n    Caller-&gt;&gt;HAL:PLAT_INIT()\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:PLAT_API_SetPowerState()\n    Note over HAL: Sets the current power state.\n    HAL-&gt;&gt;Device:Setting power mode.\n    Device--&gt;&gt;HAL:Return\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:PLAT_API_GetPowerState()\n    Note over HAL: Gets the current power state.\n    HAL-&gt;&gt;Device:Getting current Power Mode\n    Device--&gt;&gt;HAL:Return\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:PLAT_API_SetWakeupSrc()\n    Note over HAL: Sets the wake-up source.\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL:PLAT_API_GetWakeupSrc()\n    Note over HAL: Gets the current wake-up source.\n    HAL--&gt;&gt;Caller:return\n    Caller -&gt;&gt;HAL:PLAT_TERM()\n    HAL--&gt;&gt;Caller:return</code></pre>"},{"location":"external_content/power_manager/docs/pages/power-manager_halSpec/#state-diagram","title":"State Diagram","text":"<pre><code>flowchart TD\n    PO[Powered On]\n    POF[Powered Off]\n    SB[Standby]\n    LS[Light Sleep]\n    DS[DeepSleep]\n    PO --&gt;|Application Initiated, State: Standby, User Inaction, Power Off| SB\n    PO --&gt;|Crash/Pysical Power OFF| POF\n    SB --&gt;|Application Initiated, State: Deep Sleep, User Inaction/Time Out| DS\n    SB --&gt;|Application Initiated, State: ON, Key Pressed/CEC/MD/FFV| PO\n    SB --&gt;|Reboot / Reboot/Physical Power Off| POF\n    LS --&gt;|Application Initiated, State: Deep Sleep, User Inaction/Time Out| DS\n    LS --&gt;|Application Initiated, State: ON, Key Pressed/CEC/MD/FFV| PO\n    LS --&gt;|Reboot / Physical Power Off| POF\n    DS --&gt;|DS Timeout/MD/FFV, Key Pressed/CEC, WoL/WoWL| LS\n    DS --&gt;|DS Timeout/MD/FFV, Key Pressed/CEC, WoL/WoWL, When Light Sleep is not available| SB\n    DS --&gt;|Physical Power Off| POF\n    POF --&gt;|Cold boot / Plugin / Reset / Reboot| SB</code></pre>"},{"location":"external_content/power_manager_test/","title":"Unit Testing Suite For Power Manager HAL","text":""},{"location":"external_content/power_manager_test/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Acronyms, Terms and Abbreviations</li> <li>Description</li> <li>Reference Documents</li> <li>Notes</li> </ul>"},{"location":"external_content/power_manager_test/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>HAL</code>- Hardware Abstraction Layer</li> <li><code>L1</code> - Functional Tests</li> <li><code>L2</code> - Module functional Testing</li> <li><code>High-Level Test Specification</code> : These specification will provide a broad overview of the system's functionality from the callers' perspective. It focuses on major use cases, system behavior, and overall caller experience.</li> <li><code>Low-Level Test Specification</code> : These specification will delve deeper into the technical details. They will define specific test cases with inputs, expected outputs, and pass/fail criteria for individual functionalities, modules, or APIs.</li> </ul>"},{"location":"external_content/power_manager_test/#description","title":"Description","text":"<p>This repository contains the Unit Test Suites (L1 &amp; L2) for Power Manager <code>HAL</code>.</p>"},{"location":"external_content/power_manager_test/#reference-documents","title":"Reference Documents","text":"SNo Document Name Document Description Document Link 1 <code>HAL</code> Specification Document This document provides specific information on the APIs for which tests are written in this module power-manager_halSpec.md 2 High Level Test Specification High Level Test Specification Documentation this module power-manager_High-Level_TestSpec.md 3 <code>L2</code> Low Level Test Specification <code>L2</code>Low Level Test Specification Documentation this module power-manager_L2_Low-Level_TestSpec.md"},{"location":"external_content/power_manager_test/#notes","title":"Notes","text":"<ul> <li>All APIs need to be implemented in this current version. If any API is not supported, please add stub implementation with return type PWRMGR_OPERATION_NOT_SUPPORTED for the same.</li> <li>Building against the actual library may introduce SOC dependencies. Hence, a template SKELETON library is created without SOC dependencies. On the real platform (target), it can be mounted, copied and bound with the actual library.</li> <li>When executing the binary, ensure to include a platform-specific profile file as an argument for the designated test cases. The following example illustrates this:</li> </ul> <p><code>bash ./hal_test -p sink_powerManager.yaml</code></p> <p>Alternatively, use the run.sh script with the profile file:</p> <p><code>bash ./run.sh -p /absolute/path/to/profile/file</code></p> <p>Profiles file available for sink and source at sink profile yaml file and  source  profile yaml file</p> <ul> <li>Install Python Environment and Activation Scripts please check theHPK Documentation</li> </ul>"},{"location":"external_content/power_manager_test/CHANGELOG/","title":"Changelog","text":""},{"location":"external_content/power_manager_test/CHANGELOG/#changelog","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file. Dates are displayed in UTC.</p> <p>Generated by <code>auto-changelog</code>.</p>"},{"location":"external_content/power_manager_test/CHANGELOG/#140","title":"1.4.0","text":"<ul> <li>gh #30 Setting SetWakeupSrc to false causing issues <code>#31</code></li> <li>gh #32 Update UTCore version to 4.x <code>#33</code></li> <li>gh #28 powerManager: L3 Test case Development <code>#29</code></li> <li>gh #22 powerManager: L3 Test case Development <code>#23</code></li> <li>gh #24 initial l3 layout <code>#25</code></li> </ul>"},{"location":"external_content/power_manager_test/CHANGELOG/#131","title":"1.3.1","text":"<p>13 August 2024</p> <ul> <li>gh #20 Update the run.sh script &amp; README.md <code>#21</code></li> <li>Bumped CHANGELOG.md - 1.3.1 <code>13480f5</code></li> <li>Merge tag '1.3.0' into develop <code>302a2bf</code></li> </ul>"},{"location":"external_content/power_manager_test/CHANGELOG/#130","title":"1.3.0","text":"<p>9 August 2024</p> <ul> <li>gh #18 Feature/gh18 makefile cleanup <code>#19</code></li> <li>gh #15 Code Cleanup in L1 for power_manager <code>#17</code></li> <li>gh #11 Test profile changes for powermanager <code>#16</code></li> <li>gh #12 Power_manager updated interface changes <code>#13</code></li> <li>gh #15 updating codecleanup changes <code>2d4c50f</code></li> <li>gh #11 Addressing review comments for powermanager <code>1a21adc</code></li> <li>gh #12 power_manager updated interface changes <code>fc35036</code></li> </ul>"},{"location":"external_content/power_manager_test/CHANGELOG/#120","title":"1.2.0","text":"<p>26 June 2024</p> <ul> <li>gh #5 power manager test suit spec &amp; L2 code <code>#6</code></li> <li>gh #5 updated yaml file and code modification to read it <code>d378296</code></li> <li>Updated test spec and moved test procedure to <code>de1532b</code></li> <li>gh #5 Updated test spec name &amp; minior changes <code>fea7dd0</code></li> </ul>"},{"location":"external_content/power_manager_test/CHANGELOG/#111","title":"1.1.1","text":"<p>5 June 2024</p> <ul> <li>Bumped CHANGELOG.md - 1.1.1 <code>73761a8</code></li> <li>Updated README.md <code>109688c</code></li> <li>Merge tag '1.1.0' into develop <code>70ee094</code></li> </ul>"},{"location":"external_content/power_manager_test/CHANGELOG/#110","title":"1.1.0","text":"<p>5 June 2024</p> <ul> <li>gh #7 power_manager: Disabling enhanced error code <code>#9</code></li> <li>Enhanced error code moved to kvp\u00a0 profiler <code>1c42890</code></li> <li>powermanager  enhanced error code update <code>6b331f1</code></li> <li>Bumped CHANGELOG.md - 1.1.0 <code>a63b08b</code></li> </ul>"},{"location":"external_content/power_manager_test/CHANGELOG/#104","title":"1.0.4","text":"<p>20 February 2024</p> <ul> <li>Bumped CHANGELOG.md - 1.0.4 <code>3527421</code></li> <li>Updated tag version in README.md <code>99eea2b</code></li> <li>Merge tag '1.0.3' into develop <code>1711046</code></li> </ul>"},{"location":"external_content/power_manager_test/CHANGELOG/#103","title":"1.0.3","text":"<p>29 January 2024</p> <ul> <li>UT Core 2.0 update and cleanup <code>2ad7e46</code></li> <li>removed unnecessary definitions <code>7ca65c6</code></li> <li>Bumped CHANGELOG.md - 1.0.3 <code>82df645</code></li> </ul>"},{"location":"external_content/power_manager_test/CHANGELOG/#102","title":"1.0.2","text":"<p>12 December 2023</p> <ul> <li>Updated README.md with hal &amp; haltest supported version <code>79edc5c</code></li> <li>Bumped CHANGELOG.md - 1.0.2 <code>425aff0</code></li> <li>Merge tag '1.0.1' into develop <code>892ceed</code></li> </ul>"},{"location":"external_content/power_manager_test/CHANGELOG/#101","title":"1.0.1","text":"<p>7 December 2023</p> <ul> <li>baseline version <code>5786990</code></li> <li>Added CHANGELOG.md - 1.0.1 <code>5a94736</code></li> <li>Initial commit <code>ded9b27</code></li> </ul>"},{"location":"external_content/power_manager_test/CONTRIBUTING/","title":"Contributing","text":"<ul> <li>If you wish to make code contributions to this project, the source is hosted at github.com/rdkcentral.</li> </ul> <p>You can submit your changes for review via that site, by raising an issue in github, (https://github.com/rdkcentral/xxxx/issues), and following the sequence below.</p> <ul> <li>create a branch with a name follow the guidelines gh(x)_(synopsis)</li> <li>where x is the ticket number</li> <li>where synopsis is a short synopsis for the reason for the branch.</li> <li>create a pull request (https://github.com/rdkcentral/xxxx/compare) when the code changes are ready for review.</li> <li> <p>The team will review, and if accepted your changes will be merged to the mainline.</p> </li> <li> <p>In order to contribute code, first-time users are requested to agree to the license.</p> </li> <li> <p>where <code>xxxx</code> is your module name</p> </li> </ul>"},{"location":"external_content/power_manager_test/docs/pages/CONTRIBUTING/","title":"Contributing","text":"<ul> <li>If you wish to make code contributions to this project, the source is hosted at github.com/rdkcentral.</li> </ul> <p>You can submit your changes for review via that site, by raising an issue in github, (https://github.com/rdkcentral/xxxx/issues), and following the sequence below.</p> <ul> <li>create a branch with a name follow the guidelines gh(x)_(synopsis)</li> <li>where x is the ticket number</li> <li>where synopsis is a short synopsis for the reason for the branch.</li> <li>create a pull request (https://github.com/rdkcentral/xxxx/compare) when the code changes are ready for review.</li> <li> <p>The team will review, and if accepted your changes will be merged to the mainline.</p> </li> <li> <p>In order to contribute code, first-time users are requested to agree to the license.</p> </li> <li> <p>where <code>xxxx</code> is your module name</p> </li> </ul>"},{"location":"external_content/power_manager_test/docs/pages/power-manager_High-Level_TestSpec/","title":"Power Manager High Level Test Specification Documentation","text":""},{"location":"external_content/power_manager_test/docs/pages/power-manager_High-Level_TestSpec/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>HAL</code> - Hardware Abstraction Layer</li> <li><code>API</code> - Application Programming Interface</li> <li><code>L2</code> - Level 2 Testing ()</li> <li><code>L3</code> - Level 3 Testing ()</li> <li><code>IR</code> - Infrared</li> <li><code>CEC</code> - Consumer Electronics Control</li> <li><code>LAN</code> - Local Area Network</li> <li><code>NA</code> - Not Applicable</li> <li><code>Y</code> - Yes</li> </ul>"},{"location":"external_content/power_manager_test/docs/pages/power-manager_High-Level_TestSpec/#introduction","title":"Introduction","text":"<p>This document provides an overview of High Level testing requirements for the Power Manager module. It outlines the scope of testing, objectives, testing levels and approaches, specific test requirements, control plane emulator requirements and expected deliverables.</p> <p>Interface of the test is available here: Power Manager HAL header</p> <p>The Power manager Hal Spec document: Power Manager HAL Spec</p>"},{"location":"external_content/power_manager_test/docs/pages/power-manager_High-Level_TestSpec/#testing-scope","title":"Testing Scope","text":"# Test Functionality Description 1 Set And Get Power States Power Manager should set the power state provided by caller and same should be retrieved 2 Set and Get Status of Wakeup Sources Power Manager should set the wakeup source provided by caller and same should be retrieved 3 Testing Wakeup Source Power manager should accept the supported wakeup sources and device should wakeup from standby/sleep modes using wakeup sources set by caller 4 Test Reset Functionality Power manager should reboot the device"},{"location":"external_content/power_manager_test/docs/pages/power-manager_High-Level_TestSpec/#emulator-requirements","title":"Emulator Requirements","text":"<ul> <li>Boot configuration: Wakeup sources supported by the device. See DeepSleep_WakeupReason_t.</li> </ul>"},{"location":"external_content/power_manager_test/docs/pages/power-manager_High-Level_TestSpec/#set-and-get-power-states","title":"Set And Get Power States","text":"Description HAL APIs L2 L3 Control plane requirements Set various power states and retrieve it for verification based on the platform configuration file. For source devices, check with the \"source_powerManager.yaml\" using the path \"powermanager.PowerStates\" and for sink devices, check with the \"sink_powerManager.yaml\" using the path \"powermanager.PowerStates\" PLAT_API_SetPowerState, PLAT_API_GetPowerState <code>Y</code> <code>NA</code> <code>NA</code>"},{"location":"external_content/power_manager_test/docs/pages/power-manager_High-Level_TestSpec/#test-startup-requirement-set-and-get-power-states","title":"Test Startup Requirement - Set And Get Power States","text":"<p><code>NA</code></p>"},{"location":"external_content/power_manager_test/docs/pages/power-manager_High-Level_TestSpec/#emulator-requirements-set-and-get-power-states","title":"Emulator Requirements - Set And Get Power States","text":"<p><code>NA</code></p>"},{"location":"external_content/power_manager_test/docs/pages/power-manager_High-Level_TestSpec/#control-plane-requirements-set-and-get-power-states","title":"Control Plane Requirements - Set And Get Power States","text":"<p><code>NA</code></p>"},{"location":"external_content/power_manager_test/docs/pages/power-manager_High-Level_TestSpec/#set-and-get-status-of-wakeup-sources","title":"Set and Get Status of Wakeup Sources","text":"Description HAL APIs L2 L3 Control plane requirements Set status of various wakeup sources and retrieves status for verification based on the platform configuration. For source devices, check with the \"source_powerManager.yaml\" using the path \"powermanager.WakeupSources\" and for sink devices, check with the \"sink_powerManager.yaml\" using the path \"powermanager.WakeupSources\" PLAT_API_SetWakeupSrc, PLAT_API_GetWakeupSrc <code>Y</code> <code>NA</code> <code>NA</code>"},{"location":"external_content/power_manager_test/docs/pages/power-manager_High-Level_TestSpec/#test-startup-requirement-set-and-get-status-of-wakeup-sources","title":"Test Startup Requirement - Set and Get Status of Wakeup Sources","text":"<p><code>NA</code></p>"},{"location":"external_content/power_manager_test/docs/pages/power-manager_High-Level_TestSpec/#emulator-requirements-set-and-get-status-of-wakeup-sources","title":"Emulator Requirements - Set and Get Status of Wakeup Sources","text":"<p>Emulator Requirements</p>"},{"location":"external_content/power_manager_test/docs/pages/power-manager_High-Level_TestSpec/#control-plane-requirements-set-and-get-status-of-wakeup-sources","title":"Control Plane Requirements - Set and Get Status of Wakeup Sources","text":"<p><code>NA</code></p>"},{"location":"external_content/power_manager_test/docs/pages/power-manager_High-Level_TestSpec/#testing-wakeup-source","title":"Testing Wakeup Source","text":"<p>Testing the wake-up sources is already done within the deep-sleep L3 test specification.</p>"},{"location":"external_content/power_manager_test/docs/pages/power-manager_High-Level_TestSpec/#test-reset-functionality","title":"Test Reset Functionality","text":"<p>This function is depreciated and we are not testing depreciated functions.</p>"},{"location":"external_content/power_manager_test/docs/pages/power-manager_L2_Low-Level_TestSpec/","title":"Power Manager L2 Low Level Test Specification and Procedure Documentation","text":""},{"location":"external_content/power_manager_test/docs/pages/power-manager_L2_Low-Level_TestSpec/#overview","title":"Overview","text":"<p>This document describes the Low Level 2 Test Specification and Procedure for the PLAT POWER module.</p>"},{"location":"external_content/power_manager_test/docs/pages/power-manager_L2_Low-Level_TestSpec/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>HAL</code> - Hardware Abstraction Layer, may include some common components</li> <li><code>UT</code>  - Unit Test(s)</li> <li><code>OEM</code>  - Original Equipment Manufacture</li> <li><code>SoC</code>  - System on a Chip</li> </ul>"},{"location":"external_content/power_manager_test/docs/pages/power-manager_L2_Low-Level_TestSpec/#definitions","title":"Definitions","text":"<ul> <li><code>ut-core</code> - Common Testing Framework https://github.com/rdkcentral/ut-core, which wraps a open-source framework that can be expanded to the requirements for future framework.</li> </ul>"},{"location":"external_content/power_manager_test/docs/pages/power-manager_L2_Low-Level_TestSpec/#references","title":"References","text":"<ul> <li><code>High Level Test Specification</code> - Power Manager High Level Test Spec</li> <li><code>HAL Interface file</code> - Power Manager HAL header</li> </ul>"},{"location":"external_content/power_manager_test/docs/pages/power-manager_L2_Low-Level_TestSpec/#level-2-test-procedure","title":"Level 2 Test Procedure","text":"<p>The following functions are expecting to test the module operates correctly.</p>"},{"location":"external_content/power_manager_test/docs/pages/power-manager_L2_Low-Level_TestSpec/#test-1","title":"Test 1","text":"Title Details Function Name <code>test_l2_plat_power_SetAndGetPowerState</code> Description Set various power states and retrieve it for verification Test Group 02 Test Case ID 001 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/power_manager_test/docs/pages/power-manager_L2_Low-Level_TestSpec/#test-procedure-test-1","title":"Test Procedure - Test 1","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the platform using PLAT_INIT None PWRMGR_SUCCESS Should be successful 02 Set supported power states using PLAT_API_SetPowerState powerState = Read <code>powermanager.PowerStates</code> from the configuration file PWRMGR_SUCCESS Should be successful 03 Get the current power state using PLAT_API_GetPowerState and verify getState = valid buffer PWRMGR_SUCCESS, getState = powerState Should be successful 04 Terminate the platform using PLAT_TERM None PWRMGR_SUCCESS Should be successful <pre><code>graph TB\nA[Call PLAT_INIT] --&gt;|PWRMGR_SUCCESS| B{Call PLAT_API_SetPowerState &lt;br&gt; with supported power states}\nB --&gt;|PWRMGR_SUCCESS| C[Call PLAT_API_GetPowerState]\nC --&gt;D[Verify get and &lt;br&gt; set power states]\nD --&gt;|PWRMGR_SUCCESS| B\nB --&gt;|End of loop|L[Call PLAT_TERM]\nL --&gt;|PWRMGR_SUCCESS| M[Test case success]\nA --&gt;|Failure| N[Test case fail]\nL --&gt;|Failure| T[Test case fail]</code></pre>"},{"location":"external_content/power_manager_test/docs/pages/power-manager_L2_Low-Level_TestSpec/#test-2","title":"Test 2","text":"Title Details Function Name <code>test_l2_plat_power_SetAndGetWakeupSrc</code> Description Set status of various wakeup sources and retrieves status for verification based on the platform configuration Test Group 02 Test Case ID 002 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/power_manager_test/docs/pages/power-manager_L2_Low-Level_TestSpec/#test-procedure-test-2","title":"Test Procedure - Test 2","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the platform using PLAT_INIT None PWRMGR_SUCCESS Should be successful 02 Set supported wakeup source to true using PLAT_API_SetWakeupSrc for each source type srcType = Read <code>powermanager.WakeupSources</code> from configuration file, enable = true PWRMGR_SUCCESS Should be successful 03 Get supported wakeup source status using PLAT_API_GetWakeupSrc for each source type and verify srcType = Read <code>powermanager.WakeupSources</code> from configuration file PWRMGR_SUCCESS, enable = true Should be successful 04 Set supported wakeup source to false using PLAT_API_SetWakeupSrc for each source type srcType = Read <code>powermanager.WakeupSources</code> from configuration file, enable = false PWRMGR_SUCCESS Should be successful 05 Get supported wakeup source status using PLAT_API_GetWakeupSrc for each source type and verify srcType = Read <code>powermanager.WakeupSources</code> from configuration file PWRMGR_SUCCESS, enable = false Should be successful 06 Terminate the platform using PLAT_TERM None PWRMGR_SUCCESS Should be successful <pre><code>graph TB\nA[Call PLAT_INIT] --&gt;|PWRMGR_SUCCESS| B{For each supported wakeup source type &lt;br&gt; in PWRMGR_WakeupSrcType_t}\nB --&gt; C[Call PLAT_API_SetWakeupSrc &lt;br&gt; and enable set to true]\nC --&gt;|PWRMGR_SUCCESS| D[Call PLAT_API_GetWakeupSrc &lt;br&gt; and verify]\nD --&gt;|PWRMGR_SUCCESS, &lt;br&gt;enable = true| E[Call PLAT_API_SetWakeupSrc &lt;br&gt; and enable set to false]\nE --&gt;|PWRMGR_SUCCESS| F[Call PLAT_API_GetWakeupSrc and verify]\nF --&gt;|PWRMGR_SUCCESS, &lt;br&gt; enable = false| B\nA --&gt;|Failure| G[Test case fail]\nB --&gt; L[Call PLAT_TERM]\nL --&gt;|PWRMGR_SUCCESS| M[Test case success]\nL --&gt;|Failure| N[Test case fail]</code></pre>"},{"location":"external_content/python_raft_wiki/Core-Framework%3A-Common-Remote/","title":"Common Remote Module","text":"<p>This document describes the <code>commonRemote</code> module, a Python module designed to provide a consistent interface for interacting with various remote control devices. It abstracts away the low-level details of different remote technologies, allowing you to write test scripts that work seamlessly with different remote types.</p>"},{"location":"external_content/python_raft_wiki/Core-Framework%3A-Common-Remote/#key-features","title":"Key Features","text":"<ul> <li>Remote Control Abstraction: Offers a unified way to send commands to different types of remotes, such as Olimex, SkyProc, and Arduino.</li> <li>Key Mapping:  Translates standardized key names used in test scripts to the specific key codes required by each remote.</li> <li>Configuration-Driven: Remote type and key map are defined in a configuration file for easy switching and customization.</li> </ul>"},{"location":"external_content/python_raft_wiki/Core-Framework%3A-Common-Remote/#classes","title":"Classes","text":""},{"location":"external_content/python_raft_wiki/Core-Framework%3A-Common-Remote/#remotecontrollermapping","title":"<code>remoteControllerMapping</code>","text":"<ul> <li>Purpose: Manages the translation of standard key names (e.g., \"POWER\", \"VOLUME_UP\") to the corresponding key codes for the currently active remote.</li> <li>Key Methods:<ul> <li><code>getMappedKey(key)</code>: Returns the mapped key code for the given standard key name.</li> <li><code>getKeyMap()</code>: Returns the currently active key map.</li> <li><code>setKeyMap(newMapName)</code>: Switches to a different key map.</li> </ul> </li> </ul>"},{"location":"external_content/python_raft_wiki/Core-Framework%3A-Common-Remote/#commonremoteclass","title":"<code>commonRemoteClass</code>","text":"<ul> <li>Purpose: The primary interface for interacting with remote control devices. It encapsulates the <code>remoteControllerMapping</code> class and handles communication with the specific remote implementation.</li> <li>Key Methods:<ul> <li><code>sendKey(keycode, delay=1, repeat=1, randomRepeat=0)</code>: <ul> <li>Translates the <code>keycode</code> using the active key map.</li> <li>Sends the translated key code to the remote.</li> <li>Optionally adds delays and repeats.</li> </ul> </li> <li><code>setKeyMap(name)</code>: Switches to the specified key map.</li> <li><code>getKeyMap()</code>: Returns the currently active key map.</li> </ul> </li> </ul>"},{"location":"external_content/python_raft_wiki/Core-Framework%3A-Common-Remote/#configuring-the-remote-control-class","title":"Configuring the Remote Control Class","text":"<p>The remote control interface is configured from the main framework wide <code>config.yaml</code> using the subsection YAML snippet:</p> <pre><code>remoteController:\n    # [ type: \"olimex\" ip: \"192.168.0.17\" port: 7 map: \"rc6\"]\n    # [ type: \"skyProc\" map: \"skyq_map\" ]\n    # [ type: \"arduino\" map: \"arduino\" port: 'COM8' baudrate: 9600]\n    # [ type: \"None\" ]\n    type: \"olimex\"\n    map: \"xmp_a\"\n    port: 7\n    ip: \"192.168.0.103\"\n    config: \"commander_maps.yaml\"\n</code></pre> <p>This configuration specifies that:</p> <ul> <li><code>type: \"olimex\"</code>: An Olimex remote control device is used for sending commands.</li> <li><code>map: \"xmp_a\"</code>: The key map named \"xmp_a\" will be used to translate standardized key names to the specific codes required by the Olimex remote. This map should be defined as per the Key Mapping Metchanism below.</li> <li><code>port: 7</code>: The port number used to communicate with the Olimex device.</li> <li><code>ip: \"192.168.0.103\"</code>: The IP address of the Olimex remote control device.</li> <li><code>config</code>: \"commander_maps.yaml\": This explicitly specifies the YAML file that contains the definitions of the key maps.</li> </ul>"},{"location":"external_content/python_raft_wiki/Core-Framework%3A-Common-Remote/#supported-remote-types","title":"Supported Remote Types","text":"<p>The <code>commonRemote</code> module supports the following remote control types:</p> <ul> <li><code>olimex</code>: For Olimex remote control devices. Requires <code>ip</code> and <code>port</code> in the configuration.</li> <li><code>skyProc</code>: For SkyProc remote control devices.</li> <li><code>arduino</code>: For Arduino based remote control solutions. Requires <code>port</code> and <code>baudrate</code> in the configuration.</li> <li><code>None</code>:  For simulating remote control actions or using alternative control mechanisms.</li> </ul>"},{"location":"external_content/python_raft_wiki/Core-Framework%3A-Common-Remote/#key-mapping-mechanism","title":"Key Mapping Mechanism","text":"<ol> <li> <p>Remote Configuration: A configuration file (<code>remoteConfig</code>) defines the <code>type</code> of remote and the <code>map</code> to use.</p> </li> <li> <p>Key Map Files: YAML files (e.g., <code>olimex_map.yml</code>) store the key mappings for each remote type:</p> </li> </ol> <pre><code>- name: \"MyOlimexMap\"\n  prefix: \"OLIMEX_\" # Optional prefix for translated keys\n  codes:\n    UP: \"0x20\"\n    DOWN: \"0x21\"\n    POWER: \"0x0C\"\n</code></pre> <ol> <li> <p>Key Translation: When <code>sendKey(rc.POWER)</code> is called:</p> </li> <li> <p>The <code>commonRemoteClass</code> retrieves the active key map.</p> </li> <li>It looks up enum \"rc.POWER\" in the map and finds its corresponding code (e.g., \"0x0C\").</li> <li>If a prefix is defined (e.g., \"OLIMEX_\"), it's added to the code.</li> <li>The final command (e.g., \"OLIMEX_0x0C\") is sent to the remote device.</li> </ol>"},{"location":"external_content/python_raft_wiki/Core-Framework%3A-Common-Remote/#usage-example","title":"Usage Example","text":"<pre><code>from framework.core.webpageModules.commonRemote import commonRemoteClass\n\n# ... your test setup ...\n\nmy_remote = commonRemoteClass(my_logger, remote_config)  # Initialize with remote configuration\n\n# Send the \"OK\" key (which might be mapped to \"ENTER\" on the remote)\nmy_remote.setKeyMap(\"rc6\")\nmy_remote.sendKey(rc.ENTER) \n\n# Switch to a different remote\nmy_remote.setKeyMap(\"tpv\")\nmy_remote.sendKey(rc.ENTER) \n</code></pre>"},{"location":"external_content/python_raft_wiki/Core-Framework%3A-Common-Remote/#benefits","title":"Benefits","text":"<ul> <li>Simplified Test Scripts: Test scripts remain independent of specific remote control implementations.</li> <li>Maintainability: Key mappings are centralized in configuration files, making updates and modifications easier.</li> <li>Flexibility: Supports various remote types and allows for custom key mappings.</li> </ul>"},{"location":"external_content/python_raft_wiki/Core-Framework%3A-Common-Remote/#key-map-files","title":"Key Map Files","text":"<p>Key map files are YAML files that define the mapping between enum test key names and remote-specific key codes. Each file can contain multiple key maps, each with a unique name.</p> <p>Example <code>olimex_map.yml</code>:</p> <pre><code>remoteMaps:\n  remoteCommanderMap0:\n    name: \"MyOlimexMap\"\n    prefix: \"OLIMEX_\" # Optional prefix for translated keys\n    codes:\n      UP: \"0x20\"\n      DOWN: \"0x21\"\n      POWER: \"0x0C\"\n      SELECT: \"select\"\n</code></pre>"},{"location":"external_content/python_raft_wiki/Core-Framework%3A-Common-Remote/#example-multi-remote-commander-maps","title":"Example multi remote commander maps","text":"<pre><code>remoteMaps:\n  remoteCommanderMap0:\n    name : \"rc6\"\n    prefix: \"RC6=\"\n    codes:\n     #-------------PORTABLE:--------------\n     NUM_0 : \"0\"\n     NUM_1 : \"1\"\n     NUM_2 : \"2\"\n     NUM_3 : \"3\"\n     NUM_4 : \"4\"\n     NUM_5 : \"5\"\n     NUM_6 : \"6\"\n     NUM_7 : \"7\"\n     NUM_8 : \"8\"\n     NUM_9 : \"9\"\n     # PREVPROG = \"0x0A\" # No action\n     POWER : \"OnOff\"\n     MUTE\u00a0 : \"Mute\"\n     VOL_UP : \"VolUp\"\n     VOL_DOWN : \"VolDown\"\n     PAUSE : \"Pause\"\n     DOWN : \"NavDown\"\n     LEFT : \"NavLeft\"\n     RIGHT : \"NavRight\"\n     SELECT : \"NavEnter\"\n     HOME : \"Home\"\n     #---------NON-PORTABLE:--------------\n     BACK : \"Back\"\n     CROSS : \"Cross\"\n     MIC : \"Mic\"\n     RGYB : \"Rgyb\"\n     MENU : \"Menu\"\n     PICK_UP : \"PickUp\"\n     EXIT: \"Back\"\n     EXIT_WAIT: \"Back DURATION=5000 COR0=10 COR1=-5\"\n     #------------------------------------\n\nremoteCommanderMap1:\n  name : \"tpv\"\n  prefix: \"TPV=\"\n  codes:\n    #-------------PORTABLE:--------------\n    NUM_0 : \"0\"\n    NUM_1 : \"1\"\n    NUM_2 : \"2\"\n    NUM_3 : \"3\"\n    NUM_4 : \"4\"\n    NUM_5 : \"5\"\n    NUM_6 : \"6\"\n    NUM_7 : \"7\"\n    NUM_8 : \"8\"\n    NUM_9 : \"9\"\n    MUTE\u00a0 : \"Mute\"\n    CHANNEL_UP\u00a0 : \"Ch+\"\n    CHANNEL_DOWN : \"Ch-\"\n    UP : \"NavUp\"\n    DOWN : \"NavDown\"\n    LEFT : \"NavLeft\"\n    RIGHT : \"NavRight\"\n    SELECT : \"NavEnter\"\n    #---------NON-PORTABLE:--------------\n    TEST : \"Test\"\n    RST : \"Rst\"\n    FAC : \"Fac\"\n    CSM : \"Csm\"\n    PATTERN : \"Pattern\"\n    ANTENNA_CABLE : \"AntennaCable\"\n    PRE_CH : \"PreCh\"\n    VOL_MAX : \"VolMax\"\n    CTC : \"Ctc\"\n    VOL_BUZZ : \"VolBuzz\"\n    MENU : \"Menu\"\n    BI : \"BI\"\n    CH_SCAN : \"ChScan\"\n    CCTT : \"Cctt\"\n    PIC : \"Pic\"\n    LOG_LED : \"LogLed\"\n    AUDIO : \"Audio\"\n    D2D3 : \"D2D3\"\n    ARC : \"Arc\"\n    CIP : \"Ci+\"\n    VIRGIN : \"Virgin\"\n    CVBS : \"Cvbs\"\n    YPBPR_SCART : \"YpbprScart\"\n    HDMI : \"Hdmi\"\n    VGA : \"Vga\"\n    REGIN : \"Regin\"\n    CLONE : \"Clone\"\n    RESERVE1 : \"Reserve1\"\n    DCR : \"Dcr\"\n    WIFI_SSID : \"WifiSsid\"\n    BLK : \"Blk\"\n    WP : \"Wp\"\n    LIGHT_SENSOR : \"LightSensor\"\n    USB : \"Usb\"\n    RJ45 : \"Rj45\"\n    RS232 : \"Rs232\"\n    RESERVE2 : \"Reserve2\"\n    EXIT_WAIT: \"Back DURATION=5000 COR0=10 COR1=-5\"\n    #------------------------------------\n\nremoteCommanderMap2:\n  name: \"xmp_d\" # Works with XR100)\n  prefix: \"XMP_d=\"\n  codes:\n    POWER: \"OnOff\"\n    HOME: \"Home\"\n    CROSS: \"Cross\"\n    MENU: \"Menu\" # ... on remote\n    UP: \"NavUp\"\n    DOWN: \"NavDown\"\n    RIGHT: \"NavRight\"\n    LEFT: \"NavLeft\"\n    SELECT: \"NavEnter\"\n    BACK: \"Back\"\n    EXIT: \"Back\"\n    NUM_1: \"1\"\n    NUM_2: \"2\"\n    NUM_3: \"3\"\n    NUM_4: \"4\"\n    NUM_5: \"5\"\n    NUM_6: \"6\"\n    NUM_7: \"7\"\n    NUM_8: \"8\"\n    NUM_9: \"9\"\n    NUM_0: \"0\"\n    INPUT : \"Input\"\n    OPTIONS : \"Options\"\n    EXIT_WAIT: \"Back DURATION=5000 COR0=10 COR1=-5\"\n    INPUT_HOLD : \"Input DURATION=2000 COR0=10 COR1=-5\"\n\nremoteCommanderMap3:\n  name: \"xmp_e\"\n  prefix: \"XMP_e=\"\n  codes:\n    POWER: \"OnOff\"\n    HOME: \"Home\"\n    CROSS: \"Cross\"\n    MENU: \"Menu\" # ... on remote\n    UP: \"NavUp\"\n    DOWN: \"NavDown\"\n    RIGHT: \"NavRight\"\n    LEFT: \"NavLeft\"\n    SELECT: \"NavEnter\"\n    BACK: \"Back\"\n    EXIT: \"Back\"\n    NETFLIX: \"Netflix\"\n    PRIME_VIDEO: \"PrimeVideo\"\n    PEACOCK: \"Peacock\"\n    DISNEY: \"Disney\"\n    NUM_1: \"1\"\n    NUM_2: \"2\"\n    NUM_3: \"3\"\n    NUM_4: \"4\"\n    NUM_5: \"5\"\n    NUM_6: \"6\"\n    NUM_7: \"7\"\n    NUM_8: \"8\"\n    NUM_9: \"9\"\n    NUM_0: \"0\"\n    INPUT : \"Input\"\n    OPTIONS : \"Options\"\n    EXIT_WAIT: \"Back DURATION=5000 COR0=10 COR1=-5\"\n    INPUT_HOLD : \"Input DURATION=2000 COR0=10 COR1=-5\"\n</code></pre>"},{"location":"external_content/python_raft_wiki/Core-Framework%3A-HDMI-CEC-Controller-Extension/","title":"HDMI CEC Controller Extension for <code>raft_framework</code>","text":"<p>This document describes a Python extension for the <code>raft_framework</code> that enables the testing of HDMI CEC devices.</p>"},{"location":"external_content/python_raft_wiki/Core-Framework%3A-HDMI-CEC-Controller-Extension/#overview","title":"Overview","text":"<p>This extension solves the problem of testing HDMI CEC devices on TVs and Set Top Boxes by providing a way to control and monitor CEC communication through third-party emulators. It offers a high-level class, <code>HDMICECController</code>, that simplifies the integration of CEC testing into development workflows.</p>"},{"location":"external_content/python_raft_wiki/Core-Framework%3A-HDMI-CEC-Controller-Extension/#class-documentation","title":"Class Documentation","text":""},{"location":"external_content/python_raft_wiki/Core-Framework%3A-HDMI-CEC-Controller-Extension/#hdmiceccontroller","title":"<code>HDMICECController</code>","text":"<p>This class provides a straightforward interface for controlling and monitoring CEC devices. It handles the underlying complexities of CEC communication, allowing you to focus on your testing logic.</p> <ul> <li>Initialization: <ul> <li>Takes a logger and a configuration dictionary as arguments. </li> <li>The configuration specifies the type of controller to use and the adaptor path.</li> </ul> </li> <li>Sending messages:  Sends CEC messages to devices on the network.</li> <li>Starting and stopping monitoring:  Starts and stops the monitoring of CEC traffic.</li> <li>Reading the monitoring log:  Provides a method to read the monitoring log until a specific message is found, which is useful for verifying expected CEC events.</li> <li>Listing devices:  Retrieves and lists the discovered CEC devices on the network.</li> </ul> <p>Example Usage:</p> <pre><code>from framework.core.logModule import logModule\nfrom your_module import HDMICECController, MonitoringType\n\nlog = logModule()\nconfig = {\n    'type': 'cec-client',  # Specifies the underlying controller type\n    'adaptor': '/dev/ttyACM0'  # Path to the CEC adaptor\n}\ncec = HDMICECController(log, config)\n\n# Send a message\ncec.send_message('on 0')  # Example: Send a \"power on\" command\n\n# Start monitoring CEC traffic\ncec.startMonitoring(deviceType=MonitoringType.RECORDER)\n\n# Stop monitoring\ncec.stopMonitoring()\n\n# Read the monitoring log until a specific message is found\nresult = cec.readUntil('standby') \n</code></pre>"},{"location":"external_content/python_raft_wiki/Core-Framework%3A-HDMI-CEC-Controller-Extension/#integration-with-device-manager","title":"Integration with Device Manager","text":"<p>The <code>HDMICECController</code> is integrated into a device management system.  The device manager will  check for an \"hdmiCECController\" configuration within a device's settings. If present, it can create an instance of <code>HDMICECController</code> using the provided configuration and a logging object.</p> <pre><code>config = device.get(\"hdmiCECController\")\nif config is not None:\n    self.hdmiCECController = HDMICECController(log, config)\n</code></pre> <p>This allows the device manager to seamlessly use the HDMI CEC controller extension for testing and managing CEC devices.</p>"},{"location":"external_content/python_raft_wiki/Core-Framework%3A-HDMI-CEC-Controller-Extension/#conclusion","title":"Conclusion","text":"<p>This extension provides a valuable tool for development engineers working with HDMI CEC devices. It simplifies the process of testing and interacting with CEC devices by providing a user-friendly, high-level interface that hides the underlying implementation details.</p>"},{"location":"external_content/python_raft_wiki/Core-Framework%3A-Power-Control/","title":"Core Framework: Power Control","text":""},{"location":"external_content/python_raft_wiki/Core-Framework%3A-Power-Control/#power-control","title":"Power Control","text":"<p>This section details the <code>powerControlClass</code>, a Python class within the framework that provides a standardized way to manage the power state of devices connected to your testing rack. This class abstracts the complexities of different power switch hardware, offering a simple interface for controlling power on, power off, and reboot operations.</p>"},{"location":"external_content/python_raft_wiki/Core-Framework%3A-Power-Control/#1-supported-power-switch-types","title":"1. Supported Power Switch Types","text":"<p>The <code>powerControlClass</code> supports a variety of power switches commonly used in testing environments:</p> <ul> <li><code>orvbioS20</code>:  A network-controlled relay board.</li> <li><code>kasa</code>: TP-Link Kasa smart plugs and power strips.</li> <li><code>hs100</code>:  TP-Link HS100 smart plugs (also supported by Kasa).</li> <li><code>apc</code>:  APC network-managed power distribution units (PDUs).</li> <li><code>olimex</code>:  Olimex relay boards.</li> <li><code>SLP</code>:  Sentry Power Manager (SPM) with Serial-over-LAN (SLP) interface.</li> <li><code>none</code>: For testing or simulating power control without actual hardware.</li> </ul>"},{"location":"external_content/python_raft_wiki/Core-Framework%3A-Power-Control/#2-configuration","title":"2. Configuration","text":"<p>The power control configuration is defined within your rack configuration file (e.g., <code>example_rack_config.yml</code>). Each device slot in your rack can be associated with a specific power switch and its settings.</p> <p>Example Configuration (from <code>example_rack_config.yml</code>):</p> <pre><code>  slot1:\n    device: \"broadcom-stb\"\n    powerSwitch:      # Specific power switch for each slot\n      type: \"HS100\"\n      ip: \"192.168.1.7\"\n      port: 9999\n</code></pre> <p>This configuration specifies that the device in <code>slot1</code> is connected to an HS100 smart plug with the IP address \"192.168.1.7\".</p> <p>Configuration Parameters:</p> <p>Each power switch type requires specific parameters:</p> <ul> <li><code>orvbioS20</code>: <code>ip</code>, <code>mac</code>, and optionally <code>port</code> and <code>relay</code>.</li> <li><code>kasa</code>: <code>ip</code> and <code>options</code>. Use <code>--plug</code> for single plugs and <code>--strip</code> with <code>--index</code> for power strips.</li> <li><code>hs100</code>: <code>ip</code> and optionally <code>port</code>.</li> <li><code>apc</code>: <code>ip</code>, <code>username</code>, and <code>password</code>.</li> <li><code>olimex</code>: <code>ip</code>, <code>relay</code>, and optionally <code>port</code>.</li> <li><code>SLP</code>: <code>ip</code>, <code>username</code>, <code>password</code>, <code>outlet_id</code>, and optionally <code>port</code>.</li> </ul>"},{"location":"external_content/python_raft_wiki/Core-Framework%3A-Power-Control/#3-using-the-powercontrolclass","title":"3. Using the <code>powerControlClass</code>","text":"<p>The framework typically handles the instantiation of the <code>powerControlClass</code> based on your rack configuration. You usually interact with its methods through other parts of the framework.</p> <p>Available Methods:</p> <ul> <li><code>powerOn()</code>: Powers on the device.</li> <li><code>powerOff()</code>: Powers off the device.</li> <li><code>reboot()</code>:  Performs a power cycle (off then on).</li> </ul> <p>These methods return <code>True</code> if the operation is successful and <code>False</code> otherwise.</p>"},{"location":"external_content/python_raft_wiki/Core-Framework%3A-Power-Control/#4-error-handling-and-logging","title":"4. Error Handling and Logging","text":"<p>The <code>powerControlClass</code> incorporates error handling with retries to increase the reliability of power operations. It also uses the framework's logging mechanism to record events and errors, aiding in debugging and monitoring.</p>"},{"location":"external_content/python_raft_wiki/Core-Framework%3A-Power-Control/#5-important-considerations","title":"5. Important Considerations","text":"<ul> <li>Ensure your rack configuration file accurately reflects your hardware setup and power switch connections.</li> <li>Consult the documentation for individual power switch modules for detailed information and troubleshooting.</li> <li>This section assumes familiarity with the overall framework and its configuration. Refer to other sections for foundational knowledge.</li> </ul>"},{"location":"external_content/python_raft_wiki/Core-Framework%3A-Webpage-Controller-Module/","title":"Core Framework: Webpage Controller Module","text":""},{"location":"external_content/python_raft_wiki/Core-Framework%3A-Webpage-Controller-Module/#overview","title":"Overview","text":"<p>The <code>webpageController.py</code> module, located in the <code>framework/core</code> directory of the <code>python_raft</code> framework, is designed to manage web page interactions and dynamic rendering. It handles the interaction between the front-end user interface (UI) and the back-end server-side logic, facilitating the dynamic binding of data to UI components, event handling, and template rendering.</p> <p>This module is a core component for building web-based applications where the UI needs to be updated in response to backend logic, such as real-time data changes or user input processing.</p>"},{"location":"external_content/python_raft_wiki/Core-Framework%3A-Webpage-Controller-Module/#features","title":"Features","text":"<ul> <li> <p>Web Page Management   Manages the full lifecycle of web pages, ensuring they are properly rendered, updated, and cleaned up. It supports rendering both static and dynamic content on the web page.</p> </li> <li> <p>Event Handling   The module facilitates handling of events triggered by user interactions such as clicks, form submissions, and other UI actions. These events are linked to back-end logic, which can then modify the UI or process data accordingly.</p> </li> <li> <p>Template Integration   The <code>webpageController</code> works with HTML templates that define the structure of the web page. Data from the server is dynamically injected into these templates to render content based on the current state of the application.</p> </li> <li> <p>Backend Integration   It facilitates communication between the front-end and the server-side logic. The <code>webpageController</code> ensures that UI updates and event actions are properly synced with the backend, making it easier to manage the state of the application.</p> </li> </ul>"},{"location":"external_content/python_raft_wiki/Core-Framework%3A-Webpage-Controller-Module/#key-design-considerations","title":"Key Design Considerations","text":"<ul> <li> <p>Dynamic Content Rendering   The module supports dynamic content rendering where the web page's content is updated based on real-time data received from the server. This ensures that the web page is always up-to-date without requiring full page reloads.</p> </li> <li> <p>Template Binding   Data binding in the <code>webpageController</code> allows variables from the back end to be passed directly into the HTML templates. This mechanism provides a clean separation of concerns, with the template handling the presentation and the backend managing the application logic.</p> </li> <li> <p>State Management   The module maintains the state of the web page during user interactions and ensures that data changes are reflected appropriately in the UI. It helps manage complex UI states, particularly in cases where the UI is updated based on external factors (e.g., user input or server responses).</p> </li> <li> <p>Seamless UI Updates   Through AJAX and other techniques, the <code>webpageController</code> allows for non-blocking UI updates, providing a smooth and responsive user experience.</p> </li> </ul>"},{"location":"external_content/python_raft_wiki/Core-Framework%3A-Webpage-Controller-Module/#use-cases","title":"Use Cases","text":"<ul> <li> <p>Real-time Dashboards   Suitable for applications that need to display live data, such as dashboards monitoring system health, performance metrics, or user activity.</p> </li> <li> <p>Interactive Forms   Ideal for forms that require dynamic validation or changes based on user selections or backend data.</p> </li> <li> <p>Multi-page Applications   Perfect for building multi-page web applications with modular UI components that can interact with the server, updating different sections of the page without a full reload.</p> </li> </ul>"},{"location":"external_content/python_raft_wiki/Core-Framework%3A-Webpage-Controller-Module/#integration","title":"Integration","text":"<p>To use the <code>webpageController.py</code> module, import it into your application, create an instance of the <code>WebpageController</code>, and bind your backend data to the appropriate template. The controller will take care of rendering the content and handling user interactions.</p>"},{"location":"external_content/python_raft_wiki/Core-Framework%3A-Webpage-Controller-Module/#example","title":"Example","text":"<pre><code>from framework.core.webpageController import WebpageController\n\n# Create an instance of the WebpageController\ncontroller = WebpageController()\n\n# Define template and data\ntemplate = \"dashboard.html\"\ndata = {\"user\": \"John Doe\", \"status\": \"Active\"}\n\n# Render the webpage\ncontroller.render_page(template, data)\n</code></pre>"},{"location":"external_content/python_raft_wiki/Core-Framework%3A-Webpage-Controller-Module/#benefits","title":"Benefits","text":"<ul> <li> <p>Modularity   The design of the <code>webpageController</code> promotes modularity, allowing different UI components to be reused across various parts of the application while ensuring consistent behavior and state management.</p> </li> <li> <p>Maintainability   By separating the logic of web page rendering and data handling, the module encourages a cleaner and more maintainable codebase. Developers can focus on the application logic without worrying about the intricacies of the front-end rendering process.</p> </li> <li> <p>Scalability   The framework is designed to scale easily for larger applications with multiple web pages or more complex interactions. It can handle increasing user interactions and content updates efficiently.</p> </li> </ul> <p>More detailed information can be found in the docs folder webpage_controller_design.md</p>"},{"location":"external_content/python_raft_wiki/Home/","title":"Welcome to the python_raft wiki!","text":"<p>python_raft is a Python-based engineering testing framework for validating embedded devices. It simplifies test development with modules for device control, remote control interaction, and more.</p>"},{"location":"external_content/python_raft_wiki/Home/#key-features","title":"Key Features","text":"<ul> <li>Modular Design: Easily integrate and extend functionalities.</li> <li>Remote Control Abstraction: Standardized interaction with various remote control devices.</li> <li>Device Management:  Control and communicate with devices under test.</li> <li>Logging and Reporting: Track test execution and results.</li> <li>Webpage Interaction:  Interact with web pages and applications.</li> <li>Extensible Framework:  Enhance capabilities with plug-ins and extensions.</li> </ul>"},{"location":"external_content/python_raft_wiki/Home/#getting-started","title":"Getting Started","text":"<ul> <li>Setting up new projects</li> </ul>"},{"location":"external_content/python_raft_wiki/Home/#raft-modules","title":"Raft Modules","text":"<ul> <li>Command Modules: Execute shell commands and interact with the device's OS.</li> <li>Common Remote: Control various remote control devices with key mapping and configuration.</li> <li>Config Parser: Parse configuration files.</li> <li>Device Manager: Manage connections and communication with devices.</li> <li>Log Module: Flexible logging framework for test activities.</li> <li>Outbound Client: Communicate with external services.</li> <li>Power Control: Manage device power states.</li> <li>Rack Controller: Interact with hardware racks and test equipment.</li> <li>Test Controller: Core framework for organizing and executing tests.</li> <li>Webpage Controller: Interact with web pages through a browser.</li> <li>HDMI-CEC-Controller-Extension:  Support HDMI-CEC control.</li> </ul>"},{"location":"external_content/python_raft_wiki/Home/#framework-plugins","title":"Framework Plugins","text":"<ul> <li>ut-raft: Integrate python_raft with unit testing frameworks.</li> </ul>"},{"location":"external_content/python_raft_wiki/Starting-a-new-testing-project/","title":"Starting a new testing project","text":"Contents  * [Create a new repository](#create-a-new-repository)   * [Optional: Set the upstream for the new repository](#optional-set-the-upstream-for-the-new-repository) * [Directory Structure](#directory-structure) * [Install script](#install-script)   * [install.sh](#installsh) * [Setup configs](#setup-configs) * [Additional setup](#additional-setup)   * [Common test controller](#common-test-controller)"},{"location":"external_content/python_raft_wiki/Starting-a-new-testing-project/#create-a-new-repository","title":"Create a new repository","text":"<p>Run the following commands: <pre><code>mkdir &lt;new repo name&gt;\ncd &lt;new repo name&gt;\ngit init -b main\n</code></pre> Replace <code>&lt;new repo name&gt;</code> with the real name of the repository you are creating</p>"},{"location":"external_content/python_raft_wiki/Starting-a-new-testing-project/#optional-set-the-upstream-for-the-new-repository","title":"Optional: Set the upstream for the new repository","text":"<p><pre><code>git remote add origin &lt;repository url&gt;\n</code></pre> Replace <code>&lt;repository url&gt;</code> with the real url of the repository you are creating</p>"},{"location":"external_content/python_raft_wiki/Starting-a-new-testing-project/#directory-structure","title":"Directory Structure","text":"<pre><code>new_repo\n\u2514\u2500\u2500 tests\n    \u251c\u2500\u2500 common\n    \u2514\u2500\u2500 configs\n</code></pre> <p>The above directory structure is recommended for new project with all tests being added to the test folder. The RAFT framework should also be cloned into the tests folder The common directory is used to store code that can be shared between tests. For an example of this see the common test controller The configs directory is used to store the common configuration for yours tests. It is recommended that the example rack and device configs from the raft examples folder are copied here, so they can be referred to later.</p> <p>The below commands will create this structure for you:</p> <pre><code>mkdir -p tests/common\nmkdir tests/configs\n</code></pre>"},{"location":"external_content/python_raft_wiki/Starting-a-new-testing-project/#install-script","title":"Install script","text":"<p>Below is a bash script that can be copied and modified install all the requirements for your test project.</p> <p>It is intended to be used with the above directory structure, it should be run in the directory above <code>tests</code>.</p> <p>To modify an extend this script follow the comments at the bottom of the script. It has premade functions to allow for cloning extra repos, checking packages requirements and installing pip packages.</p> Install script  ### install.sh <pre><code>#!/usr/bin/env bash\n\nMY_PATH=\"$(realpath ${BASH_SOURCE[0]})\"\nMY_DIR=\"$(dirname ${MY_PATH})\"\nRAFT_DIR=\"${MY_DIR}/tests/raft\"\n\nNO_COLOR=\"\\e[0m\"\nRED=\"\\e[0;31m\"\nCYAN=\"\\e[0;36m\"\nYELLOW=\"\\e[1;33m\"\nGREEN=\"\\e[0;32m\"\nRED_BOLD=\"\\e[1;31m\"\nBLUE_BOLD=\"\\e[1;34m\"\nYELLOW_BOLD=\"\\e[1;33m\"\n\nfunction ECHO()\n{\n    echo -e \"$*\"\n}\n\nfunction DEBUG()\n{\n    # if set -x is in use debug messages are useless as whole stript will be shown\n    if [[ \"$-\" =~ \"x\" ]]; then\n        return\n    fi\n    if [[ \"${DEBUG_FLAG}\" == \"1\" ]];then\n        ECHO \"${BLUE_BOLD}DEBUG: ${CYAN}$*${NO_COLOR}\" &gt; /dev/stderr\n    fi\n}\n\nfunction INFO()\n{\n    ECHO \"${GREEN}$*${NO_COLOR}\"\n}\n\nfunction WARNING()\n{\n    ECHO \"${YELLOW_BOLD}Warning: ${YELLOW}$*${NO_COLOR}\" &gt; /dev/stderr\n}\n\nfunction ERROR()\n{\n    ECHO \"${RED_BOLD}ERROR: ${RED}$*${NO_COLOR}\" \n    exit 1\n}\n\n\nfunction check_installed()\n{\n    DEBUG \"BEGIN: $FUNCNAME $*\"\n    pkg=$1\n    version=$2\n    check=\"$(command -v ${pkg})\"\n    if [[ -n \"${check}\" ]];then\n        DEBUG \"Package is installed: [${pkg}]\"\n        if [[ -n \"${version}\" ]];then\n            DEBUG \"Performing version check: [${version}]\"\n            ver_check=\"$(${pkg} --version | grep ${version})\"\n            if [[ -z \"${ver_check}\" ]];then\n                ERROR \"${pkg} is installed but version is not [${version}]\"\n            fi\n            DEBUG \"${pkg} version is correct\"\n        fi\n        return\n    fi\n    ERROR \"Required package is not installed: [${pkg}]\"\n    DEBUG \"END: $FUNCNAME\"\n}\n\nfunction install_pip_requirements()\n{\n    DEBUG \"BEGIN: $FUNCNAME $*\"\n    local requirements_file=\"$1\"\n    if [[ ! -e \"${requirements_file}\" ]];then\n        ERROR \"Could not install pip requirements.\\nFile not found: [${requirements_file}]\"\n    fi\n    pip install -qr \"${requirements_file}\"\n    if [[ \"$?\" != \"0\" ]];then\n        ERROR \"Pip install failed.\\nPlease try manually with:\\ncd ${RAFT_DIR}; pip install -r requirements.txt; cd -\"\n    fi\n    DEBUG \"END: $FUNCNAME\"\n}\n\nfunction clone_repo()\n{\n    DEBUG \"BEGIN: $FUNCNAME $*\"\n    local repo_url=\"$1\"\n    if [[ -z \"${repo_url}\" ]];then\n        ERROR \"A url for a repository must be passed to the clone repo function\"\n    fi\n    local path=\"$2\"\n    if [[ -z \"${path}\" ]];then\n        path=\"${MY_DIR}/$(echo \"${repo_url}\"|grep -Po '\\/\\K.*?(?=\\.git)')\"\n    fi\n    if [[ -e \"${path}\" ]];then\n        WARNING \"[$path] appears to already be installed.\"\n        valid_resp=0\n        while [[ \"${valid_resp}\" == \"0\" ]]\n        do\n            read -p \"Would you like to reinstall it? y/n\"$'\\n' result\n            case \"${result}\" in\n                \"y\"|\"Y\")\n                    valid_resp=1\n                    rm -rf \"${path}\"\n                    ;;\n                \"n\"|\"N\")\n                    valid_resp=1\n                    exit 0\n                    ;;\n                *)\n                    continue\n                    ;;\n            esac\n        done\n    fi\n    git clone \"${repo_url}\" \"${path}\"\n    DEBUG \"END: $FUNCNAME\"\n}\n\nfunction clone_python_raft()\n{\n    DEBUG \"BEGIN: $FUNCNAME $*\"\n    clone_repo git@github.com:rdkcentral/python_raft.git \"${RAFT_DIR}\"\n    install_pip_requirements \"${RAFT_DIR}\"/requirements.txt\n    DEBUG \"END: $FUNCNAME\"\n}\n\n### Check packages are installed ###\n# check_installed package version\ncheck_installed python3 \"3.11.8\"\n\n### Clone required repos ###\n# clone_repo url path\nclone_python_raft\n\n### Install required python packages ###\n# install_pip_requirements \n</code></pre> <p>This script should be created and run in the top level of your repo. <pre><code>new_repo\n\u251c\u2500\u2500 tests\n\u2502   \u251c\u2500\u2500 common\n\u2502   \u2514\u2500\u2500 configs\n\u2514\u2500\u2500 install.sh\n</code></pre></p> <p>Once the script is created it can be run with the following commands: <pre><code>chmod +x install.sh\n./install.sh\n</code></pre></p>"},{"location":"external_content/python_raft_wiki/Starting-a-new-testing-project/#setup-configs","title":"Setup configs","text":"<p>After running the install script you should have the following directories: <pre><code>new_repo\n\u251c\u2500\u2500 install.sh\n\u2514\u2500\u2500 tests\n    \u251c\u2500\u2500 common\n    \u251c\u2500\u2500 configs\n    \u2514\u2500\u2500 raft\n        \u251c\u2500\u2500 CHANGELOG.md\n        \u251c\u2500\u2500 CONTRIBUTING.md\n        \u251c\u2500\u2500 COPYING -&gt; LICENSE\n        \u251c\u2500\u2500 docs\n        \u251c\u2500\u2500 examples\n        \u251c\u2500\u2500 framework\n        \u251c\u2500\u2500 installation\n        \u251c\u2500\u2500 LICENSE\n        \u251c\u2500\u2500 NOTICE\n        \u251c\u2500\u2500 README.md\n        \u251c\u2500\u2500 requirements.txt\n        \u2514\u2500\u2500 tests\n</code></pre> Simply copy the example configs from <code>raft/examples/</code> to your configs directory and edit them as required. <pre><code>cd tests\ncp raft/examples/configs/example*.yml configs/\n</code></pre></p>"},{"location":"external_content/python_raft_wiki/Starting-a-new-testing-project/#additional-setup","title":"Additional setup","text":""},{"location":"external_content/python_raft_wiki/Starting-a-new-testing-project/#common-test-controller","title":"Common test controller","text":"<p>A common test controller allows users to implement their own custom methods that can be shared among all their tests.</p> <p>Create a file called <code>raft_controller.py</code> in the <code>common</code> directory and insert the following code into it. <pre><code>#!/usr/bin/env python3\n\nimport sys\nfrom os import path\n\n# Since this test is in a sub-directory we need to add the directory above\n# so we can import the framework correctly\nMY_PATH = path.abspath(__file__)\nMY_DIR = path.dirname(MY_PATH)\nsys.path.append(path.join(MY_DIR,'../raft/'))\nfrom framework.core import testController,logModule\n\nclass RAFTController(testController):\n\n    def __init__(self, testName=\"\", qcId=\"\", maxRunTime=testController.TEST_MAX_RUN_TIME, level=logModule.STEP, loop=1, log=None):\n        super().__init__(testName=testName, qcId=qcId, maxRunTime=maxRunTime, level=level, loop=loop, log=log)\n</code></pre></p>"},{"location":"external_content/python_raft_wiki/Tips-and-Tricks-for-setting-up-new-projects/","title":"Tips and Tricks for setting up new projects","text":"<p>This guide is intended as a collection of recommendations to setup a new project for testing</p>  Contents  * [Directory structure](#directory-structure) * [Install script](#install-script) * [Example of common test controller](#example-of-common-test-controller)"},{"location":"external_content/python_raft_wiki/Tips-and-Tricks-for-setting-up-new-projects/#directory-structure","title":"Directory structure","text":"<pre><code>\u2514\u2500\u2500 tests\n    \u251c\u2500\u2500 common\n    \u2514\u2500\u2500 configs\n</code></pre> <p>The above directory structure is recommended for new project with all tests being added to the test folder. The RAFT framework should also be cloned into the tests folder The common directory is used to store code that can be shared between tests. For an example of this see the common test controller The configs directory is used to store the common configuration for yours tests. It is recommended that the example rack and device configs from the raft examples folder are copied here, so they can be referred to later.</p>"},{"location":"external_content/python_raft_wiki/Tips-and-Tricks-for-setting-up-new-projects/#install-script","title":"Install script","text":"<p>Below is a bash script that can be copied and modified install all the requirements for your test project.</p> <p>It is intended to be used with the above directory structure, it should be run in the directory above <code>tests</code>.</p> <p>To modify an extend this script follow the comments at the bottom of the script. It has premade functions to allow for cloning extra repos, checking packages requirements and installing pip packages.</p> Install script  ### install.sh <pre><code>#!/usr/bin/env bash\n\nMY_PATH=\"$(realpath ${BASH_SOURCE[0]})\"\nMY_DIR=\"$(dirname ${MY_PATH})\"\nRAFT_DIR=\"${MY_DIR}/tests/raft\"\n\nNO_COLOR=\"\\e[0m\"\nRED=\"\\e[0;31m\"\nCYAN=\"\\e[0;36m\"\nYELLOW=\"\\e[1;33m\"\nGREEN=\"\\e[0;32m\"\nRED_BOLD=\"\\e[1;31m\"\nBLUE_BOLD=\"\\e[1;34m\"\nYELLOW_BOLD=\"\\e[1;33m\"\n\nfunction ECHO()\n{\n    echo -e \"$*\"\n}\n\nfunction DEBUG()\n{\n    # if set -x is in use debug messages are useless as whole stript will be shown\n    if [[ \"$-\" =~ \"x\" ]]; then\n        return\n    fi\n    if [[ \"${DEBUG_FLAG}\" == \"1\" ]];then\n        ECHO \"${BLUE_BOLD}DEBUG: ${CYAN}$*${NO_COLOR}\" &gt; /dev/stderr\n    fi\n}\n\nfunction INFO()\n{\n    ECHO \"${GREEN}$*${NO_COLOR}\"\n}\n\nfunction WARNING()\n{\n    ECHO \"${YELLOW_BOLD}Warning: ${YELLOW}$*${NO_COLOR}\" &gt; /dev/stderr\n}\n\nfunction ERROR()\n{\n    ECHO \"${RED_BOLD}ERROR: ${RED}$*${NO_COLOR}\" \n    exit 1\n}\n\n\nfunction check_installed()\n{\n    DEBUG \"BEGIN: $FUNCNAME $*\"\n    pkg=$1\n    version=$2\n    check=\"$(command -v ${pkg})\"\n    if [[ -n \"${check}\" ]];then\n        DEBUG \"Package is installed: [${pkg}]\"\n        if [[ -n \"${version}\" ]];then\n            DEBUG \"Performing version check: [${version}]\"\n            ver_check=\"$(${pkg} --version | grep ${version})\"\n            if [[ -z \"${ver_check}\" ]];then\n                ERROR \"${pkg} is installed but version is not [${version}]\"\n            fi\n            DEBUG \"${pkg} version is correct\"\n        fi\n        return\n    fi\n    ERROR \"Required package is not installed: [${pkg}]\"\n    DEBUG \"END: $FUNCNAME\"\n}\n\nfunction install_pip_requirements()\n{\n    DEBUG \"BEGIN: $FUNCNAME $*\"\n    local requirements_file=\"$1\"\n    if [[ ! -e \"${requirements_file}\" ]];then\n        ERROR \"Could not install pip requirements.\\nFile not found: [${requirements_file}]\"\n    fi\n    pip install -qr \"${requirements_file}\"\n    if [[ \"$?\" != \"0\" ]];then\n        ERROR \"Pip install failed.\\nPlease try manually with:\\ncd ${RAFT_DIR}; pip install -r requirements.txt; cd -\"\n    fi\n    DEBUG \"END: $FUNCNAME\"\n}\n\nfunction clone_repo()\n{\n    DEBUG \"BEGIN: $FUNCNAME $*\"\n    local repo_url=\"$1\"\n    if [[ -z \"${repo_url}\" ]];then\n        ERROR \"A url for a repository must be passed to the clone repo function\"\n    fi\n    local path=\"$2\"\n    if [[ -z \"${path}\" ]];then\n        path=\"${MY_DIR}/$(echo \"${repo_url}\"|grep -Po '\\/\\K.*?(?=\\.git)')\"\n    fi\n    if [[ -e \"${path}\" ]];then\n        WARNING \"[$path] appears to already be installed.\"\n        valid_resp=0\n        while [[ \"${valid_resp}\" == \"0\" ]]\n        do\n            read -p \"Would you like to reinstall it? y/n\"$'\\n' result\n            case \"${result}\" in\n                \"y\"|\"Y\")\n                    valid_resp=1\n                    rm -rf \"${path}\"\n                    ;;\n                \"n\"|\"N\")\n                    valid_resp=1\n                    exit 0\n                    ;;\n                *)\n                    continue\n                    ;;\n            esac\n        done\n    fi\n    git clone \"${repo_url}\" \"${path}\"\n    DEBUG \"END: $FUNCNAME\"\n}\n\nfunction clone_python_raft()\n{\n    DEBUG \"BEGIN: $FUNCNAME $*\"\n    clone_repo git@github.com:rdkcentral/python_raft.git \"${RAFT_DIR}\"\n    install_pip_requirements \"${RAFT_DIR}\"/requirements.txt\n    DEBUG \"END: $FUNCNAME\"\n}\n\n### Check packages are installed ###\n# check_installed package version\ncheck_installed python3 \"3.11.8\"\n\n### Clone required repos ###\n# clone_repo url path\nclone_python_raft\n\n### Install required python packages ###\n# install_pip_requirements \n</code></pre>"},{"location":"external_content/python_raft_wiki/Tips-and-Tricks-for-setting-up-new-projects/#example-of-common-test-controller","title":"Example of common test controller","text":"<pre><code>#!/usr/bin/env python3\n\nimport sys\nfrom os import path\n\n# Since this test is in a sub-directory we need to add the directory above\n# so we can import the framework correctly\nMY_PATH = path.abspath(__file__)\nMY_DIR = path.dirname(MY_PATH)\nsys.path.append(path.join(MY_DIR,'../raft/'))\nfrom framework.core import testController,logModule\n\nclass RAFTController(testController):\n\n    def __init__(self, testName=\"\", qcId=\"\", maxRunTime=testController.TEST_MAX_RUN_TIME, level=logModule.STEP, loop=1, log=None):\n        super().__init__(testName=testName, qcId=qcId, maxRunTime=maxRunTime, level=level, loop=loop, log=log)\n</code></pre> <p>The above code snippet shows how the testController can be subclassed. This allows users to implement their own custom methods that can be shared among all their tests.</p> <p>Note: If the above directory structure isn't used, the lines at the top, appending to the path, will need correcting. The path to the framework directory must be appended to the <code>sys.path</code> variable for the <code>import</code> to work.</p>"},{"location":"external_content/rmf_audio_capture/","title":"RMF Audio Capture HAL Documentation","text":""},{"location":"external_content/rmf_audio_capture/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>API</code>    - Application Programming Interface</li> <li><code>HAL</code>    - Hardware Abstraction layer</li> <li><code>PCM</code>    - Pulse Code Modulation</li> <li><code>RDK</code>    - Reference Development Kit</li> <li><code>RMF</code>    - RDK Media Framework</li> <li><code>STB</code>    - Set Top Box</li> <li><code>Caller</code> - Any user of the interface</li> </ul>"},{"location":"external_content/rmf_audio_capture/#description","title":"Description","text":"<p>RMF Audio Capture <code>HAL</code> must deliver a constant stream of raw audio data (<code>PCM</code>) to the <code>caller</code>. The purpose of audio capture is to tap the final mix of the decoded audio. The audio data delivered via this interface is required to track as closely as possible, i. e., minimal latency, to the audio that's being rendered by the device at a given point of time. Audio Capture must support capture of primary audio, and may optionally support auxiliary audio (alternate language audio tracks etc.) as well. Where auxiliary audio is supported, <code>HAL</code> must be able to support concurrent capture sessions for both primary and auxiliary audio. However, <code>caller</code> will not seek to open more than one instance of a capture per source at any point of time.</p> <p>Should a situation arise where there is no audio data available to capture (eg: no active video playback), <code>HAL</code> must continue to send buffers to caller that are filled with silence. <code>HAL</code> must maintain the expected data rate for the format while doing so.</p> <p>As far as audio format support is concerned, <code>HAL</code> is not required to support all formats and sampling rates defined in the header file. However, 16-bit stereo PCM format must be supported at a sampling rate of 44.1kHz or higher.</p> <pre><code>flowchart LR\n    subgraph Inputs\n        A1[\"audio 1\"]\n        A2[\"audio 2\"]\n        AN[\"audio N\"]\n    end\n\n    A1 --&gt; Mixer\n    A2 --&gt; Mixer\n    AN --&gt; Mixer\n\n    Mixer --&gt;|mixed audio| AudioCapture\n    AudioCapture --&gt;|to caller| Caller\n\n    Mixer --&gt;|mixed audio| Output\n    Output[\"to speaker, HDMI, SPDIF,\nbluetooth output\"]</code></pre>"},{"location":"external_content/rmf_audio_capture/#component-runtime-execution-requirements","title":"Component Runtime Execution Requirements","text":"<p>These requirements ensure that the <code>HAL</code> executes correctly within the run-time environment that it will be used in.</p>"},{"location":"external_content/rmf_audio_capture/#initialization-and-startup","title":"Initialization and Startup","text":"<p>Caller is expected to have complete control over the lifecycle of Audio Capture <code>HAL</code> (from open to close).</p>"},{"location":"external_content/rmf_audio_capture/#threading-model","title":"Threading Model","text":"<p>This interface is required to be thread-safe and will be invoked from multiple <code>caller</code> threads. Data callback <code>RMF_AudioCaptureBufferReadyCb()</code> must originate in a thread that's separate from <code>caller</code> context(s). Caller will not make any <code>HAL</code> calls in the context of <code>RMF_AudioCaptureBufferReadyCb()</code> and <code>RMF_AudioCapture_StatusChangeCb()</code>.</p>"},{"location":"external_content/rmf_audio_capture/#process-model","title":"Process Model","text":"<p>Caller will take care of Audio Capture <code>HAL</code> initialization. The interface is expected to support a single instantiation with a single process.</p>"},{"location":"external_content/rmf_audio_capture/#memory-model","title":"Memory Model","text":"<p>Audio Capture <code>HAL</code> is responsible for its own memory management. The buffer used for audio data passed by <code>RMF_AudioCaptureBufferReadyCb()</code> must be managed after the callback returns.</p>"},{"location":"external_content/rmf_audio_capture/#power-management-requirements","title":"Power Management Requirements","text":"<p>This interface is not required to be involved in any power management funtionality.</p>"},{"location":"external_content/rmf_audio_capture/#asynchronous-notification-model","title":"Asynchronous Notification Model","text":"<p>No asynchronous notification is required.</p>"},{"location":"external_content/rmf_audio_capture/#blocking-calls","title":"Blocking calls","text":"<p>The following callbacks may block depending on the <code>caller's</code> internal operations but will endeavour to return as soon as possible.</p> <ol> <li><code>RMF_AudioCaptureBufferReadyCb()</code></li> <li><code>RMF_AudioCapture_StatusChangeCb()</code></li> </ol>"},{"location":"external_content/rmf_audio_capture/#internal-error-handling","title":"Internal Error Handling","text":"<p>All APIs must return errors synchronously as a return argument. The interface is responsible for managing its internal errors.</p>"},{"location":"external_content/rmf_audio_capture/#persistence-model","title":"Persistence Model","text":"<p>There is no requirement to persist any settings information. The necessary parameters will be passed with <code>RMF_AudioCapture_Start()</code> for every audio capture session.</p>"},{"location":"external_content/rmf_audio_capture/#non-functional-requirements","title":"Non-functional requirements","text":"<p>The following non-functional requirements are required to be supported by this interface:</p>"},{"location":"external_content/rmf_audio_capture/#logging-and-debugging-requirements","title":"Logging and debugging requirements","text":"<p>This interface is required to support DEBUG, INFO and ERROR messages. DEBUG is required to be disabled by default and enabled when needed.</p>"},{"location":"external_content/rmf_audio_capture/#memory-and-performance-requirements","title":"Memory and performance requirements","text":"<p>This interface is required to use only minimal memory/CPU resources while in closed/stopped state.</p>"},{"location":"external_content/rmf_audio_capture/#quality-control","title":"Quality Control","text":"<ul> <li>This interface is required to perform static analysis, our preferred tool is Coverity.</li> <li>Have a zero-warning policy with regards to compiling. All warnings are required to be treated as errors.</li> <li>Copyright validation is required to be performed e.g.: Black duck, FossID.</li> <li>Use of memory analysis tools like Valgrind are encouraged to identify leaks/corruptions.</li> <li><code>HAL</code> Tests will endeavour to create worst case scenarios to assist investigations.</li> <li>Improvements by any party to the testing suite are required to be fed back.</li> </ul>"},{"location":"external_content/rmf_audio_capture/#licensing","title":"Licensing","text":"<p>The Audio Capture header file is released under Apache 2.0 license. The implementation may use any license compatible with the aforementioned header file.</p>"},{"location":"external_content/rmf_audio_capture/#build-requirements","title":"Build Requirements","text":"<p>This interface is required to build into shared library. The shared library must be named <code>librmfAudioCapture.so</code>. The building mechanism must be independent of Yocto.</p>"},{"location":"external_content/rmf_audio_capture/#variability-management","title":"Variability Management","text":"<p>Any new <code>API</code> introduced must be implemented by all the 3rd party modules. Currently there is little to no variability expected across various implementations. Any change to the interface must be reviewed and approved by component architects and owners.</p>"},{"location":"external_content/rmf_audio_capture/#platform-or-product-customization","title":"Platform or Product Customization","text":"<p>The default settings returned via <code>RMF_AudioCapture_GetDefaultSettings()</code> will be configured with parameters that are favourable to the implementation. The <code>caller</code> will typically not change any of these parameters unless strictly necessary.</p>"},{"location":"external_content/rmf_audio_capture/#interface-api-documentation","title":"Interface API Documentation","text":"<p><code>API</code> documentation is provided via doxygen comments in the header file.</p>"},{"location":"external_content/rmf_audio_capture/#theory-of-operations","title":"Theory of operations","text":"<p><code>Caller</code> will configure Audio Capture interface with the necessary settings and start the capture. <code>HAL</code> will deliver audio and status updates via the registered callbacks in a timely fashion. Calling <code>RMF_AudioCapture_Open()</code> is a necessary precondition for the remaining APIs to work.</p>"},{"location":"external_content/rmf_audio_capture/#architecture-diagram","title":"Architecture Diagram","text":"<pre><code>flowchart\n    D[Caller] --&gt; |control| E[Audio Capture HAL]\n    E --&gt; |audio data| D</code></pre> <p>Following is a typical sequence of operation: 1. Open the interface using <code>RMF_AudioCapture_Open()</code> or <code>RMF_AudioCapture_Open_Type()</code>. 2. Get default settings using <code>RMF_AudioCapture_GetDefaultSettings()</code>. This returns a struct of parameters favourable to the <code>HAL</code>. Application may tweak certain members of this struct and pass it with the start call. 3. Start audio capture using <code>RMF_AudioCapture_Start()</code>. The interface will continuously deliver audio data to <code>caller</code> in real time via callback <code>RMF_AudioCaptureBufferReadyCb()</code>. 4. When the audio stream is no longer needed, stop audio capture using <code>RMF_AudioCapture_Stop()</code>. This will stop the 'HAL' callbacks. 5. Close the interface using <code>RMF_AudioCapture_Close()</code>.</p>"},{"location":"external_content/rmf_audio_capture/#diagrams","title":"Diagrams","text":""},{"location":"external_content/rmf_audio_capture/#operational-call-sequence","title":"Operational call sequence","text":"<pre><code>   sequenceDiagram\n    caller-&gt;&gt;HAL: RMF_AudioCapture_Open()/RMF_AudioCapture_Open_Type()\n    activate HAL\n    HAL--&gt;&gt;caller: handle\n    deactivate HAL\n    caller-&gt;&gt;HAL: RMF_AudioCapture_GetDefaultSettings()\n    activate HAL\n    HAL--&gt;&gt;caller: default settings\n    deactivate HAL\n    caller-&gt;&gt;caller: generate settings from default settings\n    caller-&gt;&gt;HAL: RMF_AudioCapture_Start(handle, settings)\n    activate HAL\n    loop as long as stop is not called\n    HAL-&gt;&gt;caller:RMF_AudioCaptureBufferReadyCb(audio buffer)\n    activate caller\n    caller-&gt;&gt;caller:consume buffer\n    caller--&gt;&gt;HAL: return\n    deactivate caller\n    end\n    caller-&gt;&gt;HAL: RMF_AudioCapture_Stop(handle)\n    deactivate HAL\n    caller-&gt;&gt;HAL: RMF_AudioCapture_Close(handle</code></pre>"},{"location":"external_content/rmf_audio_capture/#state-machine-diagram","title":"State machine Diagram","text":"<pre><code>stateDiagram-v2\n    [*] --&gt; Open: Open()\n    Open --&gt; Started: Start()\n    Started: Started\\n(pumping data)\n    Started --&gt; Open: Stop()\n    Open --&gt; Closed: Close()\n    Closed --&gt; [*]</code></pre>"},{"location":"external_content/rmf_audio_capture/CHANGELOG/","title":"Changelog","text":""},{"location":"external_content/rmf_audio_capture/CHANGELOG/#changelog","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file. Dates are displayed in UTC.</p> <p>Generated by <code>auto-changelog</code>.</p>"},{"location":"external_content/rmf_audio_capture/CHANGELOG/#105","title":"1.0.5","text":"<ul> <li>gh #6 HAL spec updates following review <code>#7</code></li> <li>RDK-51275: HAL spec updates following review <code>26840a6</code></li> <li>Merge tag '1.0.4' into develop <code>92e29fa</code></li> </ul>"},{"location":"external_content/rmf_audio_capture/CHANGELOG/#104","title":"1.0.4","text":"<p>23 November 2023</p> <ul> <li>baseline version <code>a70dca8</code></li> <li>Added CHANGELOG.md - 1.0.4 <code>b51c356</code></li> <li>Initial commit <code>74f0003</code></li> </ul>"},{"location":"external_content/rmf_audio_capture/CONTRIBUTING/","title":"Contributing","text":"<ul> <li>If you wish to make code contributions to this project, the source is hosted at github.com/rdkcentral.</li> </ul> <p>You can submit your changes for review via that site, by raising an issue in github, (https://github.com/rdkcentral/xxxx/issues), and following the sequence below.</p> <ul> <li>create a branch with a name follow the guidelines gh(x)_(synopsis)</li> <li>where x is the ticket number</li> <li>where synopsis is a short synopsis for the reason for the branch.</li> <li>create a pull request (https://github.com/rdkcentral/xxxx/compare) when the code changes are ready for review.</li> <li> <p>The team will review, and if accepted your changes will be merged to the mainline.</p> </li> <li> <p>In order to contribute code, first-time users are requested to agree to the license.</p> </li> <li> <p>where <code>xxxx</code> is your module name</p> </li> </ul>"},{"location":"external_content/rmf_audio_capture/docs/pages/","title":"RMF Audio Capture HAL Documentation","text":""},{"location":"external_content/rmf_audio_capture/docs/pages/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>API</code>    - Application Programming Interface</li> <li><code>HAL</code>    - Hardware Abstraction layer</li> <li><code>PCM</code>    - Pulse Code Modulation</li> <li><code>RDK</code>    - Reference Development Kit</li> <li><code>RMF</code>    - RDK Media Framework</li> <li><code>STB</code>    - Set Top Box</li> <li><code>Caller</code> - Any user of the interface</li> </ul>"},{"location":"external_content/rmf_audio_capture/docs/pages/#description","title":"Description","text":"<p>RMF Audio Capture <code>HAL</code> must deliver a constant stream of raw audio data (<code>PCM</code>) to the <code>caller</code>. The purpose of audio capture is to tap the final mix of the decoded audio. The audio data delivered via this interface is required to track as closely as possible, i. e., minimal latency, to the audio that's being rendered by the device at a given point of time. Audio Capture must support capture of primary audio, and may optionally support auxiliary audio (alternate language audio tracks etc.) as well. Where auxiliary audio is supported, <code>HAL</code> must be able to support concurrent capture sessions for both primary and auxiliary audio. However, <code>caller</code> will not seek to open more than one instance of a capture per source at any point of time.</p> <p>Should a situation arise where there is no audio data available to capture (eg: no active video playback), <code>HAL</code> must continue to send buffers to caller that are filled with silence. <code>HAL</code> must maintain the expected data rate for the format while doing so.</p> <p>As far as audio format support is concerned, <code>HAL</code> is not required to support all formats and sampling rates defined in the header file. However, 16-bit stereo PCM format must be supported at a sampling rate of 44.1kHz or higher.</p> <pre><code>flowchart LR\n    subgraph Inputs\n        A1[\"audio 1\"]\n        A2[\"audio 2\"]\n        AN[\"audio N\"]\n    end\n\n    A1 --&gt; Mixer\n    A2 --&gt; Mixer\n    AN --&gt; Mixer\n\n    Mixer --&gt;|mixed audio| AudioCapture\n    AudioCapture --&gt;|to caller| Caller\n\n    Mixer --&gt;|mixed audio| Output\n    Output[\"to speaker, HDMI, SPDIF,\nbluetooth output\"]</code></pre>"},{"location":"external_content/rmf_audio_capture/docs/pages/#component-runtime-execution-requirements","title":"Component Runtime Execution Requirements","text":"<p>These requirements ensure that the <code>HAL</code> executes correctly within the run-time environment that it will be used in.</p>"},{"location":"external_content/rmf_audio_capture/docs/pages/#initialization-and-startup","title":"Initialization and Startup","text":"<p>Caller is expected to have complete control over the lifecycle of Audio Capture <code>HAL</code> (from open to close).</p>"},{"location":"external_content/rmf_audio_capture/docs/pages/#threading-model","title":"Threading Model","text":"<p>This interface is required to be thread-safe and will be invoked from multiple <code>caller</code> threads. Data callback <code>RMF_AudioCaptureBufferReadyCb()</code> must originate in a thread that's separate from <code>caller</code> context(s). Caller will not make any <code>HAL</code> calls in the context of <code>RMF_AudioCaptureBufferReadyCb()</code> and <code>RMF_AudioCapture_StatusChangeCb()</code>.</p>"},{"location":"external_content/rmf_audio_capture/docs/pages/#process-model","title":"Process Model","text":"<p>Caller will take care of Audio Capture <code>HAL</code> initialization. The interface is expected to support a single instantiation with a single process.</p>"},{"location":"external_content/rmf_audio_capture/docs/pages/#memory-model","title":"Memory Model","text":"<p>Audio Capture <code>HAL</code> is responsible for its own memory management. The buffer used for audio data passed by <code>RMF_AudioCaptureBufferReadyCb()</code> must be managed after the callback returns.</p>"},{"location":"external_content/rmf_audio_capture/docs/pages/#power-management-requirements","title":"Power Management Requirements","text":"<p>This interface is not required to be involved in any power management funtionality.</p>"},{"location":"external_content/rmf_audio_capture/docs/pages/#asynchronous-notification-model","title":"Asynchronous Notification Model","text":"<p>No asynchronous notification is required.</p>"},{"location":"external_content/rmf_audio_capture/docs/pages/#blocking-calls","title":"Blocking calls","text":"<p>The following callbacks may block depending on the <code>caller's</code> internal operations but will endeavour to return as soon as possible.</p> <ol> <li><code>RMF_AudioCaptureBufferReadyCb()</code></li> <li><code>RMF_AudioCapture_StatusChangeCb()</code></li> </ol>"},{"location":"external_content/rmf_audio_capture/docs/pages/#internal-error-handling","title":"Internal Error Handling","text":"<p>All APIs must return errors synchronously as a return argument. The interface is responsible for managing its internal errors.</p>"},{"location":"external_content/rmf_audio_capture/docs/pages/#persistence-model","title":"Persistence Model","text":"<p>There is no requirement to persist any settings information. The necessary parameters will be passed with <code>RMF_AudioCapture_Start()</code> for every audio capture session.</p>"},{"location":"external_content/rmf_audio_capture/docs/pages/#non-functional-requirements","title":"Non-functional requirements","text":"<p>The following non-functional requirements are required to be supported by this interface:</p>"},{"location":"external_content/rmf_audio_capture/docs/pages/#logging-and-debugging-requirements","title":"Logging and debugging requirements","text":"<p>This interface is required to support DEBUG, INFO and ERROR messages. DEBUG is required to be disabled by default and enabled when needed.</p>"},{"location":"external_content/rmf_audio_capture/docs/pages/#memory-and-performance-requirements","title":"Memory and performance requirements","text":"<p>This interface is required to use only minimal memory/CPU resources while in closed/stopped state.</p>"},{"location":"external_content/rmf_audio_capture/docs/pages/#quality-control","title":"Quality Control","text":"<ul> <li>This interface is required to perform static analysis, our preferred tool is Coverity.</li> <li>Have a zero-warning policy with regards to compiling. All warnings are required to be treated as errors.</li> <li>Copyright validation is required to be performed e.g.: Black duck, FossID.</li> <li>Use of memory analysis tools like Valgrind are encouraged to identify leaks/corruptions.</li> <li><code>HAL</code> Tests will endeavour to create worst case scenarios to assist investigations.</li> <li>Improvements by any party to the testing suite are required to be fed back.</li> </ul>"},{"location":"external_content/rmf_audio_capture/docs/pages/#licensing","title":"Licensing","text":"<p>The Audio Capture header file is released under Apache 2.0 license. The implementation may use any license compatible with the aforementioned header file.</p>"},{"location":"external_content/rmf_audio_capture/docs/pages/#build-requirements","title":"Build Requirements","text":"<p>This interface is required to build into shared library. The shared library must be named <code>librmfAudioCapture.so</code>. The building mechanism must be independent of Yocto.</p>"},{"location":"external_content/rmf_audio_capture/docs/pages/#variability-management","title":"Variability Management","text":"<p>Any new <code>API</code> introduced must be implemented by all the 3rd party modules. Currently there is little to no variability expected across various implementations. Any change to the interface must be reviewed and approved by component architects and owners.</p>"},{"location":"external_content/rmf_audio_capture/docs/pages/#platform-or-product-customization","title":"Platform or Product Customization","text":"<p>The default settings returned via <code>RMF_AudioCapture_GetDefaultSettings()</code> will be configured with parameters that are favourable to the implementation. The <code>caller</code> will typically not change any of these parameters unless strictly necessary.</p>"},{"location":"external_content/rmf_audio_capture/docs/pages/#interface-api-documentation","title":"Interface API Documentation","text":"<p><code>API</code> documentation is provided via doxygen comments in the header file.</p>"},{"location":"external_content/rmf_audio_capture/docs/pages/#theory-of-operations","title":"Theory of operations","text":"<p><code>Caller</code> will configure Audio Capture interface with the necessary settings and start the capture. <code>HAL</code> will deliver audio and status updates via the registered callbacks in a timely fashion. Calling <code>RMF_AudioCapture_Open()</code> is a necessary precondition for the remaining APIs to work.</p>"},{"location":"external_content/rmf_audio_capture/docs/pages/#architecture-diagram","title":"Architecture Diagram","text":"<pre><code>flowchart\n    D[Caller] --&gt; |control| E[Audio Capture HAL]\n    E --&gt; |audio data| D</code></pre> <p>Following is a typical sequence of operation: 1. Open the interface using <code>RMF_AudioCapture_Open()</code> or <code>RMF_AudioCapture_Open_Type()</code>. 2. Get default settings using <code>RMF_AudioCapture_GetDefaultSettings()</code>. This returns a struct of parameters favourable to the <code>HAL</code>. Application may tweak certain members of this struct and pass it with the start call. 3. Start audio capture using <code>RMF_AudioCapture_Start()</code>. The interface will continuously deliver audio data to <code>caller</code> in real time via callback <code>RMF_AudioCaptureBufferReadyCb()</code>. 4. When the audio stream is no longer needed, stop audio capture using <code>RMF_AudioCapture_Stop()</code>. This will stop the 'HAL' callbacks. 5. Close the interface using <code>RMF_AudioCapture_Close()</code>.</p>"},{"location":"external_content/rmf_audio_capture/docs/pages/#diagrams","title":"Diagrams","text":""},{"location":"external_content/rmf_audio_capture/docs/pages/#operational-call-sequence","title":"Operational call sequence","text":"<pre><code>   sequenceDiagram\n    caller-&gt;&gt;HAL: RMF_AudioCapture_Open()/RMF_AudioCapture_Open_Type()\n    activate HAL\n    HAL--&gt;&gt;caller: handle\n    deactivate HAL\n    caller-&gt;&gt;HAL: RMF_AudioCapture_GetDefaultSettings()\n    activate HAL\n    HAL--&gt;&gt;caller: default settings\n    deactivate HAL\n    caller-&gt;&gt;caller: generate settings from default settings\n    caller-&gt;&gt;HAL: RMF_AudioCapture_Start(handle, settings)\n    activate HAL\n    loop as long as stop is not called\n    HAL-&gt;&gt;caller:RMF_AudioCaptureBufferReadyCb(audio buffer)\n    activate caller\n    caller-&gt;&gt;caller:consume buffer\n    caller--&gt;&gt;HAL: return\n    deactivate caller\n    end\n    caller-&gt;&gt;HAL: RMF_AudioCapture_Stop(handle)\n    deactivate HAL\n    caller-&gt;&gt;HAL: RMF_AudioCapture_Close(handle</code></pre>"},{"location":"external_content/rmf_audio_capture/docs/pages/#state-machine-diagram","title":"State machine Diagram","text":"<pre><code>stateDiagram-v2\n    [*] --&gt; Open: Open()\n    Open --&gt; Started: Start()\n    Started: Started\\n(pumping data)\n    Started --&gt; Open: Stop()\n    Open --&gt; Closed: Close()\n    Closed --&gt; [*]</code></pre>"},{"location":"external_content/rmf_audio_capture/docs/pages/CHANGELOG/","title":"CHANGELOG","text":""},{"location":"external_content/rmf_audio_capture/docs/pages/CHANGELOG/#changelog","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file. Dates are displayed in UTC.</p> <p>Generated by <code>auto-changelog</code>.</p>"},{"location":"external_content/rmf_audio_capture/docs/pages/CHANGELOG/#105","title":"1.0.5","text":"<ul> <li>gh #6 HAL spec updates following review <code>#7</code></li> <li>RDK-51275: HAL spec updates following review <code>26840a6</code></li> <li>Merge tag '1.0.4' into develop <code>92e29fa</code></li> </ul>"},{"location":"external_content/rmf_audio_capture/docs/pages/CHANGELOG/#104","title":"1.0.4","text":"<p>23 November 2023</p> <ul> <li>baseline version <code>a70dca8</code></li> <li>Added CHANGELOG.md - 1.0.4 <code>b51c356</code></li> <li>Initial commit <code>74f0003</code></li> </ul>"},{"location":"external_content/rmf_audio_capture/docs/pages/CONTRIBUTING/","title":"Contributing","text":"<ul> <li>If you wish to make code contributions to this project, the source is hosted at github.com/rdkcentral.</li> </ul> <p>You can submit your changes for review via that site, by raising an issue in github, (https://github.com/rdkcentral/xxxx/issues), and following the sequence below.</p> <ul> <li>create a branch with a name follow the guidelines gh(x)_(synopsis)</li> <li>where x is the ticket number</li> <li>where synopsis is a short synopsis for the reason for the branch.</li> <li>create a pull request (https://github.com/rdkcentral/xxxx/compare) when the code changes are ready for review.</li> <li> <p>The team will review, and if accepted your changes will be merged to the mainline.</p> </li> <li> <p>In order to contribute code, first-time users are requested to agree to the license.</p> </li> <li> <p>where <code>xxxx</code> is your module name</p> </li> </ul>"},{"location":"external_content/rmf_audio_capture/docs/pages/LICENSE/","title":"LICENSE","text":"<pre><code>                             Apache License\n                       Version 2.0, January 2004\n                    http://www.apache.org/licenses/\n</code></pre> <p>TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION</p> <ol> <li> <p>Definitions.</p> <p>\"License\" shall mean the terms and conditions for use, reproduction,   and distribution as defined by Sections 1 through 9 of this document.</p> <p>\"Licensor\" shall mean the copyright owner or entity authorized by   the copyright owner that is granting the License.</p> <p>\"Legal Entity\" shall mean the union of the acting entity and all   other entities that control, are controlled by, or are under common   control with that entity. For the purposes of this definition,   \"control\" means (i) the power, direct or indirect, to cause the   direction or management of such entity, whether by contract or   otherwise, or (ii) ownership of fifty percent (50%) or more of the   outstanding shares, or (iii) beneficial ownership of such entity.</p> <p>\"You\" (or \"Your\") shall mean an individual or Legal Entity   exercising permissions granted by this License.</p> <p>\"Source\" form shall mean the preferred form for making modifications,   including but not limited to software source code, documentation   source, and configuration files.</p> <p>\"Object\" form shall mean any form resulting from mechanical   transformation or translation of a Source form, including but   not limited to compiled object code, generated documentation,   and conversions to other media types.</p> <p>\"Work\" shall mean the work of authorship, whether in Source or   Object form, made available under the License, as indicated by a   copyright notice that is included in or attached to the work   (an example is provided in the Appendix below).</p> <p>\"Derivative Works\" shall mean any work, whether in Source or Object   form, that is based on (or derived from) the Work and for which the   editorial revisions, annotations, elaborations, or other modifications   represent, as a whole, an original work of authorship. For the purposes   of this License, Derivative Works shall not include works that remain   separable from, or merely link (or bind by name) to the interfaces of,   the Work and Derivative Works thereof.</p> <p>\"Contribution\" shall mean any work of authorship, including   the original version of the Work and any modifications or additions   to that Work or Derivative Works thereof, that is intentionally   submitted to Licensor for inclusion in the Work by the copyright owner   or by an individual or Legal Entity authorized to submit on behalf of   the copyright owner. For the purposes of this definition, \"submitted\"   means any form of electronic, verbal, or written communication sent   to the Licensor or its representatives, including but not limited to   communication on electronic mailing lists, source code control systems,   and issue tracking systems that are managed by, or on behalf of, the   Licensor for the purpose of discussing and improving the Work, but   excluding communication that is conspicuously marked or otherwise   designated in writing by the copyright owner as \"Not a Contribution.\"</p> <p>\"Contributor\" shall mean Licensor and any individual or Legal Entity   on behalf of whom a Contribution has been received by Licensor and   subsequently incorporated within the Work.</p> </li> <li> <p>Grant of Copyright License. Subject to the terms and conditions of       this License, each Contributor hereby grants to You a perpetual,       worldwide, non-exclusive, no-charge, royalty-free, irrevocable       copyright license to reproduce, prepare Derivative Works of,       publicly display, publicly perform, sublicense, and distribute the       Work and such Derivative Works in Source or Object form.</p> </li> <li> <p>Grant of Patent License. Subject to the terms and conditions of       this License, each Contributor hereby grants to You a perpetual,       worldwide, non-exclusive, no-charge, royalty-free, irrevocable       (except as stated in this section) patent license to make, have made,       use, offer to sell, sell, import, and otherwise transfer the Work,       where such license applies only to those patent claims licensable       by such Contributor that are necessarily infringed by their       Contribution(s) alone or by combination of their Contribution(s)       with the Work to which such Contribution(s) was submitted. If You       institute patent litigation against any entity (including a       cross-claim or counterclaim in a lawsuit) alleging that the Work       or a Contribution incorporated within the Work constitutes direct       or contributory patent infringement, then any patent licenses       granted to You under this License for that Work shall terminate       as of the date such litigation is filed.</p> </li> <li> <p>Redistribution. You may reproduce and distribute copies of the       Work or Derivative Works thereof in any medium, with or without       modifications, and in Source or Object form, provided that You       meet the following conditions:</p> <p>(a) You must give any other recipients of the Work or       Derivative Works a copy of this License; and</p> <p>(b) You must cause any modified files to carry prominent notices       stating that You changed the files; and</p> <p>(c) You must retain, in the Source form of any Derivative Works       that You distribute, all copyright, patent, trademark, and       attribution notices from the Source form of the Work,       excluding those notices that do not pertain to any part of       the Derivative Works; and</p> <p>(d) If the Work includes a \"NOTICE\" text file as part of its       distribution, then any Derivative Works that You distribute must       include a readable copy of the attribution notices contained       within such NOTICE file, excluding those notices that do not       pertain to any part of the Derivative Works, in at least one       of the following places: within a NOTICE text file distributed       as part of the Derivative Works; within the Source form or       documentation, if provided along with the Derivative Works; or,       within a display generated by the Derivative Works, if and       wherever such third-party notices normally appear. The contents       of the NOTICE file are for informational purposes only and       do not modify the License. You may add Your own attribution       notices within Derivative Works that You distribute, alongside       or as an addendum to the NOTICE text from the Work, provided       that such additional attribution notices cannot be construed       as modifying the License.</p> <p>You may add Your own copyright statement to Your modifications and   may provide additional or different license terms and conditions   for use, reproduction, or distribution of Your modifications, or   for any such Derivative Works as a whole, provided Your use,   reproduction, and distribution of the Work otherwise complies with   the conditions stated in this License.</p> </li> <li> <p>Submission of Contributions. Unless You explicitly state otherwise,       any Contribution intentionally submitted for inclusion in the Work       by You to the Licensor shall be under the terms and conditions of       this License, without any additional terms or conditions.       Notwithstanding the above, nothing herein shall supersede or modify       the terms of any separate license agreement you may have executed       with Licensor regarding such Contributions.</p> </li> <li> <p>Trademarks. This License does not grant permission to use the trade       names, trademarks, service marks, or product names of the Licensor,       except as required for reasonable and customary use in describing the       origin of the Work and reproducing the content of the NOTICE file.</p> </li> <li> <p>Disclaimer of Warranty. Unless required by applicable law or       agreed to in writing, Licensor provides the Work (and each       Contributor provides its Contributions) on an \"AS IS\" BASIS,       WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or       implied, including, without limitation, any warranties or conditions       of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A       PARTICULAR PURPOSE. You are solely responsible for determining the       appropriateness of using or redistributing the Work and assume any       risks associated with Your exercise of permissions under this License.</p> </li> <li> <p>Limitation of Liability. In no event and under no legal theory,       whether in tort (including negligence), contract, or otherwise,       unless required by applicable law (such as deliberate and grossly       negligent acts) or agreed to in writing, shall any Contributor be       liable to You for damages, including any direct, indirect, special,       incidental, or consequential damages of any character arising as a       result of this License or out of the use or inability to use the       Work (including but not limited to damages for loss of goodwill,       work stoppage, computer failure or malfunction, or any and all       other commercial damages or losses), even if such Contributor       has been advised of the possibility of such damages.</p> </li> <li> <p>Accepting Warranty or Additional Liability. While redistributing       the Work or Derivative Works thereof, You may choose to offer,       and charge a fee for, acceptance of support, warranty, indemnity,       or other liability obligations and/or rights consistent with this       License. However, in accepting such obligations, You may act only       on Your own behalf and on Your sole responsibility, not on behalf       of any other Contributor, and only if You agree to indemnify,       defend, and hold each Contributor harmless for any liability       incurred by, or claims asserted against, such Contributor by reason       of your accepting any such warranty or additional liability.</p> </li> </ol> <p>END OF TERMS AND CONDITIONS</p> <p>APPENDIX: How to apply the Apache License to your work.</p> <pre><code>  To apply the Apache License to your work, attach the following\n  boilerplate notice, with the fields enclosed by brackets \"[]\"\n  replaced with your own identifying information. (Don't include\n  the brackets!)  The text should be enclosed in the appropriate\n  comment syntax for the file format. We also recommend that a\n  file or class name and description of purpose be included on the\n  same \"printed page\" as the copyright notice for easier\n  identification within third-party archives.\n</code></pre> <p>Copyright [yyyy] [name of copyright owner]</p> <p>Licensed under the Apache License, Version 2.0 (the \"License\");    you may not use this file except in compliance with the License.    You may obtain a copy of the License at</p> <pre><code>   http://www.apache.org/licenses/LICENSE-2.0\n</code></pre> <p>Unless required by applicable law or agreed to in writing, software    distributed under the License is distributed on an \"AS IS\" BASIS,    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.    See the License for the specific language governing permissions and    limitations under the License.</p>"},{"location":"external_content/rmf_audio_capture/docs/pages/NOTICE/","title":"NOTICE","text":"<p>This component contains software that is Copyright (c) 2023 RDK Management. The component is licensed to you under the Apache License, Version 2.0 (the \"License\"). You may not use the component except in compliance with the License.</p> <p>The component may include material which is licensed under other licenses / copyrights as listed below.  Your use of this material within the component is also subject to the terms and conditions of these licenses.  The LICENSE file contains the text of all the licenses which apply within this component.</p>"},{"location":"external_content/rmf_audio_capture/docs/pages/rmf-audio-capture_halSpec/","title":"RMF Audio Capture HAL Documentation","text":""},{"location":"external_content/rmf_audio_capture/docs/pages/rmf-audio-capture_halSpec/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>API</code>    - Application Programming Interface</li> <li><code>HAL</code>    - Hardware Abstraction layer</li> <li><code>PCM</code>    - Pulse Code Modulation</li> <li><code>RDK</code>    - Reference Development Kit</li> <li><code>RMF</code>    - RDK Media Framework</li> <li><code>STB</code>    - Set Top Box</li> <li><code>Caller</code> - Any user of the interface</li> </ul>"},{"location":"external_content/rmf_audio_capture/docs/pages/rmf-audio-capture_halSpec/#description","title":"Description","text":"<p>RMF Audio Capture <code>HAL</code> must deliver a constant stream of raw audio data (<code>PCM</code>) to the <code>caller</code>. The purpose of audio capture is to tap the final mix of the decoded audio. The audio data delivered via this interface is required to track as closely as possible, i. e., minimal latency, to the audio that's being rendered by the device at a given point of time. Audio Capture must support capture of primary audio, and may optionally support auxiliary audio (alternate language audio tracks etc.) as well. Where auxiliary audio is supported, <code>HAL</code> must be able to support concurrent capture sessions for both primary and auxiliary audio. However, <code>caller</code> will not seek to open more than one instance of a capture per source at any point of time.</p> <p>Should a situation arise where there is no audio data available to capture (eg: no active video playback), <code>HAL</code> must continue to send buffers to caller that are filled with silence. <code>HAL</code> must maintain the expected data rate for the format while doing so.</p> <p>As far as audio format support is concerned, <code>HAL</code> is not required to support all formats and sampling rates defined in the header file. However, 16-bit stereo PCM format must be supported at a sampling rate of 44.1kHz or higher.</p> <pre><code>flowchart LR\n    subgraph Inputs\n        A1[\"audio 1\"]\n        A2[\"audio 2\"]\n        AN[\"audio N\"]\n    end\n\n    A1 --&gt; Mixer\n    A2 --&gt; Mixer\n    AN --&gt; Mixer\n\n    Mixer --&gt;|mixed audio| AudioCapture\n    AudioCapture --&gt;|to caller| Caller\n\n    Mixer --&gt;|mixed audio| Output\n    Output[\"to speaker, HDMI, SPDIF,\nbluetooth output\"]</code></pre>"},{"location":"external_content/rmf_audio_capture/docs/pages/rmf-audio-capture_halSpec/#component-runtime-execution-requirements","title":"Component Runtime Execution Requirements","text":"<p>These requirements ensure that the <code>HAL</code> executes correctly within the run-time environment that it will be used in.</p>"},{"location":"external_content/rmf_audio_capture/docs/pages/rmf-audio-capture_halSpec/#initialization-and-startup","title":"Initialization and Startup","text":"<p>Caller is expected to have complete control over the lifecycle of Audio Capture <code>HAL</code> (from open to close).</p>"},{"location":"external_content/rmf_audio_capture/docs/pages/rmf-audio-capture_halSpec/#threading-model","title":"Threading Model","text":"<p>This interface is required to be thread-safe and will be invoked from multiple <code>caller</code> threads. Data callback <code>RMF_AudioCaptureBufferReadyCb()</code> must originate in a thread that's separate from <code>caller</code> context(s). Caller will not make any <code>HAL</code> calls in the context of <code>RMF_AudioCaptureBufferReadyCb()</code> and <code>RMF_AudioCapture_StatusChangeCb()</code>.</p>"},{"location":"external_content/rmf_audio_capture/docs/pages/rmf-audio-capture_halSpec/#process-model","title":"Process Model","text":"<p>Caller will take care of Audio Capture <code>HAL</code> initialization. The interface is expected to support a single instantiation with a single process.</p>"},{"location":"external_content/rmf_audio_capture/docs/pages/rmf-audio-capture_halSpec/#memory-model","title":"Memory Model","text":"<p>Audio Capture <code>HAL</code> is responsible for its own memory management. The buffer used for audio data passed by <code>RMF_AudioCaptureBufferReadyCb()</code> must be managed after the callback returns.</p>"},{"location":"external_content/rmf_audio_capture/docs/pages/rmf-audio-capture_halSpec/#power-management-requirements","title":"Power Management Requirements","text":"<p>This interface is not required to be involved in any power management funtionality.</p>"},{"location":"external_content/rmf_audio_capture/docs/pages/rmf-audio-capture_halSpec/#asynchronous-notification-model","title":"Asynchronous Notification Model","text":"<p>No asynchronous notification is required.</p>"},{"location":"external_content/rmf_audio_capture/docs/pages/rmf-audio-capture_halSpec/#blocking-calls","title":"Blocking calls","text":"<p>The following callbacks may block depending on the <code>caller's</code> internal operations but will endeavour to return as soon as possible.</p> <ol> <li><code>RMF_AudioCaptureBufferReadyCb()</code></li> <li><code>RMF_AudioCapture_StatusChangeCb()</code></li> </ol>"},{"location":"external_content/rmf_audio_capture/docs/pages/rmf-audio-capture_halSpec/#internal-error-handling","title":"Internal Error Handling","text":"<p>All APIs must return errors synchronously as a return argument. The interface is responsible for managing its internal errors.</p>"},{"location":"external_content/rmf_audio_capture/docs/pages/rmf-audio-capture_halSpec/#persistence-model","title":"Persistence Model","text":"<p>There is no requirement to persist any settings information. The necessary parameters will be passed with <code>RMF_AudioCapture_Start()</code> for every audio capture session.</p>"},{"location":"external_content/rmf_audio_capture/docs/pages/rmf-audio-capture_halSpec/#non-functional-requirements","title":"Non-functional requirements","text":"<p>The following non-functional requirements are required to be supported by this interface:</p>"},{"location":"external_content/rmf_audio_capture/docs/pages/rmf-audio-capture_halSpec/#logging-and-debugging-requirements","title":"Logging and debugging requirements","text":"<p>This interface is required to support DEBUG, INFO and ERROR messages. DEBUG is required to be disabled by default and enabled when needed.</p>"},{"location":"external_content/rmf_audio_capture/docs/pages/rmf-audio-capture_halSpec/#memory-and-performance-requirements","title":"Memory and performance requirements","text":"<p>This interface is required to use only minimal memory/CPU resources while in closed/stopped state.</p>"},{"location":"external_content/rmf_audio_capture/docs/pages/rmf-audio-capture_halSpec/#quality-control","title":"Quality Control","text":"<ul> <li>This interface is required to perform static analysis, our preferred tool is Coverity.</li> <li>Have a zero-warning policy with regards to compiling. All warnings are required to be treated as errors.</li> <li>Copyright validation is required to be performed e.g.: Black duck, FossID.</li> <li>Use of memory analysis tools like Valgrind are encouraged to identify leaks/corruptions.</li> <li><code>HAL</code> Tests will endeavour to create worst case scenarios to assist investigations.</li> <li>Improvements by any party to the testing suite are required to be fed back.</li> </ul>"},{"location":"external_content/rmf_audio_capture/docs/pages/rmf-audio-capture_halSpec/#licensing","title":"Licensing","text":"<p>The Audio Capture header file is released under Apache 2.0 license. The implementation may use any license compatible with the aforementioned header file.</p>"},{"location":"external_content/rmf_audio_capture/docs/pages/rmf-audio-capture_halSpec/#build-requirements","title":"Build Requirements","text":"<p>This interface is required to build into shared library. The shared library must be named <code>librmfAudioCapture.so</code>. The building mechanism must be independent of Yocto.</p>"},{"location":"external_content/rmf_audio_capture/docs/pages/rmf-audio-capture_halSpec/#variability-management","title":"Variability Management","text":"<p>Any new <code>API</code> introduced must be implemented by all the 3rd party modules. Currently there is little to no variability expected across various implementations. Any change to the interface must be reviewed and approved by component architects and owners.</p>"},{"location":"external_content/rmf_audio_capture/docs/pages/rmf-audio-capture_halSpec/#platform-or-product-customization","title":"Platform or Product Customization","text":"<p>The default settings returned via <code>RMF_AudioCapture_GetDefaultSettings()</code> will be configured with parameters that are favourable to the implementation. The <code>caller</code> will typically not change any of these parameters unless strictly necessary.</p>"},{"location":"external_content/rmf_audio_capture/docs/pages/rmf-audio-capture_halSpec/#interface-api-documentation","title":"Interface API Documentation","text":"<p><code>API</code> documentation is provided via doxygen comments in the header file.</p>"},{"location":"external_content/rmf_audio_capture/docs/pages/rmf-audio-capture_halSpec/#theory-of-operations","title":"Theory of operations","text":"<p><code>Caller</code> will configure Audio Capture interface with the necessary settings and start the capture. <code>HAL</code> will deliver audio and status updates via the registered callbacks in a timely fashion. Calling <code>RMF_AudioCapture_Open()</code> is a necessary precondition for the remaining APIs to work.</p>"},{"location":"external_content/rmf_audio_capture/docs/pages/rmf-audio-capture_halSpec/#architecture-diagram","title":"Architecture Diagram","text":"<pre><code>flowchart\n    D[Caller] --&gt; |control| E[Audio Capture HAL]\n    E --&gt; |audio data| D</code></pre> <p>Following is a typical sequence of operation: 1. Open the interface using <code>RMF_AudioCapture_Open()</code> or <code>RMF_AudioCapture_Open_Type()</code>. 2. Get default settings using <code>RMF_AudioCapture_GetDefaultSettings()</code>. This returns a struct of parameters favourable to the <code>HAL</code>. Application may tweak certain members of this struct and pass it with the start call. 3. Start audio capture using <code>RMF_AudioCapture_Start()</code>. The interface will continuously deliver audio data to <code>caller</code> in real time via callback <code>RMF_AudioCaptureBufferReadyCb()</code>. 4. When the audio stream is no longer needed, stop audio capture using <code>RMF_AudioCapture_Stop()</code>. This will stop the 'HAL' callbacks. 5. Close the interface using <code>RMF_AudioCapture_Close()</code>.</p>"},{"location":"external_content/rmf_audio_capture/docs/pages/rmf-audio-capture_halSpec/#diagrams","title":"Diagrams","text":""},{"location":"external_content/rmf_audio_capture/docs/pages/rmf-audio-capture_halSpec/#operational-call-sequence","title":"Operational call sequence","text":"<pre><code>   sequenceDiagram\n    caller-&gt;&gt;HAL: RMF_AudioCapture_Open()/RMF_AudioCapture_Open_Type()\n    activate HAL\n    HAL--&gt;&gt;caller: handle\n    deactivate HAL\n    caller-&gt;&gt;HAL: RMF_AudioCapture_GetDefaultSettings()\n    activate HAL\n    HAL--&gt;&gt;caller: default settings\n    deactivate HAL\n    caller-&gt;&gt;caller: generate settings from default settings\n    caller-&gt;&gt;HAL: RMF_AudioCapture_Start(handle, settings)\n    activate HAL\n    loop as long as stop is not called\n    HAL-&gt;&gt;caller:RMF_AudioCaptureBufferReadyCb(audio buffer)\n    activate caller\n    caller-&gt;&gt;caller:consume buffer\n    caller--&gt;&gt;HAL: return\n    deactivate caller\n    end\n    caller-&gt;&gt;HAL: RMF_AudioCapture_Stop(handle)\n    deactivate HAL\n    caller-&gt;&gt;HAL: RMF_AudioCapture_Close(handle</code></pre>"},{"location":"external_content/rmf_audio_capture/docs/pages/rmf-audio-capture_halSpec/#state-machine-diagram","title":"State machine Diagram","text":"<pre><code>stateDiagram-v2\n    [*] --&gt; Open: Open()\n    Open --&gt; Started: Start()\n    Started: Started\\n(pumping data)\n    Started --&gt; Open: Stop()\n    Open --&gt; Closed: Close()\n    Closed --&gt; [*]</code></pre>"},{"location":"external_content/rmf_audio_capture_test/","title":"Unit Testing Suite For RMF Audio Capture HAL","text":""},{"location":"external_content/rmf_audio_capture_test/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Acronyms, Terms and Abbreviations</li> <li>Description</li> <li>Reference Documents</li> <li>Notes</li> </ul>"},{"location":"external_content/rmf_audio_capture_test/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>L1</code> - Functional Tests</li> <li><code>L2</code> - Module functional Testing</li> <li><code>L3</code> - Module testing with External Stimulus is required to validate and control device</li> <li><code>HAL</code>- Hardware Abstraction Layer</li> <li><code>High-Level Test Specification</code> : These specification will provide a broad overview of the system's functionality from the callers' perspective. It focuses on major use cases, system behavior, and overall caller experience.</li> <li><code>Low-Level Test Specification</code> : These specification will delve deeper into the technical details. They will define specific test cases with inputs, expected outputs, and pass/fail criteria for individual functionalities, modules, or APIs.</li> </ul>"},{"location":"external_content/rmf_audio_capture_test/#description","title":"Description","text":"<p>This repository contains the Unit Test Suites(L1 &amp; L2) for RMF Audio Capture <code>HAL</code>.</p>"},{"location":"external_content/rmf_audio_capture_test/#reference-documents","title":"Reference Documents","text":"SNo Document Name Document Description Document Link 1 <code>HAL</code> Specification Document This document provides specific information on the APIs for which tests are written in this module rmf-audio-capture_halSpec.md 2 High Level Test Specification Document High Level Test Specification Documentation this module rmf-audio-capture_High-Level_TestSpec.md 3 <code>L2</code> Low Level Test Specification Document <code>L2</code>Low Level Test Specification Documentation this module rmf-audio-capture_L2-Low-Level_TestSpecification.md 4 <code>L3</code> Low Level Test Specification Document <code>L3</code>Low Level Test Specification Documentation this module rmf-audio-capture_L3_Low-Level_TestSpecification.md 5 <code>L3</code> Low Level Test Procedure Document <code>L3</code>Low Level Test Procedure Documentation this module rmf-audio-capture_L3_TestProcedure.md"},{"location":"external_content/rmf_audio_capture_test/#notes","title":"Notes","text":"<ul> <li>All APIs need to be implemented in this current version. If any API is not supported, please add stub implementation with return type RMF_SUCCESS for the same.</li> <li>Building against the actual library may introduce SOC dependencies. Hence, a template SKELETON library is created without SOC dependencies. On the real platform (target), it can be mounted, copied and bound with the actual library.</li> <li>When executing the binary, ensure to include a platform-specific profile file as an argument for the designated test cases. The following example illustrates this:</li> </ul> <p><code>bash  ./hal_test -p rmfAudioCaptureAuxSupported.yaml</code></p> <p>Alternatively, use the run.sh script with the profile file:</p> <p><code>bash ./run.sh -p /absolute/path/to/profile/file</code></p> <ul> <li>Profile files define the configuration for the platform available here at aux supported and  aux not supported</li> </ul>"},{"location":"external_content/rmf_audio_capture_test/#setting-python-environment-for-running-the-l1-l2-and-l3-automation-test-cases","title":"Setting Python environment for running the <code>L1</code> <code>L2</code> and <code>L3</code> automation test cases","text":"<ul> <li>For running the <code>L1</code> <code>L2</code> and <code>L3</code> test suite, a host PC or server with a Python environment is required.</li> <li>Install Python Environment and Activation Scripts as detailed in the HPK Documentation</li> <li>To run the <code>L1</code> <code>L2</code> test cases follow the rmf-audio-capture_L1_L2_TestProcedure.md</li> <li>To run the <code>L3</code> test cases follow the rmf-audio-capture_L3_TestProcedure.md</li> </ul>"},{"location":"external_content/rmf_audio_capture_test/CHANGELOG/","title":"Changelog","text":""},{"location":"external_content/rmf_audio_capture_test/CHANGELOG/#changelog","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file. Dates are displayed in UTC.</p> <p>Generated by <code>auto-changelog</code>.</p>"},{"location":"external_content/rmf_audio_capture_test/CHANGELOG/#140","title":"1.4.0","text":"<ul> <li>gh #23 L3 tests python implementation <code>#24</code></li> <li>gh #20 L3 C- tests implementation <code>#21</code></li> </ul>"},{"location":"external_content/rmf_audio_capture_test/CHANGELOG/#131","title":"1.3.1","text":"<p>13 August 2024</p> <ul> <li>gh #18 Update run.sh script &amp; README.md <code>#19</code></li> <li>Bumped CHANGELOG.md - 1.3.1 <code>7fdfe70</code></li> <li>Merge tag '1.3.0' into develop <code>23980f5</code></li> </ul>"},{"location":"external_content/rmf_audio_capture_test/CHANGELOG/#130","title":"1.3.0","text":"<p>9 August 2024</p> <ul> <li>gh #16 build error update <code>#17</code></li> <li>gh #14 L1 code clean up <code>#15</code></li> <li>gh# 9 L1 test profile improvement <code>#13</code></li> <li>gh #11 l2 interface update <code>#12</code></li> <li>gh #14 code cleanup <code>0c0f0aa</code></li> <li>gh #108 addressed comments <code>45bfde3</code></li> <li>gh #14 updated changes <code>24a0b07</code></li> </ul>"},{"location":"external_content/rmf_audio_capture_test/CHANGELOG/#120","title":"1.2.0","text":"<p>17 July 2024</p> <ul> <li>gh #3 High level, Low level Spec &amp; L2 code <code>#4</code></li> <li>gh #3 RDK-51420: Updated L2 test spec and implementation <code>f4b9ae8</code></li> <li>gh #3 Added image and Updated comments <code>467d0ca</code></li> <li>gh #3 removed unnecessary docs &amp; updated readme <code>65fc3c5</code></li> </ul>"},{"location":"external_content/rmf_audio_capture_test/CHANGELOG/#110","title":"1.1.0","text":"<p>5 June 2024</p> <ul> <li>gh #7 rmf_audio: enhanced error code Macro implementation <code>#8</code></li> <li>gh #7 adress review comment <code>ba738bf</code></li> <li>update for adding the MACRO for enhance code <code>f5b3312</code></li> <li>gh #7 update to fix review comments <code>ddeff81</code></li> </ul>"},{"location":"external_content/rmf_audio_capture_test/CHANGELOG/#104","title":"1.0.4","text":"<p>20 February 2024</p> <ul> <li>Bumped CHANGELOG.md - 1.0.4 <code>da66ce8</code></li> <li>Updated tag version in README.md <code>9c5bd19</code></li> <li>Merge tag '1.0.3' into develop <code>d13bed1</code></li> </ul>"},{"location":"external_content/rmf_audio_capture_test/CHANGELOG/#103","title":"1.0.3","text":"<p>29 January 2024</p> <ul> <li>gh #1 updated ut version 2 in build.sh and change UT_ASSERT_EQUAL_NOT_FATAL to UT_ASSERT_EQUAL <code>03bf24b</code></li> <li>Bumped CHANGELOG.md - 1.0.3 <code>74e3ad4</code></li> <li>Merge tag '1.0.2' into develop <code>7def399</code></li> </ul>"},{"location":"external_content/rmf_audio_capture_test/CHANGELOG/#102","title":"1.0.2","text":"<p>12 December 2023</p> <ul> <li>Bumped CHANGELOG.md - 1.0.2 <code>4391f0f</code></li> <li>Updated README.md with hal &amp; haltest supported version <code>b0f5bea</code></li> <li>Merge tag '1.0.1' into develop <code>f3d6dc5</code></li> </ul>"},{"location":"external_content/rmf_audio_capture_test/CHANGELOG/#101","title":"1.0.1","text":"<p>29 November 2023</p> <ul> <li>baseline version <code>c263cc7</code></li> <li>Added CHANGELOG.md - 1.0.1 <code>3a473f1</code></li> <li>Removed L2 template documents' references <code>8f0a404</code></li> </ul>"},{"location":"external_content/rmf_audio_capture_test/CONTRIBUTING/","title":"Contributing","text":"<ul> <li>If you wish to make code contributions to this project, the source is hosted at github.com/rdkcentral.</li> </ul> <p>You can submit your changes for review via that site, by raising an issue in github, (https://github.com/rdkcentral/xxxx/issues), and following the sequence below.</p> <ul> <li>create a branch with a name follow the guidelines gh(x)_(synopsis)</li> <li>where x is the ticket number</li> <li>where synopsis is a short synopsis for the reason for the branch.</li> <li>create a pull request (https://github.com/rdkcentral/xxxx/compare) when the code changes are ready for review.</li> <li> <p>The team will review, and if accepted your changes will be merged to the mainline.</p> </li> <li> <p>In order to contribute code, first-time users are requested to agree to the license.</p> </li> <li> <p>where <code>xxxx</code> is your module name</p> </li> </ul>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/","title":"RMF Audio Capture High Level Test Specification Documentation","text":""},{"location":"external_content/rmf_audio_capture_test/docs/pages/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>HAL</code> - Hardware Abstraction Layer, may include some common components</li> <li><code>UT</code> - Unit Test(s)</li> <li><code>SoC</code> - System on a Chip</li> <li><code>HAL</code> - Hardware Abstraction Layer</li> <li><code>API</code> - Application Programming Interface</li> <li><code>L2</code> - Level2 Testing</li> <li><code>L3</code> - Level3 Testing</li> <li><code>NA</code> - Not Applicable</li> <li><code>Y</code> - Yes</li> </ul>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/#introduction","title":"Introduction","text":"<p>This document provides an overview of the testing requirements for the RMF audio capture module. It outlines the scope of testing, objectives, testing levels and approaches, specific test requirements, and expected deliverables.</p> <ul> <li><code>HAL</code> specification is available here: rmf-audio-capture_halSpec.md</li> <li><code>HAL</code> interface is available here: rmfAudioCapture header</li> </ul>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/#test-scenarios","title":"Test Scenarios","text":"# Test Functionality Description 1 Check primary audio capture Run a capture of primary audio for a while and verify delivery of data 2 Check auxiliary audio capture Run a capture of auxiliary audio (on supported devices only) for a while and verify delivery of data 3 Check concurrent audio capture Run parallel captures of primary and auxiliary audio (on supported devices only) and verify delivery of data"},{"location":"external_content/rmf_audio_capture_test/docs/pages/#check-primary-audio-capture","title":"Check primary audio capture","text":"Description HAL APIs L2 L3 Control plane requirements Run primary audio capture for 10 seconds and verify receipt of commensurate amount of audio samples. Verify that there are no more data ready callbacks issued after the RMF_AudioCapture_Stop returns RMF_AudioCapture_Open, RMF_AudioCapture_GetDefaultSettings, RMF_AudioCapture_Start, RMF_AudioCapture_Stop, RMF_AudioCapture_Close <code>Y</code> <code>NA</code> <code>NA</code> Run primary audio capture for 10 seconds with known source material and verify that captured audio is faithful to the source within margin of error RMF_AudioCapture_Open, RMF_AudioCapture_GetDefaultSettings, RMF_AudioCapture_Start, RMF_AudioCapture_Stop, RMF_AudioCapture_Close <code>NA</code> <code>Y</code> <code>Y</code> Run primary audio capture for 2 minutes and verify that a commensurate amount of audio data is delivered. Also verify that jitter low enough to avoid underruns with an application buffer that's half the FIFO size. RMF_AudioCapture_Open, RMF_AudioCapture_GetDefaultSettings, RMF_AudioCapture_GetCurrentSettings, RMF_AudioCapture_Start, RMF_AudioCapture_Stop, RMF_AudioCapture_Close <code>NA</code> <code>Y</code> <code>N</code>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/#test-startup-requirement-check-primary-audio-capture","title":"Test Startup Requirement - Check primary audio capture","text":"<ul> <li>Ensure audio is playing in the background before starting L3 tests.</li> </ul>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/#emulator-requirements-check-primary-audio-capture","title":"Emulator Requirements - Check primary audio capture","text":"<ul> <li>Emulator to implement RMF_AudioCapture HAL that is able to deliver a known 10-second audio clip (from wav or raw PCM file) when triggered by control plane.</li> </ul>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/#control-plane-requirements-check-primary-audio-capture","title":"Control Plane Requirements - Check primary audio capture","text":"<ul> <li>Control plane must be able to trigger emulator HAL to deliver a known 10-second audio clip.</li> </ul>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/#check-auxiliary-audio-capture","title":"Check auxiliary audio capture","text":"<p>Applicable only on devices that support auxiliary capture.</p> Description HAL APIs L2 L3 Control plane requirements Run auxiliary audio capture for 10 seconds and verify receipt of commensurate amount of audio samples. Verify that there are no more data ready callbacks issued after the RMF_AudioCapture_Stop returns. Note:  read aux support from profile file <code>rmfaudiocapture\\features\\auxsupport</code> RMF_AudioCapture_Open_Type, RMF_AudioCapture_GetDefaultSettings, RMF_AudioCapture_Start, RMF_AudioCapture_Stop, RMF_AudioCapture_Close <code>Y</code> <code>NA</code> <code>NA</code> Run auxiliary audio capture for 10 seconds with known source material and verify that captured audio is faithful to the source within margin of error.Note:  read aux support from profile file <code>rmfaudiocapture\\features\\auxsupport</code> RMF_AudioCapture_Open_Type, RMF_AudioCapture_GetDefaultSettings, RMF_AudioCapture_Start, RMF_AudioCapture_Stop, RMF_AudioCapture_Close <code>NA</code> <code>Y</code> <code>Y</code> Run auxiliary audio capture for 2 minutes and verify that a commensurate amount of audio data is delivered. Also verify that jitter low enough to avoid underruns with an application buffer that's half the FIFO size. Note:  read aux support from profile file <code>rmfaudiocapture\\features\\auxsupport</code> RMF_AudioCapture_Open, RMF_AudioCapture_GetDefaultSettings, RMF_AudioCapture_GetCurrentSettings, RMF_AudioCapture_Start, RMF_AudioCapture_Stop, RMF_AudioCapture_Close <code>NA</code> <code>Y</code> <code>N</code>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/#test-startup-requirement-check-auxiliary-audio-capture","title":"Test Startup Requirement - Check auxiliary audio capture","text":"<ul> <li>Ensure audio is playing in the background before starting L3 test. Test content must have auxiliary audio track.</li> </ul>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/#emulator-requirements-check-auxiliary-audio-capture","title":"Emulator Requirements - Check auxiliary audio capture","text":"<ul> <li>Emulator to implement RMF_AudioCapture HAL that is able to deliver a known 10-second audio clip (from wav or raw PCM file) when triggered by control plane.</li> </ul>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/#control-plane-requirements-check-auxiliary-audio-capture","title":"Control Plane Requirements - Check auxiliary audio capture","text":"<ul> <li>Control plane must be able to trigger emulator HAL to deliver a known 10-second audio clip.</li> </ul>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/#check-concurrent-audio-capture","title":"Check concurrent audio capture","text":"<p>Applicable only on devices that support auxiliary capture.</p> Description HAL APIs L2 L3 Control plane requirements Run auxiliary+primary audio capture for 10 seconds and verify receipt of commensurate amount of audio samples.  Verify that there are no more data ready callbacks issued after the RMF_AudioCapture_Stop returns. Note:  read aux support from profile file <code>rmfaudiocapture\\features\\auxsupport</code> RMF_AudioCapture_Open_Type, RMF_AudioCapture_GetDefaultSettings, RMF_AudioCapture_Start, RMF_AudioCapture_Stop, RMF_AudioCapture_Close <code>Y</code> <code>NA</code> <code>NA</code> Open primary and auxiliary capture interfaces, then issue a series of start and stop calls in a mixed sequence that verifies that primary and audio capture sessions are truly independent of each other and free of side-effects when the other is started or stopped. Note:  read aux support from profile file <code>rmfaudiocapture\\features\\auxsupport</code> RMF_AudioCapture_Open_Type, RMF_AudioCapture_GetDefaultSettings, RMF_AudioCapture_Start, RMF_AudioCapture_Stop, RMF_AudioCapture_Close <code>NA</code> <code>Y</code> <code>N</code> Run auxiliary+primary audio capture for 10 seconds with known source material and verify that captured audio clips are faithful to the source within margin of error. Note:  read aux support from profile file <code>rmfaudiocapture\\features\\auxsupport</code> RMF_AudioCapture_Open_Type, RMF_AudioCapture_GetDefaultSettings, RMF_AudioCapture_Start, RMF_AudioCapture_Stop, RMF_AudioCapture_Close <code>NA</code> <code>Y</code> <code>Y</code> Run auxiliary+primary audio capture for 2 minutes and verify that a commensurate amount of audio data is delivered. Also verify that jitter low enough to avoid underruns with an application buffer that's half the FIFO size. Note:  read aux support from profile file <code>rmfaudiocapture\\features\\auxsupport</code> RMF_AudioCapture_Open_Type, RMF_AudioCapture_GetDefaultSettings, RMF_AudioCapture_GetCurrentSettings, RMF_AudioCapture_Start, RMF_AudioCapture_Stop, RMF_AudioCapture_Close <code>NA</code> <code>Y</code> <code>N</code>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/#test-startup-requirement-check-concurrent-audio-capture","title":"Test Startup Requirement - Check concurrent audio capture","text":"<ul> <li>Ensure audio is playing in the background before starting L3 test. Test content must have primary as well as auxiliary audio tracks.</li> </ul>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/#emulator-requirements-check-concurrent-audio-capture","title":"Emulator Requirements - Check concurrent audio capture","text":"<ul> <li>Emulator to implement RMF_AudioCapture HAL that is able to deliver two distinct 10-second audio clips (from wav or raw PCM file) to each capture interface when triggered by control plane. It must be able to drive primary and auxiliary captures concurrently.</li> </ul>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/#control-plane-requirements-check-concurrent-audio-capture","title":"Control Plane Requirements - Check concurrent audio capture","text":"<ul> <li>Control plane must be able to trigger emulator HAL to deliver a known 10-second audio clip.</li> </ul>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/CHANGELOG/","title":"CHANGELOG","text":""},{"location":"external_content/rmf_audio_capture_test/docs/pages/CHANGELOG/#changelog","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file. Dates are displayed in UTC.</p> <p>Generated by <code>auto-changelog</code>.</p>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/CHANGELOG/#140","title":"1.4.0","text":"<ul> <li>gh #23 L3 tests python implementation <code>#24</code></li> <li>gh #20 L3 C- tests implementation <code>#21</code></li> </ul>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/CHANGELOG/#131","title":"1.3.1","text":"<p>13 August 2024</p> <ul> <li>gh #18 Update run.sh script &amp; README.md <code>#19</code></li> <li>Bumped CHANGELOG.md - 1.3.1 <code>7fdfe70</code></li> <li>Merge tag '1.3.0' into develop <code>23980f5</code></li> </ul>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/CHANGELOG/#130","title":"1.3.0","text":"<p>9 August 2024</p> <ul> <li>gh #16 build error update <code>#17</code></li> <li>gh #14 L1 code clean up <code>#15</code></li> <li>gh# 9 L1 test profile improvement <code>#13</code></li> <li>gh #11 l2 interface update <code>#12</code></li> <li>gh #14 code cleanup <code>0c0f0aa</code></li> <li>gh #108 addressed comments <code>45bfde3</code></li> <li>gh #14 updated changes <code>24a0b07</code></li> </ul>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/CHANGELOG/#120","title":"1.2.0","text":"<p>17 July 2024</p> <ul> <li>gh #3 High level, Low level Spec &amp; L2 code <code>#4</code></li> <li>gh #3 RDK-51420: Updated L2 test spec and implementation <code>f4b9ae8</code></li> <li>gh #3 Added image and Updated comments <code>467d0ca</code></li> <li>gh #3 removed unnecessary docs &amp; updated readme <code>65fc3c5</code></li> </ul>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/CHANGELOG/#110","title":"1.1.0","text":"<p>5 June 2024</p> <ul> <li>gh #7 rmf_audio: enhanced error code Macro implementation <code>#8</code></li> <li>gh #7 adress review comment <code>ba738bf</code></li> <li>update for adding the MACRO for enhance code <code>f5b3312</code></li> <li>gh #7 update to fix review comments <code>ddeff81</code></li> </ul>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/CHANGELOG/#104","title":"1.0.4","text":"<p>20 February 2024</p> <ul> <li>Bumped CHANGELOG.md - 1.0.4 <code>da66ce8</code></li> <li>Updated tag version in README.md <code>9c5bd19</code></li> <li>Merge tag '1.0.3' into develop <code>d13bed1</code></li> </ul>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/CHANGELOG/#103","title":"1.0.3","text":"<p>29 January 2024</p> <ul> <li>gh #1 updated ut version 2 in build.sh and change UT_ASSERT_EQUAL_NOT_FATAL to UT_ASSERT_EQUAL <code>03bf24b</code></li> <li>Bumped CHANGELOG.md - 1.0.3 <code>74e3ad4</code></li> <li>Merge tag '1.0.2' into develop <code>7def399</code></li> </ul>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/CHANGELOG/#102","title":"1.0.2","text":"<p>12 December 2023</p> <ul> <li>Bumped CHANGELOG.md - 1.0.2 <code>4391f0f</code></li> <li>Updated README.md with hal &amp; haltest supported version <code>b0f5bea</code></li> <li>Merge tag '1.0.1' into develop <code>f3d6dc5</code></li> </ul>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/CHANGELOG/#101","title":"1.0.1","text":"<p>29 November 2023</p> <ul> <li>baseline version <code>c263cc7</code></li> <li>Added CHANGELOG.md - 1.0.1 <code>3a473f1</code></li> <li>Removed L2 template documents' references <code>8f0a404</code></li> </ul>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/CONTRIBUTING/","title":"Contributing","text":"<ul> <li>If you wish to make code contributions to this project, the source is hosted at github.com/rdkcentral.</li> </ul> <p>You can submit your changes for review via that site, by raising an issue in github, (https://github.com/rdkcentral/xxxx/issues), and following the sequence below.</p> <ul> <li>create a branch with a name follow the guidelines gh(x)_(synopsis)</li> <li>where x is the ticket number</li> <li>where synopsis is a short synopsis for the reason for the branch.</li> <li>create a pull request (https://github.com/rdkcentral/xxxx/compare) when the code changes are ready for review.</li> <li> <p>The team will review, and if accepted your changes will be merged to the mainline.</p> </li> <li> <p>In order to contribute code, first-time users are requested to agree to the license.</p> </li> <li> <p>where <code>xxxx</code> is your module name</p> </li> </ul>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/LICENSE/","title":"LICENSE","text":"<pre><code>                             Apache License\n                       Version 2.0, January 2004\n                    http://www.apache.org/licenses/\n</code></pre> <p>TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION</p> <ol> <li> <p>Definitions.</p> <p>\"License\" shall mean the terms and conditions for use, reproduction,   and distribution as defined by Sections 1 through 9 of this document.</p> <p>\"Licensor\" shall mean the copyright owner or entity authorized by   the copyright owner that is granting the License.</p> <p>\"Legal Entity\" shall mean the union of the acting entity and all   other entities that control, are controlled by, or are under common   control with that entity. For the purposes of this definition,   \"control\" means (i) the power, direct or indirect, to cause the   direction or management of such entity, whether by contract or   otherwise, or (ii) ownership of fifty percent (50%) or more of the   outstanding shares, or (iii) beneficial ownership of such entity.</p> <p>\"You\" (or \"Your\") shall mean an individual or Legal Entity   exercising permissions granted by this License.</p> <p>\"Source\" form shall mean the preferred form for making modifications,   including but not limited to software source code, documentation   source, and configuration files.</p> <p>\"Object\" form shall mean any form resulting from mechanical   transformation or translation of a Source form, including but   not limited to compiled object code, generated documentation,   and conversions to other media types.</p> <p>\"Work\" shall mean the work of authorship, whether in Source or   Object form, made available under the License, as indicated by a   copyright notice that is included in or attached to the work   (an example is provided in the Appendix below).</p> <p>\"Derivative Works\" shall mean any work, whether in Source or Object   form, that is based on (or derived from) the Work and for which the   editorial revisions, annotations, elaborations, or other modifications   represent, as a whole, an original work of authorship. For the purposes   of this License, Derivative Works shall not include works that remain   separable from, or merely link (or bind by name) to the interfaces of,   the Work and Derivative Works thereof.</p> <p>\"Contribution\" shall mean any work of authorship, including   the original version of the Work and any modifications or additions   to that Work or Derivative Works thereof, that is intentionally   submitted to Licensor for inclusion in the Work by the copyright owner   or by an individual or Legal Entity authorized to submit on behalf of   the copyright owner. For the purposes of this definition, \"submitted\"   means any form of electronic, verbal, or written communication sent   to the Licensor or its representatives, including but not limited to   communication on electronic mailing lists, source code control systems,   and issue tracking systems that are managed by, or on behalf of, the   Licensor for the purpose of discussing and improving the Work, but   excluding communication that is conspicuously marked or otherwise   designated in writing by the copyright owner as \"Not a Contribution.\"</p> <p>\"Contributor\" shall mean Licensor and any individual or Legal Entity   on behalf of whom a Contribution has been received by Licensor and   subsequently incorporated within the Work.</p> </li> <li> <p>Grant of Copyright License. Subject to the terms and conditions of       this License, each Contributor hereby grants to You a perpetual,       worldwide, non-exclusive, no-charge, royalty-free, irrevocable       copyright license to reproduce, prepare Derivative Works of,       publicly display, publicly perform, sublicense, and distribute the       Work and such Derivative Works in Source or Object form.</p> </li> <li> <p>Grant of Patent License. Subject to the terms and conditions of       this License, each Contributor hereby grants to You a perpetual,       worldwide, non-exclusive, no-charge, royalty-free, irrevocable       (except as stated in this section) patent license to make, have made,       use, offer to sell, sell, import, and otherwise transfer the Work,       where such license applies only to those patent claims licensable       by such Contributor that are necessarily infringed by their       Contribution(s) alone or by combination of their Contribution(s)       with the Work to which such Contribution(s) was submitted. If You       institute patent litigation against any entity (including a       cross-claim or counterclaim in a lawsuit) alleging that the Work       or a Contribution incorporated within the Work constitutes direct       or contributory patent infringement, then any patent licenses       granted to You under this License for that Work shall terminate       as of the date such litigation is filed.</p> </li> <li> <p>Redistribution. You may reproduce and distribute copies of the       Work or Derivative Works thereof in any medium, with or without       modifications, and in Source or Object form, provided that You       meet the following conditions:</p> <p>(a) You must give any other recipients of the Work or       Derivative Works a copy of this License; and</p> <p>(b) You must cause any modified files to carry prominent notices       stating that You changed the files; and</p> <p>(c) You must retain, in the Source form of any Derivative Works       that You distribute, all copyright, patent, trademark, and       attribution notices from the Source form of the Work,       excluding those notices that do not pertain to any part of       the Derivative Works; and</p> <p>(d) If the Work includes a \"NOTICE\" text file as part of its       distribution, then any Derivative Works that You distribute must       include a readable copy of the attribution notices contained       within such NOTICE file, excluding those notices that do not       pertain to any part of the Derivative Works, in at least one       of the following places: within a NOTICE text file distributed       as part of the Derivative Works; within the Source form or       documentation, if provided along with the Derivative Works; or,       within a display generated by the Derivative Works, if and       wherever such third-party notices normally appear. The contents       of the NOTICE file are for informational purposes only and       do not modify the License. You may add Your own attribution       notices within Derivative Works that You distribute, alongside       or as an addendum to the NOTICE text from the Work, provided       that such additional attribution notices cannot be construed       as modifying the License.</p> <p>You may add Your own copyright statement to Your modifications and   may provide additional or different license terms and conditions   for use, reproduction, or distribution of Your modifications, or   for any such Derivative Works as a whole, provided Your use,   reproduction, and distribution of the Work otherwise complies with   the conditions stated in this License.</p> </li> <li> <p>Submission of Contributions. Unless You explicitly state otherwise,       any Contribution intentionally submitted for inclusion in the Work       by You to the Licensor shall be under the terms and conditions of       this License, without any additional terms or conditions.       Notwithstanding the above, nothing herein shall supersede or modify       the terms of any separate license agreement you may have executed       with Licensor regarding such Contributions.</p> </li> <li> <p>Trademarks. This License does not grant permission to use the trade       names, trademarks, service marks, or product names of the Licensor,       except as required for reasonable and customary use in describing the       origin of the Work and reproducing the content of the NOTICE file.</p> </li> <li> <p>Disclaimer of Warranty. Unless required by applicable law or       agreed to in writing, Licensor provides the Work (and each       Contributor provides its Contributions) on an \"AS IS\" BASIS,       WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or       implied, including, without limitation, any warranties or conditions       of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A       PARTICULAR PURPOSE. You are solely responsible for determining the       appropriateness of using or redistributing the Work and assume any       risks associated with Your exercise of permissions under this License.</p> </li> <li> <p>Limitation of Liability. In no event and under no legal theory,       whether in tort (including negligence), contract, or otherwise,       unless required by applicable law (such as deliberate and grossly       negligent acts) or agreed to in writing, shall any Contributor be       liable to You for damages, including any direct, indirect, special,       incidental, or consequential damages of any character arising as a       result of this License or out of the use or inability to use the       Work (including but not limited to damages for loss of goodwill,       work stoppage, computer failure or malfunction, or any and all       other commercial damages or losses), even if such Contributor       has been advised of the possibility of such damages.</p> </li> <li> <p>Accepting Warranty or Additional Liability. While redistributing       the Work or Derivative Works thereof, You may choose to offer,       and charge a fee for, acceptance of support, warranty, indemnity,       or other liability obligations and/or rights consistent with this       License. However, in accepting such obligations, You may act only       on Your own behalf and on Your sole responsibility, not on behalf       of any other Contributor, and only if You agree to indemnify,       defend, and hold each Contributor harmless for any liability       incurred by, or claims asserted against, such Contributor by reason       of your accepting any such warranty or additional liability.</p> </li> </ol> <p>END OF TERMS AND CONDITIONS</p> <p>APPENDIX: How to apply the Apache License to your work.</p> <pre><code>  To apply the Apache License to your work, attach the following\n  boilerplate notice, with the fields enclosed by brackets \"[]\"\n  replaced with your own identifying information. (Don't include\n  the brackets!)  The text should be enclosed in the appropriate\n  comment syntax for the file format. We also recommend that a\n  file or class name and description of purpose be included on the\n  same \"printed page\" as the copyright notice for easier\n  identification within third-party archives.\n</code></pre> <p>Copyright [yyyy] [name of copyright owner]</p> <p>Licensed under the Apache License, Version 2.0 (the \"License\");    you may not use this file except in compliance with the License.    You may obtain a copy of the License at</p> <pre><code>   http://www.apache.org/licenses/LICENSE-2.0\n</code></pre> <p>Unless required by applicable law or agreed to in writing, software    distributed under the License is distributed on an \"AS IS\" BASIS,    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.    See the License for the specific language governing permissions and    limitations under the License.</p>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/NOTICE/","title":"NOTICE","text":"<p>This component contains software that is Copyright (c) 2023 RDK Management.</p> <p>The component is licensed to you under the Apache License, Version 2.0 (the \"License\"). You may not use the component except in compliance with the License.</p> <p>The component may include material which is licensed under other licenses / copyrights as listed below.  Your use of this material within the component is also subject to the terms and conditions of these licenses.  The LICENSE file contains the text of all the licenses which apply within this component.</p>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_High-Level_TestSpec/","title":"RMF Audio Capture High Level Test Specification Documentation","text":""},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_High-Level_TestSpec/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>HAL</code> - Hardware Abstraction Layer, may include some common components</li> <li><code>UT</code> - Unit Test(s)</li> <li><code>SoC</code> - System on a Chip</li> <li><code>HAL</code> - Hardware Abstraction Layer</li> <li><code>API</code> - Application Programming Interface</li> <li><code>L2</code> - Level2 Testing</li> <li><code>L3</code> - Level3 Testing</li> <li><code>NA</code> - Not Applicable</li> <li><code>Y</code> - Yes</li> </ul>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_High-Level_TestSpec/#introduction","title":"Introduction","text":"<p>This document provides an overview of the testing requirements for the RMF audio capture module. It outlines the scope of testing, objectives, testing levels and approaches, specific test requirements, and expected deliverables.</p> <ul> <li><code>HAL</code> specification is available here: rmf-audio-capture_halSpec.md</li> <li><code>HAL</code> interface is available here: rmfAudioCapture header</li> </ul>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_High-Level_TestSpec/#test-scenarios","title":"Test Scenarios","text":"# Test Functionality Description 1 Check primary audio capture Run a capture of primary audio for a while and verify delivery of data 2 Check auxiliary audio capture Run a capture of auxiliary audio (on supported devices only) for a while and verify delivery of data 3 Check concurrent audio capture Run parallel captures of primary and auxiliary audio (on supported devices only) and verify delivery of data"},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_High-Level_TestSpec/#check-primary-audio-capture","title":"Check primary audio capture","text":"Description HAL APIs L2 L3 Control plane requirements Run primary audio capture for 10 seconds and verify receipt of commensurate amount of audio samples. Verify that there are no more data ready callbacks issued after the RMF_AudioCapture_Stop returns RMF_AudioCapture_Open, RMF_AudioCapture_GetDefaultSettings, RMF_AudioCapture_Start, RMF_AudioCapture_Stop, RMF_AudioCapture_Close <code>Y</code> <code>NA</code> <code>NA</code> Run primary audio capture for 10 seconds with known source material and verify that captured audio is faithful to the source within margin of error RMF_AudioCapture_Open, RMF_AudioCapture_GetDefaultSettings, RMF_AudioCapture_Start, RMF_AudioCapture_Stop, RMF_AudioCapture_Close <code>NA</code> <code>Y</code> <code>Y</code> Run primary audio capture for 2 minutes and verify that a commensurate amount of audio data is delivered. Also verify that jitter low enough to avoid underruns with an application buffer that's half the FIFO size. RMF_AudioCapture_Open, RMF_AudioCapture_GetDefaultSettings, RMF_AudioCapture_GetCurrentSettings, RMF_AudioCapture_Start, RMF_AudioCapture_Stop, RMF_AudioCapture_Close <code>NA</code> <code>Y</code> <code>N</code>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_High-Level_TestSpec/#test-startup-requirement-check-primary-audio-capture","title":"Test Startup Requirement - Check primary audio capture","text":"<ul> <li>Ensure audio is playing in the background before starting L3 tests.</li> </ul>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_High-Level_TestSpec/#emulator-requirements-check-primary-audio-capture","title":"Emulator Requirements - Check primary audio capture","text":"<ul> <li>Emulator to implement RMF_AudioCapture HAL that is able to deliver a known 10-second audio clip (from wav or raw PCM file) when triggered by control plane.</li> </ul>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_High-Level_TestSpec/#control-plane-requirements-check-primary-audio-capture","title":"Control Plane Requirements - Check primary audio capture","text":"<ul> <li>Control plane must be able to trigger emulator HAL to deliver a known 10-second audio clip.</li> </ul>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_High-Level_TestSpec/#check-auxiliary-audio-capture","title":"Check auxiliary audio capture","text":"<p>Applicable only on devices that support auxiliary capture.</p> Description HAL APIs L2 L3 Control plane requirements Run auxiliary audio capture for 10 seconds and verify receipt of commensurate amount of audio samples. Verify that there are no more data ready callbacks issued after the RMF_AudioCapture_Stop returns. Note:  read aux support from profile file <code>rmfaudiocapture\\features\\auxsupport</code> RMF_AudioCapture_Open_Type, RMF_AudioCapture_GetDefaultSettings, RMF_AudioCapture_Start, RMF_AudioCapture_Stop, RMF_AudioCapture_Close <code>Y</code> <code>NA</code> <code>NA</code> Run auxiliary audio capture for 10 seconds with known source material and verify that captured audio is faithful to the source within margin of error.Note:  read aux support from profile file <code>rmfaudiocapture\\features\\auxsupport</code> RMF_AudioCapture_Open_Type, RMF_AudioCapture_GetDefaultSettings, RMF_AudioCapture_Start, RMF_AudioCapture_Stop, RMF_AudioCapture_Close <code>NA</code> <code>Y</code> <code>Y</code> Run auxiliary audio capture for 2 minutes and verify that a commensurate amount of audio data is delivered. Also verify that jitter low enough to avoid underruns with an application buffer that's half the FIFO size. Note:  read aux support from profile file <code>rmfaudiocapture\\features\\auxsupport</code> RMF_AudioCapture_Open, RMF_AudioCapture_GetDefaultSettings, RMF_AudioCapture_GetCurrentSettings, RMF_AudioCapture_Start, RMF_AudioCapture_Stop, RMF_AudioCapture_Close <code>NA</code> <code>Y</code> <code>N</code>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_High-Level_TestSpec/#test-startup-requirement-check-auxiliary-audio-capture","title":"Test Startup Requirement - Check auxiliary audio capture","text":"<ul> <li>Ensure audio is playing in the background before starting L3 test. Test content must have auxiliary audio track.</li> </ul>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_High-Level_TestSpec/#emulator-requirements-check-auxiliary-audio-capture","title":"Emulator Requirements - Check auxiliary audio capture","text":"<ul> <li>Emulator to implement RMF_AudioCapture HAL that is able to deliver a known 10-second audio clip (from wav or raw PCM file) when triggered by control plane.</li> </ul>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_High-Level_TestSpec/#control-plane-requirements-check-auxiliary-audio-capture","title":"Control Plane Requirements - Check auxiliary audio capture","text":"<ul> <li>Control plane must be able to trigger emulator HAL to deliver a known 10-second audio clip.</li> </ul>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_High-Level_TestSpec/#check-concurrent-audio-capture","title":"Check concurrent audio capture","text":"<p>Applicable only on devices that support auxiliary capture.</p> Description HAL APIs L2 L3 Control plane requirements Run auxiliary+primary audio capture for 10 seconds and verify receipt of commensurate amount of audio samples.  Verify that there are no more data ready callbacks issued after the RMF_AudioCapture_Stop returns. Note:  read aux support from profile file <code>rmfaudiocapture\\features\\auxsupport</code> RMF_AudioCapture_Open_Type, RMF_AudioCapture_GetDefaultSettings, RMF_AudioCapture_Start, RMF_AudioCapture_Stop, RMF_AudioCapture_Close <code>Y</code> <code>NA</code> <code>NA</code> Open primary and auxiliary capture interfaces, then issue a series of start and stop calls in a mixed sequence that verifies that primary and audio capture sessions are truly independent of each other and free of side-effects when the other is started or stopped. Note:  read aux support from profile file <code>rmfaudiocapture\\features\\auxsupport</code> RMF_AudioCapture_Open_Type, RMF_AudioCapture_GetDefaultSettings, RMF_AudioCapture_Start, RMF_AudioCapture_Stop, RMF_AudioCapture_Close <code>NA</code> <code>Y</code> <code>N</code> Run auxiliary+primary audio capture for 10 seconds with known source material and verify that captured audio clips are faithful to the source within margin of error. Note:  read aux support from profile file <code>rmfaudiocapture\\features\\auxsupport</code> RMF_AudioCapture_Open_Type, RMF_AudioCapture_GetDefaultSettings, RMF_AudioCapture_Start, RMF_AudioCapture_Stop, RMF_AudioCapture_Close <code>NA</code> <code>Y</code> <code>Y</code> Run auxiliary+primary audio capture for 2 minutes and verify that a commensurate amount of audio data is delivered. Also verify that jitter low enough to avoid underruns with an application buffer that's half the FIFO size. Note:  read aux support from profile file <code>rmfaudiocapture\\features\\auxsupport</code> RMF_AudioCapture_Open_Type, RMF_AudioCapture_GetDefaultSettings, RMF_AudioCapture_GetCurrentSettings, RMF_AudioCapture_Start, RMF_AudioCapture_Stop, RMF_AudioCapture_Close <code>NA</code> <code>Y</code> <code>N</code>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_High-Level_TestSpec/#test-startup-requirement-check-concurrent-audio-capture","title":"Test Startup Requirement - Check concurrent audio capture","text":"<ul> <li>Ensure audio is playing in the background before starting L3 test. Test content must have primary as well as auxiliary audio tracks.</li> </ul>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_High-Level_TestSpec/#emulator-requirements-check-concurrent-audio-capture","title":"Emulator Requirements - Check concurrent audio capture","text":"<ul> <li>Emulator to implement RMF_AudioCapture HAL that is able to deliver two distinct 10-second audio clips (from wav or raw PCM file) to each capture interface when triggered by control plane. It must be able to drive primary and auxiliary captures concurrently.</li> </ul>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_High-Level_TestSpec/#control-plane-requirements-check-concurrent-audio-capture","title":"Control Plane Requirements - Check concurrent audio capture","text":"<ul> <li>Control plane must be able to trigger emulator HAL to deliver a known 10-second audio clip.</li> </ul>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_L2-Low-Level_TestSpecification/","title":"RMF AUDIO CAPTURE L2 Low Level Test Specification and Procedure Documentation","text":""},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_L2-Low-Level_TestSpecification/#overview","title":"Overview","text":"<p>This document describes the level 2 testing suite for the RMF AUDIO CAPTURE module.</p>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_L2-Low-Level_TestSpecification/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>HAL</code> - Hardware Abstraction Layer, may include some common components</li> <li><code>UT</code>  - Unit Test(s)</li> <li><code>OEM</code>  - Original Equipment Manufacture</li> <li><code>SoC</code>  - System on a Chip</li> </ul>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_L2-Low-Level_TestSpecification/#references","title":"References","text":"<ul> <li><code>High Level Test Specification</code> - rmf-audio-capture_High-Level_TestSpec.md</li> </ul>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_L2-Low-Level_TestSpecification/#level-2-test-procedure","title":"Level 2 Test Procedure","text":"<p>The following functions are expecting to test the module operates correctly.</p>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_L2-Low-Level_TestSpecification/#test-1","title":"Test 1","text":"Title Details Function Name <code>test_l2_rmfAudioCapture_primary_data_check</code> Description Run primary audio capture for 10 seconds and verify receipt of commensurate amount of audio samples. Verify that there are no more data ready callbacks issued after the RMF_AudioCapture_Stop returns Test Group Module : 02 Test Case ID 1 Priority High <p>Pre-Conditions : None</p> <p>Dependencies : None</p> <p>User Interaction : If user chose to run the test in interactive mode, then the test case has to be selected via console.</p> <p>Test Procedure :</p> Variation / Steps Description Test Data Expected Result Notes 01 Call <code>RMF_AudioCapture_Open()</code> to open interface handle = valid pointer RMF_SUCCESS Should be successful 02 Call <code>RMF_AudioCapture_GetDefaultSettings()</code> to get default settings valid settings returns RMF_SUCCESS Should be successful 03 Call <code>RMF_AudioCapture_Start()</code> with settings obtained above to start audio capture settings=default settings from previous step, data callback will increment a static byte counter every time it runs. Data callback will also set an atomic int cookie variable to 1 every time it runs, status callback NULL RMF_SUCCESS Should be successful 04 Capture audio for 10 seconds sleep(10) N/A N/A 05 Call <code>RMF_AudioCapture_Stop</code> with handle and set cookie variable to 0 immediately afterwards handle = valid pointer RMF_SUCCESS Should be successful 06 Sleep for 1 second and verify that no more callbacks have arrived by verifying that cookie variable remains 0 N/A cookie=0 Should be successful 07 Call <code>RMF_AudioCapture_Close()</code> to release resources current handle RMF_SUCCESS Should be successful 08 Compare actual total bytes logged by data callback with expected total. Expected total = 10 * byte-rate computed from audio parameters in default settings byte rate = num. channels * bytes per channel * sampling frequency Actual bytes received must be within 10% margin of error of expected Should be successful <pre><code>flowchart TD\n    A[Call RMF_AudioCapture_Open] --&gt;|RMF_SUCCESS| B[Call RMF_AudioCapture_GetDefaultSettings]\n    A --&gt;|Failure| A1[Test case fail]\n    B --&gt;|Failure| B1[Test case fail]\n    B --&gt;|RMF_SUCCESS| B2[Call RMF_AudioCapture_Start with settings]\n    B2 --&gt; |Failure| B3[Test case fail]\n    B2 --&gt;|RMF_SUCCESS| C[Wait 10 seconds]\n    C --&gt; D[Call RMF_AudioCapture_Stop, set cookie = 0]\n    D --&gt; DCW{Wait for 1 second. &lt;br&gt; Is cookie = 0?}\n    DCW --&gt; |No| DCF[Test case fail]\n    DCW --&gt; |Yes|E[call RMF_AudioCapture_Close]\n    E --&gt; |Failure| E1[Test case fail]\n    E --&gt;|RMF_SUCCESS| F{Total captured data &lt;br&gt; size comparable to &lt;br&gt; estimated total?}\n    F --&gt;|Yes| G[Test case success]\n    F --&gt;|No| F1[Test case fail]</code></pre>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_L2-Low-Level_TestSpecification/#test-2","title":"Test 2","text":"Title Details Function Name <code>test_l2_rmfAudioCapture_auxiliary_data_check</code> Description Run auxiliary audio capture for 10 seconds and verify receipt of commensurate amount of audio samples. Verify that there are no more data ready callbacks issued after the RMF_AudioCapture_Stop returns Test Group Module : 02 Test Case ID 002 Priority High <p>Pre-Conditions : Device must support auxiliary audio capture.</p> <p>Dependencies : None</p> <p>User Interaction : If user chose to run the test in interactive mode, then the test case has to be selected via console.</p> <p>Test Procedure :</p> Variation / Steps Description Test Data Expected Result Notes 01 Call <code>RMF_AudioCapture_Open_Type()</code> to open interface handle = valid pointer, type=auxiliary RMF_SUCCESS Should be successful 02 Call <code>RMF_AudioCapture_GetDefaultSettings()</code> to get default settings valid settings returns RMF_SUCCESS Should be successful 03 Call <code>RMF_AudioCapture_Start()</code> with settings obtained above to start audio capture settings=default settings from previous step, data callback will increment a static byte counter every time it runs. Data callback will also set an atomic int cookie variable to 1 every time it runs, status callback NULL RMF_SUCCESS Should be successful 04 Capture audio for 10 seconds sleep(10) N/A N/A 05 Call <code>RMF_AudioCapture_Stop</code> with handle and set cookie variable to 0 immediately afterwards handle = valid pointer RMF_SUCCESS Should be successful 06 Sleep for 1 second and verify that no more callbacks have arrived by verifying that cookie variable remains 0 N/A cookie=0 Should be successful 07 Call <code>RMF_AudioCapture_Close()</code> to release resources current handle RMF_SUCCESS Should be successful 08 Compare actual total bytes logged by data callback with expected total. Expected total = 10 * byte-rate computed from audio parameters in default settings byte rate = num. channels * bytes per channel * sampling frequency Actual bytes received must be within 10% margin of error of expected Should be successful <pre><code>flowchart TD\n    A[Call RMF_AudioCapture_Open_Type] --&gt;|RMF_SUCCESS| B[Call RMF_AudioCapture_GetDefaultSettings]\n    A --&gt;|Failure| A1[Test case fail]\n    B --&gt;|Failure| B1[Test case fail]\n    B --&gt;|RMF_SUCCESS| B2[Call RMF_AudioCapture_Start with settings]\n    B2 --&gt; |Failure| B3[Test case fail]\n    B2 --&gt;|RMF_SUCCESS| C[Wait 10 seconds]\n    C --&gt; D[Call RMF_AudioCapture_Stop, set cookie = 0]\n    D --&gt; DCW{Wait for 1 second. &lt;br&gt; Is cookie = 0?}\n    DCW --&gt; |No| DCF[Test case fail]\n    DCW --&gt; |Yes|E[call RMF_AudioCapture_Close]\n    E --&gt; |Failure| E1[Test case fail]\n    E --&gt;|RMF_SUCCESS| F{Total captured data &lt;br&gt; size comparable to &lt;br&gt; estimated total?}\n    F --&gt;|Yes| G[Test case success]\n    F --&gt;|No| F1[Test case fail]</code></pre>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_L2-Low-Level_TestSpecification/#test-3","title":"Test 3","text":"Title Details Function Name <code>test_l2_rmfAudioCapture_combined_data_check</code> Description Run auxiliary+primary audio capture for 10 seconds and verify receipt of commensurate amount of audio samples. Verify that there are no more data ready callbacks issued after the RMF_AudioCapture_Stop returns. Test Group Module : 02 Test Case ID 003 Priority High <p>Pre-Conditions : Device must support auxiliary audio capture.</p> <p>Dependencies : None</p> <p>User Interaction : If user chose to run the test in interactive mode, then the test case has to be selected via console.</p> <p>Test Procedure :</p> Variation / Steps Description Test Data Expected Result Notes 01 Call <code>RMF_AudioCapture_Open_Type()</code> to open interface handle = valid pointer; type = \"auxiliary\" RMF_SUCCESS Should be successful 02 Call <code>RMF_AudioCapture_Open_Type()</code> to open interface handle = valid pointer; type = \"primary\" RMF_SUCCESS Should be successful 03 Call <code>RMF_AudioCapture_GetDefaultSettings()</code> to get default settings valid settings pointer returns RMF_SUCCESS Should be successful 04 Call <code>RMF_AudioCapture_Start()</code> with settings obtained above to start audio capture handle = primary handle, settings initalized to default settings, data callback will increment a static byte counter every time it runs. Data callback will also set an atomic int cookie variable to 1 every time it runs, cbBufferReadyParm = pointer to primary capture context with byte counter and cookie, status callback NULL RMF_SUCCESS Should be successful 05 Call <code>RMF_AudioCapture_Start()</code> with settings obtained above to start audio capture handle = auxiliary handle, settings initalized to default settings, data callback will increment a static byte counter every time it runs. Data callback will also set an atomic int cookie variable to 1 every time it runs, cbBufferReadyParm = pointer to auxiliary capture context with byte counter and cookie, status callback NULL RMF_SUCCESS Should be successful 06 Capture audio for 10 seconds sleep(10) N/A Should be successful 07 Call <code>RMF_AudioCapture_Stop</code> with primary handle and set primary context cookie variable to 0 immediately afterwards handle = primary RMF_SUCCESS Should be successful 08 Call <code>RMF_AudioCapture_Stop</code> with auxiliary handle and set auxiliary context cookie variable to 0 immediately afterwards handle = auxiliary RMF_SUCCESS Should be successful 09 Sleep for 1 second and verify that no more callbacks have arrived by verifying that cookie variables for both primary and auxiliary contexts remain 0 N/A primary and auxiliary cookies = 0 Should be successful 10 Call <code>RMF_AudioCapture_Close()</code> to release resources current primary handle RMF_SUCCESS Should be successful 11 Call <code>RMF_AudioCapture_Close()</code> to release resources current auxiliary handle RMF_SUCCESS Should be successful 12 Compare actual total bytes logged by data callbacks for both primary and auxiliary contexts with expected total. Expected total = 10 * byte-rate computed from audio parameters in default settings byte rate = num. channels * bytes per channel * sampling frequency Actual bytes received must be within 10% margin of error of expected Should be successful <pre><code>flowchart TD\n    A[Call RMF_AudioCapture_Open_Type &lt;br&gt; for primary] --&gt;|RMF_SUCCESS| B[Call RMF_AudioCapture_Open_Type &lt;br&gt; for auxillary]\n    A --&gt;|Fail| A_Fail[Test case fail]\n    B --&gt;|RMF_SUCCESS| C[Call RMF_AudioCapture_GetDefaultSettings]\n    B --&gt;|Fail| B_Fail[Test case fail]\n    C --&gt;|RMF_SUCCESS| D[Modify settings,&lt;br&gt; set cbBufferReady and cbBufferReadyParm for &lt;br&gt; both primary and secondary]\n    C --&gt;|Fail| C_Fail[Test case fail]\n    D --&gt; E[Call RMF_AudioCapture_Start &lt;br&gt; with primary handle]\n    E --&gt;|RMF_SUCCESS| F[Call RMF_AudioCapture_Start &lt;br&gt; with auxiliary handle]\n    E --&gt;|Fail| E_Fail[Test case fail]\n    F --&gt;|RMF_SUCCESS| G[Capture audio for 10 seconds]\n    F --&gt;|Fail| F_Fail[Test case fail]\n    G --&gt; I[Call RMF_AudioCapture_Stop &lt;br&gt; for primary handle, &lt;br&gt; set cookie = 0]\n    I --&gt;|RMF_SUCCESS| J[Call RMF_AudioCapture_Stop &lt;br&gt; for auxiliary handle, &lt;br&gt; set cookie = 0]\n    I --&gt;|Fail| I_Fail[Test case fail]\n    J --&gt;|RMF_SUCCESS| K[Wait 1 second, &lt;br&gt; verify that cookies = 0]\n    J --&gt;|Fail| J_Fail[Test case fail]\n    K --&gt; |cookies = 0|L[Call RMF_AudioCapture_Close &lt;br&gt; for primary handle]\n    K --&gt; |cookies = 1| K_FAIL[Test case fail]\n    L --&gt;|RMF_SUCCESS| M[Call RMF_AudioCapture_Close &lt;br&gt; for auxiliary handle]\n    L --&gt;|Fail| L_Fail[Test case fail]\n    M --&gt;|Fail| M_Fail[Test case fail]\n    M --&gt;|RMF_SUCCESS| N{Total captured data\\nsize comparable to\\nestimated total for\\nprimary and auxiliary?}\n    N --&gt;|Yes| N1[Test case success]\n    N --&gt;|No| N2[Test case fail]</code></pre>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_L3_Low-Level_TestSpecification/","title":"RMF Audio Capture L3 Low Level Test Specification and Procedure Documentation","text":""},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_L3_Low-Level_TestSpecification/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>HAL</code>    - Hardware Abstraction Layer</li> <li><code>API</code>    - Application Programming Interface</li> <li><code>L2</code>     - Level 2 Testing</li> <li><code>L3</code>     - Level 3 Testing</li> <li><code>DUT</code>    - Device Under Test</li> <li><code>NA</code>     - Not Applicable</li> <li><code>RAFT</code>   - Rapid Automation Framework for Testing</li> </ul>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_L3_Low-Level_TestSpecification/#overview","title":"Overview","text":"<p>This document describes the L3 Test Procedure for the RMF Audio Capture module.</p>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_L3_Low-Level_TestSpecification/#references","title":"References","text":"<ul> <li>RMF audio capture HAL Interface - rmfAudioCapture.h</li> <li>High Level Test Specification - rmf-audio-capture_High-Level_TestSpec.md</li> </ul>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_L3_Low-Level_TestSpecification/#audio-streams-requirement","title":"Audio Streams Requirement","text":"# Stream Name Description 01 Sin_120s_48k_stereo.wav 120 seconds sin wave generated at 48kz, stereo file 02 Triangle_10s_480k_stereo.wav 10 seconds triangle wave generated at 48kz, stereo file"},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_L3_Low-Level_TestSpecification/#level-3-test-cases-high-level-overview","title":"Level 3 Test Cases High Level Overview","text":"<p>Below are top test use-case for the RMF audio capture.</p> # Test-case Description HAL APIs Streams Number 1 Primary data capture Play a reference stream, run primary audio capture, verify that captured audio is faithful to the source within margin of error <code>RMF_AudioCapture_Open_Type, RMF_AudioCapture_GetDefaultSettings, RMF_AudioCapture_Start, RMF_AudioCapture_Stop, RMF_AudioCapture_Close</code> 1 2 Primary jitter test Play a reference stream, run primary audio capture, monitor jitter regularly <code>RMF_AudioCapture_Open_Type, RMF_AudioCapture_GetDefaultSettings, RMF_AudioCapture_Start, RMF_AudioCapture_Stop, RMF_AudioCapture_Close</code> 1 3 Independent data check Play reference streams simultaneously for primary and auxiliary captures, issue a series of start and stop calls in a mixed sequence that verifies that primary and audio capture sessions are truly independent of each other <code>RMF_AudioCapture_Open_Type, RMF_AudioCapture_GetDefaultSettings, RMF_AudioCapture_Start, RMF_AudioCapture_Stop, RMF_AudioCapture_Close</code> 1,2 4 Auxiliary data capture Play a reference stream, run auxiliary audio capture, verify that captured audio is faithful to the source within margin of error <code>RMF_AudioCapture_Open_Type, RMF_AudioCapture_GetDefaultSettings, RMF_AudioCapture_Start, RMF_AudioCapture_Stop, RMF_AudioCapture_Close</code> 2 5 Combined data capture Play reference streams simultaneously for primary and auxiliary captures, run primary and auxiliary audio captures, verify that captured audio is faithful to the source within margin of error <code>RMF_AudioCapture_Open_Type, RMF_AudioCapture_GetDefaultSettings, RMF_AudioCapture_Start, RMF_AudioCapture_Stop, RMF_AudioCapture_Close</code> 1,2 6 Auxiliary jitter test Play a reference stream, run auxiliary audio capture, monitor jitter regularly <code>RMF_AudioCapture_Open_Type, RMF_AudioCapture_GetDefaultSettings, RMF_AudioCapture_Start, RMF_AudioCapture_Stop, RMF_AudioCapture_Close</code> 2 7 Combined jitter test Play reference streams simultaneously for primary and auxiliary captures, run primary and auxiliary audio captures, monitor jitter regularly <code>RMF_AudioCapture_Open_Type, RMF_AudioCapture_GetDefaultSettings, RMF_AudioCapture_Start, RMF_AudioCapture_Stop, RMF_AudioCapture_Close</code> 1,2"},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_L3_Low-Level_TestSpecification/#level-3-python-test-cases-high-level-overview","title":"Level 3 Python Test Cases High Level Overview","text":"<p>The class diagram below illustrates the flow of rmfAudio L3 Python test cases:</p> <pre><code>---\ntitle: rmfAudio - Python Class Flow\n---\nclassDiagram\n    testControl &lt;|-- ut_raft : inherits\n    class ut_raft{\n    }\n    ut_raft &lt;|-- rmfAudioHelperClass : inherits\n    rmfAudioHelperClass &lt;|-- L3_TestClasses : inherits\n    L3_TestClasses ..&gt; rmfAudio : uses\n    note for testControl \"uses rackConfig.yaml and deviceConfig.yaml\"\n    note for rmfAudio \"uses platformProfile.yaml\"\n    note for L3_TestClasses \"uses testSetupConfig.yaml\"\n    note for ut_raft \"suite Navigator uses testSuite.yaml\"</code></pre> <ul> <li>testControl</li> <li>Test Control Module for running rack Testing. This module configures the <code>DUT</code> based on the rack configuration file provided to the test.</li> <li>This class is defined in <code>RAFT</code> framework. For more details refer RAFT</li> <li>ut_raft</li> <li>Python based testing framework for writing engineering tests.</li> <li>It provides common functionalities like menu navigation, configuration reader, reading user response etc.</li> <li>For more details ut-raft.</li> <li>rmfAudio</li> <li>This is test helper class which communicates with the <code>L3</code> C/C++ test running on the <code>DUT</code> through menu</li> <li>L3_TestClasses</li> <li>These are the L3 test case classes</li> <li>Each class covers the each test use-case defined in L3 Test use-cases table</li> </ul>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_L3_Low-Level_TestSpecification/#yaml-file-inputs","title":"YAML File Inputs","text":"<ul> <li>rackConfig.yaml</li> <li>Identifies the rack configuration and platform used</li> <li>References platform-specific config from <code>deviceConfig.yaml</code></li> <li> <p>For more details refer RAFT and example_rack_config.yml</p> </li> <li> <p>deviceConfig.yaml</p> </li> <li>Specifies overall configuration for the platform</li> <li>Can be overridden by:<ul> <li>Changing locally .yaml file directory</li> <li>Using --deviceConfig command line switch</li> </ul> </li> <li> <p>For more details refer RAFT and example_device_config.yml</p> </li> <li> <p>componentProfile.yaml/platformProfile.yaml</p> </li> <li>Contains component-specific configurations</li> <li>Contains platform wide configuration broken down into separate components</li> <li> <p>Example configuration file rmfAudioCaptureAuxSupported</p> </li> <li> <p>testSetupConfig.yaml</p> </li> <li>This configuration file contains the list of requirements for tests to execute. Eg: Copying the streams, setting environment variables etc.</li> <li> <p>Example configuration file rmfAudio_L3_testSetup.yml</p> </li> <li> <p>testConfig.yaml</p> </li> <li>This configuration file contains the list of menu items for C/C++ L3 test running on <code>DUT</code></li> <li>Example configuration file rmfAudio_testConfig.yml</li> </ul>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_L3_TestProcedure/","title":"RMF Audio Capture HAL L3 Python Test Procedure","text":""},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_L3_TestProcedure/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>HAL</code>    - Hardware Abstraction Layer</li> <li><code>L3</code>     - Level 3 Testing</li> <li><code>DUT</code>    - Device Under Test</li> <li><code>RAFT</code>   - Rapid Automation Framework for Testing</li> <li><code>YAML</code>   - YAML Ain't Markup Language</li> </ul>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_L3_TestProcedure/#setting-up-test-environment","title":"Setting Up Test Environment","text":"<p>To execute <code>HAL</code> <code>L3</code> Python test cases, need a Python environment. Follow these steps mentioned in HPK Public Documentation</p>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_L3_TestProcedure/#update-configuration-files","title":"Update Configuration Files","text":""},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_L3_TestProcedure/#rack-configuration-file","title":"Rack Configuration File","text":"<p>Example Rack configuration File: example_rack_config.yml</p> <p>For more details refer RAFT and example_rack_config.yml</p> <p>In this file, update the configuration to define the console sessions for the <code>DUT</code> and the outbound settings:</p> Console Session Description default Downloads the streams required for test cases ssh_player Plays the stream required for test case ssh_hal_test Executes the <code>HAL</code> binary for the test case <pre><code>rackConfig:\n  - dut:\n      ip: \"XXX.XXX.XXX.XXX\"  # IP Address of the device\n      description: \"stb device under test\"\n      platform: \"stb\"\n      consoles:\n        - default:\n            type: \"ssh\"\n            port: 10022\n            username: \"root\"\n            ip: \"XXX.XXX.XXX\" # IP address of the device\n            password: ' '\n        - ssh_player:\n            type: \"ssh\"\n            port: 10022\n            username: \"root\"\n            ip: \"XXX.XXX.XXX\" # IP address of the device\n            password: ' '\n        - ssh_hal_test:\n            type: \"ssh\"\n            port: 10022\n            username: \"root\"\n            ip: \"XXX.XXX.XXX\" # IP address of the device\n            password: ' '\n      outbound:\n        download_url: \"tftp://tftp-server.com/rack1/slot1/\"    # Download location for the CPE device\n        upload_url: \"sftp://server-address/home/workspace/tftp/rack1/slot1/\" # Upload location\n        upload_url_base_dir: \"sftp://server-address/home/workspace/tftp/rack1/slot1\"\n        httpProxy:   # Local proxy if required\n        workspaceDirectory: './logs/workspace'   # Local working directory\n</code></pre>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_L3_TestProcedure/#device-configuration-file","title":"Device Configuration File","text":"<p>Example Device configuration File: deviceConfig.yml</p> <p>For more details refer RAFT and example_device_config.yml</p> <p>Update below fileds in the device configuration file: - Set the folder path for <code>target_directory</code> where <code>HAL</code> binaries will be copied onto the device. - Specify the device profile path in <code>test/profile</code> - Update <code>streams_download_url</code> with the URL from which the streams will be downloaded - Ensure the <code>platform</code> should match with the <code>DUT</code> <code>platform</code> in Rack Configuration</p> <pre><code>deviceConfig:\n    cpe1:\n        platform: \"linux\"\n        model: \"uk\"\n        soc_vendor: \"intel\"\n        target_directory: \"/tmp/\"  # Target Directory on device\n        prompt: \"\" # Prompt string on console\n        test:\n            profile: \"../../../profiles/rmfAudioCaptureAuxSupported.yaml\"\n            streams_download_url: \"&lt;URL_Path&gt;\" #URL path from which the streams are downloaded to the device\n</code></pre>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_L3_TestProcedure/#test-setup-configuration-file","title":"Test Setup Configuration File","text":"<p>Example Test Setup configuration File: rmfAudio_L3_testSetup.yml</p> <p>Provide the streams for each test case. This path is appended with <code>streams_download_url</code> entry from Device Configuration File</p> <p>If a test case requires multiple streams or needs to be validated using several streams, ensure that all necessary streams are added sequentially for that specific test case.</p> <pre><code>rmfaudiocapture:\n  description: \"RMF Audio Capture test setup\"\n  assets:\n    device:\n      test01_primaryDataCapture:\n        postcmd:  #Setting this env. variable is required to run with mock implementation\n          - \"export INPUT_PRIMARY=&lt;PATH on Device&gt;/Sin_120s_48k_stereo.wav\"\n        streams:\n          - \"streams/Sin_120s_48k_stereo.wav\"\n      test02_primaryJitterTest:\n        postcmd:  #Setting this env. variable is required to run with mock implementation\n          - \"export INPUT_PRIMARY=&lt;PATH on Device&gt;/Sin_120s_48k_stereo.wav\"\n        streams:\n          - \"streams/Sin_120s_48k_stereo.wav\"\n      test03_independentDataCheck:\n        postcmd:  #Setting this env. variable is required to run with mock implementation\n          - \"export INPUT_PRIMARY=&lt;PATH on Device&gt;/Sin_10s_48k_stereo.wav\"\n          - \"export INPUT_AUXILIARY=&lt;PATH on Device&gt;/Triangle_10s_480k_stereo.wav\"\n        streams:\n          - \"streams/Sin_10s_48k_stereo.wav\"\n          - \"streams/Triangle_10s_480k_stereo.wav\"\n      test04_auxiliaryDataCapture:\n        postcmd:  #Setting this env. variable is required to run with mock implementation\n          - \"export INPUT_AUXILIARY=&lt;PATH on Device&gt;/Triangle_10s_480k_stereo.wav\"\n        streams: \n          - \"streams/Triangle_10s_480k_stereo.wav\"\n</code></pre>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_L3_TestProcedure/#test-configuration","title":"Test Configuration","text":"<p>Example Test Setup configuration File: rmfAudio_testConfig.yml</p> <p>Update the execute command according to the device path where <code>HAL</code> binaries are copied.</p> <pre><code>rmfaudiocapture:\n    description: \"RMF Audio Capture testing profile / menu system for UT\"\n    test:\n        artifacts:\n        #List of artifacts folders, test class copies the content of folder to the target device workspace\n          - \"../../../bin/\"\n        # exectute command, this will appended with the target device workspace path\n        execute: \"run.sh\"\n        type: UT-C # C (UT-C Cunit) / C++ (UT-G (g++ ut-core gtest backend))\n</code></pre>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_L3_TestProcedure/#run-test-cases","title":"Run Test Cases","text":"<p>Once the environment is set up, you can execute the test cases with the following command</p> <pre><code>python &lt;TestCaseName.py&gt; --config &lt;/PATH&gt;/ut/host/tests/configs/example_rack_config.yml --deviceConfig &lt;/PATH&gt;/ut/host/tests/configs/deviceConfig.yml\n</code></pre>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_L3_TestProcedure/#streams-required","title":"Streams Required","text":"<p>Refer rmf-audio-capture_L3_Low-Level_TestSpecification.md for the stream details</p>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_L3_TestProcedure/#test-cases","title":"Test Cases","text":""},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_L3_TestProcedure/#rmfaudio_test01_primarydatacapturepy","title":"rmfAudio_test01_primaryDataCapture.py","text":""},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_L3_TestProcedure/#user-input-required-test01","title":"User Input Required - test01","text":"<p>No</p>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_L3_TestProcedure/#acceptance-criteria-test01","title":"Acceptance Criteria - test01","text":"<p>Play Stream #1 and confirm that the captured audio matches with played reference stream.</p>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_L3_TestProcedure/#expected-results-test01","title":"Expected Results - test01","text":"<p>The test plays a reference stream, captures audio data on primary capture interface and verifies that the captured data matches with reference stream.</p> <p>Success Criteria</p> <ul> <li>Audio data should be captured on primary capture interface and written to a wav output file.</li> <li>Captured audio should match with played reference stream.</li> </ul>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_L3_TestProcedure/#test-steps-test01","title":"Test Steps - test01","text":"<ul> <li> <p>Run the Test:</p> </li> <li> <p>Select and run the Python script: <code>rmfAudio_test01_primaryDataCapture.py</code></p> </li> <li> <p>Download and Setup:</p> </li> </ul> <p>The test will automatically download all necessary artifacts and streams, and copy them to the target directory on the device.</p> <ul> <li> <p>Primary capture interface data Verification:</p> <p>The test will play the designated audio stream and start audio capture on primary capture interface.</p> </li> <li> <p>The test will validate captured audio data with reference audio stream with a given threshold.</p> </li> <li>If the files are a match within given threshold, the step is marked as PASS.</li> <li> <p>If the files are not a match within given threshold, the step is marked as FAIL.</p> </li> <li> <p>Completion and result:</p> </li> </ul> <p>Upon playing a designated audio stream and capturing audio data through primary capture interface, the test will conclude and present a final result: PASS or FAIL based on file comparison between capture audio data and played stream.</p>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_L3_TestProcedure/#rmfaudio_test02_primaryjittertestpy","title":"rmfAudio_test02_primaryJitterTest.py","text":""},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_L3_TestProcedure/#user-input-required-test02","title":"User Input Required - test02","text":"<p>No</p>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_L3_TestProcedure/#acceptance-criteria-test02","title":"Acceptance Criteria - test02","text":"<p>Play Stream #1 and confirm that there is no jitter detected on primary capture interface.</p>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_L3_TestProcedure/#expected-results-test02","title":"Expected Results - test02","text":"<p>The test plays a reference stream, checks bytes of audio data received on primary capture interface and verifies there is no jitter detected on primary capture interface.</p>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_L3_TestProcedure/#test-steps-test02","title":"Test Steps - test02","text":"<ul> <li> <p>Run the Test:</p> </li> <li> <p>Select and run the Python script: <code>rmfAudio_test02_primaryJitterTest.py</code></p> </li> <li> <p>Download and Setup:</p> </li> </ul> <p>The test will automatically download all necessary artifacts and streams, and copy them to the target directory on the device.</p> <ul> <li> <p>Primary capture jitter Verification:</p> <p>The test will play the designated audio stream and start monitoring bytes received on primary capture interface.</p> </li> <li> <p>The test will monitor bytes received on primary audio capture continuously against a set threshold.</p> </li> <li>If bytes captured are greater than given threshold, the step is marked as PASS.</li> <li> <p>If bytes captured are less than given threshold, the step is marked as FAIL.</p> </li> <li> <p>Completion and Result:</p> </li> </ul> <p>Upon playing a designated audio stream and monitoring bytes received on primary data interface, the test will conclude and present a final result: PASS or FAIL based on whether bytes captured were within a given threshold.</p>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_L3_TestProcedure/#rmfaudio_test03_independentdatacheckpy","title":"rmfAudio_test03_independentDataCheck.py","text":""},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_L3_TestProcedure/#user-input-required-test03","title":"User Input Required - test03","text":"<p>No</p>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_L3_TestProcedure/#acceptance-criteria-test03","title":"Acceptance Criteria - test03","text":"<p>Play Stream #1 and Stream #2 and verify that primary and auxiliary data captures work independent of each other.</p>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_L3_TestProcedure/#expected-results-test03","title":"Expected Results - test03","text":"<p>The test plays a reference stream each on primary and auxiliary interfaces, then issues a series of start and stop calls in a mixed sequence that verifies that primary and audio capture sessions are truly independent of each other and free of side-effects when the other is started or stopped.</p>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_L3_TestProcedure/#test-steps-test03","title":"Test Steps - test03","text":"<ul> <li> <p>Run the Test:</p> </li> <li> <p>Select and run the Python script: <code>rmfAudio_test03_independentDataCheck.py</code></p> </li> <li> <p>Download and Setup:</p> </li> </ul> <p>The test will automatically download all necessary artifacts and streams, and copy them to the target directory on the device.</p> <ul> <li> <p>Independent data check Verification:</p> <p>The test will play the designated audio stream on both primary and auxiliary interfaces and start monitoring bytes received before and after each start and stop call.</p> </li> <li> <p>The test will check bytes received on primary and auxiliary audio capture during series of start and stop calls in a mixed sequence. </p> </li> <li>If bytes captured shows that the captures are independent of each other, the step is marked as PASS.</li> <li> <p>If bytes captured shows that the captures are dependent on each other, the step is marked as FAIL.</p> </li> <li> <p>Completion and Result:</p> </li> </ul> <p>Upon playing a designated audio stream each on primary and auxiliary interfaces, the test will conclude and present a final result: PASS or FAIL based on whether bytes captured shows that the captures are independent of each other</p>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_L3_TestProcedure/#rmfaudio_test04_auxiliarydatacapturepy","title":"rmfAudio_test04_auxiliaryDataCapture.py","text":""},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_L3_TestProcedure/#user-input-required-test04","title":"User Input Required - test04","text":"<p>No</p>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_L3_TestProcedure/#acceptance-criteria-test04","title":"Acceptance Criteria - test04","text":"<p>Play Stream #2 and confirm that the captured audio matches with played reference stream.</p>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_L3_TestProcedure/#expected-results-test04","title":"Expected Results - test04","text":"<p>The test plays a reference stream, captures audio data on auxiliary capture interface and verifies that the captured data matches with reference stream.</p> <p>Success Criteria</p> <ul> <li>Audio data should be captured on auxiliary capture interface and written to a wav output file.</li> <li>Captured audio should match with played reference stream.</li> </ul>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_L3_TestProcedure/#test-steps-test04","title":"Test Steps - test04","text":"<ul> <li> <p>Run the Test:</p> </li> <li> <p>Select and run the Python script: <code>rmfAudio_test04_auxiliaryDataCapture.py</code></p> </li> <li> <p>Download and Setup:</p> </li> </ul> <p>The test will automatically download all necessary artifacts and streams, and copy them to the target directory on the device.</p> <ul> <li> <p>Auxiliary capture interface data Verification:</p> <p>The test will play the designated audio stream and start audio capture on auxiliary capture interface.</p> </li> <li> <p>The test will validate captured audio data with reference audio stream with a given threshold.</p> </li> <li>If the files are a match within given threshold, the step is marked as PASS.</li> <li> <p>If the files are not a match within given threshold, the step is marked as FAIL.</p> </li> <li> <p>Completion and result:</p> </li> </ul> <p>Upon playing a designated audio stream and capturing audio data through auxiliary capture interface, the test will conclude and present a final result: PASS or FAIL based on file comparison between capture audio data and played stream.</p>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_L3_TestProcedure/#rmfaudio_test05_combineddatacapturepy","title":"rmfAudio_test05_combinedDataCapture.py","text":""},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_L3_TestProcedure/#user-input-required-test05","title":"User Input Required - test05","text":"<p>No</p>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_L3_TestProcedure/#acceptance-criteria-test05","title":"Acceptance Criteria - test05","text":"<p>Play Stream #1 and Stream #2 and confirm that the captured audio matches with played reference stream.</p>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_L3_TestProcedure/#expected-results-test05","title":"Expected Results - test05","text":"<p>The test plays a reference stream, captures audio data on both primary and auxiliary capture interfaces and verifies that the captured data matches with corresponding reference stream.</p> <p>Success Criteria</p> <ul> <li>Audio data should be captured on primary and auxiliary capture interfaces simulataneously and written to a wav output file.</li> <li>Captured audio should match with corresponding played reference stream.</li> </ul>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_L3_TestProcedure/#test-steps-test05","title":"Test Steps - test05","text":"<ul> <li> <p>Run the Test:</p> </li> <li> <p>Select and run the Python script: <code>rmfAudio_test05_combinedDataCapture.py</code></p> </li> <li> <p>Download and Setup:</p> </li> </ul> <p>The test will automatically download all necessary artifacts and streams, and copy them to the target directory on the device.</p> <ul> <li> <p>Combined audio capture data Verification:</p> <p>The test will play the designated audio streams and start audio capture simulataneously on primary and auxiliary capture interfaces.</p> </li> <li> <p>The test will validate captured audio data with corresponding reference audio stream with a given threshold.</p> </li> <li>If the files are a match within given threshold, the step is marked as PASS.</li> <li> <p>If the files are not a match within given threshold, the step is marked as FAIL.</p> </li> <li> <p>Completion and result:</p> </li> </ul> <p>Upon playing a designated audio stream and capturing audio data simultaneously through primary and auxiliary capture interfaces, the test will conclude and present a final result: PASS or FAIL based on file comparison between capture audio data and played stream.</p>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_L3_TestProcedure/#rmfaudio_test06_auxiliaryjittertestpy","title":"rmfAudio_test06_auxiliaryJitterTest.py","text":""},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_L3_TestProcedure/#user-input-required-test06","title":"User Input Required - test06","text":"<p>No</p>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_L3_TestProcedure/#acceptance-criteria-test06","title":"Acceptance Criteria - test06","text":"<p>Play Stream #2 and confirm that there is no jitter detected on auxiliary capture interface.</p>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_L3_TestProcedure/#expected-results-test06","title":"Expected Results - test06","text":"<p>The test plays a reference stream, checks bytes of audio data received on auxiliary capture interface and verifies there is no jitter detected on auxiliary capture interface.</p>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_L3_TestProcedure/#test-steps-test06","title":"Test Steps - test06","text":"<ul> <li> <p>Run the Test:</p> </li> <li> <p>Select and run the Python script: <code>rmfAudio_test06_auxiliaryJitterTest.py</code></p> </li> <li> <p>Download and Setup:</p> </li> </ul> <p>The test will automatically download all necessary artifacts and streams, and copy them to the target directory on the device.</p> <ul> <li> <p>Auxiliary capture jitter Verification:</p> <p>The test will play the designated audio stream and start monitoring bytes received on auxiliary capture interface.</p> </li> <li> <p>The test will monitor bytes received on auxiliary capture continuously against a set threshold.</p> </li> <li>If bytes captured are greater than given threshold, the step is marked as PASS.</li> <li> <p>If bytes captured are less than given threshold, the step is marked as FAIL.</p> </li> <li> <p>Completion and Result:</p> </li> </ul> <p>Upon playing a designated audio stream and monitoring bytes received on auxiliary capture interface, the test will conclude and present a final result: PASS or FAIL based on whether bytes captured were within a given threshold.</p>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_L3_TestProcedure/#rmfaudio_test07_combinedjittertestpy","title":"rmfAudio_test07_combinedJitterTest.py","text":""},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_L3_TestProcedure/#user-input-required-test07","title":"User Input Required - test07","text":"<p>No</p>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_L3_TestProcedure/#acceptance-criteria-test07","title":"Acceptance Criteria - test07","text":"<p>Play Stream #1 and Stream #2 and confirm that there is no jitter detected on primary and auxiliary capture interfaces.</p>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_L3_TestProcedure/#expected-results-test07","title":"Expected Results - test07","text":"<p>The test plays a reference stream, checks bytes of audio data received simulataneously on primary and auxiliary capture interface and verifies there is no jitter detected on both audio capture interfaces.</p>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_L3_TestProcedure/#test-steps-test07","title":"Test Steps - test07","text":"<ul> <li> <p>Run the Test:</p> </li> <li> <p>Select and run the Python script: <code>rmfAudio_test07_combinedJitterTest.py</code></p> </li> <li> <p>Download and Setup:</p> </li> </ul> <p>The test will automatically download all necessary artifacts and streams, and copy them to the target directory on the device.</p> <ul> <li> <p>Primary and auxiliary combined capture jitter Verification:</p> <p>The test will play the designated audio streams and start monitoring bytes received on primary and auxiliary capture interfaces.</p> </li> <li> <p>The test will monitor bytes received on primary and auxiliary audio captures continuously against a set threshold.</p> </li> <li>If bytes captured are greater than given threshold, the step is marked as PASS.</li> <li> <p>If bytes captured are less than given threshold, the step is marked as FAIL.</p> </li> <li> <p>Completion and Result:</p> </li> </ul> <p>Upon playing a designated audio stream and monitoring bytes received on primary and auxiliary capture interfaces, the test will conclude and present a final result: PASS or FAIL based on whether bytes captured were within a given threshold.</p>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_L3_TestProcedure/#rmfaudio_l3_runallpy","title":"rmfAudio_L3_Runall.py","text":"<p>This python file runs all the tests</p> <pre><code>python rmfAudio_L3_Runall.py --config &lt;/PATH&gt;/ut/host/tests/configs/example_rack_config.yml --deviceConfig &lt;/PATH&gt;/ut/host/tests/configs/deviceConfig.yml\n</code></pre>"},{"location":"external_content/rmf_audio_capture_test/docs/pages/rmf-audio-capture_L3_TestProcedure/#rmfaudio_l3_runall_primarypy","title":"rmfAudio_L3_Runall_primary.py","text":"<p>This python file runs all the tests for primary audio capture</p> <pre><code>python rmfAudio_L3_Runall_primary.py --config &lt;/PATH&gt;/ut/host/tests/configs/example_rack_config.yml --deviceConfig &lt;/PATH&gt;/ut/host/tests/configs/deviceConfig.yml\n</code></pre>"},{"location":"external_content/tvsettings/","title":"TV Settings HAL Documentation","text":""},{"location":"external_content/tvsettings/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>CPU</code> - Central Processing Unit</li> <li><code>HAL</code> - Hardware Abstraction layer</li> <li><code>PQ</code>  - Picture Quality</li> <li><code>SOC</code> - System on chip</li> <li><code>OEM</code> - Original Equipment Manufacturer</li> <li><code>ALS</code> - Auto Light Sensor</li> <li><code>API</code> - Application Programming Interface</li> <li><code>DV</code>  - Dolby Vision</li> <li><code>CMS</code> - Colorspace Management System</li> <li><code>TMAX</code>- Temperature MAX</li> <li><code>SRD</code> - Standard Dynamic Range</li> <li><code>HDR</code> - High Dynamic Range</li> <li><code>HLG</code> - Hybrid Log Gamma</li> <li><code>UHD</code> - Ultra High Definition</li> <li><code>LDIM</code>- Local Dimming</li> </ul>"},{"location":"external_content/tvsettings/#description","title":"Description","text":"<p>TV Settings <code>HAL</code> is an interface which provides <code>APIs</code> to modify/control the picture quality parameters, dimming modes and auto backlight modes.</p> <pre><code>%%{ init : { \"theme\" : \"forest\", \"flowchart\" : { \"curve\" : \"linear\" }}}%%\nflowchart TD\nCaller &lt;--&gt; x[TV Setting HAL] \nx[TV Setting HAL] &lt;--&gt; y[Video/Picture Quality Driver]\nstyle Caller fill:#99CCFF,stroke:#333,stroke-width:0.3px\nstyle y fill:#fc9,stroke:#333,stroke-width:0.3px\nstyle x fill:#9f9,stroke:#333,stroke-width:0.3px</code></pre>"},{"location":"external_content/tvsettings/#component-runtime-execution-requirements","title":"Component Runtime Execution Requirements","text":""},{"location":"external_content/tvsettings/#initialization-and-startup","title":"Initialization and Startup","text":"<p>The caller must initialize the <code>APIs</code> with picture quality modes for specific platforms and initiates communication with picture quality drivers. The standard/default values shall be maintained in default Picture profile database and any modified values for these parameters using TV Settings HAL APIs will be maintained in override Picture profile database. HAL shall be responsible to store these Picture profile data into the database. Picture profile database will have 5 types of tables: 1. Picture property table to maintain all picture properties for a given picture mode, video format and video source 2. Picture mode association table maintain the association of a given video source and video format to a picture mode 3. If input source, picture mode, and video format are not already set or specified, they will default to \"IP source,\" \"Entertainment,\" and \"SDR,\" respectively. However, if the caller attempts to change parameters that rely on these values, they will be acted upon default values accordingly. 4. White balance table for every color temperature and video source to maintain WB calibrated values 5. Gamma table for every color temperature to maintain the gamma calibrated values. 6. TMAX table for every local dimming level to maintain the TMAX value</p> <ul> <li>The capabilities of a specific platform with respect to TV picture configuration will be defined in a config file (pq_capabilities.ini which decides supported formats, picture modes, dimming modes, dvModes, resolution etc.</li> <li>Caller must initialize by calling <code>tvInit()</code> which must initialize the parameters in default picture property database. These parameters are decided by Soc vendor  based on platform capability.</li> <li>On every bootup the default picture profile database will be copied to override picture profile database.</li> </ul>"},{"location":"external_content/tvsettings/#table-format","title":"Table Format","text":""},{"location":"external_content/tvsettings/#picture-property-table","title":"Picture Property Table","text":"Video Source Video Format Picture Mode Picture Property HDMI1 SDR Standard/Entertainment Brightness Contrast Sharpness Saturation Hue Backlight Dolbymode AspectRatio Colortemperature Dimming Mode Local Dimming Low Latency CMS State CMS Saturation RED CMS Saturation BLUE CMS Saturation GREEN CMS Saturation YELLOW CMS Saturation CYAN CMS Saturation MAGENTA CMS Hue RED CMS Hue BLUE CMS Hue GREEN CMS Hue YELLOW CMS Hue CYAN CMS Hue MAGENTA CMS Luma RED CMS Luma BLUE CMS Luma GREEN CMS Luma YELLOW CMS Luma CYAN CMS Luma MAGENTA Theater/Movie Repeat as standard FilmMaker Repeat as standard Sports Repeat as standard Game Repeat as standard Custom/Expert Repeat as standard EnergySaving Repeat as standard Vivid Repeat as standard Graphics Repeat as standard HDR10 Repeat as SDR HLG Repeat as SDR DV Repeat as SDR HDMI2 Repeat as HDMI1 HDMI3 Repeat as HDMI1 Tunner Repeat as HDMI1 IP Repeat as HDMI1 Composite Repeat as HDMI1 <p>Note: Currently Dolby mode is treated as a picture property and not a picture mode. In future Dolby mode might be treated as picture mode. Values of index in pq_capabilites.ini are mapped to enum values in tvTypes.h</p>"},{"location":"external_content/tvsettings/#picture-association-table","title":"Picture Association Table","text":"Video Source Video Format Picture Mode HDMI1 SDR Standard/Entertainment Theater/Movie FilmMaker Sports Game Custom/Expert EnergySaving Vivid Graphics HDR10 Repeat as SDR HLG Repeat as SDR DV Repeat as SDR HDMI2 Repeat as HDMI1 HDMI3 Repeat as HDMI1 Tunner Repeat as HDMI1 IP Repeat as HDMI1 Composite Repeat as HDMI1"},{"location":"external_content/tvsettings/#wb-table","title":"WB Table","text":"Video Source White Balance Property Value Range HDMI1 Cold White Balance Table Red Gain 0-2047 Green Gain 0-2047 Blue Gain 0-2047 Red offset (-1024) to (+1023) Green offset (-1024) to (+1023) Blue offset (-1024) to (+1023) Warm White Balance Table Repeat as Cold White Balance Table Normal White Balance Table Repeat as Cold White Balance Table User White Balance Table Repeat as Cold White Balance Table Boost cold White Balance Table Repeat as Cold White Balance Table Bost warm White Balance Table Repeat as Cold White Balance Table Boost normal White Balance Table Repeat as Cold White Balance Table Boost user White Balance Table Repeat as Cold White Balance Table HDMI2 Repeat as HDMI1 HDMI3 Repeat as HDMI1 Tunner Repeat as HDMI1 IP Repeat as HDMI1 Composite Repeat as HDMI1"},{"location":"external_content/tvsettings/#gamma-table","title":"Gamma Table","text":"Gamma Index Property Value Range Cold Gamma Table 0 Red Gain 0-1023 Green Gain 0-1023 Blue Gain 0-1023 1 Repeat as 0 2 Repeat as 0 . 254 Repeat as 0 255 Repeat as 0 Warm Gamma Table Repeat as Cold Gamma Table Normal Gamma Table Repeat as Cold Gamma Table User Gamma Table Repeat as Cold Gamma Table Boorst cold Gamma Table Repeat as Cold Gamma Table Boost warm Gamma Table Repeat as Cold Gamma Table Boost normal Gamma Table Repeat as Cold Gamma Table Boost user Gamma Table Repeat as Cold Gamma Table"},{"location":"external_content/tvsettings/#tmax-table","title":"TMAX Table","text":"TMAX Value Range Non Boost 0 to 10000 Boost 0 to 10000 Burst 0 to 10000"},{"location":"external_content/tvsettings/#threading-model","title":"Threading Model","text":"<p>This interface is not required to be thread safe.  There are no constraints on thread creation or signal handling. </p>"},{"location":"external_content/tvsettings/#process-model","title":"Process Model","text":"<p>This interface is expected to support a single instantiation with a single process.</p>"},{"location":"external_content/tvsettings/#memory-model","title":"Memory Model","text":"<p>The caller is responsible for allocating and cleaning up any memory used.</p>"},{"location":"external_content/tvsettings/#power-management-requirements","title":"Power Management Requirements","text":"<p>This interface is not required to participate in power management.</p>"},{"location":"external_content/tvsettings/#asynchronous-notification-model","title":"Asynchronous Notification Model","text":"<p>This interface requires callback notification registration for VideoFormatChange, VideoResolutionChange, VideoFrameRateChange, VideoContentChange. The caller must return the callback context as fast as possible and will not block.</p>"},{"location":"external_content/tvsettings/#blocking-calls","title":"Blocking calls","text":"<p>This interface is required to have no blocking calls.</p>"},{"location":"external_content/tvsettings/#internal-error-handling","title":"Internal Error Handling","text":"<p>All <code>APIs</code> must return error synchronously as return argument.</p>"},{"location":"external_content/tvsettings/#persistence-model","title":"Persistence Model","text":"<p>Each vendor needs to define their own config file which is expected to be stored in rootfs and this must be a readonly. Config file must contain the supported formats, picture modes, dimming modes, dvModes, resolution etc.</p>"},{"location":"external_content/tvsettings/#non-functional-requirements","title":"Non-functional requirements","text":"<p>Following non-functional requirement must be supported by the TV Settings <code>HAL</code> component:</p>"},{"location":"external_content/tvsettings/#logging-and-debugging-requirements","title":"Logging and debugging requirements","text":"<p>This interface is required to support DEBUG, INFO and ERROR messages. DEBUG is required to be disabled by default and enabled when needed.</p>"},{"location":"external_content/tvsettings/#memory-and-performance-requirements","title":"Memory and performance requirements","text":"<p>This interface is required  to not cause excessive memory and <code>CPU</code> utilization.</p>"},{"location":"external_content/tvsettings/#quality-control","title":"Quality Control","text":"<ul> <li>This interface is required to perform static analysis, our preferred tool is Coverity.</li> <li>Have a zero-warning policy with regards to compiling. All warnings must be treated as errors.</li> <li>Use of memory analysis tools like Valgrind are encouraged to identify leaks/corruptions.</li> <li><code>HAL</code> Tests will endeavour to create worst case scenarios to assist investigations.</li> <li>Copyright validation is required to be performed, e.g.: <code>Black duck</code>, <code>FossID</code>.</li> <li>Improvements by any party to the testing suite are required to be fed back.</li> </ul>"},{"location":"external_content/tvsettings/#licensing","title":"Licensing","text":"<p>This interface is expected to get released under the Apache License 2.0.</p>"},{"location":"external_content/tvsettings/#build-requirements","title":"Build Requirements","text":"<p>TV Settings <code>HAL</code> source code must build into a shared library and must be named as <code>libtvsettings-hal.so</code>.</p>"},{"location":"external_content/tvsettings/#variability-management","title":"Variability Management","text":"<p>Any changes in the <code>APIs</code> must be reviewed and approved by component architects.</p>"},{"location":"external_content/tvsettings/#platform-or-product-customization","title":"Platform or Product Customization","text":"<p>Product or platform specification requirements will be handled in vendor specific config file.</p>"},{"location":"external_content/tvsettings/#interface-api-documentation","title":"Interface API Documentation","text":"<p><code>API</code> documentation will be provided by Doxygen which will be generated from the header file(s).</p>"},{"location":"external_content/tvsettings/#theory-of-operation-and-key-concepts","title":"Theory of operation and key concepts","text":"<p>This interface handles various functionalities/requests related to Picture Quality settings :</p> <ul> <li>Brightness</li> <li>Contrast</li> <li>Hue</li> <li>Saturation</li> <li>White Balance</li> <li>Sharpness</li> <li>Color Temperature</li> <li>Backlight </li> <li>Aspect Ratio</li> <li>Dimming Modes</li> <li>Local Dimming Level</li> <li>Low Latency state</li> <li>Notify Video Format Change</li> <li>Notify Video Resolution Change</li> <li>Notify Video FrameRate Change</li> <li>Notify Video Content Change</li> </ul> <p>There are other platform specific Picture Quality settings that can be managed by this interface :</p> <ul> <li>CMS</li> <li>Dolby Vision</li> </ul>"},{"location":"external_content/tvsettings/#diagrams","title":"Diagrams","text":""},{"location":"external_content/tvsettings/#operational-call-diagram","title":"Operational Call Diagram","text":""},{"location":"external_content/tvsettings/#init-and-callback-sequence","title":"Init and Callback Sequence","text":"<pre><code>sequenceDiagram\nparticipant Caller as Caller\n    participant HAL as TV Settings HAL\n    participant OPPDB as Override Picture Profile DB\n    participant DPPDB as Default Picture Profile DB\n    participant Driver as SoC\n\n    Caller-&gt;&gt;HAL:tvInit()\n    Note over HAL: Initialize the TV Setting HAL APIs\n    HAL-&gt;&gt;Driver: Allocates resources\n    Driver--&gt;&gt;HAL:return\n    HAL-&gt;&gt;DPPDB: tvSettings_GetDefaultPQParams() Read default picture profile properites\n    DPPDB--&gt;&gt;HAL:return\n    HAL-&gt;&gt;OPPDB: Copy default picture profile properites\n    OPPDB--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL: SetTVPictureMode()\n    Note over HAL: Set the default picture mode entertainment\n    HAL-&gt;&gt;OPPDB: tvSettings_GetPQParams() Read associated picture properties\n    OPPDB--&gt;&gt;HAL:return\n    Note over HAL: Reload gamma and white balance if there is a colour temperature value change.\n    HAL-&gt;&gt;OPPDB: Read associated Gamma and White balance\n    OPPDB--&gt;&gt;HAL:return\n    Note over HAL: Reload TMAX if there is a LDIM level change\n    HAL-&gt;&gt;OPPDB: Read associated TMAX value\n    OPPDB--&gt;&gt;HAL:return\n    Note over HAL: Apply the new picture properties, gamma, TMAX and white balance if they have changed.\n    HAL-&gt;&gt;Driver: Apply new picture properties\n    Driver--&gt;&gt;HAL:return\n    HAL-&gt;&gt;OPPDB: Update the Picture mode association table\n    Note over HAL: Associate new picture mode to current video format and current video source\n    OPPDB--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n\n    Caller-&gt;&gt;HAL: RegisterCallBack\n    Note over HAL:RegisterCallBack for Format/Resolution/FrameRate/VideoContent Change\n    HAL--&gt;&gt;Caller:return\n\n    Driver--&gt;&gt;HAL:Notify on video format/framerate/resolution/videocontent/videosource change\n    Note over HAL: Reload associated Picture mode and all associated picture properties if there is video format and video source change.\n    Note over HAL: However video source change will not be notified to caller\n    HAL-&gt;&gt;OPPDB: Read associated picture mode\n    OPPDB--&gt;&gt;HAL:return\n    HAL-&gt;&gt;OPPDB: Read associated picture properties\n    OPPDB--&gt;&gt;HAL:return\n    Note over HAL: Reload gamma and white balance if there is a colour temperature value change.\n    HAL-&gt;&gt;OPPDB: Read associated Gamma and White balance\n    OPPDB--&gt;&gt;HAL:return\n    Note over HAL: Reload TMAX if there is a LDIM level change\n    HAL-&gt;&gt;OPPDB: Read associated TMAX value\n    OPPDB--&gt;&gt;HAL:return\n    Note over HAL: Apply the new picture properties, gamma and white balance if they have changed.\n    HAL-&gt;&gt;Driver: Apply new picture properties\n    Driver--&gt;&gt;HAL: return\n    HAL--&gt;&gt;Caller:Notify on video format/framerate/resolution/content change</code></pre>"},{"location":"external_content/tvsettings/#setgetsave-picture-quality-parameter-sequence","title":"Set/Get/Save Picture Quality Parameter Sequence LEGEND: tvSettings_SetMethods:tvSettings_GetMethods:tvSettings_SaveMethods :RegisterCallback :","text":"<pre><code>sequenceDiagram\nparticipant Caller as Caller\n    participant HAL as TV Settings HAL\n    participant OPPDB as Override Picture Profile DB\n    participant DPPDB as Default Picture Profile DB\n    participant Driver as SoC\n\n    Caller-&gt;&gt;HAL: tvSettings_SetMethods\n    Note over HAL: APIs to set the Picture Quality Parameters\n    HAL-&gt;&gt;Driver:Sets the PQ Parameters\n    Driver--&gt;&gt;HAL:return\n    HAL-&gt;&gt;OPPDB: Saves the new PQ Parameter\n    OPPDB--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n\n    Caller-&gt;&gt;HAL: tvSettings_GetMethods\n    Note over HAL: APIs to get the PQ Parameters\n    HAL-&gt;&gt;Driver:Gets the PQ Parameters\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n\n    Caller-&gt;&gt;HAL: tvSettings_SaveMethods\n    Note over HAL: APIs to save the Picture Quality Parameters\n    HAL-&gt;&gt;OPPDB:Save the PQ Parameters\n    OPPDB--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n\n    Caller-&gt;&gt;HAL: tvSettings_GetPQParam\n    Note over HAL: APIs to get PQ param from override Picture Profile Database\n    HAL-&gt;&gt;OPPDB:Get the PQ Parameters\n    OPPDB--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n\n    Caller-&gt;&gt;HAL: tvSettings_GetDefaultPQParam\n    Note over HAL: APIs to get Default PQ param from default Picture Profile Database\n    HAL-&gt;&gt;DPPDB:Get the PQ Parameters\n    DPPDB--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return</code></pre> <p>SetBrightness(), SetContrast(), SetSaturation(), SetHue(),SetSharpness(), SetColorTemperature(),SetBacklight(), etc..</p> <p>GetBrightness(), GetContrast(), GetSaturation(), GetHue(),GetSharpness(), GetColorTemperature(),GetBacklight(), GetPQParams(), GetDefaultPQParams() etc..</p> <p>SaveBrightness(), SaveContrast(), SaveSaturation(), SaveHue(),SaveSharpness(), SaveColorTemperature(),SaveBacklight(), etc..</p> <p>RegisterVideoFormatChangeCB(),RegisterVideoContentChangeCB(),RegisterVideoResolutionChangeCB(), RegisterVideoFrameRateChangeCB()</p>"},{"location":"external_content/tvsettings/#set-with-saveonly-flag-sequence","title":"Set With SaveOnly Flag Sequence LEGEND: tvSettings_SetMethods:","text":"<pre><code>sequenceDiagram\nparticipant Caller as Caller\n    participant HAL as TV Settings HAL\n    participant OPPDB as Override Picture Profile DB\n    participant DPPDB as Default Picture Profile DB\n    participant Driver as SoC\n\n    alt is when saveonly flag is 0\n    Caller-&gt;&gt;HAL: tvSettings_SetMethods\n    Note over HAL: APIs to set the values for color temperature\n    HAL-&gt;&gt;Driver:Sets the values\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    else is when saveonly flag is 1\n    Caller-&gt;&gt;HAL: tvSettings_SetMethods\n    Note over HAL: APIs to set the values for color temperature\n    HAL-&gt;&gt;OPPDB: Saves the new values\n    OPPDB--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    end</code></pre> <p>SetColorTemp_Rgain_onSource(), SetColorTemp_Ggain_onSource(), SetColorTemp_Bgain_onSource(), SetColorTemp_R_post_offset_onSource(), SetColorTemp_G_post_offset_onSource(), SetColorTemp_B_post_offset_onSource()</p>"},{"location":"external_content/tvsettings/#gammatmax-sequenceset-and-save","title":"Gamma/TMax sequence(set and save) LEGEND: tvSettings_SetMethods:tvSettings_SaveMethods :","text":"<pre><code>sequenceDiagram\nparticipant Caller as Caller\n    participant HAL as TV Settings HAL\n    participant OPPDB as Override Picture Profile DB\n    participant DPPDB as Default Picture Profile DB\n    participant Driver as SoC\n\n    Caller-&gt;&gt;HAL: tvSettings_SetMethods_GammaTable\n    Note over HAL: APIs to set the values for color temperature\n    HAL-&gt;&gt;Driver:Sets the values\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n\n    Caller-&gt;&gt;HAL: tvSettings_SaveMethods_GammaTable\n    Note over HAL: APIs to save the values for color temperature\n    HAL-&gt;&gt;OPPDB: Saves the new values\n    OPPDB--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return</code></pre> <p>SetGammaTable(), SetDvTmaxValue()</p> <p>SaveGammaTable(), SaveDvTmaxValue()</p>"},{"location":"external_content/tvsettings/#terminate-sequence","title":"Terminate Sequence","text":"<pre><code>sequenceDiagram\nparticipant Caller as Caller\n    participant HAL as TV Settings HAL\n    participant OPPDB as Override Picture Profile DB\n    participant DPPDB as Default Picture Profile DB\n    participant Driver as SoC\n\n    Caller -&gt;&gt;HAL:tvTerm()\n    HAL -&gt;&gt; Driver: Releases all the resources allocated during tvInit()\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return</code></pre>"},{"location":"external_content/tvsettings/#functional-diagram","title":"Functional Diagram","text":"<pre><code>stateDiagram-v2\n    [*] --&gt; ClosedState\n    ClosedState --&gt; OpenState: tvInit()-Initialize Picture Quality params\n    OpenState --&gt; ControlState: Set/Get PQ params\n    ControlState --&gt; Validate: Recieve success/failure response from driver\n    Validate --&gt; OpenState\n    OpenState --&gt; MonitorState: Watch for events\n    MonitorState --&gt; NotifyState: Notify events\n    NotifyState --&gt; MonitorState</code></pre>"},{"location":"external_content/tvsettings/CHANGELOG/","title":"Changelog","text":""},{"location":"external_content/tvsettings/CHANGELOG/#changelog","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file. Dates are displayed in UTC.</p> <p>Generated by <code>auto-changelog</code>.</p>"},{"location":"external_content/tvsettings/CHANGELOG/#210","title":"2.1.0","text":"<ul> <li>gh #46 Remove ODM specific apis - phase1 <code>#47</code></li> <li>Merge tag '2.0.0' into develop <code>3389b5d</code></li> </ul>"},{"location":"external_content/tvsettings/CHANGELOG/#200","title":"2.0.0","text":"<p>8 November 2024</p> <ul> <li>gh #34 tvsettings-interface-to-get-number-of-dimming-zones-supported <code>#35</code></li> <li>gh #21 tv settings interface to find ldim short dev <code>#26</code></li> <li>gh #25 updated pq_capabilities.ini <code>d37668d</code></li> <li>gh #25 updated pq capabilities <code>d5ef30e</code></li> <li>Update tvSettings.h <code>3c4175e</code></li> </ul>"},{"location":"external_content/tvsettings/CHANGELOG/#140","title":"1.4.0","text":"<p>27 August 2024</p> <ul> <li>gh #27 Add DolbyMode Game Support <code>#31</code></li> <li>Bumped CHANGELOG.md - 1.4.0 <code>0d5d3ef</code></li> <li>Merge tag '1.3.0' into develop <code>cc56e5c</code></li> </ul>"},{"location":"external_content/tvsettings/CHANGELOG/#130","title":"1.3.0","text":"<p>12 July 2024</p> <ul> <li>gh #23 HAL Interface update for default values <code>#24</code></li> <li>gh #19 PQ capabilites_ini_changes <code>#15</code></li> <li>gh #17 Post Requirement changes for the TV setting interface. <code>#18</code></li> <li>gh #19 Added index for different capabilities <code>36b298f</code></li> <li>Bumped CHANGELOG.md - 1.3.0 <code>25743a5</code></li> <li>gh #19 Updated hal spec document for composite input <code>86cc71b</code></li> </ul>"},{"location":"external_content/tvsettings/CHANGELOG/#120","title":"1.2.0","text":"<p>7 March 2024</p> <ul> <li>gh #12 Add supercool wb support <code>#13</code></li> <li>bumped change log <code>b90c8b7</code></li> <li>gh #12 addressed review comment <code>0e6e503</code></li> <li>gh #12 change enum sequnce for backward compatibility <code>5504305</code></li> </ul>"},{"location":"external_content/tvsettings/CHANGELOG/#117","title":"1.1.7","text":"<p>20 February 2024</p> <ul> <li>Bumped CHANGELOG.md - 1.1.7 <code>4765623</code></li> <li>Updated generate_docs.sh &amp; removed version info from spec <code>f0c3b32</code></li> <li>Merge tag '1.1.6' into develop <code>18473bc</code></li> </ul>"},{"location":"external_content/tvsettings/CHANGELOG/#116","title":"1.1.6","text":"<p>15 February 2024</p> <ul> <li>gh #6 Remove const for get and correct in params <code>#9</code></li> <li>gh #5 add correct tvsettings hal specs <code>785dbf3</code></li> <li>gh #5 add correct tvsettings hal specs <code>fcfb87b</code></li> <li>gh #10 return tvError in callbacks <code>45427f7</code></li> </ul>"},{"location":"external_content/tvsettings/CHANGELOG/#115","title":"1.1.5","text":"<p>23 January 2024</p> <ul> <li>Feature/issue1 clean unnecessary APs <code>#4</code></li> <li>baseline version <code>#2</code></li> <li>Clean_unnecessary_APIs <code>18a363a</code></li> <li>Bumped CHANGELOG.md - 0.1.1 <code>828de6a</code></li> <li>Bumped CHANGELOG.md - 1.1.5 <code>511c34d</code></li> </ul>"},{"location":"external_content/tvsettings/CHANGELOG/#020","title":"0.2.0","text":"<p>3 May 2024</p> <ul> <li>baseline version <code>3ff7ac3</code></li> <li>Bumped CHANGELOG.md - 0.2.0 <code>02afd4f</code></li> <li>Initial commit <code>b1ecbb3</code></li> </ul>"},{"location":"external_content/tvsettings/CHANGELOG/#011","title":"0.1.1","text":"<p>29 December 2023</p> <ul> <li>Bumped CHANGELOG.md - 0.1.1 <code>828de6a</code></li> <li>Update the tvSettings.h &amp; README.md with sha <code>6a8e377</code></li> <li>Merge tag '0.1.0' into develop <code>dfdff28</code></li> </ul>"},{"location":"external_content/tvsettings/CHANGELOG/#010","title":"0.1.0","text":"<p>20 December 2023</p> <ul> <li>baseline version <code>#2</code></li> <li>Added CHANGELOG.md - 0.1.0 <code>18d5cd8</code></li> <li>Updated the NOTICE with sky uk copy right <code>f1245f1</code></li> <li>Readme update <code>9ac80d4</code></li> </ul>"},{"location":"external_content/tvsettings/CONTRIBUTING/","title":"Contributing","text":"<ul> <li>If you wish to make code contributions to this project, the source is hosted at github.com/rdkcentral.</li> </ul> <p>You can submit your changes for review via that site, by raising an issue in github, (https://github.com/rdkcentral/xxxx/issues), and following the sequence below.</p> <ul> <li>create a branch with a name follow the guidelines gh(x)_(synopsis)</li> <li>where x is the ticket number</li> <li>where synopsis is a short synopsis for the reason for the branch.</li> <li>create a pull request (https://github.com/rdkcentral/xxxx/compare) when the code changes are ready for review.</li> <li> <p>The team will review, and if accepted your changes will be merged to the mainline.</p> </li> <li> <p>In order to contribute code, first-time users are requested to agree to the license.</p> </li> <li> <p>where <code>xxxx</code> is your module name</p> </li> </ul>"},{"location":"external_content/tvsettings/docs/pages/CONTRIBUTING/","title":"Contributing","text":"<ul> <li>If you wish to make code contributions to this project, the source is hosted at github.com/rdkcentral.</li> </ul> <p>You can submit your changes for review via that site, by raising an issue in github, (https://github.com/rdkcentral/xxxx/issues), and following the sequence below.</p> <ul> <li>create a branch with a name follow the guidelines gh(x)_(synopsis)</li> <li>where x is the ticket number</li> <li>where synopsis is a short synopsis for the reason for the branch.</li> <li>create a pull request (https://github.com/rdkcentral/xxxx/compare) when the code changes are ready for review.</li> <li> <p>The team will review, and if accepted your changes will be merged to the mainline.</p> </li> <li> <p>In order to contribute code, first-time users are requested to agree to the license.</p> </li> <li> <p>where <code>xxxx</code> is your module name</p> </li> </ul>"},{"location":"external_content/tvsettings/docs/pages/tv-settings_halSpec/","title":"TV Settings HAL Documentation","text":""},{"location":"external_content/tvsettings/docs/pages/tv-settings_halSpec/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>CPU</code> - Central Processing Unit</li> <li><code>HAL</code> - Hardware Abstraction layer</li> <li><code>PQ</code>  - Picture Quality</li> <li><code>SOC</code> - System on chip</li> <li><code>OEM</code> - Original Equipment Manufacturer</li> <li><code>ALS</code> - Auto Light Sensor</li> <li><code>API</code> - Application Programming Interface</li> <li><code>DV</code>  - Dolby Vision</li> <li><code>CMS</code> - Colorspace Management System</li> <li><code>TMAX</code>- Temperature MAX</li> <li><code>SRD</code> - Standard Dynamic Range</li> <li><code>HDR</code> - High Dynamic Range</li> <li><code>HLG</code> - Hybrid Log Gamma</li> <li><code>UHD</code> - Ultra High Definition</li> <li><code>LDIM</code>- Local Dimming</li> </ul>"},{"location":"external_content/tvsettings/docs/pages/tv-settings_halSpec/#description","title":"Description","text":"<p>TV Settings <code>HAL</code> is an interface which provides <code>APIs</code> to modify/control the picture quality parameters, dimming modes and auto backlight modes.</p> <pre><code>%%{ init : { \"theme\" : \"forest\", \"flowchart\" : { \"curve\" : \"linear\" }}}%%\nflowchart TD\nCaller &lt;--&gt; x[TV Setting HAL] \nx[TV Setting HAL] &lt;--&gt; y[Video/Picture Quality Driver]\nstyle Caller fill:#99CCFF,stroke:#333,stroke-width:0.3px\nstyle y fill:#fc9,stroke:#333,stroke-width:0.3px\nstyle x fill:#9f9,stroke:#333,stroke-width:0.3px</code></pre>"},{"location":"external_content/tvsettings/docs/pages/tv-settings_halSpec/#component-runtime-execution-requirements","title":"Component Runtime Execution Requirements","text":""},{"location":"external_content/tvsettings/docs/pages/tv-settings_halSpec/#initialization-and-startup","title":"Initialization and Startup","text":"<p>The caller must initialize the <code>APIs</code> with picture quality modes for specific platforms and initiates communication with picture quality drivers. The standard/default values shall be maintained in default Picture profile database and any modified values for these parameters using TV Settings HAL APIs will be maintained in override Picture profile database. HAL shall be responsible to store these Picture profile data into the database. Picture profile database will have 5 types of tables: 1. Picture property table to maintain all picture properties for a given picture mode, video format and video source 2. Picture mode association table maintain the association of a given video source and video format to a picture mode 3. If input source, picture mode, and video format are not already set or specified, they will default to \"IP source,\" \"Entertainment,\" and \"SDR,\" respectively. However, if the caller attempts to change parameters that rely on these values, they will be acted upon default values accordingly. 4. White balance table for every color temperature and video source to maintain WB calibrated values 5. Gamma table for every color temperature to maintain the gamma calibrated values. 6. TMAX table for every local dimming level to maintain the TMAX value</p> <ul> <li>The capabilities of a specific platform with respect to TV picture configuration will be defined in a config file (pq_capabilities.ini which decides supported formats, picture modes, dimming modes, dvModes, resolution etc.</li> <li>Caller must initialize by calling <code>tvInit()</code> which must initialize the parameters in default picture property database. These parameters are decided by Soc vendor  based on platform capability.</li> <li>On every bootup the default picture profile database will be copied to override picture profile database.</li> </ul>"},{"location":"external_content/tvsettings/docs/pages/tv-settings_halSpec/#table-format","title":"Table Format","text":""},{"location":"external_content/tvsettings/docs/pages/tv-settings_halSpec/#picture-property-table","title":"Picture Property Table","text":"Video Source Video Format Picture Mode Picture Property HDMI1 SDR Standard/Entertainment Brightness Contrast Sharpness Saturation Hue Backlight Dolbymode AspectRatio Colortemperature Dimming Mode Local Dimming Low Latency CMS State CMS Saturation RED CMS Saturation BLUE CMS Saturation GREEN CMS Saturation YELLOW CMS Saturation CYAN CMS Saturation MAGENTA CMS Hue RED CMS Hue BLUE CMS Hue GREEN CMS Hue YELLOW CMS Hue CYAN CMS Hue MAGENTA CMS Luma RED CMS Luma BLUE CMS Luma GREEN CMS Luma YELLOW CMS Luma CYAN CMS Luma MAGENTA Theater/Movie Repeat as standard FilmMaker Repeat as standard Sports Repeat as standard Game Repeat as standard Custom/Expert Repeat as standard EnergySaving Repeat as standard Vivid Repeat as standard Graphics Repeat as standard HDR10 Repeat as SDR HLG Repeat as SDR DV Repeat as SDR HDMI2 Repeat as HDMI1 HDMI3 Repeat as HDMI1 Tunner Repeat as HDMI1 IP Repeat as HDMI1 Composite Repeat as HDMI1 <p>Note: Currently Dolby mode is treated as a picture property and not a picture mode. In future Dolby mode might be treated as picture mode. Values of index in pq_capabilites.ini are mapped to enum values in tvTypes.h</p>"},{"location":"external_content/tvsettings/docs/pages/tv-settings_halSpec/#picture-association-table","title":"Picture Association Table","text":"Video Source Video Format Picture Mode HDMI1 SDR Standard/Entertainment Theater/Movie FilmMaker Sports Game Custom/Expert EnergySaving Vivid Graphics HDR10 Repeat as SDR HLG Repeat as SDR DV Repeat as SDR HDMI2 Repeat as HDMI1 HDMI3 Repeat as HDMI1 Tunner Repeat as HDMI1 IP Repeat as HDMI1 Composite Repeat as HDMI1"},{"location":"external_content/tvsettings/docs/pages/tv-settings_halSpec/#wb-table","title":"WB Table","text":"Video Source White Balance Property Value Range HDMI1 Cold White Balance Table Red Gain 0-2047 Green Gain 0-2047 Blue Gain 0-2047 Red offset (-1024) to (+1023) Green offset (-1024) to (+1023) Blue offset (-1024) to (+1023) Warm White Balance Table Repeat as Cold White Balance Table Normal White Balance Table Repeat as Cold White Balance Table User White Balance Table Repeat as Cold White Balance Table Boost cold White Balance Table Repeat as Cold White Balance Table Bost warm White Balance Table Repeat as Cold White Balance Table Boost normal White Balance Table Repeat as Cold White Balance Table Boost user White Balance Table Repeat as Cold White Balance Table HDMI2 Repeat as HDMI1 HDMI3 Repeat as HDMI1 Tunner Repeat as HDMI1 IP Repeat as HDMI1 Composite Repeat as HDMI1"},{"location":"external_content/tvsettings/docs/pages/tv-settings_halSpec/#gamma-table","title":"Gamma Table","text":"Gamma Index Property Value Range Cold Gamma Table 0 Red Gain 0-1023 Green Gain 0-1023 Blue Gain 0-1023 1 Repeat as 0 2 Repeat as 0 . 254 Repeat as 0 255 Repeat as 0 Warm Gamma Table Repeat as Cold Gamma Table Normal Gamma Table Repeat as Cold Gamma Table User Gamma Table Repeat as Cold Gamma Table Boorst cold Gamma Table Repeat as Cold Gamma Table Boost warm Gamma Table Repeat as Cold Gamma Table Boost normal Gamma Table Repeat as Cold Gamma Table Boost user Gamma Table Repeat as Cold Gamma Table"},{"location":"external_content/tvsettings/docs/pages/tv-settings_halSpec/#tmax-table","title":"TMAX Table","text":"TMAX Value Range Non Boost 0 to 10000 Boost 0 to 10000 Burst 0 to 10000"},{"location":"external_content/tvsettings/docs/pages/tv-settings_halSpec/#threading-model","title":"Threading Model","text":"<p>This interface is not required to be thread safe.  There are no constraints on thread creation or signal handling. </p>"},{"location":"external_content/tvsettings/docs/pages/tv-settings_halSpec/#process-model","title":"Process Model","text":"<p>This interface is expected to support a single instantiation with a single process.</p>"},{"location":"external_content/tvsettings/docs/pages/tv-settings_halSpec/#memory-model","title":"Memory Model","text":"<p>The caller is responsible for allocating and cleaning up any memory used.</p>"},{"location":"external_content/tvsettings/docs/pages/tv-settings_halSpec/#power-management-requirements","title":"Power Management Requirements","text":"<p>This interface is not required to participate in power management.</p>"},{"location":"external_content/tvsettings/docs/pages/tv-settings_halSpec/#asynchronous-notification-model","title":"Asynchronous Notification Model","text":"<p>This interface requires callback notification registration for VideoFormatChange, VideoResolutionChange, VideoFrameRateChange, VideoContentChange. The caller must return the callback context as fast as possible and will not block.</p>"},{"location":"external_content/tvsettings/docs/pages/tv-settings_halSpec/#blocking-calls","title":"Blocking calls","text":"<p>This interface is required to have no blocking calls.</p>"},{"location":"external_content/tvsettings/docs/pages/tv-settings_halSpec/#internal-error-handling","title":"Internal Error Handling","text":"<p>All <code>APIs</code> must return error synchronously as return argument.</p>"},{"location":"external_content/tvsettings/docs/pages/tv-settings_halSpec/#persistence-model","title":"Persistence Model","text":"<p>Each vendor needs to define their own config file which is expected to be stored in rootfs and this must be a readonly. Config file must contain the supported formats, picture modes, dimming modes, dvModes, resolution etc.</p>"},{"location":"external_content/tvsettings/docs/pages/tv-settings_halSpec/#non-functional-requirements","title":"Non-functional requirements","text":"<p>Following non-functional requirement must be supported by the TV Settings <code>HAL</code> component:</p>"},{"location":"external_content/tvsettings/docs/pages/tv-settings_halSpec/#logging-and-debugging-requirements","title":"Logging and debugging requirements","text":"<p>This interface is required to support DEBUG, INFO and ERROR messages. DEBUG is required to be disabled by default and enabled when needed.</p>"},{"location":"external_content/tvsettings/docs/pages/tv-settings_halSpec/#memory-and-performance-requirements","title":"Memory and performance requirements","text":"<p>This interface is required  to not cause excessive memory and <code>CPU</code> utilization.</p>"},{"location":"external_content/tvsettings/docs/pages/tv-settings_halSpec/#quality-control","title":"Quality Control","text":"<ul> <li>This interface is required to perform static analysis, our preferred tool is Coverity.</li> <li>Have a zero-warning policy with regards to compiling. All warnings must be treated as errors.</li> <li>Use of memory analysis tools like Valgrind are encouraged to identify leaks/corruptions.</li> <li><code>HAL</code> Tests will endeavour to create worst case scenarios to assist investigations.</li> <li>Copyright validation is required to be performed, e.g.: <code>Black duck</code>, <code>FossID</code>.</li> <li>Improvements by any party to the testing suite are required to be fed back.</li> </ul>"},{"location":"external_content/tvsettings/docs/pages/tv-settings_halSpec/#licensing","title":"Licensing","text":"<p>This interface is expected to get released under the Apache License 2.0.</p>"},{"location":"external_content/tvsettings/docs/pages/tv-settings_halSpec/#build-requirements","title":"Build Requirements","text":"<p>TV Settings <code>HAL</code> source code must build into a shared library and must be named as <code>libtvsettings-hal.so</code>.</p>"},{"location":"external_content/tvsettings/docs/pages/tv-settings_halSpec/#variability-management","title":"Variability Management","text":"<p>Any changes in the <code>APIs</code> must be reviewed and approved by component architects.</p>"},{"location":"external_content/tvsettings/docs/pages/tv-settings_halSpec/#platform-or-product-customization","title":"Platform or Product Customization","text":"<p>Product or platform specification requirements will be handled in vendor specific config file.</p>"},{"location":"external_content/tvsettings/docs/pages/tv-settings_halSpec/#interface-api-documentation","title":"Interface API Documentation","text":"<p><code>API</code> documentation will be provided by Doxygen which will be generated from the header file(s).</p>"},{"location":"external_content/tvsettings/docs/pages/tv-settings_halSpec/#theory-of-operation-and-key-concepts","title":"Theory of operation and key concepts","text":"<p>This interface handles various functionalities/requests related to Picture Quality settings :</p> <ul> <li>Brightness</li> <li>Contrast</li> <li>Hue</li> <li>Saturation</li> <li>White Balance</li> <li>Sharpness</li> <li>Color Temperature</li> <li>Backlight </li> <li>Aspect Ratio</li> <li>Dimming Modes</li> <li>Local Dimming Level</li> <li>Low Latency state</li> <li>Notify Video Format Change</li> <li>Notify Video Resolution Change</li> <li>Notify Video FrameRate Change</li> <li>Notify Video Content Change</li> </ul> <p>There are other platform specific Picture Quality settings that can be managed by this interface :</p> <ul> <li>CMS</li> <li>Dolby Vision</li> </ul>"},{"location":"external_content/tvsettings/docs/pages/tv-settings_halSpec/#diagrams","title":"Diagrams","text":""},{"location":"external_content/tvsettings/docs/pages/tv-settings_halSpec/#operational-call-diagram","title":"Operational Call Diagram","text":""},{"location":"external_content/tvsettings/docs/pages/tv-settings_halSpec/#init-and-callback-sequence","title":"Init and Callback Sequence","text":"<pre><code>sequenceDiagram\nparticipant Caller as Caller\n    participant HAL as TV Settings HAL\n    participant OPPDB as Override Picture Profile DB\n    participant DPPDB as Default Picture Profile DB\n    participant Driver as SoC\n\n    Caller-&gt;&gt;HAL:tvInit()\n    Note over HAL: Initialize the TV Setting HAL APIs\n    HAL-&gt;&gt;Driver: Allocates resources\n    Driver--&gt;&gt;HAL:return\n    HAL-&gt;&gt;DPPDB: tvSettings_GetDefaultPQParams() Read default picture profile properites\n    DPPDB--&gt;&gt;HAL:return\n    HAL-&gt;&gt;OPPDB: Copy default picture profile properites\n    OPPDB--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    Caller-&gt;&gt;HAL: SetTVPictureMode()\n    Note over HAL: Set the default picture mode entertainment\n    HAL-&gt;&gt;OPPDB: tvSettings_GetPQParams() Read associated picture properties\n    OPPDB--&gt;&gt;HAL:return\n    Note over HAL: Reload gamma and white balance if there is a colour temperature value change.\n    HAL-&gt;&gt;OPPDB: Read associated Gamma and White balance\n    OPPDB--&gt;&gt;HAL:return\n    Note over HAL: Reload TMAX if there is a LDIM level change\n    HAL-&gt;&gt;OPPDB: Read associated TMAX value\n    OPPDB--&gt;&gt;HAL:return\n    Note over HAL: Apply the new picture properties, gamma, TMAX and white balance if they have changed.\n    HAL-&gt;&gt;Driver: Apply new picture properties\n    Driver--&gt;&gt;HAL:return\n    HAL-&gt;&gt;OPPDB: Update the Picture mode association table\n    Note over HAL: Associate new picture mode to current video format and current video source\n    OPPDB--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n\n    Caller-&gt;&gt;HAL: RegisterCallBack\n    Note over HAL:RegisterCallBack for Format/Resolution/FrameRate/VideoContent Change\n    HAL--&gt;&gt;Caller:return\n\n    Driver--&gt;&gt;HAL:Notify on video format/framerate/resolution/videocontent/videosource change\n    Note over HAL: Reload associated Picture mode and all associated picture properties if there is video format and video source change.\n    Note over HAL: However video source change will not be notified to caller\n    HAL-&gt;&gt;OPPDB: Read associated picture mode\n    OPPDB--&gt;&gt;HAL:return\n    HAL-&gt;&gt;OPPDB: Read associated picture properties\n    OPPDB--&gt;&gt;HAL:return\n    Note over HAL: Reload gamma and white balance if there is a colour temperature value change.\n    HAL-&gt;&gt;OPPDB: Read associated Gamma and White balance\n    OPPDB--&gt;&gt;HAL:return\n    Note over HAL: Reload TMAX if there is a LDIM level change\n    HAL-&gt;&gt;OPPDB: Read associated TMAX value\n    OPPDB--&gt;&gt;HAL:return\n    Note over HAL: Apply the new picture properties, gamma and white balance if they have changed.\n    HAL-&gt;&gt;Driver: Apply new picture properties\n    Driver--&gt;&gt;HAL: return\n    HAL--&gt;&gt;Caller:Notify on video format/framerate/resolution/content change</code></pre>"},{"location":"external_content/tvsettings/docs/pages/tv-settings_halSpec/#setgetsave-picture-quality-parameter-sequence","title":"Set/Get/Save Picture Quality Parameter Sequence LEGEND: tvSettings_SetMethods:tvSettings_GetMethods:tvSettings_SaveMethods :RegisterCallback :","text":"<pre><code>sequenceDiagram\nparticipant Caller as Caller\n    participant HAL as TV Settings HAL\n    participant OPPDB as Override Picture Profile DB\n    participant DPPDB as Default Picture Profile DB\n    participant Driver as SoC\n\n    Caller-&gt;&gt;HAL: tvSettings_SetMethods\n    Note over HAL: APIs to set the Picture Quality Parameters\n    HAL-&gt;&gt;Driver:Sets the PQ Parameters\n    Driver--&gt;&gt;HAL:return\n    HAL-&gt;&gt;OPPDB: Saves the new PQ Parameter\n    OPPDB--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n\n    Caller-&gt;&gt;HAL: tvSettings_GetMethods\n    Note over HAL: APIs to get the PQ Parameters\n    HAL-&gt;&gt;Driver:Gets the PQ Parameters\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n\n    Caller-&gt;&gt;HAL: tvSettings_SaveMethods\n    Note over HAL: APIs to save the Picture Quality Parameters\n    HAL-&gt;&gt;OPPDB:Save the PQ Parameters\n    OPPDB--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n\n    Caller-&gt;&gt;HAL: tvSettings_GetPQParam\n    Note over HAL: APIs to get PQ param from override Picture Profile Database\n    HAL-&gt;&gt;OPPDB:Get the PQ Parameters\n    OPPDB--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n\n    Caller-&gt;&gt;HAL: tvSettings_GetDefaultPQParam\n    Note over HAL: APIs to get Default PQ param from default Picture Profile Database\n    HAL-&gt;&gt;DPPDB:Get the PQ Parameters\n    DPPDB--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return</code></pre> <p>SetBrightness(), SetContrast(), SetSaturation(), SetHue(),SetSharpness(), SetColorTemperature(),SetBacklight(), etc..</p> <p>GetBrightness(), GetContrast(), GetSaturation(), GetHue(),GetSharpness(), GetColorTemperature(),GetBacklight(), GetPQParams(), GetDefaultPQParams() etc..</p> <p>SaveBrightness(), SaveContrast(), SaveSaturation(), SaveHue(),SaveSharpness(), SaveColorTemperature(),SaveBacklight(), etc..</p> <p>RegisterVideoFormatChangeCB(),RegisterVideoContentChangeCB(),RegisterVideoResolutionChangeCB(), RegisterVideoFrameRateChangeCB()</p>"},{"location":"external_content/tvsettings/docs/pages/tv-settings_halSpec/#set-with-saveonly-flag-sequence","title":"Set With SaveOnly Flag Sequence LEGEND: tvSettings_SetMethods:","text":"<pre><code>sequenceDiagram\nparticipant Caller as Caller\n    participant HAL as TV Settings HAL\n    participant OPPDB as Override Picture Profile DB\n    participant DPPDB as Default Picture Profile DB\n    participant Driver as SoC\n\n    alt is when saveonly flag is 0\n    Caller-&gt;&gt;HAL: tvSettings_SetMethods\n    Note over HAL: APIs to set the values for color temperature\n    HAL-&gt;&gt;Driver:Sets the values\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    else is when saveonly flag is 1\n    Caller-&gt;&gt;HAL: tvSettings_SetMethods\n    Note over HAL: APIs to set the values for color temperature\n    HAL-&gt;&gt;OPPDB: Saves the new values\n    OPPDB--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n    end</code></pre> <p>SetColorTemp_Rgain_onSource(), SetColorTemp_Ggain_onSource(), SetColorTemp_Bgain_onSource(), SetColorTemp_R_post_offset_onSource(), SetColorTemp_G_post_offset_onSource(), SetColorTemp_B_post_offset_onSource()</p>"},{"location":"external_content/tvsettings/docs/pages/tv-settings_halSpec/#gammatmax-sequenceset-and-save","title":"Gamma/TMax sequence(set and save) LEGEND: tvSettings_SetMethods:tvSettings_SaveMethods :","text":"<pre><code>sequenceDiagram\nparticipant Caller as Caller\n    participant HAL as TV Settings HAL\n    participant OPPDB as Override Picture Profile DB\n    participant DPPDB as Default Picture Profile DB\n    participant Driver as SoC\n\n    Caller-&gt;&gt;HAL: tvSettings_SetMethods_GammaTable\n    Note over HAL: APIs to set the values for color temperature\n    HAL-&gt;&gt;Driver:Sets the values\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return\n\n    Caller-&gt;&gt;HAL: tvSettings_SaveMethods_GammaTable\n    Note over HAL: APIs to save the values for color temperature\n    HAL-&gt;&gt;OPPDB: Saves the new values\n    OPPDB--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return</code></pre> <p>SetGammaTable(), SetDvTmaxValue()</p> <p>SaveGammaTable(), SaveDvTmaxValue()</p>"},{"location":"external_content/tvsettings/docs/pages/tv-settings_halSpec/#terminate-sequence","title":"Terminate Sequence","text":"<pre><code>sequenceDiagram\nparticipant Caller as Caller\n    participant HAL as TV Settings HAL\n    participant OPPDB as Override Picture Profile DB\n    participant DPPDB as Default Picture Profile DB\n    participant Driver as SoC\n\n    Caller -&gt;&gt;HAL:tvTerm()\n    HAL -&gt;&gt; Driver: Releases all the resources allocated during tvInit()\n    Driver--&gt;&gt;HAL:return\n    HAL--&gt;&gt;Caller:return</code></pre>"},{"location":"external_content/tvsettings/docs/pages/tv-settings_halSpec/#functional-diagram","title":"Functional Diagram","text":"<pre><code>stateDiagram-v2\n    [*] --&gt; ClosedState\n    ClosedState --&gt; OpenState: tvInit()-Initialize Picture Quality params\n    OpenState --&gt; ControlState: Set/Get PQ params\n    ControlState --&gt; Validate: Recieve success/failure response from driver\n    Validate --&gt; OpenState\n    OpenState --&gt; MonitorState: Watch for events\n    MonitorState --&gt; NotifyState: Notify events\n    NotifyState --&gt; MonitorState</code></pre>"},{"location":"external_content/tvsettings_test/","title":"Unit Testing Suite For TV Settings HAL","text":""},{"location":"external_content/tvsettings_test/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Acronyms, Terms and Abbreviations</li> <li>Description</li> <li>Reference Documents</li> <li>Notes</li> </ul>"},{"location":"external_content/tvsettings_test/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>HAL</code>- Hardware Abstraction Layer</li> <li><code>L3</code> - Module testing with External Stimulus is required to validate and control device</li> <li><code>L2</code> - Functional Tests</li> <li> <p><code>L1</code> - Functional Tests</p> </li> <li> <p><code>High-Level Test Specification</code> : These specification will provide a broad overview of the system's functionality from the callers' perspective. It focuses on major use cases, system behavior, and overall caller experience.</p> </li> <li><code>Low-Level Test Specification</code> : These specification will delve deeper into the technical details. They will define specific test cases with inputs, expected outputs, and pass/fail criteria for individual functionalities, modules, or APIs.</li> </ul>"},{"location":"external_content/tvsettings_test/#description","title":"Description","text":"<p>This repository contains the Unit Test Suites (L1,L2 &amp; L3) for TV Settings <code>HAL</code>.</p>"},{"location":"external_content/tvsettings_test/#reference-documents","title":"Reference Documents","text":"# Document Name Document Description Document Link 1 <code>HAL</code> Specification Document This document provides specific information on the APIs for which tests are written in this module tv-settings_halSpec 2 High-Level Test Spec High Level Test Specification Documentation tv-settings_High_Level_Test_Spec.md 3 <code>L2</code> Low Level Test Spec <code>L2</code> Low Level Test Specification and Procedure Documentation tv-settings_L2_Low_Level_Test_Spec.md 4 <code>L3</code> Low Level Test Spec <code>L3</code> Low Level Test Specification tv-settings_L3_Low_Level_Test_Spec.md 5 <code>L3</code> Test Procedure Document <code>L3</code> Test procedure documentation tv-settings_L3_TestProcedure.md"},{"location":"external_content/tvsettings_test/#notes","title":"Notes","text":"<ul> <li>Building against the actual library may introduce SOC dependencies. Hence, a template SKELETON library is created without SOC dependencies. On the real platform (target), it can be mounted, copied and bound with the actual library.</li> <li>When executing the binary, ensure to include a platform-specific profile file as an argument for the designated test cases. The following example illustrates this:</li> </ul> <p><code>bash  ./hal_test -p Sink_4K_TvSettings.yaml</code></p> <p>Alternatively, use the run.sh script with the profile file:</p> <p><code>bash ./run.sh -p /absolute/path/to/profile/file</code></p> <ul> <li>Profile files define the configuration for the platform available here profile yaml file</li> <li>Install Python Environment and Activation Scripts please check the HPK Documentation</li> </ul>"},{"location":"external_content/tvsettings_test/CHANGELOG/","title":"Changelog","text":""},{"location":"external_content/tvsettings_test/CHANGELOG/#changelog","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file. Dates are displayed in UTC.</p> <p>Generated by <code>auto-changelog</code>.</p>"},{"location":"external_content/tvsettings_test/CHANGELOG/#213","title":"2.1.3","text":"<ul> <li>gh #67 Correction with saveOnly Parameter Handling in SetColorTemp_RGB gain_onSource and RGB post offset APIs <code>#67</code></li> <li>gh #61 Updated the way to read the color temperature from the profile\u2026 <code>#62</code></li> <li>gh #63 Updated the TvTerm at the L2 EnableandGetDynamic Contrast <code>#64</code></li> <li>gh #56 L1 and L2 changes for ODM API removal - Phase 1 <code>#57</code></li> <li>gh #65 Corrected the SaveOnly Param for RGB gain and RGB post offset <code>3b5963d</code></li> </ul>"},{"location":"external_content/tvsettings_test/CHANGELOG/#212","title":"2.1.2","text":"<p>28 November 2024</p> <ul> <li>gh #59 updating the utcore build version to 4.x <code>#60</code></li> <li>Bumped CHANGELOG.md - 2.1.2 <code>59f4a84</code></li> <li>Merge tag '2.1.1' into develop <code>b9d6d1d</code></li> </ul>"},{"location":"external_content/tvsettings_test/CHANGELOG/#211","title":"2.1.1","text":"<p>26 November 2024</p> <ul> <li>gh #54 updated the condition checks to be in valid range <code>#55</code></li> <li>gh #52 modified the latest enhancement changes <code>#53</code></li> <li>Bumped CHANGELOG.md - 2.1.1 <code>b4b2b3f</code></li> <li>gh #54 updated the condition checks to be in valid range for the RGB and Gray Pattern <code>2d1f77e</code></li> <li>Updated the README.md <code>8d87e89</code></li> </ul>"},{"location":"external_content/tvsettings_test/CHANGELOG/#210","title":"2.1.0","text":"<p>6 November 2024</p> <ul> <li>gh #43 Python test development <code>#44</code></li> <li>Bumped CHANGELOG.md - 2.1.0 <code>3167503</code></li> <li>Merge tag '2.0.1' into develop <code>44d1d92</code></li> <li>gh #43 Corrected testcases based on the review comments and new code cleanup <code>27cefa5</code></li> </ul>"},{"location":"external_content/tvsettings_test/CHANGELOG/#201","title":"2.0.1","text":"<p>5 November 2024</p> <ul> <li>gh #47 L1 TV Settings issues by SoC Vendor <code>#48</code></li> <li>gh #45 remove warning unwanted folders <code>#46</code></li> <li>gh #26 tvsettings: L3 C-Test case Development <code>#27</code></li> <li>gh #39 updated the tvsettings l3 test spec document <code>#40</code></li> <li>gh #26 implementation for the L3 test cases <code>5d136da</code></li> <li>gh #26 Correct Code review comments <code>faece45</code></li> <li>gh #26 updating the L3 test cases high level specifications with utraft flow for tvsettings <code>ed2814e</code></li> </ul>"},{"location":"external_content/tvsettings_test/CHANGELOG/#200","title":"2.0.0","text":"<p>26 September 2024</p> <ul> <li>gh #41 tv gamma target L1 test case <code>#42</code></li> <li>gh #34 Update yaml header information <code>#35</code></li> <li>gh #36 Update test_l1_tvSettings.c <code>#38</code></li> <li>Merge pull request #33 from rdkcentral/feature/issue29_l1_l2_getLdimZoneShortCircuitStatus <code>#33</code></li> <li>gh #29 updated L1 for new API <code>ed9406a</code></li> <li>Update test_l1_tvSettings.c <code>87f57a3</code></li> <li>gh #29 updated L2 for new API <code>f4bb8c6</code></li> </ul>"},{"location":"external_content/tvsettings_test/CHANGELOG/#131","title":"1.3.1","text":"<p>4 September 2024</p> <ul> <li>gh #28 HDR Game mode support <code>#30</code></li> <li>gh #31 L1 profile update issue fixes <code>#32</code></li> <li>Bumped CHANGELOG.md - 1.3.1 <code>5a1c5a4</code></li> <li>gh #31 L1 issue fixes <code>f740d07</code></li> <li>gh #31 L1 Profile file update issue fixes <code>c654e79</code></li> </ul>"},{"location":"external_content/tvsettings_test/CHANGELOG/#130","title":"1.3.0","text":"<p>13 August 2024</p> <ul> <li>gh #18 L1 Code cleanup <code>#23</code></li> <li>gh #13 VTS L1 Enhancement - Test Profile Changes - TV Settings <code>#14</code></li> <li>gh #16 VTS L1 update to Sepc 1.3.0 <code>#17</code></li> <li>gh #13 test profile changes <code>61124f4</code></li> <li>gh #18 Code cleanup <code>6441254</code></li> <li>gh #13 Test profile changes <code>3d94dcf</code></li> </ul>"},{"location":"external_content/tvsettings_test/CHANGELOG/#120","title":"1.2.0","text":"<p>11 July 2024</p> <ul> <li>gh #6 Added changes in SaveCMS test case <code>#9</code></li> <li>Bumped CHANGELOG.md - 1.2.0 <code>a5998b2</code></li> <li>gh #2 Merge branch 'feature/gh2_tvsettings_tvspec' into develop <code>ce0655d</code></li> <li>gh #2 update the testing scope spec <code>0c1f27b</code></li> </ul>"},{"location":"external_content/tvsettings_test/CHANGELOG/#110","title":"1.1.0","text":"<p>5 June 2024</p> <ul> <li>gh #11 tvsettings: Enhanced Error code Enable/Disable Support <code>#12</code></li> <li>Feature/callback enable <code>#10</code></li> <li>Enhanced Error code feature Moving to kvp Profiler <code>6dc6fc3</code></li> <li>Enhanced Error code Macro <code>52936de</code></li> <li>Enhanced Error code Enable/Disable Support <code>5ed3416</code></li> </ul>"},{"location":"external_content/tvsettings_test/CHANGELOG/#100","title":"1.0.0","text":"<p>20 February 2024</p> <ul> <li>baseline version <code>#1</code></li> <li>Added CHANGELOG.md - 1.0.0 <code>971cee9</code></li> <li>Updated README.md <code>68b4202</code></li> <li>Initial commit <code>95bdaa3</code></li> </ul>"},{"location":"external_content/tvsettings_test/CONTRIBUTING/","title":"Contributing","text":"<ul> <li>If you wish to make code contributions to this project, the source is hosted at github.com/rdkcentral.</li> </ul> <p>You can submit your changes for review via that site, by raising an issue in github, (https://github.com/rdkcentral/xxxx/issues), and following the sequence below.</p> <ul> <li>create a branch with a name follow the guidelines gh(x)_(synopsis)</li> <li>where x is the ticket number</li> <li>where synopsis is a short synopsis for the reason for the branch.</li> <li>create a pull request (https://github.com/rdkcentral/xxxx/compare) when the code changes are ready for review.</li> <li> <p>The team will review, and if accepted your changes will be merged to the mainline.</p> </li> <li> <p>In order to contribute code, first-time users are requested to agree to the license.</p> </li> <li> <p>where <code>xxxx</code> is your module name</p> </li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/","title":"Unit Testing Suite For TV Settings HAL","text":""},{"location":"external_content/tvsettings_test/docs/pages/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Acronyms, Terms and Abbreviations</li> <li>Description</li> <li>Reference Documents</li> <li>Notes</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>HAL</code>- Hardware Abstraction Layer</li> <li><code>L3</code> - Module testing with External Stimulus is required to validate and control device</li> <li><code>L2</code> - Functional Tests</li> <li> <p><code>L1</code> - Functional Tests</p> </li> <li> <p><code>High-Level Test Specification</code> : These specification will provide a broad overview of the system's functionality from the callers' perspective. It focuses on major use cases, system behavior, and overall caller experience.</p> </li> <li><code>Low-Level Test Specification</code> : These specification will delve deeper into the technical details. They will define specific test cases with inputs, expected outputs, and pass/fail criteria for individual functionalities, modules, or APIs.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/#description","title":"Description","text":"<p>This repository contains the Unit Test Suites (L1,L2 &amp; L3) for TV Settings <code>HAL</code>.</p>"},{"location":"external_content/tvsettings_test/docs/pages/#reference-documents","title":"Reference Documents","text":"# Document Name Document Description Document Link 1 <code>HAL</code> Specification Document This document provides specific information on the APIs for which tests are written in this module tv-settings_halSpec 2 High-Level Test Spec High Level Test Specification Documentation tv-settings_High_Level_Test_Spec.md 3 <code>L2</code> Low Level Test Spec <code>L2</code> Low Level Test Specification and Procedure Documentation tv-settings_L2_Low_Level_Test_Spec.md 4 <code>L3</code> Low Level Test Spec <code>L3</code> Low Level Test Specification tv-settings_L3_Low_Level_Test_Spec.md 5 <code>L3</code> Test Procedure Document <code>L3</code> Test procedure documentation tv-settings_L3_TestProcedure.md"},{"location":"external_content/tvsettings_test/docs/pages/#notes","title":"Notes","text":"<ul> <li>Building against the actual library may introduce SOC dependencies. Hence, a template SKELETON library is created without SOC dependencies. On the real platform (target), it can be mounted, copied and bound with the actual library.</li> <li>When executing the binary, ensure to include a platform-specific profile file as an argument for the designated test cases. The following example illustrates this:</li> </ul> <p><code>bash  ./hal_test -p Sink_4K_TvSettings.yaml</code></p> <p>Alternatively, use the run.sh script with the profile file:</p> <p><code>bash ./run.sh -p /absolute/path/to/profile/file</code></p> <ul> <li>Profile files define the configuration for the platform available here profile yaml file</li> <li>Install Python Environment and Activation Scripts please check the HPK Documentation</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/CONTRIBUTING/","title":"Contributing","text":"<ul> <li>If you wish to make code contributions to this project, the source is hosted at github.com/rdkcentral.</li> </ul> <p>You can submit your changes for review via that site, by raising an issue in github, (https://github.com/rdkcentral/xxxx/issues), and following the sequence below.</p> <ul> <li>create a branch with a name follow the guidelines gh(x)_(synopsis)</li> <li>where x is the ticket number</li> <li>where synopsis is a short synopsis for the reason for the branch.</li> <li>create a pull request (https://github.com/rdkcentral/xxxx/compare) when the code changes are ready for review.</li> <li> <p>The team will review, and if accepted your changes will be merged to the mainline.</p> </li> <li> <p>In order to contribute code, first-time users are requested to agree to the license.</p> </li> <li> <p>where <code>xxxx</code> is your module name</p> </li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/LICENSE/","title":"LICENSE","text":"<pre><code>                             Apache License\n                       Version 2.0, January 2004\n                    http://www.apache.org/licenses/\n</code></pre> <p>TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION</p> <ol> <li> <p>Definitions.</p> <p>\"License\" shall mean the terms and conditions for use, reproduction,   and distribution as defined by Sections 1 through 9 of this document.</p> <p>\"Licensor\" shall mean the copyright owner or entity authorized by   the copyright owner that is granting the License.</p> <p>\"Legal Entity\" shall mean the union of the acting entity and all   other entities that control, are controlled by, or are under common   control with that entity. For the purposes of this definition,   \"control\" means (i) the power, direct or indirect, to cause the   direction or management of such entity, whether by contract or   otherwise, or (ii) ownership of fifty percent (50%) or more of the   outstanding shares, or (iii) beneficial ownership of such entity.</p> <p>\"You\" (or \"Your\") shall mean an individual or Legal Entity   exercising permissions granted by this License.</p> <p>\"Source\" form shall mean the preferred form for making modifications,   including but not limited to software source code, documentation   source, and configuration files.</p> <p>\"Object\" form shall mean any form resulting from mechanical   transformation or translation of a Source form, including but   not limited to compiled object code, generated documentation,   and conversions to other media types.</p> <p>\"Work\" shall mean the work of authorship, whether in Source or   Object form, made available under the License, as indicated by a   copyright notice that is included in or attached to the work   (an example is provided in the Appendix below).</p> <p>\"Derivative Works\" shall mean any work, whether in Source or Object   form, that is based on (or derived from) the Work and for which the   editorial revisions, annotations, elaborations, or other modifications   represent, as a whole, an original work of authorship. For the purposes   of this License, Derivative Works shall not include works that remain   separable from, or merely link (or bind by name) to the interfaces of,   the Work and Derivative Works thereof.</p> <p>\"Contribution\" shall mean any work of authorship, including   the original version of the Work and any modifications or additions   to that Work or Derivative Works thereof, that is intentionally   submitted to Licensor for inclusion in the Work by the copyright owner   or by an individual or Legal Entity authorized to submit on behalf of   the copyright owner. For the purposes of this definition, \"submitted\"   means any form of electronic, verbal, or written communication sent   to the Licensor or its representatives, including but not limited to   communication on electronic mailing lists, source code control systems,   and issue tracking systems that are managed by, or on behalf of, the   Licensor for the purpose of discussing and improving the Work, but   excluding communication that is conspicuously marked or otherwise   designated in writing by the copyright owner as \"Not a Contribution.\"</p> <p>\"Contributor\" shall mean Licensor and any individual or Legal Entity   on behalf of whom a Contribution has been received by Licensor and   subsequently incorporated within the Work.</p> </li> <li> <p>Grant of Copyright License. Subject to the terms and conditions of       this License, each Contributor hereby grants to You a perpetual,       worldwide, non-exclusive, no-charge, royalty-free, irrevocable       copyright license to reproduce, prepare Derivative Works of,       publicly display, publicly perform, sublicense, and distribute the       Work and such Derivative Works in Source or Object form.</p> </li> <li> <p>Grant of Patent License. Subject to the terms and conditions of       this License, each Contributor hereby grants to You a perpetual,       worldwide, non-exclusive, no-charge, royalty-free, irrevocable       (except as stated in this section) patent license to make, have made,       use, offer to sell, sell, import, and otherwise transfer the Work,       where such license applies only to those patent claims licensable       by such Contributor that are necessarily infringed by their       Contribution(s) alone or by combination of their Contribution(s)       with the Work to which such Contribution(s) was submitted. If You       institute patent litigation against any entity (including a       cross-claim or counterclaim in a lawsuit) alleging that the Work       or a Contribution incorporated within the Work constitutes direct       or contributory patent infringement, then any patent licenses       granted to You under this License for that Work shall terminate       as of the date such litigation is filed.</p> </li> <li> <p>Redistribution. You may reproduce and distribute copies of the       Work or Derivative Works thereof in any medium, with or without       modifications, and in Source or Object form, provided that You       meet the following conditions:</p> <p>(a) You must give any other recipients of the Work or       Derivative Works a copy of this License; and</p> <p>(b) You must cause any modified files to carry prominent notices       stating that You changed the files; and</p> <p>(c) You must retain, in the Source form of any Derivative Works       that You distribute, all copyright, patent, trademark, and       attribution notices from the Source form of the Work,       excluding those notices that do not pertain to any part of       the Derivative Works; and</p> <p>(d) If the Work includes a \"NOTICE\" text file as part of its       distribution, then any Derivative Works that You distribute must       include a readable copy of the attribution notices contained       within such NOTICE file, excluding those notices that do not       pertain to any part of the Derivative Works, in at least one       of the following places: within a NOTICE text file distributed       as part of the Derivative Works; within the Source form or       documentation, if provided along with the Derivative Works; or,       within a display generated by the Derivative Works, if and       wherever such third-party notices normally appear. The contents       of the NOTICE file are for informational purposes only and       do not modify the License. You may add Your own attribution       notices within Derivative Works that You distribute, alongside       or as an addendum to the NOTICE text from the Work, provided       that such additional attribution notices cannot be construed       as modifying the License.</p> <p>You may add Your own copyright statement to Your modifications and   may provide additional or different license terms and conditions   for use, reproduction, or distribution of Your modifications, or   for any such Derivative Works as a whole, provided Your use,   reproduction, and distribution of the Work otherwise complies with   the conditions stated in this License.</p> </li> <li> <p>Submission of Contributions. Unless You explicitly state otherwise,       any Contribution intentionally submitted for inclusion in the Work       by You to the Licensor shall be under the terms and conditions of       this License, without any additional terms or conditions.       Notwithstanding the above, nothing herein shall supersede or modify       the terms of any separate license agreement you may have executed       with Licensor regarding such Contributions.</p> </li> <li> <p>Trademarks. This License does not grant permission to use the trade       names, trademarks, service marks, or product names of the Licensor,       except as required for reasonable and customary use in describing the       origin of the Work and reproducing the content of the NOTICE file.</p> </li> <li> <p>Disclaimer of Warranty. Unless required by applicable law or       agreed to in writing, Licensor provides the Work (and each       Contributor provides its Contributions) on an \"AS IS\" BASIS,       WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or       implied, including, without limitation, any warranties or conditions       of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A       PARTICULAR PURPOSE. You are solely responsible for determining the       appropriateness of using or redistributing the Work and assume any       risks associated with Your exercise of permissions under this License.</p> </li> <li> <p>Limitation of Liability. In no event and under no legal theory,       whether in tort (including negligence), contract, or otherwise,       unless required by applicable law (such as deliberate and grossly       negligent acts) or agreed to in writing, shall any Contributor be       liable to You for damages, including any direct, indirect, special,       incidental, or consequential damages of any character arising as a       result of this License or out of the use or inability to use the       Work (including but not limited to damages for loss of goodwill,       work stoppage, computer failure or malfunction, or any and all       other commercial damages or losses), even if such Contributor       has been advised of the possibility of such damages.</p> </li> <li> <p>Accepting Warranty or Additional Liability. While redistributing       the Work or Derivative Works thereof, You may choose to offer,       and charge a fee for, acceptance of support, warranty, indemnity,       or other liability obligations and/or rights consistent with this       License. However, in accepting such obligations, You may act only       on Your own behalf and on Your sole responsibility, not on behalf       of any other Contributor, and only if You agree to indemnify,       defend, and hold each Contributor harmless for any liability       incurred by, or claims asserted against, such Contributor by reason       of your accepting any such warranty or additional liability.</p> </li> </ol> <p>END OF TERMS AND CONDITIONS</p> <p>APPENDIX: How to apply the Apache License to your work.</p> <pre><code>  To apply the Apache License to your work, attach the following\n  boilerplate notice, with the fields enclosed by brackets \"[]\"\n  replaced with your own identifying information. (Don't include\n  the brackets!)  The text should be enclosed in the appropriate\n  comment syntax for the file format. We also recommend that a\n  file or class name and description of purpose be included on the\n  same \"printed page\" as the copyright notice for easier\n  identification within third-party archives.\n</code></pre> <p>Copyright [yyyy] [name of copyright owner]</p> <p>Licensed under the Apache License, Version 2.0 (the \"License\");    you may not use this file except in compliance with the License.    You may obtain a copy of the License at</p> <pre><code>   http://www.apache.org/licenses/LICENSE-2.0\n</code></pre> <p>Unless required by applicable law or agreed to in writing, software    distributed under the License is distributed on an \"AS IS\" BASIS,    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.    See the License for the specific language governing permissions and    limitations under the License.</p>"},{"location":"external_content/tvsettings_test/docs/pages/NOTICE/","title":"NOTICE","text":"<p>This component contains software that is Copyright (c) 2023 RDK Management.</p> <p>The component is licensed to you under the Apache License, Version 2.0 (the \"License\"). You may not use the component except in compliance with the License.</p> <p>The component may include material which is licensed under other licenses / copyrights as listed below.  Your use of this material within the component is also subject to the terms and conditions of these licenses.  The LICENSE file contains the text of all the licenses which apply within this component.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/","title":"TV Settings High Level Test Specification Document","text":""},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>SoC</code>   - System On a Chip</li> <li><code>SEI</code>   - Supplemental Enhancement Information</li> <li><code>FMM</code>   - Film Maker Mode</li> <li><code>WB</code>    - White Balance</li> <li><code>CMS</code>   - Color Management System</li> <li><code>PQ</code>    - Picture Quality</li> <li><code>LED</code>   - Light Emitting Diode</li> <li><code>LDIM</code>  - Local Dimming Module</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#references","title":"References","text":""},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#introduction","title":"Introduction","text":"<p>This document provides an overview of the testing requirements for the tvSettings module. It outlines the scope of testing, objectives, testing levels and approaches, specific test requirements, emulator requirements, control plane requirements and expected deliverables.</p> <p>Interface of the test is available in this link -  TV Settings HAL Interface</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#module-description","title":"Module Description","text":"<p>High level overview:</p> <ul> <li>TVSettings offers diverse functionalities allowing users to access information and customize settings such as picture quality, dimming preferences, and auto backlight controls.</li> <li>It facilitates communication with the System-on-Chip (SoC) to effect adjustments within TVSettings. Subsequently, it transmits this updated information to the caller.</li> <li>It applies only to the Sink devices.</li> <li>HAL specification of the document - TV Settings HAL Specification</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#testing-scope","title":"Testing Scope","text":"# Test Functionality Test Description 1 Callback Mechanisms The test validates the video format, video resolution, video content, video framerate callback, letting the system detect any changes in the primary video's format 2 Video Formats The test validates by getting the all supported video formats and verfies by getting the current video formats 3 Get Current Video Resolution The test aims to verify the current video resolution of the primary video 4 Get Current Video FrameRate The test aims to verify the video frame rate of the current primary video 5 Video sources The test aims to verify the supported video sources of the systems and its count 6 Back Light, Back light fade, Back light modes and TV Dimming Modes The test is to verify by set and Get the current backlight value, backlight fade, backlight modes and tv dimming modes for the primary video source selected, primary video format played and picture mode selected. 7 Local Dimming Level, Brightness, Contrast, Sharpness, Saturation and Hue This test verifies the functionality of setting the local dimming level, brightness, contrast, sharpness, saturation and Hue 8 Color Temperature, Aspect Ratio, Low Latency State, Dynamic Contrast and Dynamic Gamma This test verifies the functionality of setting the color temperature value to driver registers. It ensures that the new color temperature value is updated in the hardware and applied for the current primary video source, video format, and picture mode. 9 TV Dolby Vision mode This test verifies the functionality of retrieving the supported Dolby Vision modes. It ensures that the returned list contains accurate information about the available DV modes and their count. 10 Picture Modes This test verifies the functionality of retrieving the list of supported picture modes and their count. It ensures that the returned list is accurate and contains valid picture modes. 11 Color Temperature Rgain Ggain Bgain on source This test verifies the functionality of setting or saving the RGB gain value for a specific color temperature and video source. It ensures that the value is successfully applied or saved for future use. 12 Color Temperature R post G post and B post offset onsource This test verifies the functionality of setting or saving the RGB post offset value for a specific color temperature and video source. It ensures that the value is successfully applied or saved for future use. 13 <code>WB</code> Calibration Mode This test verifies the functionality of enabling or disabling white balance calibration mode. It ensures that the mode is successfully toggled and that the system behaves accordingly. 14 Get and Set Gamma Table This test verifies the functionality of setting the gamma calibrated values to the gamma hardware for the current selected color temperature. It ensures that the values are successfully applied and do not override otherSettings in the picture profile database. 15 Get and Set Dv Tmax Value This test verifies the functionality of setting the Dolby Vision TMAX parameter in the Dolby Vision core. It ensures that the provided value is valid and can be applied successfully. 16 Get Supported Component Color This test verifies the functionality of retrieving the supported component colors. It ensures that the returned value represents the bitwise OR-ed combination of all supported colors. 17 Current Component Saturation, Component Hue and Component Luma This test verifies the functionality of setting the current component saturation, component luma and component hue value. It ensures that the provided saturation, luma and hue value is valid and can be applied successfully. 18 CMS This test verifies the functionality of saving the <code>CMS</code> value in the picture profile database for specificSettings. It ensures that the <code>CMS</code> values are stored correctly and can be applied automatically when needed. 19 PQ Params This test verifies the functionality of retrieving the default <code>PQ</code> (Picture Quality) and <code>PQ</code> parameters for a given picture mode, primary video source, and video format. It ensures that the default values and <code>PQ</code> parameter values are retrieved correctly. 20 Get Max Gain Value This test verifies the functionality of retrieving the maximum gamma/white balance gain value capable for the platform. It ensures that the returned value is within the valid range and accurately reflects the maximum gain value. 21 Gamma Mode, Gamma pattern and Get TV Gamma Target This test verifies the functionality of enabling or disabling the gamma mode, gamma patter and get tv gamma target. It ensures that the gamma module can be successfully enabled or disabled as intended. 22 Get and Set RGB Pattern Gray Pattern This test verifies the functionality of setting the RGB and Gray pattern. It ensures that the primary color levels can be set accurately and displayed as intended on the screen. 23 Get Open Circuit Status This test verifies the functionality of retrieving the current open circuit status of the backlight hardware. It ensures that the returned status indicates whether any <code>LED</code> fault is detected. 24 LDIM and LDIM Sequence Test This test verifies the functionality of enabling or disabling the local dimming module, pixel compensation and sequence test. It ensures that the local dimming module can be successfully validated. 25 Set Backlight Test Mode This test verifies the functionality of setting the backlight test mode. It ensures that the backlight hardware can be configured correctly for calibration purposes based on the specified test mode. 26 Enable and Disable White Balance, Dynamic Contrast and Local Contrast This test verifies the functionality of enabling or disabling the white balance, dynamic contrast and local contrast module. It ensures that the white balance, dynamic contrast and local contrast module can be successfully enabled or disabled as intended. 27 Test the save setting values This test verifies the functionality of saving all persistence settings by rebooting the test case. 28 Get short Circuit Status This test verifies the functionality of retrieving the short circuit status of the adjacent zones. It ensures that the returned status indicates whether any short is detected. -----------"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#test-start-up-requirement","title":"Test Start up Requirement","text":"<ul> <li>The test boots with the primary video for changing the video format, video resolutions, frame rates, etc.</li> <li>The test boots with the source devices or external devices.</li> <li>The test boots with the external analyzer to check the all tvsetting functionality.</li> <li>The test begins with the following supported configuration capability information.</li> <li>Supported video formats tvVideoFormatType_t .</li> <li>Supported video resolutions tvResolutionParam_t.</li> <li>Supported video frame rates tvVideoFrameRate_t.</li> <li>Supported video sources tvVideoSrcType_t.</li> <li>Supported list of backlight support values.</li> <li>Supported list of backlight fade support values.</li> <li>Supported list of dimming mode supports.</li> <li>Supported Local Dimming Level supports tvDimmingMode_t.</li> <li>Supported brightness levels.</li> <li>Supported contrast levels.</li> <li>Supported sharpness levels.</li> <li>Supported saturation levels.</li> <li>Supported hue levels.</li> <li>Supported color temperature levels.</li> <li>Supported aspect ratio levels tvDisplayMode_t.</li> <li>Supported low latency levels.</li> <li>Supported dynamic gamma levels.</li> <li>Supported dynamic contrast levels.</li> <li>Supported Dolby Vision Modes tvDolbyMode_t.</li> <li>Supported picture modes pic_modes_t.</li> <li>Supported color temperature for RGB gain on source tvColorTemp_t tvColorTempSourceOffset_t.</li> <li>Supported color temperature for RGB post offset on source. tvColorTemp_t tvColorTempSourceOffset_t.</li> <li>Supported calibration modes.</li> <li>Supported gamma table values.</li> <li>Supported Dv Tmax values.</li> <li>Supported component color, component saturation, component hue, component luma values tvDataComponentColor_t.</li> <li>Supported component Types tvComponentType_t</li> <li>Supported <code>CMS</code> values.</li> <li>Supported <code>PQ</code> params tvPQParameterIndex_t.</li> <li>Supported Local Dimming levels ldimStateLevel_t</li> <li>Supported Max Gain values.</li> <li>Supported gamma mode values.</li> <li>Supported gamma patterns.</li> <li>Supported TV gamma target.</li> <li>Supported gamma pattern mode.</li> <li>Supported RGB pattern.</li> <li>Supported gray pattern.</li> <li>Supported LDIM pixel compensation.</li> <li>Supported backlight mode test.</li> <li>Supported white balance values.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#emulator-requirement","title":"Emulator Requirement","text":"<p>The emulator boots with the above configured capability information</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#callback-mechanisms","title":"Callback Mechanisms","text":"Description HAL APIs L2 L3 Control Plane requirements Verify that the callback is triggered when modifying the video formats. The test should include changes to various video formats (HDR10, HDR10+, HLG, SDR, etc.) RegisterVideoFormatChangeCB N Y Y Verify the behavior of the callback to ensure it provides the default VIDEO_FORMAT_SDR when changing the video formats if the playback has not started or is stopped. RegisterVideoFormatChangeCB N Y Y Verify that the callback gets triggered when modifying the video Resolution for the primary video.The test should include changes to various video Resolutions. RegisterVideoResolutionChangeCB N Y Y Verify the behavior of the callback to ensure it provides the default tvVideoResolution_NONE when changing the video formats if the playback has not started or is stopped. RegisterVideoResolutionChangeCB N Y Y Ensure that the callback is triggered when modifying the Filmmaker mode change event upon detection of the <code>FMM</code> enter event, which involves detecting <code>SEI</code> content-type 0x01 and content-subtype 0x00 RegisterVideoContentChangeCB N Y Y Ensure that the callback is triggered when modifying the Filmmaker mode change event upon detection of the <code>FMM</code> exit event, which involves detecting <code>SEI</code> content-type is other than 0x01 and content-subtype is other than 0x00 RegisterVideoContentChangeCB N Y Y Verify the behavior of the callback to ensure it provides the Filmmaker Exit event, which involves detecting SEI content-type if the playback has not started or is stopped. RegisterVideoContentChangeCB N Y Y Verify that the callback gets triggered when modifying the video framerate. The test should include changes to various video framerates RegisterVideoFrameRateChangeCB N Y Y Verify the behavior of the callback to ensure it provides the default tvVideoFrameRate_NONE if the playback has not started or is stopped. RegisterVideoFrameRateChangeCB N Y Y"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#test-startup-requirement-callback-mechanisms","title":"Test Startup Requirement - Callback Mechanisms","text":"<p>Test Start up Requirement</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#emulator-requirement-callback-mechanisms","title":"Emulator Requirement - Callback Mechanisms","text":"<p>Emulator Requirement</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#control-plane-requirement-callback-mechanisms","title":"Control Plane Requirement - Callback Mechanisms","text":"<p>The Control Plane dynamically adjusts to various video formats, video resolutions, Film Maker modes, and video frame rates to trigger the callbacks.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#video-formats","title":"Video Formats","text":"Description HAL APIs L2 L3 Control Plane requirements Get TV supported video formats and verify that the test provides all supported video formats and their count (minimum is 1 and maximum is VIDEO_FORMAT_MAX). Compare the test results with the platform-supported configurations file, 'Sink-4K-TvSettings.yaml', using the path 'VideoFormat/index' and loop through the indices, using the path 'VideoFormat/numberOfFormats' compare the count. GetTVSupportedVideoFormats() Y N N Verify getting the current video format when there is no video playback. Default is VIDEO_FORMAT_SDR GetCurrentVideoFormat() Y N N Verify getting the current video format during video playback. Check with the analyzer whether it updates the correct video format of the playback video. GetCurrentVideoFormat() N Y Y Verify the current video format by dynamically changing various video formats. Check with the analyzer whether it updates the correct video format of the playback video. GetCurrentVideoFormat() N Y Y"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#test-startup-requirement-video-formats","title":"Test Startup Requirement - Video Formats","text":"<p>Test Start up Requirement</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#emulator-requirement-video-formats","title":"Emulator Requirement - Video Formats","text":"<p>Emulator Requirement</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#control-plane-requirement-video-formats","title":"Control Plane Requirement - Video Formats","text":"<ul> <li>Control plane connects and dynamically adjusts various video formats from external devices.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#get-current-video-resolution","title":"Get Current Video Resolution","text":"Description HAL APIs L2 L3 Control Plane requirements Verify the current video resolution of the primary video. Check with the analyzer whether it updates the correct video resolution of the playback video. GetCurrentVideoResolution() N Y N Verify that the current video resolution of the primary video is 'tvVideoResolution_NONE' when playback has not started or has been stopped. GetCurrentVideoResolution() Y N N Verify the current video resolution of the primary video by playing back different videos sources with different resolutions. GetCurrentVideoResolution() N Y Y"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#test-startup-requirement-get-current-video-resolution","title":"Test Startup Requirement - Get Current Video Resolution","text":"<p>Test Start up Requirement</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#emulator-requirement-get-current-video-resolution","title":"Emulator Requirement - Get Current Video Resolution","text":"<p>Emulator Requirement</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#control-plane-requirement-get-current-video-resolution","title":"Control Plane Requirement - Get Current Video Resolution","text":"<ul> <li>Control plane connects and dynamically adjusts various video resolutions from external devices.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#get-current-video-framerate","title":"Get Current Video FrameRate","text":"Description HAL APIs L2 L3 Control Plane requirements Verify the video frame rate of the current primary video. Check with the analyzer whether it updates the correct video FrameRate of the playback video. GetCurrentVideoFrameRate() N Y N Verify that the current video frame rate of the primary video is 'tvVideoFrameRate_NONE' when playback has not started or has been stopped. GetCurrentVideoFrameRate() Y N N Verify the current video frame rate of the primary video by playing back videos with different frame rates. GetCurrentVideoFrameRate() N Y Y"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#test-startup-requirement-get-current-video-framerate","title":"Test Startup Requirement - Get Current Video FrameRate","text":"<p>Test Start up Requirement</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#emulator-requirement-get-current-video-framerate","title":"Emulator Requirement - Get Current Video FrameRate","text":"<p>Emulator Requirement</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#control-plane-requirement-get-current-video-framerate","title":"Control Plane Requirement - Get Current Video FrameRate","text":"<ul> <li>Control plane connects and dynamically adjusts various video frame rates from external devices.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#video-sources","title":"Video Sources","text":"Description HAL APIs L2 L3 Control Plane requirements Get TV Supported Video Sources - Verify the test provides all supported video sources and their count( Min is 1 and Max is VIDEO_SOURCE_MAX). Compare the test results with the platform-supported configurations file, 'Sink-4K-TvSettings.yaml', using the path 'VideoSource/index' and loop through the indices, using the path 'VideoSource/numberOfSources' compare the count. GetTVSupportedVideoSources() Y N N Verify when there is no video source device is connected. Default is VIDEO_SOURCE_IP GetCurrentVideoSource() Y N N Verify the video source selected for the current primary video. Check with the analyzer whether it updates the correct video sources of the playback video. GetCurrentVideoSource() N Y Y Verify the video source selected for the current primary video by selecting different video sources. GetCurrentVideoSource() N Y Y"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#test-startup-requirement-video-sources","title":"Test Startup Requirement - Video Sources","text":"<p>Test Start up Requirement</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#emulator-requirement-video-sources","title":"Emulator Requirement - Video Sources","text":"<p>Emulator Requirement</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#control-plane-requirement-video-sources","title":"Control Plane Requirement - Video Sources","text":"<ul> <li>Control plane connects and disconnects various video sources from external devices.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#backlight-backlightfade-backlightmodes-and-tv-dimming-modes","title":"BackLight BackLightfade Backlightmodes and TV Dimming Modes","text":"Description HAL APIs L2 L3 Control Plane requirements Sets and Gets the backlight within the valid range (0 - 100). The retrieved value should match the set value. Get values are retrieved from the <code>PQ</code> database. SetBacklight(), GetBacklight() Y N N Set and Gets the Back light and check the functionality for selected video sources, formats, and picture modes. Verify that upon switching to different content and returning to the chosen source, format, and mode, the backlight remain retained. Validate using the analyzer and various video sources, video formats and picture modes. SetBacklight(), GetBacklight() N Y Y Set and Gets the Back light fade within the valid ranges of from ( 0  - 100 ) , to ( 0 - 100 ), current( 0 - 100) and duration (0 - 10000 ms). The retrieved value should match the set value. Get values are retrieved from the <code>PQ</code> database. GetCurrentBacklightFade(), SetBacklightFade() Y N N Set and get the backlight fade to test the backlight fade settings. Verify that upon switching to different content and returning to the chosen source, format, and mode, the backlight does not retain the previous value and moves to a new backlight value, as it does not save. Check with the analyzer whether it fades between the two different backlight values specified within a given duration. Validate this behavior with various video sources and video formats. GetCurrentBacklightFade(), SetBacklightFade() N Y Y Get Supported Back light Modes - verifies to get the all supported backlight modes. Compare the test results with the platform-supported configurations file, 'Sink-4K-TvSettings.yaml', using the path 'BacklightControl/index' and loop through the indices. GetSupportedBacklightModes() Y N N Set and Gets the current Back light modes. The retrieved value should match the set value. Get values are retrieved from the <code>PQ</code> database. GetCurrentBacklightMode(), SetCurrentBacklightMode() Y N Y Set and Gets the current Back light modes by dynamically changing the various back light modes. Check by analyzer whether it adjust to the new back light modes. Validate with various video sources and formats. GetCurrentBacklightMode(), SetCurrentBacklightMode() N Y Y Set and Gets the current backlight modes by verifying the Auto backlight mode (tvBacklightMode_AMBIENT). Check with the analyzer whether it adjusts the backlight levels of the screen based on the ambient light conditions. Validate with various video sources and formats. GetCurrentBacklightMode(), SetCurrentBacklightMode() N Y Y Gets TV Supported Dimming Modes - Verify the test provides all supported backlight dimming modes and their count( Min is 1 and Max is tvDimmingMode_MAX). Compare the test results with the platform-supported configurations file, 'Sink-4K-TvSettings.yaml', using the path 'DimmingMode/index' and loop through the indices. For the count use the path 'DimmingMode/numberOfDimmingModes' GetTVSupportedDimmingModes() Y N Y Set and Gets the TV Dimming modes. The retrieved value should match the set value. Get values are retrieved from the <code>PQ</code> database. SetTVDimmingMode(), GetTVDimmingMode() Y N N Set and Gets the TV Dimming modes and check the functionality for selected video sources, formats, and picture modes. Verify that upon switching to different content and returning to the chosen source, format, and mode, the TV dimming modes remain retained. Validate with an analyzer whether the changes are applied to the hardware, and test using various video sources, video formats, and picture modes. SetTVDimmingMode(), GetTVDimmingMode() N Y Y Set and get the TV dimming modes. Test whether changing the dimming mode affects the panel's peak brightness and verify that the EDID reloads to update the VSVDB string. Validate this with the video format managed by the Dolby Vision core. Validate by analyzer. SetTVDimmingMode(), GetTVDimmingMode() N Y Y"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#test-startup-requirement-back-light-back-light-fade-back-light-modes-and-tv-dimming-modes","title":"Test Startup Requirement - Back light - Back light fade - Back light modes and TV Dimming Modes","text":"<p>Test Start up Requirement</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#emulator-requirement-back-light-back-light-fade-back-light-modes-and-tv-dimming-modes","title":"Emulator Requirement - Back light - Back light fade - Back light modes and TV Dimming Modes","text":"<p>Emulator Requirement</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#control-plane-requirement-back-light-back-light-fade-back-light-modes-and-tv-dimming-modes","title":"Control Plane Requirement - Back light - Back light fade - Back light modes and TV Dimming Modes","text":"<ul> <li>Control plane checks the functionality with the analyzer by using different video sources, video formats, and picture settings to test the backlight fade, backlight, backlight modes, and TV dimming modes.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#localdimminglevel-brightness-contrast-sharpness-saturation-and-hue","title":"LocalDimmingLevel Brightness Contrast Sharpness Saturation and Hue","text":"Description HAL APIs L2 L3 Control Plane requirements Set and Gets the local Dimming level. The retrieved value should match the set value. Get values are retrieved from the  database. SetLocalDimmingLevel(), GetLocalDimmingLevel() Y N N Set and get the local dimming level, and check the functionality for selected video sources, formats, and picture modes. Verify that upon switching to different content and returning to the chosen source, format, and mode, the local dimming level remain retained. Validate with an analyzer whether the changes are applied to the hardware, and test using various video sources, video formats, and picture modes. SetLocalDimmingLevel(), GetLocalDimmingLevel() N Y Y Set and get the local Dimming level. Test whether changing the dimming level affects the panel's peak brightness and verify that the EDID reloads to update the VSVDB string. Validate this with the video format managed by the Dolby Vision core. Validate by analyzer. SetLocalDimmingLevel(), GetLocalDimmingLevel() N Y Y Set and Gets the brightness within the valid range ( 0 - 100 ). The retrieved value should match the set value. Get values are retrieved from the database. SetBrightness(), GetBrightness() Y N N Set and get the brightness level, and check the functionality for selected video sources, formats, and picture modes. Verify that upon switching to different content and returning to the chosen source, format, and mode, the brightness remain retained. Validate with an analyzer whether the changes are applied to the hardware, and test using various video sources, video formats, and picture modes. SetBrightness(), GetBrightness() N Y Y Set and Gets the contrast within the valid range ( 0 - 100 ). The retrieved value should match the set value. Get values are retrieved from the database. SetContrast(), GetContrast() Y N N Set and get the contrast level, and check the functionality for selected video sources, formats, and picture modes. Verify that upon switching to different content and returning to the chosen source, format, and mode, the contrast remain retained. Validate with an analyzer whether the changes are applied to the hardware, and test using various video sources, video formats, and picture modes. SetContrast(), GetContrast() N Y Y Set and Gets the sharpness ( 0 - 100 ). The retrieved value should match the set value. Get values are retrieved from the database. SetSharpness(), GetSharpness() Y N N Set and get the sharpness level, and check the functionality for selected video sources, formats, and picture modes. Verify that upon switching to different content and returning to the chosen source, format, and mode, the sharpness remain retained. Validate with an analyzer whether the changes are applied to the hardware, and test using various video sources, video formats, and picture modes. SetSharpness(), GetSharpness() N Y Y Set and Gets the saturation within the valid range ( 0 - 100 ). The retrieved value should match the set value. Get values are retrieved from the database. SetSaturation(), GetSaturation() Y N N Set and get the saturation level, and check the functionality for selected video sources, formats, and picture modes. Verify that upon switching to different content and returning to the chosen source, format, and mode, the saturation remain retained. Validate with an analyzer whether the changes are applied to the hardware, and test using various video sources, video formats, and picture modes. SetSaturation(), GetSaturation() N Y Y Set and Gets the Hue ( 0 - 100 ) . The retrieved value should match the set value. Get values are retrieved from the database. SetHue(), GetHue() Y N N Set and get the Hue level, and check the functionality for selected video sources, formats, and picture modes. Verify that upon switching to different content and returning to the chosen source, format, and mode, the Hue remain retained. Validate with an analyzer whether the changes are applied to the hardware, and test using various video sources, video formats, and picture modes. SetHue(), GetHue() N Y Y"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#test-startup-requirement-local-dimming-level-brightness-contrast-sharpness-saturation-and-hue","title":"Test Startup Requirement - Local Dimming Level - Brightness - Contrast - Sharpness - Saturation and Hue","text":"<p>Test Start up Requirement</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#emulator-requirement-local-dimming-level-brightness-contrast-sharpness-saturation-and-hue","title":"Emulator Requirement - Local Dimming Level - Brightness - Contrast - Sharpness - Saturation and Hue","text":"<p>Emulator Requirement</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#control-plane-requirement-local-dimming-level-brightness-contrast-sharpness-saturation-and-hue","title":"Control Plane Requirement - Local Dimming Level - Brightness - Contrast - Sharpness - Saturation and Hue","text":"<ul> <li>Control plane checks the functionality by analyzer and the different  streams to test the local dimming level, brightness levels, contrast levels, Sharpness levels and Saturation levels.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#colortemperature-aspectratio-lowlatencystate-dynamiccontrast-and-dynamicgamma","title":"ColorTemperature AspectRatio LowLatencyState DynamicContrast and DynamicGamma","text":"Description HAL APIs L2 L3 Control Plane requirements Set and Gets the Color Temperature. The retrieved value should match the set value. Get values are retrieved from the database. SetColorTemperature, GetColorTemperature Y N N Set and get the color Temperature, and check the functionality for selected video sources, formats, and picture modes. Verify that upon switching to different content and returning to the chosen source, format, and mode, the color temperature remain retained. Validate with an analyzer whether the changes are applied to the hardware, and test using various video sources, video formats, and picture modes. SetColorTemperature, GetColorTemperature N Y Y Set and Gets the Aspect Ratio. The retrieved value should match the set value. Get values are retrieved from the database. SetAspectRatio, GetAspectRatio Y N N Set and get the Aspect Ratio, and check the functionality for selected video sources, formats, and picture modes. Verify that upon switching to different content and returning to the chosen source, format, and mode, the Aspect Ratio remain retained. Validate with an analyzer whether the changes are applied to the hardware, and test using various video sources, video formats, and picture modes. SetAspectRatio, GetAspectRatio N Y Y Set and Gets the Low Latency State ( 0 for disable and 1 for enable ). The retrieved value should match the set value. Get values are retrieved from the database. SetLowLatencyState, GetLowLatencyState Y N N Set and get the dynamic contrast state, and check the functionality for selected video sources, formats, and picture modes. Validate whether the changes are applied in the PQ module. Verify that upon switching to different content and returning to the chosen source, format, and mode, the dynamic contrast should not be retained. Validate with an analyzer and test using various video sources, video formats, and picture modes. SetLowLatencyState, GetLowLatencyState N Y Y Set and Gets the Dynamic Contrast. The retrieved value should match the set value. Get values are retrieved from the database. SetDynamicContrast, GetDynamicContrast Y N N Set and Gets the Dynamic Contrast, and check the functionality for the different video sources, formats, and picture modes to ensure whether it reverts the default settings for the video format, video source and picture mode SetDynamicContrast, GetDynamicContrast N Y Y Set and Gets the Dynamic Gamma within the valid range ( 1.80 to 2.60 ). The retrieved value should match the set value. Get values are retrieved from the database. SetDynamicGamma(), GetDynamicGamma() Y N N Set and get the Dynamic Gamma. Validate the functionality by adjusting the color temperature and confirming that the new gamma curve shifts according to the set Dynamic Gamma value. Validate with the analyzer and with various video sources, formats, and color temperatures. SetDynamicGamma(), GetDynamicGamma() N Y Y"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#test-startup-requirement-color-temperature-aspect-ratio-low-latency-state-dynamic-contrast-and-dynamic-gamma","title":"Test Startup Requirement - Color Temperature - Aspect Ratio -  Low Latency State - Dynamic Contrast and Dynamic Gamma","text":"<p>Test Start up Requirement</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#emulator-requirement-color-temperature-aspect-ratio-low-latency-state-dynamic-contrast-and-dynamic-gamma","title":"Emulator Requirement - Color Temperature - Aspect Ratio -  Low Latency State - Dynamic Contrast and Dynamic Gamma","text":"<p>Emulator Requirement</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#control-plane-requirement-color-temperature-aspect-ratio-low-latency-state-dynamic-contrast-and-dynamic-gamma","title":"Control Plane Requirement - Color Temperature - Aspect Ratio -  Low Latency State - Dynamic Contrast and Dynamic Gamma","text":"<ul> <li>Control plane checks the functionality by analyzer.</li> <li>For color temperature, aspect ratio and low latency state, control plane dynamically changing the selected video sources, formats and picture modes by the external devices</li> <li>For dynamic contrast, control plane dynamically changing the different video sources, formats and picture modes by the external devices</li> <li>For dynamic gamma, control plane adjust the color temperature by the external sources.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#tv-dolby-vision-mode","title":"TV Dolby Vision mode","text":"Description HAL APIs L2 L3 Control Plane requirements Get TV Supported Dolby Vision Modes - Verify the test provides all supported Dolby vision modes and their count( Min is 0 and Max is tvMode_Max ). Compare the test results with the platform-supported configurations file, 'Sink-4K-TvSettings.yaml', using the path 'DolbyVisionMode/index' and loop through the indices. For the count use the path 'DolbyVisionMode/numberOfDolbyVisionMode' GetTVSupportedDolbyVisionModes() Y N N Set and Gets the TV Dolby Vision mode. The retrieved value should match the set value. Get values are retrieved from the database. SetTVDolbyVisionMode(), GetTVDolbyVisionMode() Y N N Set and get the Dolby Vision mode value, and check the functionality for selected video sources, formats, and picture modes. Verify that upon switching to different content and returning to the chosen source, format, and mode, the Dolby Vision mode remains retained. Validate with an analyzer whether the changes are applied to the hardware, and test using various video sources, video formats, and picture modes. SetTVDolbyVisionMode(), GetTVDolbyVisionMode() N Y Y"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#test-startup-requirement-tv-dolby-vision-mode","title":"Test Startup Requirement - TV Dolby Vision mode","text":"<p>Test Start up Requirement</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#emulator-requirement-tv-dolby-vision-mode","title":"Emulator Requirement - TV Dolby Vision mode","text":"<p>Emulator Requirement</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#control-plane-requirement-tv-dolby-vision-mode","title":"Control Plane Requirement - TV Dolby Vision mode","text":"<ul> <li>Control plane checks the functionality by analyzer and check the functionality for the different selected video sources, formats, and picture modes.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#picture-modes","title":"Picture Modes","text":"Description HAL APIs L2 L3 Control Plane requirements Get TV Supported Picture Modes - Verify the test provides all supported Picture Modes and their count( Min is 1 and Max is PIC_MODES_SUPPORTED_MAX ). Compare the test results with the platform-supported configurations file, 'Sink-4K-TvSettings.yaml', using the path 'PictureMode/index' and loop through the indices. For the count use the path 'PictureMode/numberOfPictureModes' GetTVSupportedPictureModes() Y N N Set and Gets the TV Picture Mode. The retrieved value should match the set value. Set the picture mode to a valid value as specified by <code>pic_modes_t.name</code> from the GetTVSupportedPictureModes API, with the string size limited to PIC_MODE_NAME_MAX. Get values are retrieved from the database. GetTVSupportedPictureModes(), SetTVPictureMode(), GetTVPictureMode() Y N N Set and get the TV picture modes and their associated properties, and verify the functionality across selected video sources, formats, and picture modes. Confirm that upon switching to different content and returning to the chosen source, format, and mode, the set picture mode and its properties are reloaded correctly. Validate with an analyzer whether the associated changes in picture properties are applied to the new mode, and conduct testing using various video sources, formats, and picture modes. SetTVPictureMode(), GetTVPictureMode() N Y Y"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#test-startup-requirement-picture-modes","title":"Test Startup Requirement - Picture Modes","text":"<p>Test Start up Requirement</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#emulator-requirement-picture-modes","title":"Emulator Requirement - Picture Modes","text":"<p>Emulator Requirement</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#control-plane-requirement-picture-modes","title":"Control Plane Requirement - Picture Modes","text":"<ul> <li>Control plane checks the functionality by analyzer and check the functionality for the different selected video sources, formats, and picture modes.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#color-temperature-rgain-ggain-bgain-on-source","title":"Color Temperature Rgain Ggain Bgain on source","text":"Description HAL APIs L2 L3 Control Plane requirements Loop through different color temperatures and source ids. Set and Gets the color Temperature Rgain on Source. The retrieved value should match the set value. Get values are retrieved from the database. SetColorTemp_Rgain_onSource(), GetColorTemp_Rgain_onSource() Y N N Set and Get color temperature Rgain for a specific color temperature and video source and confirm functionality across chosen video sources, formats, and picture modes. Ensure the correct utilization of Rgain in the white balance module. When 'saveOnly = 0', validate behavior upon content change and check whether it revert to default picture profile database values. Validate using the analyzer and across video sources, formats, and picture modes. SetColorTemp_Rgain_onSource(), GetColorTemp_Rgain_onSource() N Y Y Set and get color temperature Rgain for the specific video source and color temperature, and confirm functionality across chosen video sources, formats, and picture modes. Ensure the correct utilization of Rgain in the white balance module. When 'saveOnly = 1', validate behavior upon content change and switching to either selected video source, format, or picture mode color temperature will be automatically applied to the white balance module. Validate using the analyzer and across video sources, formats, and picture modes. SetColorTemp_Rgain_onSource(), GetColorTemp_Rgain_onSource() N Y Y Loop through different color temperatures and source ids. Set and Gets the color Temperature Ggain on Source. The retrieved value should match the set value. Get values are retrieved from the  database. SetColorTemp_Ggain_onSource(), GetColorTemp_Ggain_onSource() Y N N Set and Get color temperature Ggain for a specific color temperature and video source and confirm functionality across chosen video sources, formats, and picture modes. Ensure the correct utilization of Ggain in the white balance module. When 'saveOnly = 0', validate behavior upon content change and check whether it revert to default picture profile database values. Validate using the analyzer and across video sources, formats, and picture modes. SetColorTemp_Rgain_onSource(), GetColorTemp_Ggain_onSource() N Y Y Set and get color temperature Ggain for the specific video source and color temperature, and confirm functionality across chosen video sources, formats, and picture modes. Ensure the correct utilization of Ggain in the white balance module. When 'saveOnly = 1', validate behavior upon content change and switching to either selected video source, format, or picture mode color temperature will be automatically applied to the white balance module. Validate using the analyzer and across video sources, formats, and picture modes. SetColorTemp_Rgain_onSource(), GetColorTemp_Ggain_onSource() N Y Y Loop through different color temperatures and source ids. Set and Gets the color Temperature Bgain on Source. The retrieved value should match the set value. Get values are retrieved from the  database. SetColorTemp_Bgain_onSource(), GetColorTemp_Bgain_onSource() Y N N Set and Get color temperature Bgain for a specific color temperature and video source and confirm functionality across chosen video sources, formats, and picture modes. Ensure the correct utilization of Bgain in the white balance module. When 'saveOnly = 0', validate behavior upon content change and check whether it revert to default picture profile database values. Validate using the analyzer and across video sources, formats, and picture modes. SetColorTemp_Bgain_onSource(), GetColorTemp_Rgain_onSource() N Y Y Set and get color temperature Bgain for the specific video source and color temperature, and confirm functionality across chosen video sources, formats, and picture modes. Ensure the correct utilization of Bgain in the white balance module. When 'saveOnly = 1', validate behavior upon content change and switching to either selected video source, format, or picture mode color temperature will be automatically applied to the white balance module. Validate using the analyzer and across video sources, formats, and picture modes. SetColorTemp_Bgain_onSource(), GetColorTemp_Rgain_onSource() N Y Y"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#test-startup-requirement-color-temperature-rgain-ggain-bgain-on-source","title":"Test Startup Requirement - Color Temperature Rgain Ggain Bgain on source","text":"<p>Test Start up Requirement</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#emulator-requirement-color-temperature-rgain-ggain-bgain-on-source","title":"Emulator Requirement - Color Temperature Rgain Ggain Bgain on source","text":"<p>Emulator Requirement</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#control-plane-requirement-color-temperature-rgain-ggain-bgain-on-source","title":"Control Plane Requirement - Color Temperature Rgain Ggain Bgain on source","text":"<ul> <li>Control plane checks the functionality by analyzer and dynamically changing the selected video sources, formats, and picture modes.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#color-temperature-r-post-g-post-and-b-post-offset-onsource","title":"Color Temperature R post G post and B post offset onsource","text":"Description HAL APIs L2 L3 Control Plane requirements Loop through different color temperatures and source ids. Set and Gets the color Temperature R post offset on Source. The retrieved value should match the set value. Get values are retrieved from the  database. SetColorTemp_R_post_offset_onSource(), GetColorTemp_R_post_offset_onSource() Y N N Set and Get color temperature R post offset for a specific color temperature and video source and confirm functionality across chosen video sources, formats, and picture modes. Ensure the correct utilization of R post offset in the white balance module. When 'saveOnly = 0', validate behavior upon content change and check whether it revert to default picture profile database values. Validate using the analyzer and across video sources, formats, and picture modes. SetColorTemp_R_post_offset_onSource(), GetColorTemp_R_post_offset_onSource() N Y Y Set and get color temperature R post offset for the specific video source and color temperature, and confirm functionality across chosen video sources, formats, and picture modes. Ensure the correct utilization of R post offset in the white balance module. When 'saveOnly = 1', validate behavior upon content change and switching to either selected video source, format, or picture mode color temperature will be automatically applied to the white balance module. Validate using the analyzer and across video sources, formats, and picture modes. SetColorTemp_R_post_offset_onSource(), GetColorTemp_R_post_offset_onSource() N Y Y Loop through different color temperatures and source ids. Set and Gets the color Temperature G post offset on Source. The retrieved value should match the set value. Get values are retrieved from the  database. SetColorTemp_G_post_offset_onSource(), GetColorTemp_G_post_offset_onSource() Y N N Set and Get color temperature G post offset for a specific color temperature and video source and confirm functionality across chosen video sources, formats, and picture modes. Ensure the correct utilization of G post offset in the white balance module. When 'saveOnly = 0', validate behavior upon content change and check whether it revert to default picture profile database values. Validate using the analyzer and across video sources, formats, and picture modes. SetColorTemp_G_post_offset_onSource(), GetColorTemp_G_post_offset_onSource() N Y Y Set and get color temperature G post offset for the specific video source and color temperature, and confirm functionality across chosen video sources, formats, and picture modes. Ensure the correct utilization of G post offset in the white balance module. When 'saveOnly = 1', validate behavior upon content change and switching to either selected video source, format, or picture mode color temperature will be automatically applied to the white balance module. Validate using the analyzer and across video sources, formats, and picture modes. SetColorTemp_G_post_offset_onSource(), GetColorTemp_G_post_offset_onSource() N Y Y Loop through different color temperatures and source ids. Set and Gets the color Temperature B post offset on Source. The retrieved value should match the set value. Get values are retrieved from the  database. SetColorTemp_B_post_offset_onSource(), GetColorTemp_B_post_offset_onSource() Y N N Set and Get color temperature B post offset for a specific color temperature and video source and confirm functionality across chosen video sources, formats, and picture modes. Ensure the correct utilization of B post offset in the white balance module. When 'saveOnly = 0', validate behavior upon content change and check whether it revert to default picture profile database values. Validate using the analyzer and across video sources, formats, and picture modes. SetColorTemp_B_post_offset_onSource(), GetColorTemp_B_post_offset_onSource() N Y Y Set and get color temperature B post offset for the specific video source and color temperature, and confirm functionality across chosen video sources, formats, and picture modes. Ensure the correct utilization of B post offset in the white balance module. When 'saveOnly = 1', validate behavior upon content change and switching to either selected video source, format, or picture mode color temperature will be automatically applied to the white balance module. Validate using the analyzer and across video sources, formats, and picture modes. SetColorTemp_B_post_offset_onSource(), GetColorTemp_B_post_offset_onSource() N Y Y"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#test-startup-requirement-color-temperature-r-post-g-post-and-b-post-offset-onsource","title":"Test Startup Requirement - Color Temperature R post G post and B post offset onsource","text":"<p>Test Start up Requirement</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#emulator-requirement-color-temperature-r-post-g-post-and-b-post-offset-onsource","title":"Emulator Requirement - Color Temperature R post G post and B post offset onsource","text":"<p>Emulator Requirement</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#control-plane-requirement-color-temperature-r-post-g-post-and-b-post-offset-onsource","title":"Control Plane Requirement - Color Temperature R post G post and B post offset onsource","text":"<ul> <li>Control plane checks the functionality by analyzer and dynamically changing the selected video sources, formats, and picture modes.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#wb-calibration-mode","title":"<code>WB</code> Calibration Mode","text":"Description HAL APIs L2 L3 Control Plane requirements Disables the <code>WB</code> Calibration Mode and verify by the Get Current WB Calibration Mode EnableWBCalibrationMode(), GetCurrentWBCalibrationMode() Y N N Enables the <code>WB</code> Calibration Mode and verify by the Get Current WB Calibration Mode EnableWBCalibrationMode(), GetCurrentWBCalibrationMode() Y N N Enables the <code>WB</code> Calibration Mode and test. When enabled configures backlight in fixed dimming mode and sets all <code>PQ</code> elements except for gamma/white balance elements in bypass mode/disabled mode. Validate this with the analyzer and using the different video streams. EnableWBCalibrationMode(), GetCurrentWBCalibrationMode() N Y Y Disables the <code>WB</code> Calibration Mode and test. On disable restores the dimming mode and all <code>PQ</code> elements in the last known state before the WB calibration mode was enabled. Validate this with the analyzer and test using the different video streams. EnableWBCalibrationMode(), GetCurrentWBCalibrationMode() N Y Y"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#test-startup-requirement-wb-calibration-mode","title":"Test Startup Requirement - <code>WB</code> Calibration Mode","text":"<p>Test Start up Requirement</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#emulator-requirement-wb-calibration-mode","title":"Emulator Requirement - <code>WB</code> Calibration Mode","text":"<p>Emulator Requirement</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#control-plane-requirement-wb-calibration-mode","title":"Control Plane Requirement - <code>WB</code> Calibration Mode","text":"<ul> <li>Control plane uses analyzer to check the settings when it is turned on and check the backlight stay at a constant low brightness level except gamma/white balance adjustments.</li> <li>Control plane uses analyzer to check the settings When you disable this feature, it brings back the previous dimming mode and restores all PQ adjustments to the settings they were in before you activated the white balance calibration mode.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#get-and-set-gamma-table","title":"Get and Set Gamma Table","text":"Description HAL APIs L2 L3 Control Plane requirements Set and Gets the Gamma Table within the range ( 0 - 1023). The retrieved value should match the set value. Get values are retrieved from the  database. GetGammaTable(), SetGammaTable() Y N N Test the Gamma Table functionality by setting and retrieving values across chosen video sources, formats, and picture modes. Verify that when content changes or switching between video sources, formats, and picture modes occurs, any set Gamma table values are discarded ( since it is not saved ), ensuring default values from the picture profile database are utilized. Validate this behavior with an analyzer and test across multiple video sources, formats, and picture modes. GetGammaTable(), SetGammaTable() N Y Y Gets the default gamma calibrated values for gamma red, green and blue values ( 0 - 65535 ) and check the values are in the range. GetDefaultGammaTable() Y N N"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#test-startup-requirement-get-and-set-gamma-table","title":"Test Startup Requirement - Get and Set Gamma Table","text":"<p>Test Start up Requirement</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#emulator-requirement-get-and-set-gamma-table","title":"Emulator Requirement - Get and Set Gamma Table","text":"<p>Emulator Requirement</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#control-plane-requirement-get-and-set-gamma-table","title":"Control Plane Requirement - Get and Set Gamma Table","text":"<ul> <li>Control plane checks the functionality by analyzer and dynamically changing the selected video sources, formats, and picture modes.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#get-and-set-dv-tmax-value","title":"Get and Set Dv Tmax Value","text":"Description HAL APIs L2 L3 Control Plane requirements Set and Gets the Dv Tmax Value within the range ( 0 - 10000 ). The retrieved value should match the set value. Get values are retrieved from the  database. SetDvTmaxValue(), GetDvTmaxValue() Y N N Set and retrieve the Dolby Vision Tmax value and verify functionality across selected video sources, formats, and picture modes. Since it is not saved, upon changing the content and switching back to the selected video sources, formats, and picture modes, the Dolby Vision Tmax value should be discarded, and the default value from the picture profile database should be used instead. Validate functionality using the analyzer and across various video sources, formats, and picture modes. SetDvTmaxValue(), GetDvTmaxValue() N Y Y"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#test-startup-requirement-get-and-set-dv-tmax-value","title":"Test Startup Requirement - Get and Set Dv Tmax Value","text":"<p>Test Start up Requirement</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#emulator-requirement-get-and-set-dv-tmax-value","title":"Emulator Requirement - Get and Set Dv Tmax Value","text":"<p>Emulator Requirement</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#control-plane-requirement-get-and-set-dv-tmax-value","title":"Control Plane Requirement - Get and Set Dv Tmax Value","text":"<ul> <li>Control plane checks the functionality by analyzer and dynamically changing the selected video sources, formats, and picture modes.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#get-supported-component-color","title":"Get Supported Component Color","text":"Description HAL APIs L2 L3 Control Plane requirements Verifies whether the test gets the supported component colors by comparing the test results with the platform-supported configurations file, 'Sink-4K-TvSettings.yaml', using the path 'SupportedComponentColor' and loop through the indices. GetSupportedComponentColor() Y N N"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#test-startup-requirement-get-supported-component-color","title":"Test Startup Requirement - Get Supported Component Color","text":"<p>Test Start up Requirement</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#emulator-requirement-get-supported-component-color","title":"Emulator Requirement - Get Supported Component Color","text":"<p>Emulator Requirement</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#control-plane-requirement-get-supported-component-color","title":"Control Plane Requirement - Get Supported Component Color","text":"<p>None</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#currentcomponentsaturation-component-hue-and-component-luma","title":"CurrentComponentSaturation Component Hue and Component Luma","text":"Description HAL APIs L2 L3 Control Plane requirements Set and Get the component saturation by verifying whether the values are within the valid range (0 - 100). The retrieved value should match the set value. Get values are fetched from the  database. SetCurrentComponentSaturation(), GetCurrentComponentSaturation() Y N N Set and Get the Component Saturation, and verify its functionality with the currently selected video sources, formats, and picture modes to ensure it uses the set component saturation for the current selections. Confirm that when switching to different content and returning to the chosen source, format, and mode, the Component Saturation remains retained. Validate the component saturation using an analyzer and test it with different video sources, formats, and picture modes. SetCurrentComponentSaturation(), GetCurrentComponentSaturation() N Y Y Set and Get the Component Hue by verifying whether the values are within the valid range (0 - 100). The retrieved value should match the set value. Get values are fetched from the  database. SetCurrentComponentHue(), GetCurrentComponentHue() Y N N Set and Get the Component Hue, and verify its functionality with the currently selected video sources, formats, and picture modes to ensure it uses the set component Hue for the current selections. Confirm that when switching to different content and returning to the chosen source, format, and mode, the Component Hue remains retained. Validate the component Hue using an analyzer and test it with different video sources, formats, and picture modes. SetCurrentComponentHue(), GetCurrentComponentHue() N Y Y Set and Gets the Component Luma by verifying whether the values are within the valid range (0 - 100). The retrieved value should match the set value. Get values are fetched from the  database. SetCurrentComponentLuma(), GetCurrentComponentLuma() Y N N Set and Get the Component Luma, and verify its functionality with the currently selected video sources, formats, and picture modes to ensure it uses the set component Luma for the current selections. Confirm that when switching to different content and returning to the chosen source, format, and mode, the Component Luma remains retained. Validate the component Luma using an analyzer and test it with different video sources, formats, and picture modes. SetCurrentComponentLuma(), GetCurrentComponentLuma() N Y Y"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#test-startup-requirement-current-component-saturation-component-hue-and-component-luma","title":"Test Startup Requirement - Current Component Saturation - Component Hue and Component Luma","text":"<p>Test Start up Requirement</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#emulator-requirement-current-component-saturation-component-hue-and-component-luma","title":"Emulator Requirement - Current Component Saturation - Component Hue and Component Luma","text":"<p>Emulator Requirement</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#control-plane-requirement-current-component-saturation-component-hue-and-component-luma","title":"Control Plane Requirement - Current Component Saturation - Component Hue and Component Luma","text":"<ul> <li>Control plane verifies functionality using an analyzer and dynamically changes the content, then switches back to the selected video sources, formats, and picture modes.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#cms","title":"CMS","text":"Description HAL APIs L2 L3 Control Plane requirements Save CMS value and verify functionality with specific video sources, formats, and picture modes. Confirm its use for the selected video source, format, and mode. Ensure automatic application of the CMS value upon returning to chosen settings. Validate functionality with an analyzer across various video sources, picture modes, video formats, component types, and color types. Loop through different video sources, video formats, component type and color type. Check the case where component type and color type are 'none', ensuring CMS value acts as CMS state. Also, check the case where component type and color type are not 'none', ensuring CMS value acts within saturation (0 - 100), hue (0 - 100), and luma (0 - 30) ranges. SaveCMS() N Y Y Set and Gets the <code>CMS</code> State. The retrieved value should match the set value. Get values are retrieved from the database. SetCMSState(), GetCMSState() Y N N Set and Get the CMS state and verify its functionality with the currently selected video sources, formats, and picture modes to ensure it uses the saved CMS state for the selected video source, format, and mode. Ensure that when switching to different content and then returning to the selected source, format, and mode, the CMS state is applied automatically. Validate using an analyzer and with different video sources, formats, and picture modes. SetCMSState(), GetCMSState() N Y Y"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#test-startup-requirement-cms","title":"Test Startup Requirement - CMS","text":"<p>Test Start up Requirement</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#emulator-requirement-cms","title":"Emulator Requirement - CMS","text":"<p>Emulator Requirement</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#control-plane-requirement-cms","title":"Control Plane Requirement - CMS","text":"<ul> <li>Control plane verifies functionality using an analyzer and dynamically changes the content, then switches back to the selected video sources, formats, and picture modes.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#pq-params","title":"PQ Params","text":"Description HAL APIs L2 L3 Control Plane requirements To test the Get <code>PQ</code> Parameters, loop through the different video sources, video formats, and picture quality modes for all combinations and set the brightness, contrast, sharpness, and component saturation value (loop through different saturation colors) to 50%. For Tmax, set the value to 500, and for low latency, set it to 1. After setting these values, loop through the different video sources, video formats, and picture quality modes again, read back the GetPQ parameter values and ensure that all are set to the required values: brightness, contrast, sharpness, and component saturation at 50%, Tmax at 500, and low latency at 1. SaveBrightness(), SaveContrast(), SaveSaturation(), SaveHue(), SaveLowLatencyState(), SetCurrentComponentSaturation(), SaveDvTmaxValue(), GetPQParams() Y N N"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#test-startup-requirement-get-default-pq-params","title":"Test Startup Requirement - Get Default PQ Params","text":"<p>Test Start up Requirement</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#emulator-requirement-get-default-pq-params","title":"Emulator Requirement - Get Default PQ Params","text":"<p>Emulator Requirement</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#control-plane-requirement-get-default-pq-params","title":"Control Plane Requirement - Get Default PQ Params","text":"<p>None</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#get-max-gain-value","title":"Get Max Gain Value","text":"Description HAL APIs L2 L3 Control Plane requirements Gets the max gamma/<code>WB</code> gain value for the platform and check it is in the range. The valid range can be from 2^10 till (2^31)-1. GetMaxGainValue() Y N N"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#test-startup-requirement-get-max-gain-value","title":"Test Startup Requirement - Get Max Gain Value","text":"<p>Test Start up Requirement</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#emulator-requirement-get-max-gain-value","title":"Emulator Requirement - Get Max Gain Value","text":"<p>Emulator Requirement</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#control-plane-requirement-get-max-gain-value","title":"Control Plane Requirement - Get Max Gain Value","text":"<p>None</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#gammamode-gammapattern-and-get-tv-gamma-target","title":"GammaMode Gammapattern and Get TV Gamma Target","text":"Description HAL APIs L2 L3 Control Plane requirements Enable Gamma Mode - Verifies enabling or disabling the gamma mode. It ensures successful enabling or disabling of the gamma module. Validation is required through different playback streams to test Gamma Mode, and validation by an analyzer. EnableGammaMode() N Y Y Verify the Set Gamma Pattern Mode by setting the primary color level at 10-bit resolution (0 - 1023) and checking if it bypasses all PQ elements and displays the passed primary colors. Switch between different content and return to the selected source, ensuring that the Set Gamma Pattern mode is not retained as it does not save. Test with various video streams and formats. Validate this using the analyzer. SetGammaPatternMode(true), SetGammaPattern() N Y Y Verify the Set Gamma Pattern Mode by setting the primary color level at 8-bit resolution (0 - 255) and checking if it bypasses all PQ elements and displays the passed primary colors. Switch between different content and return to the selected source, ensuring that the Set Gamma Pattern mode is not retained as it does not save. Test with various video streams and formats. Validate this using the analyzer. SetGammaPatternMode(true), SetGammaPattern() N Y Y Get TV Gamma Target verifies the functionality of retrieving the target x and y coordinates for the panel gamma based on a given color temperature. It ensures that the returned coordinates are within the range of 0 to 1.0. Validate with various color temperatures (tvColorTemp_t). GetTVGammaTarget() Y N N"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#test-startup-requirement-gamma-mode-gamma-pattern-and-get-tv-gamma-target","title":"Test Startup Requirement - Gamma Mode - Gamma pattern and Get TV Gamma Target","text":"<p>Test Start up Requirement</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#emulator-requirement-gamma-mode-gamma-pattern-and-get-tv-gamma-target","title":"Emulator Requirement - Gamma Mode - Gamma pattern and Get TV Gamma Target","text":"<p>Emulator Requirement</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#control-plane-requirement-gamma-mode-gamma-pattern-and-get-tv-gamma-target","title":"Control Plane Requirement - Gamma Mode - Gamma pattern and Get TV Gamma Target","text":"<ul> <li>Control plane verifies functionality using an analyzer and dynamically changes the content, then switches back to the selected sources.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#get-and-set-rgb-pattern-gray-pattern","title":"Get and Set RGB Pattern Gray Pattern","text":"Description HAL APIs L2 L3 Control Plane requirements Set and Gets the RGB Pattern within the range ( 0 - 255 ). The retrieved value should match the set value. Get values are retrieved from the database. SetRGBPattern(), GetRGBPattern() Y N N Set and Get the RGB Pattern at 8-bit resolution. The test sets the primary color level at 8-bit resolution and ensures the pattern is processed through the PQ pipeline before reaching the panel. Use the analyzer to test the scenario. Additionally, test the functionality with various video streams and formats. SetRGBPattern(), GetRGBPattern() N Y Y Set and Gets the Gray Pattern within the range ( 0 - 255 ). The retrieved value should match the set value. Get values are retrieved from the database. SetGrayPattern(), GetGrayPattern() Y N N Set and Get the Gray Pattern after enabling the set gamma pattern mode. The test sets various gray pattern levels and ensures it bypasses all PQ elements to display a full-screen gray pattern. Verify this using the analyzer and test with different playback streams to confirm the Gray Pattern is displayed correctly SetGammaPatternMode(true), SetGrayPattern(), GetGrayPattern() N Y Y Set and Gets the Gray Pattern after disabling the set gamma pattern mode. Verify whether Set Gray Pattern take effect using the analyzer. SetGammaPatternMode(false), SetGrayPattern(), GetGrayPattern() N Y Y"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#test-startup-requirement-get-and-set-rgb-pattern-gray-pattern","title":"Test Startup Requirement - Get and Set RGB Pattern Gray Pattern","text":"<p>Test Start up Requirement</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#emulator-requirement-get-and-set-rgb-pattern-gray-pattern","title":"Emulator Requirement - Get and Set RGB Pattern Gray Pattern","text":"<p>Emulator Requirement</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#control-plane-requirement-get-and-set-rgb-pattern-gray-pattern","title":"Control Plane Requirement - Get and Set RGB Pattern Gray Pattern","text":"<ul> <li>Control plane checks the functionality by analyzer and using the different playback streams to test the RGB pattern, Gray Pattern.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#get-open-circuit-status","title":"Get Open Circuit Status","text":"Description HAL APIs L2 L3 Control Plane requirements Verifies the functionality of retrieving the current open circuit status of the backlight hardware. It ensures that the returned status indicates whether any <code>LED</code> fault is detected. GetOpenCircuitStatus() Y N N"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#test-startup-requirement-get-open-circuit-status","title":"Test Startup Requirement - Get Open Circuit Status","text":"<p>Test Start up Requirement</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#emulator-requirement-get-open-circuit-status","title":"Emulator Requirement - Get Open Circuit Status","text":"<p>Emulator Requirement</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#control-plane-requirement-get-open-circuit-status","title":"Control Plane Requirement - Get Open Circuit Status","text":"<p>None</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#ldim-and-ldim-sequence-test","title":"LDIM and LDIM Sequence Test","text":"Description HAL APIs L2 L3 Control Plane requirements Enable <code>LDIM</code> - Enables or disables the local dimming module. When disabled, check that the backlight for all zones remains at a fixed level, and when enabled, it should not remain at a fixed level. Verify with the analyzer and different video sources, formats. EnableLDIM() N Y Y Enable <code>LDIM</code> Pixel Compensation - Verifies the functionality of enabling or disabling the pixel compensation block for <code>LDIM</code> (Local Dimming). Check by analyzer and verify its functionality by playing different video streams to ensure any changes in pixel intensity caused by backlighting in local dimming zones. EnableLDIMPixelCompensation() N Y Y Start <code>LDIM</code> Sequence Test - Verifies the local dimming sequence test. Initially, all local dimming (<code>LDIM</code>) zones are turned off, then each zone is turned on for a specified duration, sequentially repeating for all <code>LDIM</code> zones. Finally, the original state of all <code>LDIM</code> zones is restored at the end of the test. Monitor the behavior of the local dimming zones during the test using the analyzer. StartLDIMSequenceTest() N Y Y"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#test-startup-requirement-ldim-and-ldim-sequence-test","title":"Test Startup Requirement - LDIM and LDIM Sequence Test","text":"<p>Test Start up Requirement</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#emulator-requirement-ldim-and-ldim-sequence-test","title":"Emulator Requirement - LDIM and LDIM Sequence Test","text":"<p>Emulator Requirement</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#control-plane-requirement-ldim-and-ldim-sequence-test","title":"Control Plane Requirement - LDIM and LDIM Sequence Test","text":"<ul> <li>The control plane verifies functionality using an analyzer and dynamically changes various streams and formats.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#set-backlight-test-mode","title":"Set Backlight Test Mode","text":"Description HAL APIs L2 L3 Control Plane requirements Verifies the backlight hardware for calibration. Need to run the backlight test for normal, boost, burst and Reset modes. Monitor the calibration process by analyzer to confirm that it proceeds as intended. SetBacklightTestMode() N Y N"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#test-startup-requirement-set-backlight-test-mode","title":"Test Startup Requirement - Set Backlight Test Mode","text":"<p>Test Start up Requirement</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#emulator-requirement-set-backlight-test-mode","title":"Emulator Requirement - Set Backlight Test Mode","text":"<p>Emulator Requirement</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#control-plane-requirement-set-backlight-test-mode","title":"Control Plane Requirement - Set Backlight Test Mode","text":"<p>None</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#enable-and-disable-white-balance-dynamiccontrast-and-local-contrast","title":"Enable and Disable White Balance DynamicContrast and Local Contrast","text":"Description HAL APIs L2 L3 Control Plane requirements Enable White Balance - Verifies enabling or disabling the white balance module. Check with different playback video streams and verify the presence of white balance using the analyzer EnableWhiteBalance() N Y N Enable Dynamic Contrast - Verifies the functionality of enabling or disabling the dynamic contrast module. Check the status by get dynamic contrast. EnableDynamicContrast(), GetDynamicContrast() Y N N Enable Dynamic Contrast - Verifies enabling or disabling the Dynamic Contrast module. Check with different playback video streams and verify the presence of Dynamic Contrast using the analyzer EnableDynamicContrast() N Y Y Enable Local Contrast - Verifies the functionality of enabling or disabling the local contrast module. Check with different playback video streams and verify the presence of local contrast using the analyzer EnableLocalContrast() N Y Y"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#test-startup-requirement-enable-and-disable-white-balance-dynamic-contrast-and-local-contrast","title":"Test Startup Requirement - Enable and Disable White Balance - Dynamic Contrast and Local Contrast","text":"<p>Test Start up Requirement</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#emulator-requirement-enable-and-disable-white-balance-dynamic-contrast-and-local-contrast","title":"Emulator Requirement - Enable and Disable White Balance - Dynamic Contrast and Local Contrast","text":"<p>Emulator Requirement</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#control-plane-requirement-enable-and-disable-white-balance-dynamic-contrast-and-local-contrast","title":"Control Plane Requirement - Enable and Disable White Balance - Dynamic Contrast and Local Contrast","text":"<ul> <li>Control plane checks the functionality by analyzer and using the different playback streams to test the White balance, Dynamic contrast and Local contrast.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#test-the-save-setting-values","title":"Test the save setting values","text":"Description HAL APIs L2 L3 Control Plane requirements Set, get, and save the backlight settings. In the same boot, verify getting the backlight settings. Verify that upon switching to different content and returning to the chosen source, format, and mode, the backlight remain retained. Validate using the analyzer and various video sources, video formats and picture modes. SetBacklight(), GetBacklight(), SaveBacklight() N Y Y Set, get, and save the TV Dimming modes. In the same boot, verify getting  the TV Dimming modes. Verify that upon switching to different content and returning to the chosen source, format, and mode, the TV Dimming Mode remain retained. Validate using the analyzer and various video sources, video formats and picture modes. SetTVDimmingMode(), GetTVDimmingMode(), SaveTVDimmingMode() N Y Y Set, get, and save the local Dimming level. In the same boot, verify getting  the local Dimming level. Verify that upon switching to different content and returning to the chosen source, format, and mode, the Local Dimming mode remain retained. Validate using the analyzer and various video sources, video formats and picture modes. SetLocalDimmingLevel(), GetLocalDimmingLevel(), SaveLocalDimmingLevel() N Y Y Set, get, and save the brightness. In the same boot, verify getting  the brightness. Verify that upon switching to different content and returning to the chosen source, format, and mode, the Brightness level remain retained. Validate using the analyzer and various video sources, video formats and picture modes. SetBrightness(), GetBrightness(), SaveBrightness() N Y Y Set, get, and save the contrast. In the same boot, verify getting  the contrast. Verify that upon switching to different content and returning to the chosen source, format, and mode, the Contrast level remain retained. Validate using the analyzer and various video sources, video formats and picture modes. SetContrast(), GetContrast(), SaveContrast() N Y Y Set, get, and save the sharpness. In the same boot, verify getting  the sharpness. Verify that upon switching to different content and returning to the chosen source, format, and mode, the Sharpness remain retained. Validate using the analyzer and various video sources, video formats and picture modes. SetSharpness(), GetSharpness(), SaveSharpness() N Y Y Set, get, and save the Saturation. In the same boot, verify getting  the Saturation. Verify that upon switching to different content and returning to the chosen source, format, and mode, the Saturation remain retained. Validate using the analyzer and various video sources, video formats and picture modes. SetSaturation(), GetSaturation(), SaveSaturation() N Y Y Set, get, and save the Hue. In the same boot, verify getting  the Hue. Verify that upon switching to different content and returning to the chosen source, format, and mode, the Hue remain retained. Validate using the analyzer and various video sources, video formats and picture modes. SetHue(), GetHue(), SaveHue() N Y Y Set, get, and save the Low Latency State. In the same boot, verify getting  the Low Latency State. Verify that upon switching to different content and returning to the chosen source, format, and mode, the low latency state remain retained. Validate using the analyzer and various video sources, video formats and picture modes. SetLowLatencyState(), GetLowLatencyState() N Y Y Set, get, and save the Aspect Ratio. In the same boot, verify getting  the Aspect Ratio. Verify that upon switching to different content and returning to the chosen source, format, and mode, the Aspect Ratio remain retained. Validate using the analyzer and various video sources, video formats and picture modes. SetAspectRatio(), GetAspectRatio(), SaveAspectRatio() N Y Y Set, get, and save the Color Temperature. In the same boot, verify getting  the Color Temperature. Verify that upon switching to different content and returning to the chosen source, format, and mode, the Color Temperature remain retained. Validate using the analyzer and various video sources, video formats and picture modes. SetColorTemperature(), GetColorTemperature(), SaveColorTemperature() N Y Y Set, Get the Dynamic Gamma and in the same boot, verify getting  Dynamic Gamma. Verify that upon switching to different content and returning to the chosen source, format, and mode, the Dynamic Gamma remain retained.  Validate using the analyzer and various video sources, video formats and picture modes. GetDynamicGamma(), SetDynamicGamma() N Y Y Set, Get the Dynamic Contrast and in the same boot, verify getting  Dynamic Contrast. Verify that upon switching to different content and returning to the chosen source, format, and mode, the Dynamic Contrast should not retained as it does not save in database. Validate using the analyzer and various video sources, video formats and picture modes. SetDynamicContrast(), GetDynamicContrast() N Y Y Set, Save and Get the TV Dolby Vision mode and in the same boot, verify getting  TV Dolby Vision mode. Verify that upon switching to different content and returning to the chosen source, format, and mode, the Dolby Vision mode remain retained. Validate using the analyzer and various video sources, video formats and picture modes. SetTVDolbyVisionMode(), GetTVDolbyVisionMode(), SaveTVDolbyVisionMode() N Y Y Set and Get the TV Picture Mode. in the same boot, verify getting  TV Picture Mode. Verify that upon switching to different content and returning to the chosen source, format, and mode, the TV Picture Mode remain retained.  Validate using the analyzer and various video sources, video formats and picture modes. GetTVPictureMode(), SetTVPictureMode(), SaveSourcePictureMode() N Y Y Set and Get the color Temperature Rgain on Source and in the same boot, verify getting  color Temperature Rgain on Source when SaveOnly is enabled. Verify that upon switching to different content and returning to the chosen source, format, and mode, the Color Temperature R gain remain retained. Validate using the analyzer and various video sources and color temperatures. SetColorTemp_Rgain_onSource(), GetColorTemp_Rgain_onSource() N Y Y Set and Get the color Temperature Rgain on Source and in the same boot, verify getting  color Temperature Rgain on Source when SaveOnly is disabled. Verify that upon switching to different content and returning to the chosen source, format, and mode, the Color Temperature R gain should not get retained. Validate using the analyzer and various video sources and color temperatures. SetColorTemp_Rgain_onSource(), GetColorTemp_Rgain_onSource() N Y Y Set and Get the color Temperature Rgain on Source and in the same boot, verify getting  color Temperature Ggain on Source when SaveOnly is enabled. Verify that upon switching to different content and returning to the chosen source, format, and mode, the Color Temperature G gain remain retained. Validate using the analyzer and various video sources and color temperatures. SetColorTemp_Ggain_onSource(), GetColorTemp_Ggain_onSource() N Y Y Set and Get the color Temperature Rgain on Source and in the same boot, verify getting  color Temperature Ggain on Source when SaveOnly is disabled. Verify that upon switching to different content and returning to the chosen source, format, and mode, the Color Temperature G gain should not get retained. Validate using the analyzer and various video sources and color temperatures. SetColorTemp_Ggain_onSource(), GetColorTemp_Ggain_onSource() N Y Y Set and Get the color Temperature Rgain on Source and in the same boot, verify getting  color Temperature Bgain on Source when SaveOnly is enabled. Verify that upon switching to different content and returning to the chosen source, format, and mode, the Color Temperature B gain remain retained. Validate using the analyzer and various video sources and color temperatures. SetColorTemp_Bgain_onSource(), GetColorTemp_Bgain_onSource() N Y Y Set and Get the color Temperature Rgain on Source and in the same boot, verify getting  color Temperature Bgain on Source when SaveOnly is disabled. Verify that upon switching to different content and returning to the chosen source, format, and mode, the Color Temperature B gain should not get retained. Validate using the analyzer and various video sources and color temperatures. SetColorTemp_Bgain_onSource(), GetColorTemp_Bgain_onSource() N Y Y Set and Get the color Temperature R post offset on Source and in the same boot, verify getting  color Temperature R post offset on Source when SaveOnly is enabled. Verify that upon switching to different content and returning to the chosen source, format, and mode, the color Temperature R post offset on Source remain retained. Validate using the analyzer and various video sources and color temperatures. SetColorTemp_R_post_offset_onSource(), GetColorTemp_R_post_offset_onSource() N Y Y Set and Get the color Temperature R post offset on Source and in the same boot, verify getting  color Temperature R post offset on Source when SaveOnly is disabled. Verify that upon switching to different content and returning to the chosen source, format, and mode, the color Temperature R post offset on Source should not retained. Validate using the analyzer and various video sources  and color temperatures SetColorTemp_R_post_offset_onSource(), GetColorTemp_R_post_offset_onSource() N Y Y Set and Get the color Temperature R post offset on Source and in the same boot, verify getting  color Temperature G post offset on Source when SaveOnly is enabled. Verify that upon switching to different content and returning to the chosen source, format, and mode, the color Temperature G post offset on Source remain retained. Validate using the analyzer and various video sources and color temperatures SetColorTemp_G_post_offset_onSource(), GetColorTemp_G_post_offset_onSource() N Y Y Set and Get the color Temperature R post offset on Source and in the same boot, verify getting  color Temperature G post offset on Source when SaveOnly is disabled. Verify that upon switching to different content and returning to the chosen source, format, and mode, the color Temperature G post offset on Source should not retained. Validate using the analyzer and various video sources and color temperatures SetColorTemp_G_post_offset_onSource(), GetColorTemp_G_post_offset_onSource() N Y Y Set and Get the color Temperature R post offset on Source and in the same boot, verify getting  color Temperature B post offset on Source when SaveOnly is enabled. Verify that upon switching to different content and returning to the chosen source, format, and mode, the color Temperature B post offset on Source remain retained. Validate using the analyzer and various video sources and color Temperatures. SetColorTemp_B_post_offset_onSource(), GetColorTemp_B_post_offset_onSource() N Y Y Set and Get the color Temperature R post offset on Source and in the same boot, verify getting  color Temperature B post offset on Source when SaveOnly is disabled. Verify that upon switching to different content and returning to the chosen source, format, and mode, the color Temperature B post offset on Source should not retained. Validate using the analyzer and various video sources and color Temperatures. SetColorTemp_B_post_offset_onSource(), GetColorTemp_B_post_offset_onSource() N Y Y Set, Save and Get the Gamma Table and in the same boot, verify getting  Gamma Table. Verify that upon switching to different content and returning to the chosen specific color temperature and check the gamma calibrated values get retained. Validate using the analyzer and various video sources, video formats and picture modes. SetGammaTable(), GetGammaTable(), SaveGammaTable() N Y Y Set and Get the Component Saturation and in the same boot, verify getting  Component Saturation. Verify that upon switching to different content and returning to the chosen source, format, and mode and check the compontent saturation values get retained. Validate using the analyzer and various video sources, video formats and picture modes. SetCurrentComponentSaturation(), GetCurrentComponentSaturation() N Y Y Set and Get the Component Saturation and in the same boot, verify getting  Component Hue. Verify that upon switching to different content and returning to the chosen source, format, and mode and check the compontent Hue values get retained. Validate using the analyzer and various video sources, video formats and picture modes. SetCurrentComponentHue(), GetCurrentComponentHue() N Y Y Set and Get the Component Saturation and in the same boot, verify getting  Component Luma. Verify that upon switching to different content and returning to the chosen source, format, and mode and check the compontent Luma values get retained. Validate using the analyzer and various video sources, video formats and picture modes. SetCurrentComponentLuma(), GetCurrentComponentLuma() N Y Y Set, Save and Get the CMS State and in the same boot, verify getting  CMS State. Verify that upon switching to different content and returning to the chosen source, format, and mode, and check the CMS state values get retained. Validate using the analyzer and various video sources, video formats and picture modes. SetCMSState(), GetCMSState(), SaveCMS() N Y Y"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#test-startup-requirement-test-the-save-setting-values","title":"Test Startup Requirement - Test the save setting values","text":"<p>Test Start up Requirement</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#emulator-requirement-test-the-save-setting-values","title":"Emulator Requirement - Test the save setting values","text":"<p>Emulator Requirement</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#control-plane-requirement-test-the-save-setting-values","title":"Control Plane Requirement - Test the save setting values","text":"<ul> <li>Control plane dynamically changes the video sources, video formats and picture modes.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#get-short-circuit-status","title":"Get Short Circuit Status","text":"Description HAL APIs L2 L3 Control Plane requirements Verifies the functionality of retrieving the short circuit status of the adjacent zones. It ensures that the returned status indicates whether any short is detected. GetLdimZoneShortCircuitStatus() Y N N"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#test-startup-requirement-get-short-circuit-status","title":"Test Startup Requirement - Get Short Circuit Status","text":"<p>Test Start up Requirement</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#emulator-requirement-get-open-circuit-status_1","title":"Emulator Requirement - Get Open Circuit Status","text":"<p>Emulator Requirement</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_High_Level_Test_Spec/#control-plane-requirement-get-short-circuit-status","title":"Control Plane Requirement - Get Short Circuit Status","text":"<p>None</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/","title":"TVSETTINGS L2 Low Level Test Specification and Procedure Documentation","text":""},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#overview","title":"Overview","text":"<p>This document describes the Low level L2 Test Specification and Procedure Documentation for the TVSETTINGS module.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>HAL</code> - Hardware Abstraction Layer, may include some common components</li> <li><code>UT</code>  - Unit Test(s)</li> <li><code>OEM</code>  - Original Equipment Manufacture</li> <li><code>SoC</code>  - System on a Chip</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#definitions","title":"Definitions","text":"<ul> <li><code>ut-core</code> - Common Testing Framework https://github.com/rdkcentral/ut-core, which wraps a open-source framework that can be expanded to the requirements for future framework.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#references","title":"References","text":"<ul> <li><code>High Level Test Specification</code> - tv-settings_High_Level_Test_Spec.md</li> <li><code>HAL Interface file</code> - tv-settings_header</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#level-2-test-procedure","title":"Level 2 Test Procedure","text":"<p>The following functions are expecting to test the module operates correctly.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-1","title":"Test 1","text":"Title Details Function Name <code>test_l2_tvSettings_GetSupportedVideoFormats</code> Description Get TV supported video formats and verify that the test provides all supported video formats and their count (minimum is 1 and maximum is VIDEO_FORMAT_MAX). Compare the test results with the platform-supported configurations file  using the path 'tvSettings/VideoFormat/index' and loop through the indices. Using the path 'tvSettings/VideoFormat/numberOfFormats' compare the count. Test Group 02 Test Case ID 001 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-procedure-test-1","title":"Test Procedure  - Test 1","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize TV using TvInit None tvERROR_NONE Should be successful 02 Get supported video formats using GetTVSupportedVideoFormats videoFormats = valid buffer, numberOfFormats = valid buffer tvERROR_NONE Should be successful 03 Verify the number of formats numberOfFormats = valid buffer tvERROR_NONE Should be successful 04 Loop through the indices and verify each video format videoFormats[i] = valid buffer tvERROR_NONE Should be successful 05 Terminate TV using TvTerm None tvERROR_NONE Should be successful <pre><code>graph TB\n    A[TvInit] --&gt;|tvERROR_NONE| B[GetTVSupportedVideoFormats]\n    A --&gt;|Failure| A1[Test case fail]\n    B --&gt;|tvERROR_NONE| C[Compare video formats and count]\n    B --&gt;|Failure| B1[Test case fail]\n    C --&gt;|Match| D[TvTerm]\n    D --&gt;|tvERROR_NONE| E[Test case success]\n    D --&gt;|Failure| D1[Test case fail]</code></pre>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-2","title":"Test 2","text":"Title Details Function Name <code>test_l2_tvSettings_GetCurrentVideoFormat_NoVideoPlayback</code> Description Verify getting the current video format when there is no video playback. Default is VIDEO_FORMAT_SDR Test Group 02 Test Case ID 002 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-procedure-test-2","title":"Test Procedure  - Test 2","text":"Variation / Steps Description Test Data Expected Result Notes 01 Invoke TvInit with no input parameters None tvERROR_NONE Should be successful 02 Invoke GetCurrentVideoFormat with valid pointer to tvVideoFormatType_t variable and verify value videoFormat = valid pointer tvERROR_NONE, VIDEO_FORMAT_SDR Should be successful 03 Invoke TvTerm with no input parameters None tvERROR_NONE Should be successful <pre><code>graph TB\nA[TvInit] --&gt;|tvERROR_NONE| B[GetCurrentVideoFormat]\nA --&gt;|!= tvERROR_NONE| A1[Test case fail]\nB --&gt;|tvERROR_NONE| C[Verify tvVideoFormatType_t &lt;br&gt; == VIDEO_FORMAT_SDR]\nB --&gt;|!= tvERROR_NONE| B1[Test case fail]\nC --&gt;|True| D[TvTerm]\nD --&gt;|tvERROR_NONE| E[Test case success]\nD --&gt;|!= tvERROR_NONE| D1[Test case fail]</code></pre>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-3","title":"Test 3","text":"Title Details Function Name <code>test_l2_tvSettings_VerifyCurrentVideoResolution</code> Description Verify that the current video resolution of the primary video is 'tvVideoResolution_NONE' when playback has not started or has been stopped. Test Group 02 Test Case ID 003 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-procedure-test-3","title":"Test Procedure  - Test 3","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the TV using TvInit None tvERROR_NONE Should be successful 02 Get the current video resolution using GetCurrentVideoResolution res = valid buffer tvERROR_NONE Should be successful 03 Check if the resolution value is 'tvVideoResolution_NONE' resolutionValue = tvVideoResolution_NONE tvVideoResolution_NONE Should be successful 04 Check if the frame height is 0 frameHeight = 0 0 Should be successful 05 Check if the frame width is 0 frameWidth = 0 0 Should be successful 06 Check if the video is not interlaced isInterlaced = 0 0 Should be successful 07 Terminate the TV using TvTerm None tvERROR_NONE Should be successful <pre><code>graph TB\n    TvInit[Call TvInit API] --&gt;|tvERROR_NONE| GetCurrentVideoResolution\n    TvInit --&gt;|!= tvERROR_NONE| TestcaseFail1[Test case fail]\n    GetCurrentVideoResolution[Call GetCurrentVideoResolution API] --&gt;|Success| CheckResolutionValue\n    GetCurrentVideoResolution --&gt;|Failure| TestcaseFail2[Test case fail]\n    CheckResolutionValue[Check resolutionValue field] --&gt;|tvVideoResolution_NONE| CheckFrameHeight\n    CheckResolutionValue --&gt;|!= tvVideoResolution_NONE| TestcaseFail3[Test case fail]\n    CheckFrameHeight[Check frameHeight field] --&gt;|0| CheckFrameWidth\n    CheckFrameWidth[Check frameWidth field] --&gt;|0| CheckIsInterlaced\n    CheckIsInterlaced[Check isInterlaced field] --&gt;|0| TvTerm\n    TvTerm[Call TvTerm API] --&gt;|tvERROR_NONE| TestcaseSuccess[Test case success]\n    TvTerm --&gt;|!= tvERROR_NONE| TestcaseFail7[Test case fail]</code></pre>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-4","title":"Test 4","text":"Title Details Function Name <code>test_l2_tvSettings_VerifyFrameRateWhenStopped</code> Description Verify that the default video frame rate is 'tvVideoFrameRate_NONE' when there is no playback. Test Group 02 Test Case ID 004 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-procedure-test-4","title":"Test Procedure  - Test 4","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the TV using TvInit None tvERROR_NONE Should be successful 02 Get the current video frame rate using GetCurrentVideoFrameRate  and verify the value frameRate = valid buffer tvERROR_NONE, frameRate = tvVideoFrameRate_NONE Should be successful 03 Terminate the TV using TvTerm None tvERROR_NONE Should be successful <pre><code>graph TB\nA[TvInit API Call] --&gt;|Success: tvERROR_NONE| B[GetCurrentVideoFrameRate API Call]\nA --&gt;|Failure: Not tvERROR_NONE| A1[Test Case Fail]\nB --&gt;|Success: tvVideoFrameRate_NONE| C[Verify Frame Rate is tvVideoFrameRate_NONE]\nB --&gt;|Failure: Not tvVideoFrameRate_NONE| B1[Test Case Fail]\nC --&gt;|Success| D[TvTerm API Call]\nD --&gt;|Success: tvERROR_NONE| E[Test Case Success]\nD --&gt;|Failure: Not tvERROR_NONE| D1[Test Case Fail]</code></pre>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-5","title":"Test 5","text":"Title Details Function Name <code>test_l2_tvSettings_GetTVSupportedVideoSources</code> Description Get TV Supported Video Sources - Verify the test provides all supported video sources and their count( Min is 1 and Max is VIDEO_SOURCE_MAX). Compare the test results with the platform-supported configurations file  using the path 'tvSettings/VideoSource/index' and loop through the indices, using the path 'tvSettings/VideoSource/numberOfFormats' compare the count. Test Group 02 Test Case ID 005 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-procedure-test","title":"Test Procedure  - Test","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize TV using TvInit() None tvERROR_NONE Should be successful 02 Get supported video sources and their count using GetTVSupportedVideoSources() videoSources = valid buffer, numberOfSources = valid buffer tvERROR_NONE Should be successful 03 Verify the number of sources is between 1 and VIDEO_SOURCE_MAX numberOfSources = returned value True Should be successful 04 Loop through the indices and compare the test results with the platform-supported configurations file using the path 'tvSettings/VideoSource/index' videoSources[i] = returned value, key = \"tvSettingsVideoSource/index/i\" True Should be successful 05 Terminate TV using TvTerm() None tvERROR_NONE Should be successful <pre><code>graph TB\n    A[TvInit] --&gt;|tvERROR_NONE| B[GetTVSupportedVideoSources]\n    A --&gt;|!= tvERROR_NONE| A1[Test case fail]\n    B --&gt;|tvERROR_NONE| C[Verify count of video sources]\n    B --&gt;|!= tvERROR_NONE| B1[Test case fail]\n    C --&gt;|1 &lt;= count &lt;= VIDEO_SOURCE_MAX| D[Compare video sources with Configuration file]\n    D --&gt; E[Compare count of video sources with configuration file]\n    E --&gt; F[TvTerm]\n    F --&gt;|tvERROR_NONE| G[Test case pass]\n    F --&gt;|!= tvERROR_NONE| F1[Test case fail]</code></pre>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-6","title":"Test 6","text":"Title Details Function Name <code>test_l2_tvSettings_VerifyNoVideoSource</code> Description Verify when there is no video source device is connected. Default is VIDEO_SOURCE_IP Test Group 02 Test Case ID 006 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-procedure-test-6","title":"Test Procedure  - Test 6","text":"Variation / Steps Description Test Data Expected Result Notes 01 Invoke TvInit() to initialize the TV None tvERROR_NONE Should be successful 02 Invoke GetCurrentVideoSource() with valid pointer to get the current video source currentSource = valid pointer tvERROR_NONE, VIDEO_SOURCE_IP Should be successful 03 Invoke TvTerm() to terminate the TV None tvERROR_NONE Should be successful <pre><code>graph TB\n    A[TvInit] --&gt;|tvERROR_NONE| B[GetCurrentVideoSource]\n    A --&gt;|!=tvERROR_NONE| A1[Test case fail]\n    B --&gt;|VIDEO_SOURCE_IP| C[TvTerm]\n    B --&gt;|!=VIDEO_SOURCE_IP| B1[Test case fail]\n    C --&gt;|tvERROR_NONE| D[Test case success]\n    C --&gt;|!=tvERROR_NONE| C1[Test case fail]</code></pre>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-7","title":"Test 7","text":"Title Details Function Name <code>test_l2_tvSettings_SetAndGetBacklight</code> Description Sets and Gets the backlight within the valid range (0 - 100). The retrieved value should match the set value. Get values are retrieved from the <code>PQ</code> database. Test Group 02 Test Case ID 007 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-procedure-test-7","title":"Test Procedure  - Test 7","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the TV using TvInit() None tvERROR_NONE Should be successful 02 Set the backlight value using SetBacklight() backlight = 0,25,50,75,100 tvERROR_NONE Should be successful 03 Get the backlight value using GetBacklight() and verify with set value getBacklight = valid buffer tvERROR_NONE, backlight = 0,25,50,75,100 Should be successful 04 Terminate the TV using TvTerm() None tvERROR_NONE Should be successful <pre><code>graph TB\nA[TvInit] --&gt;|Success| B[SetBacklight]\nA --&gt;|Failure| A1[Test case fail]\nB --&gt;|Success| D[GetBacklight]\nB --&gt;|Failure| B1[Test case fail]\nD --&gt;|Success| F[Verify get and set backlight value]\nD --&gt;|Failure| D1[Test case fail]\nF --&gt;|Success| G[TvTerm]\nG --&gt;|Success| H[Test case success]\nG --&gt;|Failure| G1[Test case fail]</code></pre>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-8","title":"Test 8","text":"Title Details Function Name <code>test_l2_tvSettings_SetAndGetBacklightFade</code> Description Set and Gets the Back light fade within the valid ranges of from ( 0  - 100 ), to ( 0 - 100 ), current( 0 - 100) and duration (0 - 10000 ms). The retrieved value should match the set value. Get values are retrieved from the <code>PQ</code> database. Test Group 02 Test Case ID 008 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-procedure-test-8","title":"Test Procedure  - Test 8","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the TV using TvInit() None tvERROR_NONE Should be successful 02 Set the Backlight Fade using SetBacklightFade() with 5 different values from = value(0-100), to = value(0-100) , duration = value(0-10000) tvERROR_NONE Should be successful 03 Get the current Backlight Fade using GetCurrentBacklightFade() get_from, get_to, get_current tvERROR_NONE Should be successful 04 Validate the set and get values of from , to, duration from = get_from, to = get_to, get_current between 0 to 100 Should be successful 05 Terminate the TV using TvTerm() None tvERROR_NONE Should be successful <pre><code>graph TB\nA[TvInit] --&gt;|Success| B[SetBacklightFade]\nA --&gt;|Failure| A1[Test case fail]\nB --&gt;|Success| D[GetCurrentBacklightFade]\nB --&gt;|Failure| B1[Test case fail]\nD --&gt;|Success| F[Check get and set to, from , current values match]\nD --&gt;|Failure| D1[Test case fail]\nF --&gt;|Success| G[TvTerm]\nG --&gt;|Success| H[Test case success]\nG --&gt;|Failure| G1[Test case fail]</code></pre>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-9","title":"Test 9","text":"Title Details Function Name <code>test_l2_tvSettings_GetSupportedBacklightModes</code> Description Get Supported Back light Modes - verifies to get all the supported backlight modes. Compare the test results with the platform-supported configurations file  using the path 'tvSettings/BacklightControl/index' and loop through the indices. Test Group 02 Test Case ID 009 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-procedure-test-9","title":"Test Procedure  - Test 9","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the TV using TvInit None tvERROR_NONE Should be successful 02 Get the supported backlight modes using GetSupportedBacklightModes blModes = valid pointer tvERROR_NONE Should be successful 03 Compare the obtained backlight modes with the platform-supported configurations file blModes, \"tvSettings/BacklightControl/index\" None Should be successful 04 Terminate the TV using TvTerm None tvERROR_NONE Should be successful <pre><code>graph TB\n    A[TvInit API Call] --&gt;|tvERROR_NONE| B[GetSupportedBacklightModes API Call]\n    A --&gt;|Not tvERROR_NONE| A1[Test Case Fail]\n    B --&gt;|tvERROR_NONE| C[Compare supported mode with configuration file]\n    B --&gt;|Not tvERROR_NONE| B1[Test Case Fail]\n    C --&gt;|match| D[TvTerm API Call]\n    D --&gt;|tvERROR_NONE| E[Test Case Success]\n    D --&gt;|Not tvERROR_NONE| D1[Test Case Fail]</code></pre>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-10","title":"Test 10","text":"Title Details Function Name <code>test_l2_tvSettings_SetAndGetBacklightMode</code> Description Set and Gets the current Back light modes. The retrieved value should match the set value. Get values are retrieved from the <code>PQ</code> database. Test Group 02 Test Case ID 10 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-procedure-test-10","title":"Test Procedure  - Test 10","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize TV using TvInit() None tvERROR_NONE Should be successful 02 Set current backlight mode using SetCurrentBacklightMode() setMode = Backlight modes from GetSupportedBacklightModes tvERROR_NONE Should be successful 03 Get current backlight mode using GetCurrentBacklightMode() getMode = valid buffer tvERROR_NONE Should be successful 04 Validate the set and get backlight modes are same setMode, getMode setMode should be equal to getMode Should be successful 05 Terminate TV using TvTerm() None tvERROR_NONE Should be successful <pre><code>graph TB\nA[TvInit] --&gt;|tvERROR_NONE| B[SetCurrentBacklightMode]\nA --&gt;|!=tvERROR_NONE| A1[Test case fail]\nB --&gt;|tvERROR_NONE| C[GetCurrentBacklightMode]\nB --&gt;|!=tvERROR_NONE| B1[Test case fail]\nC --&gt;|tvERROR_NONE| D[Verify get and set Backlight Mode]\nC --&gt;|!=tvERROR_NONE| C1[Test case fail]\nD --&gt;|Match| E[TvTerm]\nE --&gt;|tvERROR_NONE| F[Test case success]\nE --&gt;|!=tvERROR_NONE| E1[Test case fail]</code></pre>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-11","title":"Test 11","text":"Title Details Function Name <code>test_l2_tvSettings_GetSupportedDimmingModes</code> Description Gets TV Supported Dimming Modes - Verify the test provides all supported backlight dimming modes and their count( Min is 1 and Max is tvDimmingMode_MAX). Compare the test results with the platform-supported configurations file  using the path 'tvSettings/DimmingMode/index' and loop through the indices. Test Group 02 Test Case ID 011 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-procedure-test-11","title":"Test Procedure  - Test 11","text":"Variation / Steps Description Test Data Expected Result Notes 01 Invoke TvInit with no input parameters None tvERROR_NONE Should be successful 02 Invoke GetTVSupportedDimmingModes with valid output parameters dimmingModes = valid buffer, numDimmingModes = valid buffer tvERROR_NONE Should be successful 03 Compare the number of dimming modes with the platform-supported configurations file numDimmingModes = value from GetTVSupportedDimmingModes Equal to the value in 'tvSettings/DimmingMode/index' of Should be successful 04 Invoke TvTerm with no input parameters None tvERROR_NONE Should be successful <pre><code>graph TB\n    A[TvInit] --&gt;|Success: tvERROR_NONE| B[GetTVSupportedDimmingModes]\n    A --&gt;|Failure: Not tvERROR_NONE| A1[Test case fail]\n    B --&gt;|Success: tvERROR_NONE| C[Compare with configuration file]\n    B --&gt;|Failure: Not tvERROR_NONE| B1[Test case fail]\n    C --&gt;|Success: Matched| D[TvTerm]\n    D --&gt;|Success: tvERROR_NONE| E[Test case pass]\n    D --&gt;|Failure: Not tvERROR_NONE| D1[Test case fail]</code></pre>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-12","title":"Test 12","text":"Title Details Function Name <code>test_l2_tvSettings_SetAndGetDimmingMode</code> Description Set and Gets the TV Dimming modes. The retrieved value should match the set value. Get values are retrieved from the <code>PQ</code> database. Test Group 02 Test Case ID 12 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-procedure-test-12","title":"Test Procedure  - Test 12","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the TV using TvInit None tvERROR_NONE Should be successful 02 Set the TV Dimming mode to \"local\" using SetTVDimmingMode dimmingMode = \"local\",\"fixed\",\"global\" tvERROR_NONE Should be successful 03 Get the TV Dimming mode using GetTVDimmingMode getDimmingMode = valid buffer tvERROR_NONE Should be successful 04 Verify the set and get Dimming mode are same getDimmingMode = dimmingMode Should be successful 05 Terminate the TV using TvTerm None tvERROR_NONE Should be successful <pre><code>graph TB\nA[TvInit API Call] --&gt;|Success| B[SetTVDimmingMode API Call with &lt;br&gt; values 'local', 'fixed', 'global']\nA --&gt;|Failure| A1[Test Case Fail]\nB --&gt;|Success| D[GetTVDimmingMode API Call]\nB --&gt;|Failure| B1[Test Case Fail]\nD --&gt;|Success| F[Check get and set Dimming Mode]\nD --&gt;|Failure| D1[Test Case Fail]\nF --&gt;|Success| G[TvTerm API Call]\nG --&gt;|Success| H[Test Case Success]\nG --&gt;|Failure| G1[Test Case Fail]</code></pre>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-13","title":"Test 13","text":"Title Details Function Name <code>test_l2_tvSettings_SetAndGetLocalDimmingLevel</code> Description Set and Gets the local Dimming level. The retrieved value should match the set value. Get values are retrieved from the database. Test Group 02 Test Case ID 013 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-procedure-test-13","title":"Test Procedure  - Test 13","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the TV using TvInit() None tvERROR_NONE Should be successful 02 Set the local dimming level using SetLocalDimmingLevel() for each level in ldimStateLevels[] ldimStateLevel = LDIM_STATE_NONBOOST, LDIM_STATE_BOOST, LDIM_STATE_BURST tvERROR_NONE Should be successful 03 Get the local dimming level using GetLocalDimmingLevel() None tvERROR_NONE Should be successful 04 Assert that the set and retrieved local dimming levels are equal None ldimStateLevel = ldimStateLevelGet Should be successful 05 Terminate the TV using TvTerm() None tvERROR_NONE Should be successful <pre><code>graph TB\n    TvInit[Call TvInit] --&gt;|tvERROR_NONE| SetLocalDimmingLevel1\n    TvInit --&gt;|Failure| TestcaseFail1[Test case failed]\n    SetLocalDimmingLevel1[Call SetLocalDimmingLevel &lt;br&gt; with LDIM_STATE_NONBOOST,&lt;br&gt; LDIM_STATE_BOOST, LDIM_STATE_BURST] --&gt;|tvERROR_NONE| GetLocalDimmingLevel1\n    SetLocalDimmingLevel1 --&gt;|Failure| TestcaseFail2[Test case failed]\n    GetLocalDimmingLevel1[Call GetLocalDimmingLevel] --&gt;|tvERROR_NONE| Verify1\n    GetLocalDimmingLevel1 --&gt;|Failure| TestcaseFail3[Test case failed]\n    Verify1[Check get matches set value] --&gt;|success| TvTerm\n    TvTerm[Call TvTerm] --&gt;|tvERROR_NONE| TestCaseSuccess[Test case success]\n    TvTerm --&gt;|Failure| TestcaseFail8[Test case failed]</code></pre>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-14","title":"Test 14","text":"Title Details Function Name <code>test_l2_tvSettings_SetAndGetBrightness</code> Description Set and Gets the brightness within the valid range ( 0 - 100 ). The retrieved value should match the set value. Get values are retrieved from the database. Test Group 02 Test Case ID 14 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-procedure-test-14","title":"Test Procedure  - Test 14","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the TV using TvInit None tvERROR_NONE Should be successful 02 Set the brightness using SetBrightness for 4 different values brightness = (0-100) tvERROR_NONE Should be successful 03 Get the brightness using GetBrightness get_brightness = valid buffer tvERROR_NONE Should be successful 04 Validate the set and get brightness values are equal brightness = get_brightness Equal Should be successful 05 Terminate the TV using TvTerm None tvERROR_NONE Should be successful <pre><code>graph TB\n    Step1[Call TvInit API]--&gt;|tvERROR_NONE| Step3{Iterate for 4 valid &lt;br&gt; brightness values }\n    Step3 --&gt;Step2[Call SetBrightness API]\n    Step1 --&gt;|Failure| Fail1[Test Case Failed]\n    Step2 --&gt;|tvERROR_NONE| Step4[Call GetBrightness API]\n    Step4 --&gt;|tvERROR_NONE,&lt;br&gt; get and set matches| Step3\n    Step3 --&gt;|End of loop| Step6[Call TvTerm API]\n    Step6 --&gt;|tvERROR_NONE| End[Test Case Passed]\n    Step6 --&gt;|Failure| Fail6[Test Case Failed]</code></pre>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-15","title":"Test 15","text":"Title Details Function Name <code>test_l2_tvSettings_SetAndGetContrast</code> Description Set and Gets the contrast within the valid range ( 0 - 100 ). The retrieved value should match the set value. Get values are retrieved from the database. Test Group 02 Test Case ID 15 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-procedure-test-15","title":"Test Procedure  - Test 15","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the TV using TvInit() None tvERROR_NONE Should be successful 02 Set the contrast using SetContrast() for 4 different values contrast =  (0-100) tvERROR_NONE Should be successful 03 Get the contrast using GetContrast() getContrast = valid buffer tvERROR_NONE Should be successful 04 Check if the set and get contrast values match getContrast = contrast Should be successful 05 Terminate the TV using TvTerm() None tvERROR_NONE Should be successful <pre><code>graph TB\nA[TvInit API Call] --&gt;|tvERROR_NONE| Step1{Iterate for 4 valid &lt;br&gt; contrast values }\nStep1 --&gt; B[SetContrast API Call]\nA --&gt;|Failure| A1[Test case fail]\nB --&gt;|tvERROR_NONE| C[GetContrast API Call]\nC --&gt;|tvERROR_NONE and Contrast value matches| Step1\nB --&gt;|End of loop|D[TvTerm API Call]\nD --&gt;|tvERROR_NONE| E[Test case success]\nD --&gt;|Failure| D1[Test case fail]</code></pre>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-16","title":"Test 16","text":"Title Details Function Name <code>test_l2_tvSettings_SetAndGetSharpness</code> Description Set and Gets the sharpness ( 0 - 100 ). The retrieved value should match the set value. Get values are retrieved from the database. Test Group 02 Test Case ID 16 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-procedure-test-16","title":"Test Procedure  - Test 16","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the TV using TvInit() None tvERROR_NONE Should be successful 02 Set the sharpness using SetSharpness() for 4 different values setSharpness = (0-100) tvERROR_NONE Should be successful 03 Get the sharpness using GetSharpness() getSharpness = valid buffer tvERROR_NONE Should be successful 04 Assert that the set sharpness and the retrieved sharpness are equal setSharpness = getSharpness Should be successful 05 Terminate the TV using TvTerm() None tvERROR_NONE Should be successful <pre><code>graph TB\nA[TvInit] --&gt;|Success| Loop{Iterate for 4 valid &lt;br&gt; Sharpness values}\nLoop --&gt; B[SetSharpness]\nA --&gt;|Failure| A1[Test case fail]\nB --&gt;|Success| D[GetSharpness]\nD --&gt;|Success, &lt;br&gt; get and set matches| Loop\nLoop --&gt;|Success| G[TvTerm]\nG --&gt;|Success| H[Test case success]\nG --&gt;|Failure| G1[Test case fail]</code></pre>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-17","title":"Test 17","text":"Title Details Function Name <code>test_l2_tvSettings_SetAndGetSaturation</code> Description Set and Gets the saturation within the valid range ( 0 - 100 ). The retrieved value should match the set value. Get values are retrieved from the database. Test Group 02 Test Case ID 17 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-procedure-test-17","title":"Test Procedure  - Test 17","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the TV using TvInit() None tvERROR_NONE Should be successful 02 Set the saturation value using SetSaturation() for 4 different values saturation_set = (0-100) tvERROR_NONE Should be successful 03 Get the saturation value using GetSaturation() saturation_get = valid buffer tvERROR_NONE Should be successful 04 Compare the set and get saturation values saturation_set = saturation_get Should be successful 05 Terminate the TV using TvTerm() None tvERROR_NONE Should be successful <pre><code>graph TB\nA[TvInit] --&gt;|Success| Loop{Iterate for 4 valid &lt;br&gt; Saturation values}\nLoop --&gt; B[SetSaturation]\nA --&gt;|Failure| A1[Test case fail]\nB --&gt;|Success| D[GetSaturation]\nD --&gt;|Success, &lt;br&gt; get and set matches| Loop\nLoop --&gt;|Success| G[TvTerm]\nG --&gt;|Success| H[Test case success]\nG --&gt;|Failure| G1[Test case fail]</code></pre>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-18","title":"Test 18","text":"Title Details Function Name <code>test_l2_tvSettings_SetAndGetHue</code> Description Set and Gets the Hue ( 0 - 100 ). The retrieved value should match the set value. Get values are retrieved from the database. Test Group 02 Test Case ID 018 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-procedure-test-18","title":"Test Procedure  - Test 18","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the TV using TvInit None tvERROR_NONE Should be successful 02 Set the Hue using SetHue for 4 different values hue = (0-100) tvERROR_NONE Should be successful 03 Get the Hue using GetHue getHue = valid buffer tvERROR_NONE Should be successful 04 Validate the set and get Hue values are same hue = getHue Should be successful 05 Terminate the TV using TvTerm None tvERROR_NONE Should be successful <pre><code>graph TB\n    A[TvInit] --&gt;|tvERROR_NONE| Loop{Iterate for 4 valid &lt;br&gt; Hue values}\n    Loop --&gt; B[SetHue]\n    A --&gt;|Failure| A1[Test case fail]\n    B --&gt;|tvERROR_NONE| C[GetHue]\n    C --&gt;|tvERROR_NONE &lt;br&gt; hue value matches| Loop\n    Loop --&gt;|End of loop|D[TvTerm]\n    D --&gt;|tvERROR_NONE| E[Test case success]\n    D --&gt;|Failure| D1[Test case fail]</code></pre>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-19","title":"Test 19","text":"Title Details Function Name <code>test_l2_tvSettings_SetAndGetColorTemperature</code> Description Set and Gets the Color Temperature. The retrieved value should match the set value. Get values are retrieved from the database. Test Group 02 Test Case ID 19 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-procedure-test-19","title":"Test Procedure  - Test 19","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the TV using TvInit None tvERROR_NONE Should be successful 02 Set various color temperatures using SetColorTemperature colorTemp = tvColorTemp_STANDARD to tvColorTemp_MAX-1 tvERROR_NONE Should be successful 03 Get the color temperature using GetColorTemperature and verify get and set getColorTemp = valid buffer tvERROR_NONE, colorTemp = getColorTemp Should be successful 04 Terminate the TV using TvTerm None tvERROR_NONE Should be successful <pre><code>graph TB\n    A[TvInit API Call] --&gt;|Success| Loop{Iterate through various &lt;br&gt; Color temperature}\n    Loop --&gt; B[SetColorTemperature API Call]\n    A --&gt;|Failure| A1[Test case fail]\n    B --&gt;|Success| D[GetColorTemperature API Call]\n    D --&gt;| Success &lt;br&gt; Get and set matches|Loop\n    Loop --&gt;|End of loop| F[TvTerm API Call]\n    F --&gt;|Success| G[Test case success]\n    F --&gt;|Failure| F1[Test case fail]</code></pre>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-20","title":"Test 20","text":"Title Details Function Name <code>test_l2_tvSettings_SetAndGetAspectRatio</code> Description Set and Gets the Aspect Ratio. The retrieved value should match the set value. Get values are retrieved from the database. Test Group 02 Test Case ID 20 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-procedure-test-20","title":"Test Procedure  - Test 20","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the TV using TvInit() None tvERROR_NONE Should be successful 02 Set the Aspect Ratio using SetAspectRatio() for various aspect ratios setMode = tvDisplayMode_4x3 to tvDisplayMode_MAX-1 tvERROR_NONE Should be successful 03 Get the Aspect Ratio using GetAspectRatio() getMode = valid buffer tvERROR_NONE Should be successful 04 Validate the set and get Aspect Ratio are same setMode=getMode Should be successful 05 Terminate the TV using TvTerm() None tvERROR_NONE Should be successful <pre><code>graph TB\n    A[TvInit] --&gt;|Success| Loop{Iterate through various &lt;br&gt; aspect ratio}\n    Loop --&gt; B[SetAspectRatio]\n    A --&gt;|Failure| A1[Test case fail]\n    B --&gt;|Success| C[GetAspectRatio]\n    C --&gt;|Success &lt;br&gt; get and set matches| Loop\n    Loop --&gt;|End of loop|E[TvTerm]\n    E --&gt;|Success| F[Test case pass]\n    E --&gt;|Failure| E1[Test case fail]</code></pre>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-21","title":"Test 21","text":"Title Details Function Name <code>test_l2_tvSettings_SetAndGetLowLatencyState</code> Description Set and Gets the Low Latency State ( 0 for disable and 1 for enable ). The retrieved value should match the set value. Get values are retrieved from the database. Test Group 02 Test Case ID 021 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-procedure-test-21","title":"Test Procedure  - Test 21","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize TV using TvInit() None tvERROR_NONE Should be successful 02 Set Low Latency State to 1 using SetLowLatencyState(1) LowLatencyState = 1 tvERROR_NONE Should be successful 03 Get Low Latency State using GetLowLatencyState() and verify the value lowlatencystate = valid buffer tvERROR_NONE, lowlatencystate = 1 Should be successful 04 Set Low Latency State to 0 using SetLowLatencyState(0) LowLatencyState = 0 tvERROR_NONE Should be successful 05 Get Low Latency State using GetLowLatencyState() and verify the value lowlatencystate = valid buffer tvERROR_NONE, lowlatencystate = 0 Should be successful 06 Terminate TV using TvTerm() None tvERROR_NONE Should be successful <pre><code>graph TB\nA[TvInit] --&gt;|tvERROR_NONE| B[SetLowLatencyState with value 1]\nB --&gt;|tvERROR_NONE| C[GetLowLatencyState]\nC --&gt;|tvERROR_NONE &lt;br&gt; lowlatencystate=1| D[SetLowLatencyState with value 0]\nD --&gt;|tvERROR_NONE| E[GetLowLatencyState]\nE --&gt;|tvERROR_NONE &lt;br&gt; lowlatencystate=0| F[TvTerm]\nF --&gt;|tvERROR_NONE| G[Test case success]\nA --&gt;|Failure| A1[Test case fail]\nB --&gt;|Failure| B1[Test case fail]\nC --&gt;|Failure| C1[Test case fail]\nD --&gt;|Failure| D1[Test case fail]\nE --&gt;|Failure| E1[Test case fail]\nF --&gt;|Failure| F1[Test case fail]</code></pre>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-22","title":"Test 22","text":"Title Details Function Name <code>test_l2_tvSettings_SetAndGetDynamicContrast</code> Description Set and Gets the Dynamic Contrast. The retrieved value should match the set value. Get values are retrieved from the database. Test Group 02 Test Case ID 22 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-procedure-test-22","title":"Test Procedure  - Test 22","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the TV using TvInit None tvERROR_NONE Should be successful 02 Set Dynamic Contrast to enabled using SetDynamicContrast dynamicContrastEnable = \"enabled\" tvERROR_NONE Should be successful 03 Get the Dynamic Contrast status using GetDynamicContrast and verify isDynamicContrastEnabled = valid buffer tvERROR_NONE, isDynamicContrastEnabled = \"enabled\" Should be successful 04 Set Dynamic Contrast to disabled using SetDynamicContrast dynamicContrastEnable = \"disabled\" tvERROR_NONE Should be successful 05 Get the Dynamic Contrast status using GetDynamicContrast and verify isDynamicContrastEnabled = valid buffer tvERROR_NONE, isDynamicContrastEnabled = \"disabled\" Should be successful 06 Terminate the TV using TvTerm None tvERROR_NONE Should be successful <pre><code>graph TB\nA[TvInit] --&gt;|tvERROR_NONE| B[SetDynamicContrast &lt;br&gt; with value 'enabled']\nB --&gt;|tvERROR_NONE| C[GetDynamicContrast]\nC --&gt;|tvERROR_NONE &lt;br&gt; isDynamicContrastEnabled = 'enabled'| D[SetDynamicContrast &lt;br&gt; with value 'disabled']\nD --&gt;|tvERROR_NONE| E[GetDynamicContrast]\nE --&gt;|tvERROR_NONE &lt;br&gt; isDynamicContrastEnabled = 'disabled'| F[TvTerm]\nF --&gt; |tvERROR_NONE| G[Test case success]\nA --&gt;|Failure| A1[Test case fail]\nB --&gt;|Failure| B1[Test case fail]\nC --&gt;|Failure| C1[Test case fail]\nD --&gt;|Failure| D1[Test case fail]\nE --&gt;|Failure| E1[Test case fail]\nF --&gt;|Failure| F1[Test case fail]</code></pre>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-23","title":"Test 23","text":"Title Details Function Name <code>test_l2_tvSettings_SetAndGetDynamicGamma</code> Description Set and Gets the Dynamic Gamma within the valid range ( 1.80 to 2.60 ). The retrieved value should match the set value. Get values are retrieved from the database. Test Group 02 Test Case ID 23 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-procedure-test-23","title":"Test Procedure  - Test 23","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the TV using TvInit() None tvERROR_NONE Should be successful 02 Set the Dynamic Gamma using SetDynamicGamma() for different valid values setGammaValue = 1.80 to 2.6 tvERROR_NONE Should be successful 04 Get the Dynamic Gamma using GetDynamicGamma() getGammaValue = valid buffer tvERROR_NONE Should be successful 05 Assert that the set and get Gamma values are equal setGammaValue = getGammaValue Should be successful 06 Terminate the TV using TvTerm() None tvERROR_NONE Should be successful <pre><code>graph TB\n    A[TvInit] --&gt;|Success| Loop{Iterate through &lt;br&gt; valid values}\n    Loop --&gt; B[SetDynamicGamma]\n    A --&gt;|Failure| A1[Test case fail]\n    B --&gt;|Success| C[GetDynamicGamma]\n    C --&gt;|Success &lt;br&gt; get and set matches| Loop\n    Loop --&gt; |End of loop|E[TvTerm]\n    E --&gt;|Success| F[Test case success]\n    E --&gt;|Failure| E1[Test case fail]</code></pre>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-24","title":"Test 24","text":"Title Details Function Name <code>test_l2_tvSettings_GetSupportedDolbyVisionModes</code> Description Get TV Supported Dolby Vision Modes - Verify the test provides all supported Dolby Vision modes and their count( Min is 0 and Max is tvMode_Max ). Compare the test results with the platform-supported configurations file  using the path 'tvSettings/DolbyVisionMode/index' and loop through the indices. Test Group 02 Test Case ID 24 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-procedure-test-24","title":"Test Procedure  - Test 24","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize TV using TvInit None tvERROR_NONE Should be successful 02 Invoke GetTVSupportedDolbyVisionModes with valid dvModes and count dvModes = valid buffer, count = valid buffer tvERROR_NONE Should be successful 03 Check if the count of supported Dolby Vision modes is between 0 and tvMode_Max count = returned value from GetTVSupportedDolbyVisionModes count &gt;= 0 and count &lt;= tvMode_Max Should be successful 04 Loop through the indices and compare the test results with the platform-supported configurations file using the path 'tvSettings/DolbyVisionMode/index' dvModes[i] = returned value from GetTVSupportedDolbyVisionModes dvModes = value in the platform-supported configurations file Should be successful 05 Terminate TV using TvTerm None tvERROR_NONE Should be successful <pre><code>graph TB\nA[TvInit API Call] --&gt;|tvERROR_NONE| B[GetTVSupportedDolbyVisionModes API Call]\nA --&gt;|Failure| A1[Test case fail]\nB --&gt;|tvERROR_NONE| D[Loop through array of supported Dolby Vision modes]\nB --&gt;|Failure| B1[Test case fail]\nD --&gt;|Success| E[TvTerm API Call]\nD --&gt;|Failure| D1[Test case fail]\nE --&gt;|tvERROR_NONE| F[Test case success]\nE --&gt;|Failure| E1[Test case fail]</code></pre>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-25","title":"Test 25","text":"Title Details Function Name <code>test_l2_tvSettings_SetAndGetDolbyVisionMode</code> Description Set and Gets the TV Dolby Vision mode. The retrieved value should match the set value. Get values are retrieved from the database. Test Group 02 Test Case ID 025 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-procedure-test-25","title":"Test Procedure  - Test 25","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the TV using TvInit None tvERROR_NONE Should be successful 02 Set the TV Dolby Vision mode using SetTVDolbyVisionMode dolbyMode = value retrieved from GetTVSupportedDolbyVisionModes. tvERROR_NONE Should be successful 03 Get the TV Dolby Vision mode using GetTVDolbyVisionMode and verify getDolbyMode = valid buffer tvERROR_NONE, getDolbyMode = dolbyMode Should be successful 04 Terminate the TV using TvTerm None tvERROR_NONE Should be successful <pre><code>graph TB\nA[TvInit] --&gt;|tvERROR_NONE| Loop{Iterate through supported &lt;br&gt; Dolby Vision Modes }\nLoop --&gt; B[SetTVDolbyVisionMode]\nA --&gt;|Failure| A1[Test case fail]\nB --&gt;|tvERROR_NONE| C[GetTVDolbyVisionMode]\nC --&gt;|tvERROR_NONE &lt;br&gt; get and set matches| Loop\nLoop --&gt;|End of loop| E[TvTerm]\nE --&gt;|tvERROR_NONE| F[Test case pass]\nE --&gt;|Failure| E1[Test case fail]</code></pre>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-26","title":"Test 26","text":"Title Details Function Name <code>test_l2_tvSettings_GetTVSupportedPictureModes</code> Description Get TV Supported Picture Modes - Verify the test provides all supported Picture Modes and their count( Min is 1 and Max is PIC_MODES_SUPPORTED_MAX ). Compare the test results with the platform-supported configurations file  using the path 'tvSettings/PictureMode/index' and loop through the indices. Test Group 02 Test Case ID 26 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-procedure-test-26","title":"Test Procedure  - Test 26","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize TV using TvInit No input parameters tvERROR_NONE Should be successful 02 Get supported picture modes and their count using GetTVSupportedPictureModes pictureModes = valid buffer, count = valid buffer tvERROR_NONE, count = 1-PIC_MODES_SUPPORTED_MAX Should be successful 03 Loop through the picture modes and compare with the platform-supported configurations file pictureModes[i]-&gt;name = \"tvSettings/PictureMode/index\" value matches Should be successful 04 Terminate TV using TvTerm No input parameters tvERROR_NONE Should be successful <pre><code>graph TB\n    A[TvInit] --&gt;|tvERROR_NONE| B[GetTVSupportedPictureModes]\n    A --&gt;|!= tvERROR_NONE| C[Test case fail]\n    B --&gt;|= tvERROR_NONE &lt;br&gt; 1 &lt;= count &lt;= PIC_MODES_SUPPORTED_MAX| F[Loop and compare &lt;br&gt; with profile picture modes]\n    B --&gt;|!= tvERROR_NONE| G[Test case fail]\n    F --&gt;|Match| J[TvTerm]\n    J --&gt;|tvERROR_NONE| K[Test case pass]\n    J --&gt;|!= tvERROR_NONE| L[Test case fail]</code></pre>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-27","title":"Test 27","text":"Title Details Function Name <code>test_l2_tvSettings_SetAndGetPictureMode</code> Description Set and Gets the TV Picture Mode. The retrieved value should match the set value. Set the picture mode to a valid value as specified by <code>pic_modes_t</code>.name from the GetTVSupportedPictureModes API, with the string size limited to PIC_MODE_NAME_MAX. Get values are retrieved from the database. Test Group 02 Test Case ID 27 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-procedure-test-27","title":"Test Procedure  - Test 27","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize TV using TvInit() None tvERROR_NONE Should be successful 02 Get supported picture modes using GetTVSupportedPictureModes() pictureModes = valid buffer, count = valid buffer tvERROR_NONE Should be successful 03 Set TV picture mode using SetTVPictureMode() for each supported mode pictureMode = pictureModes[i]-&gt;name tvERROR_NONE Should be successful 04 Get TV picture mode using GetTVPictureMode() after setting each mode pictureMode = valid buffer tvERROR_NONE Should be successful 05 Validate the set and get picture modes are same pictureModes[i]-&gt;name = pictureMode Should be successful 06 Terminate TV using TvTerm() after each set and get operation None tvERROR_NONE Should be successful <pre><code>graph TB\nA[TvInit] --&gt;|tvERROR_NONE| C[GetTVSupportedPictureModes]\nC --&gt;|tvERROR_NONE &lt;br&gt; 1 &lt;= count &lt;= PIC_MODES_SUPPORTED_MAX| E[SetTVPictureMode]\nE --&gt;|tvERROR_NONE| G[GetTVPictureMode]\nG --&gt;|tvERROR_NONE &lt;br&gt; picture mode matches set picture mode| H[TvTerm]\nH --&gt;|tvERROR_NONE| I[Test case pass]\nA --&gt;|!=tvERROR_NONE| J[Test case fail]\nC --&gt;|!=tvERROR_NONE| L[Test case fail]\nE --&gt;|!=tvERROR_NONE| N[Test case fail]\nG --&gt;|!=tvERROR_NONE | P[Test case fail]\nH --&gt;|!=tvERROR_NONE| Q[Test case fail]</code></pre>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-28","title":"Test 28","text":"Title Details Function Name <code>test_l2_tvSettings_SetAndGetColorTempRgain</code> Description Loop through different color temperatures and source ids. Set and Gets the color Temperature Rgain on Source. The retrieved value should match the set value. Get values are retrieved from the  database. Test Group 02 Test Case ID 28 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-procedure-test-28","title":"Test Procedure  - Test 28","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the TV using TvInit None tvERROR_NONE Should be successful 02 Loop through different color temperatures and source ids colorTemp = tvColorTemp_STANDARD to tvColorTemp_MAX, sourceId = ALL_SRC_OFFSET to MAX_OFFSET None None 03 Set the color Temperature Rgain on Source using SetColorTemp_Rgain_onSource colorTemp = current colorTemp, setRgain = 0 to 2047, sourceId = current sourceId, saveOnly = 0 to 1 tvERROR_NONE Should be successful 04 Get the color Temperature Rgain on Source using GetColorTemp_Rgain_onSource colorTemp = current colorTemp, sourceId = current sourceId tvERROR_NONE Should be successful 05 Check if the retrieved rgain matches the set rgain rgain = setRgain Should be successful 06 Terminate the TV using TvTerm None tvERROR_NONE Should be successful <pre><code>graph TB\n    A[TvInit] --&gt;|Success| B{Loop through color &lt;br&gt; temperatures, source ids,&lt;br&gt;rgain,saveonly}\n    A --&gt;|Failure| A1[Test case fail]\n    B --&gt; C[SetColorTemp_Rgain_onSource &lt;br&gt; with valid values]\n    C --&gt;|Success| D[GetColorTemp_Rgain_onSource]\n    D --&gt;|Success, &lt;br&gt; set get rgain matches| B\n    B --&gt;|End of Loop| G[TvTerm]\n    G --&gt;|Success| H[Test case pass]\n    G --&gt;|Failure| G1[Test case fail]</code></pre>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-29","title":"Test 29","text":"Title Details Function Name <code>test_l2_tvSettings_SetAndGetColorTempGgain</code> Description Loop through different color temperatures and source ids. Set and Gets the color Temperature Ggain on Source. The retrieved value should match the set value. Get values are retrieved from the  database. Test Group 02 Test Case ID 29 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-procedure-test-29","title":"Test Procedure  - Test 29","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the TV using TvInit None tvERROR_NONE Should be successful 02 Loop through different color temperatures and source ids colorTemp = tvColorTemp_STANDARD to tvColorTemp_MAX, sourceId = ALL_SRC_OFFSET to MAX_OFFSET None Should be successful 03 Set the color Temperature Ggain on Source using SetColorTemp_Ggain_onSource colorTemp = current colorTemp, set_ggain = 0 to 2047, sourceId = current sourceId, saveOnly = 0 to 1 tvERROR_NONE Should be successful 04 Get the color Temperature Ggain on Source using GetColorTemp_Ggain_onSource colorTemp = current colorTemp, ggain = address of ggain, sourceId = current sourceId tvERROR_NONE Should be successful 05 Check if the retrieved ggain matches the set ggain ggain = set_ggain Should be successful 06 Terminate the TV using TvTerm None tvERROR_NONE Should be successful <pre><code>graph TB\n    A[TvInit] --&gt;|Success| B{Loop through color &lt;br&gt; temperatures, source ids,&lt;br&gt;ggain,saveonly}\n    A --&gt;|Failure| A1[Test case fail]\n    B --&gt; C[SetColorTemp_Ggain_onSource &lt;br&gt; with valid values]\n    C --&gt;|Success| D[GetColorTemp_Ggain_onSource]\n    D --&gt;|Success, &lt;br&gt; set get ggain matches| B\n    B --&gt;|End of Loop| G[TvTerm]\n    G --&gt;|Success| H[Test case pass]\n    G --&gt;|Failure| G1[Test case fail]</code></pre>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-30","title":"Test 30","text":"Title Details Function Name <code>test_l2_tvSettings_SetAndGetColorTempBgain</code> Description Loop through different color temperatures and source ids. Set and Gets the color Temperature Bgain on Source. The retrieved value should match the set value. Get values are retrieved from the  database. Test Group 02 Test Case ID 30 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-procedure-test-30","title":"Test Procedure  - Test 30","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the TV using TvInit None tvERROR_NONE Should be successful 02 Loop through different color temperatures and source ids colorTemp = tvColorTemp_STANDARD to tvColorTemp_MAX, sourceId = ALL_SRC_OFFSET to MAX_OFFSET None Should be successful 03 Set the color Temperature Bgain on Source using SetColorTemp_Bgain_onSource colorTemp, bgain = 0 to 2047, sourceId, saveOnly = 0 to 1 tvERROR_NONE Should be successful 04 Get the color Temperature Bgain on Source using GetColorTemp_Bgain_onSource colorTemp, &amp;get_bgain, sourceId tvERROR_NONE Should be successful 05 Check if the retrieved value matches the set value bgain = get_bgain Should be successful 06 Terminate the TV using TvTerm None tvERROR_NONE Should be successful <pre><code>graph TB\n    A[TvInit] --&gt;|Success| B{Loop through color &lt;br&gt; temperatures, source ids,&lt;br&gt;bgain,saveonly}\n    A --&gt;|Failure| A1[Test case fail]\n    B --&gt; C[SetColorTemp_Bgain_onSource &lt;br&gt; with valid values]\n    C --&gt;|Success| D[GetColorTemp_Bgain_onSource]\n    D --&gt;|Success, &lt;br&gt; set get bgain matches| B\n    B --&gt;|End of Loop| G[TvTerm]\n    G --&gt;|Success| H[Test case pass]\n    G --&gt;|Failure| G1[Test case fail]</code></pre>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-31","title":"Test 31","text":"Title Details Function Name <code>test_l2_tvSettings_SetAndGetColorTemp_R_post_offset_onSource</code> Description Loop through different color temperatures and source ids. Set and Gets the color Temperature R post offset on Source. The retrieved value should match the set value. Get values are retrieved from the  database. Test Group 02 Test Case ID 031 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-procedure-test-31","title":"Test Procedure  - Test 31","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the TV using TvInit None tvERROR_NONE Should be successful 02 Loop through different color temperatures and source ids. Set the color Temperature R post offset on Source using SetColorTemp_R_post_offset_onSource colorTemp = value, rpostoffset_set = value, sourceId = value, saveOnly = value tvERROR_NONE Should be successful 03 Get the color Temperature R post offset on Source using GetColorTemp_R_post_offset_onSource colorTemp = value, sourceId = value tvERROR_NONE Should be successful 04 Check if the retrieved value matches the set value rpostoffset_set = rpostoffset_get Should be successful 05 Terminate the TV using TvTerm None tvERROR_NONE Should be successful <pre><code>graph TB\n    A[TvInit] --&gt;|Success| B{Loop through color &lt;br&gt; temperatures, source ids,&lt;br&gt;rpostoffset,saveonly}\n    A --&gt;|Failure| A1[Test case fail]\n    B --&gt; C[SetColorTemp_R_post_offset_onSource &lt;br&gt; with valid values]\n    C --&gt;|Success| D[GetColorTemp_R_post_offset_onSource]\n    D --&gt;|Success, &lt;br&gt; set get rpostoffset matches| B\n    B --&gt;|End of Loop| G[TvTerm]\n    G --&gt;|Success| H[Test case pass]\n    G --&gt;|Failure| G1[Test case fail]</code></pre>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-32","title":"Test 32","text":"Title Details Function Name <code>test_l2_tvSettings_SetAndGetColorTempGPostOffset</code> Description Loop through different color temperatures and source ids. Set and Gets the color Temperature G post offset on Source. The retrieved value should match the set value. Get values are retrieved from the  database. Test Group 02 Test Case ID 32 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-procedure-test-32","title":"Test Procedure  - Test 32","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the TV using TvInit() None tvERROR_NONE Should be successful 02 Loop through different color temperatures and source ids colorTemp = tvColorTemp_STANDARD to tvColorTemp_MAX, sourceId = ALL_SRC_OFFSET to MAX_OFFSET None None 03 Set the color Temperature G post offset on Source using SetColorTemp_G_post_offset_onSource() colorTemp, gpostoffset_set = -1024 to 1023, sourceId, saveOnly = 0 to 1 tvERROR_NONE Should be successful 04 Get the color Temperature G post offset on Source using GetColorTemp_G_post_offset_onSource() and verify colorTemp, &amp;gpostoffset_get, sourceId tvERROR_NONE, gpostoffset_set = gpostoffset_get Should be successful 05 Terminate the TV using TvTerm() None tvERROR_NONE Should be successful <pre><code>graph TB\n    A[TvInit] --&gt;|Success| B{Loop through color &lt;br&gt; temperatures, source ids,&lt;br&gt;gpostoffset,saveonly}\n    A --&gt;|Failure| A1[Test case fail]\n    B --&gt; C[SetColorTemp_G_post_offset_onSource &lt;br&gt; with valid values]\n    C --&gt;|Success| D[GetColorTemp_G_post_offset_onSource]\n    D --&gt;|Success, &lt;br&gt; set get gpostoffset matches| B\n    B --&gt;|End of Loop| G[TvTerm]\n    G --&gt;|Success| H[Test case pass]\n    G --&gt;|Failure| G1[Test case fail]</code></pre>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-33","title":"Test 33","text":"Title Details Function Name <code>test_l2_tvSettings_SetAndGetColorTempBPostOffset</code> Description Loop through different color temperatures and source ids. Set and Gets the color Temperature B post offset on Source. The retrieved value should match the set value. Get values are retrieved from the  database. Test Group 02 Test Case ID 033 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-procedure-test-33","title":"Test Procedure  - Test 33","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the TV using TvInit None tvERROR_NONE Should be successful 02 Loop through different color temperatures and source ids. Set the color Temperature B post offset on Source using SetColorTemp_B_post_offset_onSource colorTemp = value, bpostoffset_set = value, sourceId = value, saveOnly = 0 to 1 tvERROR_NONE Should be successful 03 Get the color Temperature B post offset on Source using GetColorTemp_B_post_offset_onSource colorTemp = value, sourceId = value tvERROR_NONE Should be successful 04 Check if the retrieved value matches the set value bpostoffset_set = bpostoffset_get Should be successful 05 Terminate the TV using TvTerm None tvERROR_NONE Should be successful <pre><code>graph TB\n    A[TvInit] --&gt;|Success| B{Loop through color &lt;br&gt; temperatures, source ids,&lt;br&gt;bpostoffset,saveonly}\n    A --&gt;|Failure| A1[Test case fail]\n    B --&gt; C[SetColorTemp_B_post_offset_onSource &lt;br&gt; with valid values]\n    C --&gt;|Success| D[GetColorTemp_B_post_offset_onSource]\n    D --&gt;|Success, &lt;br&gt; set get bpostoffset matches| B\n    B --&gt;|End of Loop| G[TvTerm]\n    G --&gt;|Success| H[Test case pass]\n    G --&gt;|Failure| G1[Test case fail]</code></pre>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-34","title":"Test 34","text":"Title Details Function Name <code>test_l2_tvSettings_EnableAndVerifyWBCalibrationMode</code> Description Enables the <code>WB</code> Calibration Mode and verify by the Get Current WB Calibration Mode Test Group 02 Test Case ID 34 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-procedure-test-34","title":"Test Procedure  - Test 34","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the TV using TvInit() None tvERROR_NONE Should be successful 02 Enable WB Calibration Mode using EnableWBCalibrationMode() value = true tvERROR_NONE Should be successful 03 Get the current WB Calibration Mode using GetCurrentWBCalibrationMode()  and verify value = valid buffer tvERROR_NONE, value = true Should be successful 04 Terminate the TV using TvTerm() None tvERROR_NONE Should be successful <pre><code>graph TB\n    A[TvInit] --&gt;|tvERROR_NONE| B[EnableWBCalibrationMode &lt;br&gt; with true]\n    A --&gt;|!=tvERROR_NONE| A1[Test case fail]\n    B --&gt;|tvERROR_NONE| C[GetCurrentWBCalibrationMode]\n    B --&gt;|!=tvERROR_NONE| B1[Test case fail]\n    C --&gt;|tvERROR_NONE, output=true| F[TvTerm]\n    C --&gt;|!=tvERROR_NONE| C1[Test case fail]\n    F --&gt;|tvERROR_NONE| G[Test case pass]\n    F --&gt;|!=tvERROR_NONE| F1[Test case fail]</code></pre>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-35","title":"Test 35","text":"Title Details Function Name <code>test_l2_tvSettings_SetAndGetGammaTable</code> Description Set and Gets the Gamma Table within the range ( 0 - 1023). The retrieved value should match the set value. Get values are retrieved from the  database. Test Group 02 Test Case ID 35 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-procedure-test-35","title":"Test Procedure  - Test 35","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the TV using TvInit() None tvERROR_NONE Should be successful 02 Set the Gamma Table using SetGammaTable() with valid buffers pData_R =  0 to 1023, pData_G = 0 to 1023, pData_B = 0 to 1023, size = 256 tvERROR_NONE Should be successful 03 Get the Gamma Table using GetGammaTable() with valid buffers getData_R = valid buffer, getData_G = valid buffer, getData_B = valid buffer, size = 256 tvERROR_NONE Should be successful 04 Compare the set and get values for each color pData_R[i] = getData_R[i], pData_G[i] = getData_G[i], pData_B[i] = getData_B[i] pData_R[i] = getData_R[i], pData_G[i] = getData_G[i], pData_B[i] = getData_B[i] Should be successful 05 Terminate the TV using TvTerm() None tvERROR_NONE Should be successful <pre><code>graph TB\n    A[TvInit] --&gt;|Success| B{Iterate through &lt;br&gt; size value}\n    B --&gt; C[SetGammaTable with valid &lt;br&gt; values of R,G,B]\n    A --&gt;|Failure| A1[Test case fail]\n    C --&gt;|Success| D[GetGammaTable]\n    D --&gt;|Success, &lt;br&gt; get and set matches| B\n    B --&gt;|End of loop| F[TvTerm]\n    F --&gt;|Success| G[Test case pass]\n    F --&gt;|Failure| F1[Test case fail]</code></pre>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-36","title":"Test 36","text":"Title Details Function Name <code>test_l2_tvSettings_GetDefaultGammaTable</code> Description Gets the default gamma calibrated values for gamma red, green and blue values ( 0 - 65535 ) and check the values are in the range. Test Group 02 Test Case ID 36 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-procedure-test-36","title":"Test Procedure  - Test 36","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the TV settings using TvInit() None tvERROR_NONE Should be successful 02 Get the default gamma table for standard color temperature using GetDefaultGammaTable() colortemp = tvColorTemp_STANDARD to tvColorTemp_MAX-1, pData_R = valid array, pData_G = valid array, pData_B = valid array, size = 256 tvERROR_NONE Should be successful 03 Check if the returned gamma values for red, green and blue are in the range 0 - 65535 (pData_R, pData_G,pData_B) = 0 to 65535 Should be successful 04 Terminate the TV settings using TvTerm() None tvERROR_NONE Should be successful <pre><code>graph TB\nA[TvInit is called] --&gt;| tvERROR_NONE| Loop{Iterate through valid &lt;br&gt;color temperatures}\nLoop --&gt; B[GetDefaultGammaTable]\nA --&gt;|not tvERROR_NONE| A1[Test case fail]\nB --&gt;|tvERROR_NONE| C[Check values in pData_R, &lt;br&gt; pData_G, and pData_B arrays]\nC --&gt;|Values = 0 to 65535| Loop\nLoop --&gt;|End of loop|D[TvTerm is called]\nD --&gt;| tvERROR_NONE| E[Test case pass]\nD --&gt;|not tvERROR_NONE| D1[Test case fail]</code></pre>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-37","title":"Test 37","text":"Title Details Function Name <code>test_l2_tvSettings_SetAndGetDvTmaxValue</code> Description Set and Gets the Dv Tmax Value within the range ( 0 - 10000 ). The retrieved value should match the set value. Get values are retrieved from the  database. Test Group 02 Test Case ID 37 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-procedure-test-37","title":"Test Procedure  - Test 37","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the TV settings using TvInit None tvERROR_NONE Should be successful 02 Set the Dv Tmax Value using SetDvTmaxValue for 4 different values setValue = (0-10000) tvERROR_NONE Should be successful 03 Get the Dv Tmax Value using GetDvTmaxValue getValue = valid buffer tvERROR_NONE Should be successful 04 Assert that the set value and the retrieved value are equal setValue = getValue Should be successful 05 Terminate the TV settings using TvTerm None tvERROR_NONE Should be successful <pre><code>graph TB\n    Step1[Call TvInit API] --&gt;|Success| Loop{Iterate through &lt;br&gt; 4 valid values}\n    Loop --&gt; Step2[Call SetDvTmaxValue API]\n    Step1 --&gt;|Failure| Fail1[Test case Fail]\n    Step2 --&gt;|Success| Step3[Call GetDvTmaxValue API]\n    Step3 --&gt;|Success, &lt;br&gt; matches set value| Loop\n    Loop --&gt; Step5[Call TvTerm API]\n    Step5 --&gt;|Success| Step6[Testcase success]\n    Step5 --&gt;|Failure| TestcaseFail5[Test case Fail]</code></pre>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-38","title":"Test 38","text":"Title Details Function Name <code>test_l2_tvSettings_GetSupportedComponentColor</code> Description Verifies whether the test gets the supported component colors by comparing the test results with the platform-supported configurations file  using the path 'tvSettings/SupportedComponentColor' and loop through the indices. Test Group 02 Test Case ID 038 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-procedure-test-38","title":"Test Procedure  - Test 38","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the TV using TvInit() None tvERROR_NONE Should be successful 02 Invoke GetSupportedComponentColor() with valid address blComponentColor = valid buffer tvERROR_NONE Should be successful 03 Compare the returned value with the value in the platform-supported configurations file blComponentColor, \"tvSettings/SupportedComponentColor\" Equal values Should be successful 04 Loop through the indices of the returned value and check if the component color at each index is supported blComponentColor = returned value None Should be successful 05 Terminate the TV using TvTerm() None tvERROR_NONE Should be successful <pre><code>graph TB\n    A[TvInit] --&gt;|tvERROR_NONE|C[GetSupportedComponentColor]\n    A --&gt;|Failure| A1[Test case fail]\n    C --&gt;|tvERROR_NONE| D[Compare with profile &lt;br&gt; Loop through indices]\n    D --&gt; F[TvTerm]\n    F --&gt;|tvERROR_NONE| G[Test case pass]\n    F --&gt;|Failure| F1[Test case fail]</code></pre>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-39","title":"Test 39","text":"Title Details Function Name <code>test_l2_tvSettings_SetAndGetComponentSaturation</code> Description Set and Get the component saturation by verifying whether the values are within the valid range (0 - 100). The retrieved value should match the set value. Get values are fetched from the  database. Test Group 02 Test Case ID 39 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-procedure-test-39","title":"Test Procedure  - Test 39","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the TV using TvInit() None tvERROR_NONE Should be successful 02 Set the CMS state to true using SetCMSState() state = true tvERROR_NONE Should be successful 03 For each color component, set a  saturation value between 0 and 100 using SetCurrentComponentSaturation() color =tvDataColor_NONE to tvDataColor_MAX, saturation = (0-100) tvERROR_NONE Should be successful 04 Get the current component saturation using GetCurrentComponentSaturation() color = color component, saturation = valid buffer tvERROR_NONE Should be successful 05 Assert that the set saturation value matches the retrieved saturation value setSaturation = saturation Should be successful 06 Terminate the TV using TvTerm() None tvERROR_NONE Should be successful <pre><code>graph TB\n    A[TvInit] --&gt;|Success| B[SetCMSState with true]\n    B --&gt;|Success| Loop{Iterate through &lt;br&gt; color component}\n    Loop --&gt; C[SetCurrentComponentSaturation]\n    C --&gt;|Success| D[GetCurrentComponentSaturation]\n    D --&gt;|Success, &lt;br&gt; Saturation matches| Loop\n    Loop --&gt;|End of loop|I[TvTerm]\n    I --&gt;|Success| E[Test case success]\n    A --&gt;|Failure| J[Test case fail]\n    B --&gt;|Failure| K[Test case fail]\n    I --&gt;|Failure| R[Test case fail]</code></pre>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-40","title":"Test 40","text":"Title Details Function Name <code>test_l2_tvSettings_SetAndGetComponentHue</code> Description Set and Get the Component Hue by verifying whether the values are within the valid range (0 - 100). The retrieved value should match the set value. Get values are fetched from the database. Test Group 02 Test Case ID 040 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-procedure-test-40","title":"Test Procedure  - Test 40","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the TV using TvInit() None tvERROR_NONE Should be successful 02 Set CMS state to true using SetCMSState() state = true tvERROR_NONE Should be successful 03 Loop through each color and hue value. Set the current component hue using SetCurrentComponentHue() color = tvDataColor_NONE to tvDataColor_MAX, hue = (0-100) tvERROR_NONE Should be successful 04 Get the current component hue using GetCurrentComponentHue() and verify tvERROR_NONE, hue = set value Should be successful 05 Terminate the TV using TvTerm() None tvERROR_NONE Should be successful <pre><code>graph TB\n    A[TvInit] --&gt;|Success| B[SetCMSState with true]\n    B --&gt;|Success| Loop{Iterate through &lt;br&gt; color component}\n    Loop --&gt; C[SetCurrentComponentHue]\n    C --&gt;|Success| D[GetCurrentComponentHue]\n    D --&gt;|Success, &lt;br&gt; Hue matches| Loop\n    Loop --&gt;|End of loop|I[TvTerm]\n    I --&gt;|Success| E[Test case success]\n    A --&gt;|Failure| J[Test case fail]\n    B --&gt;|Failure| K[Test case fail]\n    I --&gt;|Failure| R[Test case fail]</code></pre>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-41","title":"Test 41","text":"Title Details Function Name <code>test_l2_tvSettings_SetAndGetComponentLuma</code> Description Set and Gets the Component Luma by verifying whether the values are within the valid range (0 - 100). The retrieved value should match the set value. Get values are fetched from the database. Test Group 02 Test Case ID 041 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-procedure-test-41","title":"Test Procedure  - Test 41","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the TV using TvInit() None tvERROR_NONE Should be successful 02 Set CMS state to true using SetCMSState() state = true tvERROR_NONE Should be successful 03 Loop through each color component. Set the luma value for the current color component using SetCurrentComponentLuma() color = tvDataColor_NONE to tvDataColor_MAX, lumaSet = (0-30) tvERROR_NONE Should be successful 04 Get the luma value for the current color component using GetCurrentComponentLuma() tvERROR_NONE, luma = lumaSet Should be successful 05 Terminate the TV using TvTerm() None tvERROR_NONE Should be successful <pre><code>graph TB\n    A[TvInit] --&gt;|Success| B[SetCMSState with true]\n    B --&gt;|Success| Loop{Iterate through &lt;br&gt; color component}\n    Loop --&gt; C[SetCurrentComponentLuma]\n    C --&gt;|Success| D[GetCurrentComponentLuma]\n    D --&gt;|Success, &lt;br&gt; luma matches| Loop\n    Loop --&gt;|End of loop|I[TvTerm]\n    I --&gt;|Success| E[Test case success]\n    A --&gt;|Failure| J[Test case fail]\n    B --&gt;|Failure| K[Test case fail]\n    I --&gt;|Failure| R[Test case fail]</code></pre>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-42","title":"Test 42","text":"Title Details Function Name <code>test_l2_tvSettings_SetAndGetCMSState</code> Description Set and Gets the <code>CMS</code> State. The retrieved value should match the set value. Get values are retrieved from the database. Test Group 02 Test Case ID 42 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-procedure-test-42","title":"Test Procedure  - Test 42","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the TV using TvInit() None tvERROR_NONE Should be successful 02 Set the CMS state to true using SetCMSState() enableCMSState = true tvERROR_NONE Should be successful 03 Get the CMS state using GetCMSState() and verify enableCMSState = valid buffer tvERROR_NONE, enableCMSState = true Should be successful 04 Set the CMS state to false using SetCMSState() enableCMSState = false tvERROR_NONE Should be successful 05 Get the CMS state using GetCMSState() and verify enableCMSState = valid buffer tvERROR_NONE, enableCMSState = false Should be successful 06 Terminate the TV using TvTerm() None tvERROR_NONE Should be successful <pre><code>graph TB\n    Step1[Call TvInit API] --&gt;|tvERROR_NONE| Step2\n    Step1 --&gt;|Failure| TestcaseFail1[Test case fail]\n    Step2[Call SetCMSState API with true] --&gt;|tvERROR_NONE| Step3\n    Step2 --&gt;|Failure| TestcaseFail2[Test case fail]\n    Step3[Call GetCMSState API, check true] --&gt;|Success, true| Step4\n    Step3 --&gt;|Failure| TestcaseFail3[Test case fail]\n    Step4[Call SetCMSState API with false] --&gt;|tvERROR_NONE| Step5\n    Step4 --&gt;|Failure| TestcaseFail4[Test case fail]\n    Step5[Call GetCMSState API, check false]--&gt;|Success, false| Step6\n    Step5 --&gt;|Failure| TestcaseFail5[Test case fail]\n    Step6[Call TvTerm API] --&gt;|tvERROR_NONE| Step7[Test case success]\n    Step6 --&gt;|Failure| TestcaseFail6[Test case fail]</code></pre>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-43","title":"Test 43","text":"Title Details Function Name <code>test_l2_tvSettings_TestGetPQParameters</code> Description To test the Get <code>PQ</code> Parameters, loop through the different video sources, video formats, and picture quality modes for all combinations and set the brightness, contrast, sharpness, and component saturation value (loop through different saturation colors) to 50%. For Tmax, set the value to 500, and for low latency, set it to 1. After setting these values, loop through the different video sources, video formats, and picture quality modes again, read back the GetPQ parameter values and ensure that all are set to the required values: brightness, contrast, sharpness, and component saturation at 50%, Tmax at 500, and low latency at 1. Test Group 02 Test Case ID 043 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-procedure-test-43","title":"Test Procedure  - Test 43","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize TV using TvInit() None tvERROR_NONE Should be successful 02 Loop through video sources, video formats, and PQ modes. Set brightness, contrast, saturation, hue, component saturation, Tmax value, and low latency state using respective APIs videoSrcType = VIDEO_SOURCE_ANALOGUE to VIDEO_SOURCE_MAX, videoFormatType = VIDEO_FORMAT_NONE to VIDEO_FORMAT_MAX, pq_mode = 0 to PQ_MODE_MAX, value = 50 for brightness, contrast, saturation, hue, and component saturation, value = 500 for Tmax, value = 1 for low latency state tvERROR_NONE Should be successful 03 Loop through video sources, video formats, and PQ modes again. Get PQ parameters using GetPQParams() and verify the values videoSrcType = VIDEO_SOURCE_ANALOGUE to VIDEO_SOURCE_MAX, videoFormatType = VIDEO_FORMAT_NONE to VIDEO_FORMAT_MAX, pq_mode = 0 to PQ_MODE_MAX, pqParamIndex = PQ_PARAM_BRIGHTNESS to PQ_PARAM_MAX tvERROR_NONE, value = 50 for brightness, contrast, saturation, hue, and component saturation, value = 500 for Tmax, value = 1 for low latency state Should be successful 04 Terminate TV using TvTerm() None tvERROR_NONE Should be successful <pre><code>graph TB\n    A[TvInit] --&gt;|Success| B{Loop through &lt;br&gt; video sources, formats, &lt;br&gt;PQ modes}\n    A --&gt;|Failure| A1[Test case fail]\n    B --&gt;|Success| C[SaveBrightness, SaveContrast,&lt;br&gt; SaveSaturation, SaveHue]\n    C --&gt;|Success| D[SetCurrentComponentSaturation,&lt;br&gt; SaveDvTmaxValue &lt;br&gt; SaveLowLatencyState]\n    D --&gt;|Success| G{Loop through video sources,&lt;br&gt; formats, PQ modes}\n    G --&gt;|Success| H[GetPQParams]\n    H --&gt;|Success| G\n    G --&gt;|ENd of loop|B\n    B --&gt;|ENd of loop| I[TvTerm]\n    I --&gt;|Success| J[Test case success]\n    I --&gt;|Failure| I1[Test case fail]</code></pre>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-44","title":"Test 44","text":"Title Details Function Name <code>test_l2_tvSettings_GetTVGammaTarget</code> Description Get TV Gamma Target verifies the functionality of retrieving the target x and y coordinates for the panel gamma based on a given color temperature. It ensures that the returned coordinates are within the range of 0 to 1.0. Validate with various color temperatures (tvColorTemp_t). Test Group 02 Test Case ID 044 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-procedure-test-44","title":"Test Procedure  - Test 44","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize TV using TvInit() None tvERROR_NONE Should be successful 02 Loop through each color temperature in tvColorTemp_t and retrieve the target x and y coordinates for the panel gamma using GetTVGammaTarget() colorTemp = tvColorTemp_STANDARD to tvColorTemp_MAX x and y = 0 to 1.0 Should be successful 03 Terminate TV using TvTerm() None tvERROR_NONE Should be successful <pre><code>graph TB\n    TvInit[Call TvInit API] --&gt;|tvERROR_NONE| Loop{Iterate through &lt;br&gt; color temperature}\n    Loop --&gt; GetTVGammaTarget1\n    TvInit --&gt;|not tvERROR_NONE| TestcaseFail1[Test case fail]\n    GetTVGammaTarget1[Call GetTVGammaTarget] --&gt;|x and y coordinates&lt;br&gt; within 0 to 1.0| Loop\n    Loop --&gt;|End of loop| TvTerm\n    TvTerm[Call TvTerm API] --&gt;|tvERROR_NONE| Success[Test case success]\n    TvTerm --&gt;|not tvERROR_NONE| TestcaseFail12[Test case fail]</code></pre>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-45","title":"Test 45","text":"Title Details Function Name <code>test_l2_tvSettings_GetMaxGainValue</code> Description Gets the max gamma/WB gain value for the platform and check it is in the range. The valid range can be from 2^10 till (2^31)-1. Test Group 02 Test Case ID 045 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-procedure-test-45","title":"Test Procedure  - Test 45","text":"Variation / Steps Description Test Data Expected Result Notes 01 Invoke TvInit() to initialize the TV settings No input data tvERROR_NONE Should be successful 02 Invoke GetMaxGainValue() to get the maximum gain value No input data Gain value = (1024 to 2147483647) Should be successful 03 Invoke TvTerm() to terminate the TV settings No input data tvERROR_NONE Should be successful <pre><code>graph TB\nA[Call TvInit API] --&gt;|Success| B[Call GetMaxGainValue API]\nA --&gt;|Failure| A1[Test case fail]\nB --&gt;|Success| C[Check returned gain value &lt;br&gt; within 1024 to 2147483647 ]\nB --&gt;|Failure| B1[Test case fail]\nC --&gt;|Success| D[Call TvTerm API]\nC --&gt;|Failure| C1[Test case fail]\nD --&gt;|Success| E[Test case success]\nD --&gt;|Failure| D1[Test case fail]</code></pre>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-46","title":"Test 46","text":"Title Details Function Name <code>test_l2_tvSettings_SetAndGetRGBPattern</code> Description Set and Gets the RGB Pattern within the range ( 0 - 255 ). The retrieved value should match the set value. Get values are retrieved from the database. Test Group 02 Test Case ID 46 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-procedure-test-46","title":"Test Procedure  - Test 46","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the TV using TvInit() None tvERROR_NONE Should be successful 02 Set the RGB pattern using SetRGBPattern() for 4 valid values (r_set, g_set, b_set) = (0 to 255) tvERROR_NONE Should be successful 03 Get the RGB pattern using GetRGBPattern() r_get, g_get, b_get tvERROR_NONE Should be successful 04 Check if the retrieved RGB values match the set values r_set = r_get, g_set = g_get, b_set = b_get tvERROR_NONE Should be successful 05 Terminate the TV using TvTerm() None tvERROR_NONE Should be successful <pre><code>graph TB\n    A[TvInit] --&gt;|Success| Loop{Iterate through &lt;br&gt; 4 valid values}\n    Loop --&gt; B[SetRGBPattern]\n    A --&gt;|Failure| A1[Test case fail]\n    B --&gt;|tvERROR_NONE| D[GetRGBPattern]\n    D --&gt;|tvERROR_NONE,&lt;br&gt; get and set matches|Loop\n    Loop --&gt;|End of loop|G[TvTerm]\n    G --&gt;|Success| H[Test case pass]\n    G --&gt;|Failure| G1[Test case fail]</code></pre>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-47","title":"Test 47","text":"Title Details Function Name <code>test_l2_tvSettings_SetAndGetGrayPattern</code> Description Set and Gets the Gray Pattern within the range ( 0 - 255 ). The retrieved value should match the set value. Get values are retrieved from the database. Test Group 02 Test Case ID 47 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-procedure-test-47","title":"Test Procedure  - Test 47","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the TV using TvInit() None tvERROR_NONE Should be successful 02 Set the Gamma Pattern Mode to true using SetGammaPatternMode() Mode = true tvERROR_NONE Should be successful 03 Set the Gray Pattern using SetGrayPattern()  for 4 valid values YUVValue = (0-255) tvERROR_NONE Should be successful 04 Get the Gray Pattern using GetGrayPattern() get_YUVValue = valid buffer tvERROR_NONE, get_YUVValue = YUVValue Should be successful 05 Terminate the TV using TvTerm() None tvERROR_NONE Should be successful <pre><code>graph TB\n    A[TvInit] --&gt;|tvERROR_NONE| B[SetGammaPatternMode true]\n    A --&gt;|Failure| A1[Test case fail]\n    B --&gt;|tvERROR_NONE| Loop{Iterate through &lt;br&gt; 4 valid values}\n    Loop --&gt; C[SetGrayPattern]\n    B --&gt;|Failure| B1[Test case fail]\n    C --&gt;|tvERROR_NONE| D[GetGrayPattern]\n    D --&gt;|tvERROR_NONE, &lt;br&gt;YUVValue matches| Loop\n    Loop --&gt;|End of loop| E[TvTerm]\n    E --&gt;|tvERROR_NONE| F[Test case success]\n    E --&gt;|Failure| E1[Test case fail]</code></pre>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-48","title":"Test 48","text":"Title Details Function Name <code>test_l2_tvSettings_RetrieveOpenCircuitStatus</code> Description Verifies the functionality of retrieving the current open circuit status of the backlight hardware. It ensures that the returned status indicates whether any <code>LED</code> fault is detected. Test Group 02 Test Case ID 48 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-procedure-test-48","title":"Test Procedure  - Test 48","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the TV using TvInit() None tvERROR_NONE Should be successful 02 Retrieve the open circuit status using GetOpenCircuitStatus() status = valid buffer tvERROR_NONE Should be successful 03 Check if the status indicates an LED fault status &gt;= 1 LED fault detected Should be successful 04 Check if the status indicates no LED fault status = 0 No LED fault detected Should be successful 05 Check if the status value is invalid status &lt; 0 Invalid status value Should fail 06 Terminate the TV using TvTerm() None tvERROR_NONE Should be successful <pre><code>graph TB\n    A[TvInit] --&gt;|tvERROR_NONE| B[GetOpenCircuitStatus]\n    A --&gt;|!=tvERROR_NONE| A1[Test case fail]\n    B --&gt;|tvERROR_NONE| C[Check returned &lt;br&gt; status]\n    B --&gt;|!=tvERROR_NONE| B1[Test case fail]\n    C --&gt;|Status &gt;= 1| F[LED fault detected]\n    C --&gt;|Status == 0| G[LED fault not &lt;br&gt; detected]\n    C --&gt;|Status &lt; 0 &lt;br&gt; or Status &gt; 1| H[Invalid status]\n    F --&gt;D[TvTerm]\n    G --&gt;D\n    H --&gt; D\n    D --&gt;|tvERROR_NONE| E[Test case pass]\n    D --&gt;|!=tvERROR_NONE| D1[Test case fail]</code></pre>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-49","title":"Test 49","text":"Title Details Function Name <code>test_l2_tvSettings_EnableAndGetDynamicContrast</code> Description Enable Dynamic Contrast - Verifies the functionality of enabling or disabling the dynamic contrast module. Check the status by get dynamic contrast. Test Group 02 Test Case ID 49 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-procedure-test-49","title":"Test Procedure - Test 49","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize TV using TvInit() None tvERROR_NONE Should be successful 02 Enable Dynamic Contrast using EnableDynamicContrast() Enable = true tvERROR_NONE Should be successful 03 Get Dynamic Contrast status using GetDynamicContrast() and verify isDynamicContrastEnabled = valid buffer tvERROR_NONE, \"enabled\" Should be successful 04 Disable Dynamic Contrast using EnableDynamicContrast() Enable = false tvERROR_NONE Should be successful 05 Get Dynamic Contrast status using GetDynamicContrast() and verify isDynamicContrastEnabled = valid buffer tvERROR_NONE, \"disabled\" Should be successful 06 Terminate TV using TvTerm() None tvERROR_NONE Should be successful <pre><code>graph TB\n    A[TvInit] --&gt;|tvERROR_NONE| B[EnableDynamicContrast with true]\n    A --&gt;|!=tvERROR_NONE| A1[Test case fail]\n    B --&gt;|tvERROR_NONE| C[GetDynamicContrast]\n    B --&gt;|!=tvERROR_NONE| B1[Test case fail]\n    C --&gt;|tvERROR_NONE&lt;br&gt; output='enabled'| D[EnableDynamicContrast with false]\n    C --&gt;|!=tvERROR_NONE| C1[Test case fail]\n    D --&gt;|tvERROR_NONE| E[GetDynamicContrast]\n    D --&gt;|!=tvERROR_NONE| D1[Test case fail]\n    E --&gt;|tvERROR_NONE or &lt;br&gt; output=='disabled'| F[TvTerm]\n    E --&gt;|!=tvERROR_NONE| E1[Test case fail]\n    F --&gt;|tvERROR_NONE| G[Test case success]\n    F --&gt;|!=tvERROR_NONE| F1[Test case fail]</code></pre>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-50","title":"Test 50","text":"Title Details Function Name <code>test_l2_tvSettings_RetrieveLDIMShortCircuitStatus</code> Description Verifies the functionality of retrieving the short circuit status of the adjacent zones. It ensures that the returned status indicates whether any short is detected. Test Group 02 Test Case ID 50 Priority High <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-procedure-test-50","title":"Test Procedure  - Test 50","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the TV using TvInit() None tvERROR_NONE Should be successful 02 Retrieve the short circuit status using GetOpenCircuitStatus() shortcircuitlist = valid pointer, listsize = number of zones, status = valid pointer tvERROR_NONE Should be successful 03 Check if the status indicates an short detected shortcircuitlist = list of zones shorted/not shorted, status &gt;= 1 short detected Should be successful 04 Check if the status indicates no short detected shortcircuitlist = list of zones shorted/not shorted, status = 0 No short detected Should be successful 05 Check if the status value is invalid status &lt; 0 Invalid status value Should fail 06 Terminate the TV using TvTerm() None tvERROR_NONE Should be successful <pre><code>graph TB\n    A[TvInit] --&gt;|tvERROR_NONE| B[GetLdimZoneShortCircuitStatus]\n    A --&gt;|!=tvERROR_NONE| A1[Test case fail]\n    B --&gt;|tvERROR_NONE| C[Check returned &lt;br&gt; status]\n    B --&gt;|!=tvERROR_NONE &amp;&amp; != tvERROR_OPERATION_NOT_SUPPORTED| B1[Test case fail]\n    C --&gt;|Status &gt;= 1| F[Short detected]\n    C --&gt;|Status == 0| G[Short not &lt;br&gt; detected]\n    C --&gt;|Status &lt; 0 &lt;br&gt; or Status &gt; 1| H[Invalid status]\n    F --&gt;D[TvTerm]\n    G --&gt;D\n    H --&gt; D\n    D --&gt;|tvERROR_NONE| E[Test case pass]\n    D --&gt;|!=tvERROR_NONE| D1[Test case fail]</code></pre>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-51","title":"Test 51","text":"Title Details Function Name <code>test_l2_tvSettings_GetNumberOfDimmingZones</code> Description Verifies the functionality of retrieving the dimming zone count. Test Group 02 Test Case ID 51 <p>|Priority|High|</p> <p>Pre-Conditions None</p> <p>Dependencies None</p> <p>User Interaction If user chose to run the test in interactive mode, then the test case has to be selected via console.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L2_Low_Level_Test_Spec/#test-procedure-test-51","title":"Test Procedure  - Test 51","text":"Variation / Steps Description Test Data Expected Result Notes 01 Initialize the TV using TvInit() None tvERROR_NONE Should be successful 02 Retrieve the dimming zone count using GetNumberOfDimmingZones() number_of_dimming_zones = valid pointer tvERROR_NONE Should be successful 03 Check if number_of_dimming_zones number_of_dimming_zones = number of dimming zones supported number of dimming zone matches the expected count for given platform Should be successful 04 Check if the status indicates no short detected number_of_dimming_zones = number of dimming zones supported number of dimming zone did not matches the expected count for given platform Should fail 05 Terminate the TV using TvTerm() None tvERROR_NONE Should be successful <pre><code>graph TB\n    A[TvInit] --&gt;|tvERROR_NONE| B[GetNumberOfDimmingZones]\n    A --&gt;|!=tvERROR_NONE| A1[Test case fail]\n    B --&gt;|tvERROR_NONE| C[Check returned &lt;br&gt; status]\n    B --&gt;|!=tvERROR_NONE &amp;&amp; != tvERROR_OPERATION_NOT_SUPPORTED| B1[Test case fail]\n    C --&gt;|number_of_dimming_zones != number_of_dimming_zones__expected_for_current_panel_platform| F[Test case fail]\n    C --&gt;|number_of_dimming_zones == number_of_dimming_zones__expected_for_current_panel_platform| G[Test case pass]\n    F --&gt;D[TvTerm]\n    G --&gt;D[TvTerm]\n    D --&gt;|tvERROR_NONE| E[Test case pass]\n    D --&gt;|!=tvERROR_NONE| D1[Test case fail]</code></pre>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_Low_Level_Test_Spec/","title":"<code>TV</code> Settings L3 Low Level Test Specification and Procedure Documentation","text":""},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_Low_Level_Test_Spec/#overview","title":"Overview","text":"<p>This document describes the L3 Low Level Test Specification and Procedure Documentation for the <code>TV</code> Settings module.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_Low_Level_Test_Spec/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>HAL</code>  - Hardware Abstraction Layer, may include some common components</li> <li><code>UT</code>   - Unit Test(s)</li> <li><code>OEM</code>  - Original Equipment Manufacture</li> <li><code>SoC</code>  - System on a Chip</li> <li><code>HDMI</code> - High-Definition Multimedia Interface</li> <li><code>HDCP</code> - High-bandwidth Digital Content Protection</li> <li><code>HDR</code>  - High Dynamic Range</li> <li><code>HLG</code>  - Hybrid Log-Gamma</li> <li><code>SDR</code>  - Standard Dynamic Range</li> <li><code>CMS</code>  - Color Management System</li> <li><code>TV</code>   - TeleVision</li> <li><code>RGB</code>  - Red Green Blue</li> <li><code>LDIM</code> - Local Dimming</li> <li><code>Y</code>    - yes supported</li> <li><code>NA</code>   - Not Supported</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_Low_Level_Test_Spec/#references","title":"References","text":"<ul> <li><code>High Level Test Specification</code> - TV Settings High Level TestSpec</li> <li><code>Interface header</code> - TV Settings HAL header</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_Low_Level_Test_Spec/#tvsettings-stream-requirement","title":"TvSettings Stream Requirement","text":"# Streams Name Streams description 1 vts_HDR10_stream Format: HDR10,Resolution: 3840 x 2160 (4K UHD),Color Depth: 10-bit,Color Space: Rec. 2020 2 vts_SDR_stream Format: SDR,Resolution: 1920 x 1080 3 vts_HLG_stream Format: HLG,Resolution: 3840 x 2160 or It can also be used with 1080p and 720p resolutions. 4 vts_DolbyVision_stream Format: Dolby Vision,Resolution: 3840 x 2160 (4K UHD),Color Depth: 10/12-bit,Color Space: Rec. 2020format and dynamic metadata. 5 vts_HDR10plus_stream Format: HDR10,Resolution: 3840 x 2160 (4K UHD),Color Depth: 10-bit,Color Space: Rec. 2020 and dynamic metadata capabilities."},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_Low_Level_Test_Spec/#level-3-test-cases-high-level-overview","title":"Level 3 Test Cases High Level Overview","text":"<p>Below are top test use-case for the <code>TV</code> Settings.</p> # Test-case Description HAL APIs Source Sink Streams Number 1 Check VideoFormat Verify the Video format by playing the pre defined stream with different video formats <code>GetCurrentVideoFormat()</code>,<code>RegisterVideoFormatChangeCB()</code> <code>N</code> <code>Y</code> 1,2,3,4 2 Check VideoResolution Verify the video Resolution by playing the pre defined stream different video Resolution <code>GetCurrentVideoResolution()</code>,<code>RegisterVideoContentChangeCB()</code> <code>N</code> <code>Y</code> 1,2,3,4 3 Check VideoFrameRate Verify the video Frame rate by playing the pre defined stream different video Frame rate <code>GetCurrentVideoFrameRate()</code>,<code>RegisterVideoResolutionChangeCB()</code> <code>N</code> <code>Y</code> 1,2,3,4 4 Check Video Source Verify the current video source of the <code>TV</code> settings. It should return the default IP, as we are testing with the IP module only. <code>GetCurrentVideoSource()</code>, <code>RegisterVideoFrameRateChangeCB()</code> <code>N</code> <code>Y</code> 1 5 Check Backlight for tvSettings Play the pre-defined video and verify the backlight setting for <code>TV</code> settings. Valid range is from 0 to 100. <code>GetBacklight()</code> <code>SetBacklight()</code> <code>N</code> <code>Y</code> 2 6 Check Backlight Fade for tvSettings Play the pre-defined video and verify the backlight fade effect for <code>TV</code> settings. Valid range for from, to is 0 to 100 and duration range is from 0 to 1000 <code>GetBacklightFade()</code> <code>SetBacklightFade()</code> <code>N</code> <code>Y</code> 2 7 Check Backlight Mode for tvSettings Play the pre-defined video and verify the backlight mode (manual, ambient, eco) for <code>TV</code> settings. <code>GetCurrentBacklightMode()</code> <code>SetCurrentBacklightMode()</code> <code>N</code> <code>Y</code> 2 8 Verify <code>TV</code> Dimming Mode for tvSettings Play the pre-defined video and verify the supported dimming mode(local, fixed, global) of the TV. <code>GetTVDimmingMode()</code> <code>SetTVDimmingMode()</code> <code>N</code> <code>Y</code> 2 9 Check Local Dimming Mode for tvSettings Play the pre-defined streams and verify the all supported local dimming mode (boost, non-boost, burst) for <code>TV</code> settings. <code>GetLocalDimmingLevel()</code> <code>SetLocalDimmingLevel()</code> <code>N</code> <code>Y</code> 1,2,3,4 10 Set Brightness for tvSettings Play the pre-defined streams and verify the brightness of <code>TV</code> settings. Valid range is from 0 - 100 <code>GetBrightness()</code> <code>SetBrightness()</code> <code>N</code> <code>Y</code> 2 11 Set Contrast for tvSettings Play the pre-defined streams and verify the contrast of <code>TV</code> settings. Valid range is from 0 - 100 <code>GetContrast()</code> <code>SetContrast()</code> <code>N</code> <code>Y</code> 2 12 Set Sharpness for tvSettings Play the pre-defined streams and verify the sharpness of <code>TV</code> settings. Valid range is from 0 - 100 <code>GetSharpness()</code> <code>SetSharpness()</code> <code>N</code> <code>Y</code> 2 13 Set Saturation for tvSettings Play the pre-defined streams and verify the saturation of <code>TV</code> settings. Valid range is from 0 - 100 <code>GetSaturation()</code> <code>SetSaturation()</code> <code>N</code> <code>Y</code> 2 14 Set Hue for tvSettings Play the pre-defined streams and verify the hue of <code>TV</code> settings. Valid range is from 0 - 100. <code>GetHue()</code> <code>SetHue()</code> <code>N</code> <code>Y</code> 2 15 Set ColorTemperature for tvSettings Play the pre-defined streams and verify the supported color temperature (standard, warm, cold, user, etc) of <code>TV</code> settings. Valid range is from 0 - 100 <code>GetColorTemperature()</code> <code>SetColorTemperature()</code> <code>N</code> <code>Y</code> 1 16 Verify Aspect Ratio for tvSettings Play the pre-defined streams and verify the supported aspect ratio (16:9, 4:3 etc) setting of <code>TV</code> settings. <code>GetAspectRatio()</code> <code>SetAspectRatio()</code> <code>N</code> <code>Y</code> 1,2,3,4 17 Check Dynamic Contrast for tvSettings Play the pre-defined streams and verify the dynamic contrast setting by enabling/disabling of <code>TV</code> settings. <code>GetDynamicContrast()</code> <code>SetDynamicContrast()</code> <code>N</code> <code>Y</code> 1 18 Check Dynamic Gamma for tvSettings Play the pre-defined streams and verify the dynamic gamma setting (1.8 to 2.6) of <code>TV</code> settings. <code>GetDynamicGamma()</code> <code>SetDynamicGamma()</code> <code>N</code> <code>Y</code> 1 19 Check Dolby Vision for tvSettings Play the pre-defined streams and verify the supported (dark, bright, game etc) Dolby Vision mode of <code>TV</code> settings. <code>GetTVDolbyVisionMode()</code> <code>SetTVDolbyVisionMode()</code> <code>N</code> <code>Y</code> 4 20 Check Picture Mode for tvSettings Play the pre-defined streams and verify the picture mode (standard, vivid, energy saving, custom, theater, game, sports etc) setting of <code>TV</code> settings. <code>GetTVPictureMode()</code> <code>SetTVPictureMode()</code> <code>N</code> <code>Y</code> 2 21 Check ColorTempRgain for tvSettings Play the pre-defined streams and verify the red gain value (0 - 2047) for color temperature in <code>TV</code> settings. <code>GetColorTemp_Rgain_onSource()</code> <code>SetColorTemp_Rgain_onSource()</code> <code>N</code> <code>Y</code> 1 22 Check ColorTempGgain for tvSettings Play the pre-defined streams and verify the green gain value (0 - 2047) for color temperature in <code>TV</code> settings. <code>GetColorTemp_Ggain_onSource()</code> <code>SetColorTemp_Ggain_onSource()</code> <code>N</code> <code>Y</code> 1 23 Check ColorTempBgain for tvSettings Play the pre-defined streams and verify the blue gain value(0-2047) for color temperature in <code>TV</code> settings. <code>GetColorTemp_Bgain_onSource()</code> <code>SetColorTemp_Bgain_onSource()</code> <code>N</code> <code>Y</code> 2 24 Verify ColorTempRpostoffset for tvSettings Verify the Rpost offset by setting the value(-1024 to 1023) for color temperature in <code>TV</code> settings. <code>GetColorTemp_R_post_offset_onSource()</code> <code>SetColorTemp_R_post_offset_onSource()</code> <code>N</code> <code>Y</code> <code>NA</code> 25 Verify ColorTempGpostoffset for tvSettings Verify the Gpost offset by setting the value(-1024 to 1023) for color temperature in <code>TV</code> settings. <code>GetColorTemp_G_post_offset_onSource()</code> <code>SetColorTemp_G_post_offset_onSource()</code> <code>N</code> <code>Y</code> <code>NA</code> 26 Verify ColorTempBpostoffset for tvSettings Verify the Bpost offset by setting the value(-1024 to 1023) for color temperature in <code>TV</code> settings. <code>GetColorTemp_B_post_offset_onSource()</code> <code>SetColorTemp_B_post_offset_onSource()</code> <code>N</code> <code>Y</code> <code>NA</code> 27 Verify WBCalibrationMode for tvSettings Play the predefined stream and verify the white balance calibration mode by enabling/disabling in <code>TV</code> settings. <code>EnableWBCalibrationMode()</code> <code>GetCurrentWBCalibrationMode()</code> <code>N</code> <code>Y</code> 2 28 Check Gamma Table for tvSettings Play the predefined streams and then verify the gamma table functionality. Valid range for RGB array is 0-1023 and size is 0-256. <code>GetGammaTable()</code> <code>SetGammaTable()</code> N Y 1,2 29 Verify DvTmaxValue for tvSettings Verify the Dolby Vision maximum brightness value in TV settings. Play the predefined streams and then verify the DvTmax value functionality. Valid range is from 0-10000 <code>GetDvTmaxValue()</code> <code>SetDvTmaxValue()</code> N Y 4 30 Verify ComponentSaturation for tvSettings Set the CMS state, play the predefined streams and then verify the component saturation functionality. Valid range is from 0-100 <code>SetCMSState()</code> <code>GetCurrentComponentSaturation()</code> <code>SetCurrentComponentSaturation()</code> N Y 1 31 Verify ComponentHue for tvSettings Set the CMS state, play the predefined streams and then verify the component hue functionality. Valid range is from 0-100 <code>SetCMSState()</code> <code>GetCurrentComponentHue()</code> <code>SetCurrentComponentHue()</code> N Y 1 32 Verify ComponentLuma for tvSettings Set the CMS state, play the predefined streams and then verify the component luma functionality. Valid range is from 0-100 <code>SetCMSState()</code> <code>GetCurrentComponentLuma()</code> <code>SetCurrentComponentLuma()</code> N Y 1 33 Verify EnableGammaMode for tvSettings Play the predefined streams and verify the gamma mode enable state by enabling/disabling in TV settings. <code>EnableGammaMode()</code> N Y 1 34 SetGammaPattern for tvSettings Play the predefined streams and verify the gamma pattern in TV settings. The RGB values are ranges for 0-1023 for 10-bit and 0-255 for 8-bit <code>SetGammaPattern()</code> N Y 1 35 RGBPattern for tvSettings Verify the RGB pattern in TV settings. <code>SetRGBPattern()</code> N Y NA 36 GrayPattern for tvSettings Verify the gray pattern in TV settings. <code>SetGrayPattern()</code> N Y NA 37 EnableLDIMPixelCompensation for tvSettings Play the predefined streams and verify the pixel compensation block by enabling/disabling. <code>EnableLDIMPixelCompensation()</code> N Y 1 38 EnableLDIM for tvSettings Play the predefined streams and verify the dimming module by enabling/disabling. <code>EnableLDIM()</code> N Y 1 39 SetBacklightTestMode for tvSettings Verify the backlight test mode setting (boost, burst, reset) in TV settings. Verify the functionality by playing the predefined streams. <code>SetBacklightTestMode()</code> N Y 1 40 EnableDynamicContrast for tvSettings Verify the dynamic contrast enable state in TV settings. Verify the functionality by playing the predefined streams. <code>EnableDynamicContrast()</code> N Y 1 41 EnableLocalContrast for tvSettings Verify the local contrast enable state in TV settings. Verify the functionality by playing the predefined streams. <code>EnableLocalContrast()</code> N Y 1 42 Save Backlight values for tvSettings Verify the saving of backlight values for TV settings. Play the predefined streams of one format, then switch to the saved video formats and verify the saving functionality. <code>SaveBacklight()</code> N Y 1,2,3,4 43 Save TVDimming Mode values for tvSettings Verify the saving of TVDimming values for TV settings. Play the predefined streams of one format, then switch to the saved video formats and verify the saving functionality. <code>SaveTVDimmingMode()</code> N Y 1,2,3,4 44 Save LocalDimming Mode values for tvSettings Verify the saving of LocalDimming values for TV settings. Play the predefined streams of one format, then switch to the saved video formats and verify the saving functionality. <code>SaveLocalDimmingLevel()</code> N Y 1,2,3,4 45 Save Brightness values for tvSettings Verify the saving of Brightness values for TV settings. Play the predefined streams of one format, then switch to the saved video formats and verify the saving functionality. <code>SaveBrightness()</code> N Y 1,2,3,4 46 Save Contrast values for tvSettings Verify the saving of Contrast values for TV settings. Play the predefined streams of one format, then switch to the saved video formats and verify the saving functionality. <code>SaveContrast()</code> N Y 1,2,3,4 47 Save Sharpness values for tvSettings Verify the saving of Sharpness values for TV settings. Play the predefined streams of one format, then switch to the saved video formats and verify the saving functionality. <code>SaveSharpness()</code> N Y 1,2,3,4 48 Save Saturation values for tvSettings Verify the saving of saturation values for TV settings. Play the predefined streams of one format, then switch to the saved video formats and verify the saving functionality. <code>SaveSaturation()</code> N Y 1,2,3,4 49 Save Hue values for tvSettings Verify the saving of hue values for TV settings. Play the predefined streams of one format, then switch to the saved video formats and verify the saving functionality. <code>SaveHue()</code> N Y 1,2,3,4 50 Save ColorTemperature for tvSettings Verify the saving of color temperature for TV settings. Play the predefined streams of one format, then switch to the saved video formats and verify the saving functionality. <code>SaveColorTemperature()</code> N Y 1,2,3,4 51 Save Aspect Ratio for tvSettings Verify the saving of aspect ratio for TV settings. Play the predefined streams of one format, then switch to the saved video formats and verify the saving functionality. <code>SaveAspectRatio()</code> N Y 1,2,3,4 52 Save Low Latency State for tvSettings Verify the saving of low latency state for TV settings. Play the predefined streams of one format, then switch to the saved video formats and verify the saving functionality. <code>SaveLowLatency()</code> N Y 1,2,3,4 53 Save Dolby Vision mode for tvSettings Verify the saving of Dolby Vision mode for TV settings. Play the predefined streams of one format, then switch to the saved video formats and verify the saving functionality. <code>SaveDolbyVision()</code> N Y 1,2,3,4 54 Save Picture Mode for tvSettings Verify the saving of picture mode for TV settings. Play the predefined streams of one format, then switch to the saved video formats and verify the saving functionality. <code>SavePictureMode()</code> N Y 1,2,3,4 55 Save CMS State for tvSettings Verify the saving of CMS state for TV settings. Play the predefined streams of one format, then switch to the saved video formats and verify the saving functionality. <code>SavePictureMode()</code> N Y 1,2,3,4"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_Low_Level_Test_Spec/#level-3-python-test-cases-high-level-overview","title":"Level 3 Python Test Cases High Level Overview","text":"<p>The class diagram below illustrates the flow of tvSettings L3 Python test cases:</p> <pre><code>---\ntitle: tvSettings - Python Class Flow\n---\nclassDiagram\n    testControl &lt;|-- ut_raft : inherits\n    class ut_raft{\n    }\n    ut_raft &lt;|-- tvSettingsHelperClass : inherits\n    tvSettingsHelperClass &lt;|-- L3_TestClasses : inherits\n    L3_TestClasses ..&gt; tvSettings : uses\n    note for testControl \"uses rackConfig.yaml and deviceConfig.yaml\"\n    note for tvSettings \"uses platformProfile.yaml\"\n    note for L3_TestClasses \"uses testSetupConfig.yaml\"\n    note for ut_raft \"suite Navigator uses testSuite.yaml\"</code></pre> <ul> <li>testControl</li> <li>Test Control Module for running rack Testing. This module configures the <code>DUT</code> based on the rack configuration file provided to the test.</li> <li>This class is defined in <code>RAFT</code> framework. For more details refer RAFT</li> <li>ut_raft</li> <li>Python based testing framework for writing engineering tests.</li> <li>It provides common functionalities like menu navigation, configuration reader, reading user response etc.</li> <li>For more details ut-raft.</li> <li>tvSettings</li> <li>This is test helper class which communicates with the <code>L3</code> C/C++ test running on the <code>DUT</code> through menu</li> <li>L3TestClasses</li> <li>These are the L3 test case classes</li> <li>Each class covers the each test use-case defined in L3 Test use-cases table</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_Low_Level_Test_Spec/#yaml-file-inputs","title":"YAML File Inputs","text":"<ul> <li>rackConfig.yaml</li> <li>Identifies the rack configuration and platform used</li> <li>References platform-specific config from <code>deviceConfig.yaml</code></li> <li> <p>For more details refer RAFT and example_rack_config.yml</p> </li> <li> <p>deviceConfig.yaml</p> </li> <li>Specifies overall configuration for the platform</li> <li>Can be overridden by:<ul> <li>Changing locally .yaml file directory</li> <li>Using --deviceConfig command line switch</li> </ul> </li> <li> <p>For more details refer RAFT and example_device_config.yml</p> </li> <li> <p>componentProfile.yaml/platformProfile.yaml</p> </li> <li>Contains component-specific configurations</li> <li>Contains platform wide configuration broken down into separate components</li> <li> <p>Example configuration file tvSettings</p> </li> <li> <p>testSetupConfig.yaml</p> </li> <li>This configuration file contains the list of requirements for tests to execute. Eg: Copying the streams, setting environment variables etc.</li> <li> <p>Example configuration file tvSettings_L3_testSetup.yml</p> </li> <li> <p>testConfig.yaml</p> </li> <li>This configuration file contains the list of menu items for C/C++ L3 test running on <code>DUT</code></li> <li>Example configuration file tvSettings_testConfig.yml</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/","title":"tvSettings HAL L3 Python Test Procedure","text":""},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#acronyms-terms-and-abbreviations","title":"Acronyms, Terms and Abbreviations","text":"<ul> <li><code>HAL</code>    - Hardware Abstraction Layer</li> <li><code>L3</code>     - Level 3 Testing</li> <li><code>RAFT</code>   - Rapid Automation Framework for Testing</li> <li><code>YAML</code>   - YAML Ain't Markup Language</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#setting-up-test-environment","title":"Setting Up Test Environment","text":"<p>To execute <code>HAL</code> <code>L3</code> Python test cases, need a Python environment. Follow these steps mentioned in HPK Public Documentation</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#update-configuration-files","title":"Update Configuration Files","text":""},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#rack-configuration-file","title":"Rack Configuration File","text":"<p>Example Rack configuration File: <code>ut/host/tests/configs/example_rack_config.yml</code></p> <p>For more details refer RAFT and example_rack_config.yml</p> <p>In this file, update the configuration to define the console sessions for the <code>DUT</code> and the outbound settings:</p> Console Session Description default Downloads the streams required for test cases ssh_player Plays the stream required for test case ssh_hal_test Executes the <code>HAL</code> binary for the test case <pre><code>rackConfig:\n  - dut:\n      ip: \"XXX.XXX.XXX.XXX\"  # IP Address of the device\n      description: \"panel device under test\"\n      platform: \"panel\"\n      consoles:\n        - default:\n            type: \"ssh\"\n            port: 10022\n            username: \"root\"\n            ip: \"XXX.XXX.XXX\" # IP address of the device\n            password: ' '\n        - ssh_player:\n            type: \"ssh\"\n            port: 10022\n            username: \"root\"\n            ip: \"XXX.XXX.XXX\" # IP address of the device\n            password: ' '\n        - ssh_hal_test:\n            type: \"ssh\"\n            port: 10022\n            username: \"root\"\n            ip: \"XXX.XXX.XXX\" # IP address of the device\n            password: ' '\n      outbound:\n        download_url: \"tftp://tftp-server.com/rack1/slot1/\"    # Download location for the CPE device\n        upload_url: \"sftp://server-address/home/workspace/tftp/rack1/slot1/\" # Upload location\n        upload_url_base_dir: \"sftp://server-address/home/workspace/tftp/rack1/slot1\"\n        httpProxy:   # Local proxy if required\n        workspaceDirectory: './logs/workspace'   # Local working directory\n</code></pre>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#device-configuration-file","title":"Device Configuration File","text":"<p>Example Device configuration File: <code>ut/host/tests/configs/deviceConfig.yml</code></p> <p>For more details refer RAFT and example_device_config.yml</p> <p>Update below fields in the device configuration file:</p> <ul> <li>Set the folder path for <code>target_directory</code> where <code>HAL</code> binaries will be copied onto the device.</li> <li>Specify the device profile path in <code>test/profile</code></li> <li>Ensure the <code>platform</code> should match with the <code>DUT</code> <code>platform</code> in Rack Configuration</li> </ul> <pre><code>deviceConfig:\n    cpe1:\n        platform:   \"Panel\"\n        model:      \"UK\"\n        soc_vendor: \"amlogic\"\n        target_directory: \"/tmp/\"\n        prompt: \"\" # Prompt string on console\n        test:\n            #TODO: Use the single profile file which contains all details (ds, hdmi, etc)\n            profile: \"../../../profiles/sink/Sink_4K_TvSettings.yaml\"\n            streams_download_url: \"&lt;URL_Path&gt;\" #URL path from which the streams are downloaded to the device\n</code></pre>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#test-setup-configuration-file","title":"Test Setup Configuration File","text":"<p>Example Test Setup configuration File: <code>ut/host/tests/tvSettings_L3_Tests/tvSettings_L3_testSetup.yml</code></p> <p>Provide the streams for each test case. This path is appended with <code>streams_download_url</code> entry from Device Configuration File</p> <p>If a test case requires multiple streams or needs to be validated using several streams, ensure that all necessary streams are added sequentially for that specific test case.</p> <pre><code>tvSettings:  # Prefix must always exist\n  description: \"tvSettings test setup\"\n  assets:\n   device:\n      test01_CheckVideoFormat:\n        streams:\n          -  \"streams/Colors_hdr.mp4\"\n          -  \"streams/DolbyVision.mp4\"\n          -  \"streams/Colors_hlg.mp4\"\n          -  \"streams/Colors_sdr.mp4\"\n      test02_CheckVideoResolution:\n        streams:\n          -  \"Streams/Colors_sdr.mp4\"\n          -  \"Streams/Colors_hdr.mp4\"\n          -  \"Streams/Colors_hlg.mp4\"\n      test03_CheckVideoFrameRate:\n        streams:\n          -  \"Streams/Colors_sdr.mp4\"\n          -  \"Streams/Colors_hdr.mp4\"\n          -  \"Streams/Colors_hlg.mp4\"\n      test04_CheckVideoSource:\n</code></pre>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#test-configuration","title":"Test Configuration","text":"<p>Example Test Setup configuration File: <code>ut/host/tests/Classes/tvSettings_testConfig.yml</code></p> <p>Update the execute command according to the device path where <code>HAL</code> binaries are copied.</p> <pre><code>tvSettings:  # Prefix must always exist\n    description: \"tvSettings testing profile / menu system for UT\"\n    test:\n        execute: \"&lt;PATH on Device&gt;run.sh -p &lt;PATH on Device&gt;Sink_4K_TvSettings.yaml\" #Execute command\n        type: UT-C # C (UT-C Cunit) / C++ (UT-G (g++ ut-core gtest backend))\n</code></pre>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#run-test-cases","title":"Run Test Cases","text":"<p>Once the environment is set up, you can execute the test cases with the following command</p> <pre><code>python &lt;TestCaseName.py&gt; --config &lt;/PATH&gt;/ut/host/tests/configs/example_rack_config.yml --deviceConfig &lt;/PATH&gt;/ut/host/tests/configs/deviceConfig.yml\n</code></pre>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#streams-required","title":"Streams Required","text":"<p>Refer tvSettings_L3_Low-Level_Test_Spec.md for the stream details</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#test-cases","title":"Test Cases","text":""},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#tvsettings_test01_checkvideoformatpy","title":"tvSettings_test01_CheckVideoFormat.py","text":""},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#user-input-required-test01","title":"User Input Required - test01","text":"<p>No: This test runs automatically without any need for user input.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#acceptance-criteria-test01","title":"Acceptance Criteria - test01","text":"<ul> <li>The device should play each video format stream in the specified order, and the callback should verify each format.</li> <li>When playback of non-SDR streams stops, the device should trigger a default SDR callback.</li> <li>Note: The order of supportedFormats in the test and the video format stream list in the test setup YAML file should match to ensure each format aligns with the corresponding stream during playback.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#expected-results-test01","title":"Expected Results - test01","text":"<p>The test initializes the TV settings, iterates through multiple video formats in the defined order, and confirms the correct video format and callback status for each playback.</p> <p>Success Criteria:</p> <ul> <li>The device should correctly display each specified video format during playback.</li> <li>The default SDR callback should activate after playback stops on non-SDR streams.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#test-steps-test01","title":"Test Steps - test01","text":"<ul> <li> <p>Initiate the Test:</p> </li> <li> <p>Run the Python file: <code>tvSettings_test01_CheckVideoFormat.py</code></p> </li> <li> <p>The test will automatically download each required video stream in the specified order to the target directory, initialize TV settings, and begin playback.</p> </li> <li> <p>Video Format Verification:</p> </li> <li> <p>For each video format in the predefined list, the test:</p> <ul> <li>Downloads the corresponding stream.</li> <li>Plays the stream and logs the current video format.</li> <li>Retrieves the video format callback status for validation.</li> <li>Retrives the video format.</li> </ul> </li> <li> <p>Playback Stop and SDR Callback Verification:</p> </li> <li> <p>After each playback, the test:</p> <ul> <li>Stops the stream.</li> <li>The SDR callback activates when stopping non-SDR streams.</li> </ul> </li> <li> <p>Cleanup:</p> </li> <li> <p>The test deletes each downloaded stream after verifying playback.</p> </li> <li> <p>Test Conclusion:</p> </li> </ul> <p>Upon completing playback and callback checks for all video formats, the test concludes and logs the final results based on automatic validations, ensuring streams were handled in the specified format order.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#tvsettings_test02_checkvideoresolutionpy","title":"tvSettings_test02_CheckVideoResolution.py","text":""},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#user-input-required-test02","title":"User Input Required - test02","text":"<p>No: This test runs automatically without any need for user input.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#acceptance-criteria-test02","title":"Acceptance Criteria - test02","text":"<p>The device should accurately play each video resolution stream and validate the callback status for each. After playback stops, the device should correctly reflect the video resolution information. Note: The order of supportedResolutions in the test and the video resolution streams in the test setup YAML file should match to ensure each resolution aligns with the corresponding stream during playback.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#expected-results-test02","title":"Expected Results - test02","text":"<p>The test initializes the TV settings, iterates through multiple video resolutions in the defined order, and confirms the correct video resolution and callback status for each playback.</p> <p>Success Criteria:</p> <ul> <li>The device should correctly display each specified video resolution during playback.</li> <li>The video resolution callback should accurately reflect each resolution and interlace status.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#test-steps-test02","title":"Test Steps - test02","text":"<ul> <li> <p>Initiate the Test:</p> </li> <li> <p>Run the Python file: <code>tvSettings_test02_CheckVideoResolution.py</code></p> </li> <li> <p>The test will automatically download each required video stream in the specified order to the target directory, initialize TV settings, and begin playback.</p> </li> <li> <p>Video Resolution Verification:</p> </li> <li> <p>For each video resolution in the predefined list, the test:</p> <ul> <li>Downloads the corresponding stream.</li> <li>Plays the stream and retrieves the current video resolution callback.</li> <li>Confirms the callback's resolution matches the expected resolution and interlace status.</li> </ul> </li> <li> <p>Callback and Resolution Check:</p> </li> <li> <p>After each playback, the test:</p> <ul> <li>Verifies that the callback resolution, width, height, and interlace status match the expected values.</li> <li>Logs results indicating whether each callback property matches the expected resolution.</li> </ul> </li> <li> <p>Cleanup:</p> </li> <li> <p>The test deletes each downloaded stream after verifying playback.</p> </li> <li> <p>Test Conclusion:</p> </li> </ul> <p>Upon completing playback and callback checks for all video resolutions, the test concludes and logs the final results based on automatic validations, ensuring streams were handled in the specified resolution order.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#tvsettings_test03_checkvideoframeratepy","title":"tvSettings_test03_CheckVideoFrameRate.py","text":""},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#user-input-required-test03","title":"User Input Required - test03","text":"<p>No: This test runs automatically without any need for user input.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#acceptance-criteria-test03","title":"Acceptance Criteria - test03","text":"<p>The device should play each video frame rate stream accurately, and the callback should verify each frame rate.</p> <p>Note: The order of supportedFrameRates in the test and the video frame rate streams in the test setup YAML file should match to ensure each frame rate aligns with the corresponding stream during playback.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#expected-results-test03","title":"Expected Results - test03","text":"<p>The test initializes the TV settings, iterates through multiple frame rates in the specified order, and confirms the correct frame rate and callback status for each playback.</p> <p>Success Criteria:</p> <ul> <li>The device should correctly display each specified frame rate during playback.</li> <li>The frame rate callback should accurately reflect each frame rate.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#test-steps-test03","title":"Test Steps - test03","text":"<ul> <li> <p>Initiate the Test:</p> </li> <li> <p>Run the Python file: <code>tvSettings_test03_CheckVideoFrameRate.py</code></p> </li> <li> <p>The test will automatically download each required video stream in the specified order to the target directory, initialize TV settings, and begin playback.</p> </li> <li> <p>Frame Rate Verification:</p> </li> <li> <p>For each frame rate in the predefined list, the test:</p> <ul> <li>Downloads the corresponding stream.</li> <li>Plays the stream and retrieves the current frame rate callback.</li> <li>Confirms the callback's frame rate matches the expected frame rate.</li> </ul> </li> <li> <p>Callback and Frame Rate Check:</p> </li> <li> <p>After each playback, the test:</p> <ul> <li>Verifies that the callback frame rate matches the expected frame rate.</li> <li>Logs results indicating whether the callback accurately reflects the frame rate of the stream.</li> </ul> </li> <li> <p>Cleanup:</p> </li> <li> <p>The test deletes each downloaded stream after verifying playback.</p> </li> <li> <p>Test Conclusion:</p> </li> </ul> <p>Upon completing playback and callback checks for all frame rates, the test concludes and logs the final results based on automatic validations, ensuring streams were handled in the specified frame rate order.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#tvsettings_test04_checkvideosourcepy","title":"tvSettings_test04_CheckVideoSource.py","text":""},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#user-input-required-test04","title":"User Input Required - test04","text":"<p>No: This test runs automatically without any need for user input.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#acceptance-criteria-test04","title":"Acceptance Criteria - test04","text":"<p>The device should play each video source stream accurately, and the test should verify that the correct video source is active.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#expected-results-test04","title":"Expected Results - test04","text":"<p>The test initializes the TV settings, iterates through multiple video sources, and confirms the correct video source for the stream playback.</p> <p>Success Criteria</p> <ul> <li>The device should correctly display each specified video source during playback.</li> <li>The correct video source should be verified for the stream.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#test-steps-test04","title":"Test Steps - test04","text":"<ul> <li> <p>Initiate the Test:</p> </li> <li> <p>Run the Python file: <code>tvSettings_test04_CheckVideoSource.py</code></p> </li> <li> <p>The test will automatically download each required video stream to the target directory, initialize TV settings, and begin playback.</p> </li> <li> <p>Video Source Verification:</p> </li> <li> <p>For each video source, the test:</p> <ul> <li>Plays the stream.</li> <li>Retrieves and logs the current video source status for validation.</li> </ul> </li> <li> <p>Cleanup:</p> </li> <li> <p>The test stops playback after verifying each video source.</p> </li> <li> <p>Test Conclusion:</p> </li> </ul> <p>Upon completing playback and source checks for all video sources, the test concludes and logs the final results based on automatic validations.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#tvsettings_test05_backlightpy","title":"tvSettings_test05_Backlight.py","text":""},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#user-input-required-test05","title":"User Input Required - test05","text":"<p>Yes: This test requires user input to verify whether the backlight level has been applied. The user will be prompted with a Yes/No question during the test execution.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#acceptance-criteria-test05","title":"Acceptance Criteria - test05","text":"<p>The device should adjust the backlight levels correctly as specified, and the user should confirm that the changes are applied.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#expected-results-test05","title":"Expected Results - test05","text":"<p>The test initializes the TV settings, iterates through defined backlight levels, and confirms the applied backlight level through user input during the playback of the stream.</p> <p>Success Criteria</p> <ul> <li>The backlight levels should change according to the specified settings.</li> <li>The user should confirm whether the backlight change is applied for each specified level.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#test-steps-test05","title":"Test Steps - test05","text":"<ul> <li> <p>Initiate the Test:</p> </li> <li> <p>Run the Python file: <code>tvSettings_test05_Backlight.py</code></p> </li> <li> <p>The test will automatically initialize the TV settings and begin playback of the designated streams.</p> </li> <li> <p>Backlight Level Verification:</p> </li> <li> <p>For the stream, the test:</p> <ul> <li>Plays the stream.</li> <li>Sets the backlight level for each predefined level.</li> <li>Prompts the user with a question:</li> <li>\"Has backlight level {backlight} applied? (Y/N):\"</li> <li>The user must respond with Y for Yes or N for No.</li> </ul> </li> <li> <p>Logging Results:</p> </li> <li> <p>The test logs the result of the user input for each backlight level and stream.</p> </li> <li> <p>Cleanup:</p> </li> <li> <p>The test stops playback after verifying each backlight level.</p> </li> <li> <p>Test Conclusion:</p> </li> </ul> <p>Upon completing playback and verification of all backlight levels, the test concludes and logs the final results based on user confirmations.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#tvsettings_test06_backlightfadepy","title":"tvSettings_test06_BacklightFade.py","text":""},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#user-input-required-test06","title":"User Input Required - test06","text":"<p>Yes: This test requires user input to verify whether the BacklightFade effect has been applied. The user will be prompted with a Yes/No question during the test execution.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#acceptance-criteria-test06","title":"Acceptance Criteria - test06","text":"<p>The device should apply the backlight fade effect as specified, and the user should confirm that the fade has occurred according to the given parameters.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#expected-results-test06","title":"Expected Results - test06","text":"<p>The test initializes the TV settings, iterates through defined backlight fade values and durations, and confirms the applied backlight fade effect through user input during the playback of the stream.</p> <p>Success Criteria</p> <ul> <li>The backlight should fade from the specified starting value to the ending value within the defined duration.</li> <li>The user should confirm whether the backlight fade effect has been applied for each specified transition.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#test-steps-test06","title":"Test Steps - test06","text":"<ul> <li> <p>Initiate the Test:</p> </li> <li> <p>Run the Python file: <code>tvSettings_test06_BacklightFade.py</code></p> </li> <li> <p>The test will automatically initialize the TV settings and begin playback of the designated streams.</p> </li> <li> <p>Backlight Fade Level Verification:</p> </li> <li> <p>For the stream, the test:</p> <ul> <li>Sets up backlight fade transitions between defined values.</li> <li>Plays the stream for a brief period to ensure visibility of the fade effect.</li> <li>Prompts the user with a question:</li> <li>\"Has BacklightFade from {fromVal} to {toVal} with duration {fadeDuration} ms applied? (Y/N):\"</li> <li>The user must respond with Y for Yes or N for No.</li> </ul> </li> <li> <p>Logging Results:</p> </li> <li> <p>The test logs the result of the user input for each backlight fade transition and stream.</p> </li> <li> <p>Cleanup:</p> </li> <li> <p>The test stops playback after verifying each backlight fade operation.</p> </li> <li> <p>Test Conclusion:</p> </li> </ul> <p>Upon completing playback and verification of all backlight fade operations, the test concludes and logs the final results based on user confirmations.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#tvsettings_test07_backlightmodepy","title":"tvSettings_test07_BacklightMode.py","text":""},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#user-input-required-test07","title":"User Input Required - test07","text":"<p>Yes: This test requires user input to confirm if the BacklightMode setting has been correctly applied. The user will be prompted with a Yes/No question during the test execution for each backlight mode setting.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#acceptance-criteria-test07","title":"Acceptance Criteria - test07","text":"<p>The device should apply the specified backlight mode as configured, and the user should verify that the mode change has been applied correctly.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#expected-results-test07","title":"Expected Results - test07","text":"<p>The test initializes the TV settings, iterates through defined backlight modes, and verifies the application of each mode during the playback of the stream by prompting the user.</p> <p>Success Criteria</p> <ul> <li>The specified backlight mode should be set and visible on the device.</li> <li>The user should confirm whether each backlight mode has been correctly applied for the stream.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#test-steps-test07","title":"Test Steps - test07","text":"<ul> <li> <p>Initiate the Test:</p> </li> <li> <p>Run the Python file: <code>tvSettings_test07_BacklightMode.py</code></p> </li> <li> <p>The test automatically initializes the TV settings and begins playback of the designated streams.</p> </li> <li> <p>Backlight Mode Verification:</p> </li> <li> <p>For the stream, the test:</p> <ul> <li>Sets up each defined backlight mode.</li> <li>Plays the stream for a brief period to ensure visibility of the backlight mode effect.</li> <li>Prompts the user with a question:</li> <li>\"Has BacklightMode level {backlightMode} applied? (Y/N):\"</li> <li>The user must respond with Y for Yes or N for No.</li> </ul> </li> <li> <p>Logging Results:</p> </li> <li> <p>The test logs the result of the user input for each backlight mode level and stream.</p> </li> <li> <p>Cleanup:</p> </li> <li> <p>The test stops playback after verifying each backlight mode level.</p> </li> <li> <p>Test Conclusion:</p> </li> </ul> <p>Upon completing playback and verification of all backlight mode levels, the test concludes and logs the final results based on user confirmations.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#tvsettings_test08_tvdimmingmodepy","title":"tvSettings_test08_TVDimmingMode.py","text":""},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#user-input-required-test08","title":"User Input Required - test08","text":"<p>Yes: This test requires manual verification of the TVDimmingMode setting.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#acceptance-criteria-test08","title":"Acceptance Criteria - test08","text":"<ul> <li>The device should apply each specified TVDimmingMode setting level successfully during stream playback.</li> <li>The user must confirm if each TVDimmingMode level is correctly applied through a Y/N prompt during manual verification.</li> <li>The test should iterate over each stream and dimming mode level, ensuring correct application.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#expected-results-test08","title":"Expected Results - test08","text":"<p>The test initializes the TV settings module, applies multiple TVDimmingMode levels during playback of each stream, and requests user feedback on the application status.</p> <p>Success Criteria:</p> <ul> <li>Each specified TVDimmingMode setting should apply correctly as verified by the user.</li> <li>Each verification result is logged, indicating successful or unsuccessful application.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#test-steps-test08","title":"Test Steps - test08","text":"<ul> <li> <p>Initiate the Test:</p> </li> <li> <p>Run the Python file: <code>tvSettings_test08_TVDimmingMode.py</code></p> </li> <li> <p>The test will automatically initialize TV settings, load test streams, and begin playback.</p> </li> <li> <p>TVDimmingMode Application Verification:</p> </li> <li> <p>For each stream, the test:</p> <ul> <li>Starts playback.</li> <li>Iterates through each available TVDimmingMode level:</li> <li>Sets the specified TVDimmingMode level.</li> <li>Prompts the user to confirm if the setting is applied with a Y/N response.</li> <li>Logs the result of each verification for review.</li> </ul> </li> <li> <p>Playback Stop:</p> </li> <li> <p>The test stops the stream after each dimming mode verification.</p> </li> <li> <p>Cleanup:</p> </li> <li> <p>The test terminates the tvSettings module after all verifications are complete.</p> </li> <li> <p>Test Conclusion:</p> </li> </ul> <p>Upon completing all TVDimmingMode verifications across streams, the test concludes. The final results log each successful or unsuccessful setting application based on user feedback.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#tvsettings_test09_localdimmingmodepy","title":"tvSettings_test09_LocalDimmingMode.py","text":""},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#user-input-required-test09","title":"User Input Required - test09","text":"<p>Yes: This test requires user input to confirm if the Local Dimming Level setting has been applied correctly. The user will be prompted with a Yes/No question to verify each Local Dimming Level for each stream.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#acceptance-criteria-test09","title":"Acceptance Criteria - test09","text":"<p>The device should apply the specified Local Dimming Level as configured, and the user should verify that the mode change has been accurately applied.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#expected-results-test09","title":"Expected Results - test09","text":"<p>The test initializes the TV settings, iterates through defined Local Dimming Levels, and verifies the application of each mode during playback of each stream through user prompts.</p> <p>Success Criteria</p> <ul> <li>The specified Local Dimming Level should be set and visibly applied on the device.</li> <li>The user should confirm whether each Local Dimming Level has been correctly applied for each stream.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#test-steps-test09","title":"Test Steps - test09","text":"<ol> <li> <p>Initiate the Test:</p> </li> <li> <p>Run the Python file: <code>tvSettings_test09_LocalDimmingLevel.py</code></p> </li> <li> <p>The test will automatically initialize the TV settings and begin playback of the designated streams.</p> </li> <li> <p>Local Dimming Level Verification:</p> </li> <li> <p>For each stream, the test:</p> <ul> <li>Sets up each defined Local Dimming Level.</li> <li>Plays the stream briefly to allow for visible confirmation of the Local Dimming Level effect.</li> <li>Prompts the user with a Yes/No question to confirm the level:</li> <li>\"Has Local Dimming Level {localDimmingLevel} applied? (Y/N):\"</li> <li>The user should respond with Y for Yes if the level is applied correctly or N for No if it is not.</li> </ul> </li> <li> <p>Logging Results:</p> </li> <li> <p>The test logs the result of each user confirmation for each Local Dimming Level and stream.</p> </li> <li> <p>Cleanup:</p> </li> <li> <p>The test stops playback after each Local Dimming Level verification.</p> </li> <li> <p>Test Conclusion:</p> </li> </ol> <p>After playback and verification of all Local Dimming Levels are completed, the test concludes and logs final results based on user input.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#note","title":"Note","text":"<p>Ensure that you monitor the screen for visible confirmation of the Local Dimming Level changes before answering each prompt.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#tvsettings_test10_brightnesspy","title":"tvSettings_test10_Brightness.py","text":""},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#user-input-required-test10","title":"User Input Required - test10","text":"<p>Yes: This test requires user input to confirm if the Brightness level setting has been applied correctly. The user will be prompted with a Yes/No question to verify each brightness level for each stream.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#acceptance-criteria-test10","title":"Acceptance Criteria - test10","text":"<p>The device should apply the specified Brightness level as configured, and the user should verify that the brightness adjustment has been accurately applied.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#expected-results-test10","title":"Expected Results - test10","text":"<p>The test initializes the TV settings, iterates through defined brightness levels, and verifies the application of each level during playback of each stream through user prompts.</p> <p>Success Criteria</p> <ul> <li>The specified Brightness level should be set and visibly applied on the device.</li> <li>The user should confirm whether each Brightness level has been correctly applied for each stream.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#test-steps-test10","title":"Test Steps - test10","text":"<ol> <li> <p>Initiate the Test:</p> </li> <li> <p>Run the Python file: <code>tvSettings_test10_Brightness.py</code></p> </li> <li> <p>The test will automatically initialize the TV settings and begin playback of the designated streams.</p> </li> <li> <p>Brightness Level Verification:</p> </li> <li> <p>For each stream, the test:</p> <ul> <li>Iterates through each defined brightness level in the list <code>[0, 25, 50, 75, 100, 50]</code>.</li> <li>Plays the stream briefly to allow for visible confirmation of the brightness change.</li> <li>Prompts the user with a Yes/No question to confirm the level:</li> <li>\"Has brightness level {brightness} applied? (Y/N):\"</li> <li>The user should respond with Y for Yes if the brightness level is applied correctly or N for No if it is not.</li> </ul> </li> <li> <p>Logging Results:</p> </li> <li> <p>The test logs the result of each user confirmation for each brightness level and stream.</p> </li> <li> <p>Cleanup:</p> </li> <li> <p>The test stops playback after each brightness level verification.</p> </li> <li> <p>Test Conclusion:</p> </li> </ol> <p>After playback and verification of all brightness levels are completed, the test concludes and logs final results based on user input.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#tvsettings_test11_contrastpy","title":"tvSettings_test11_Contrast.py","text":""},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#user-input-required-test11","title":"User Input Required - test11","text":"<p>Yes: This test requires user input to confirm if the Contrast level setting has been applied correctly. The user will be prompted with a Yes/No question to verify each contrast level for each stream.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#acceptance-criteria-test11","title":"Acceptance Criteria - test11","text":"<p>The device should apply the specified Contrast level as configured, and the user should verify that the contrast adjustment has been accurately applied.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#expected-results-test11","title":"Expected Results - test11","text":"<p>The test initializes the TV settings, iterates through defined contrast levels, and verifies the application of each level during playback of each stream through user prompts.</p> <p>Success Criteria</p> <ul> <li>The specified Contrast level should be set and visibly applied on the device.</li> <li>The user should confirm whether each Contrast level has been correctly applied for each stream.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#test-steps-test11","title":"Test Steps - test11","text":"<ol> <li> <p>Initiate the Test:</p> </li> <li> <p>Run the Python file: <code>tvSettings_test11_Contrast.py</code></p> </li> <li> <p>The test will automatically initialize the TV settings and begin playback of the designated streams.</p> </li> <li> <p>Contrast Level Verification:</p> </li> <li> <p>For each stream, the test:</p> <ul> <li>Iterates through each defined contrast level in the list <code>[0, 25, 50, 75, 100, 50]</code>.</li> <li>Plays the stream briefly to allow for visible confirmation of the contrast change.</li> <li>Prompts the user with a Yes/No question to confirm the level:</li> <li>\"Has contrast level {contrast} applied? (Y/N):\"</li> <li>The user should respond with Y for Yes if the contrast level is applied correctly or N for No if it is not.</li> </ul> </li> <li> <p>Logging Results:</p> </li> <li> <p>The test logs the result of each user confirmation for each contrast level and stream.</p> </li> <li> <p>Cleanup:</p> </li> <li> <p>The test stops playback after each contrast level verification.</p> </li> <li> <p>Test Conclusion:</p> </li> </ol> <p>After playback and verification of all contrast levels are completed, the test concludes and logs final results based on user input.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#tvsettings_test12_sharpnesspy","title":"tvSettings_test12_Sharpness.py","text":""},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#user-input-required-test12","title":"User Input Required - test12","text":"<p>Yes: This test requires user input to confirm if the Sharpness level setting has been applied correctly. The user will be prompted with a Yes/No question to verify each sharpness level for each stream.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#acceptance-criteria-test12","title":"Acceptance Criteria - test12","text":"<p>The device should apply the specified Sharpness level as configured, and the user should verify that the sharpness adjustment has been accurately applied.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#expected-results-test12","title":"Expected Results - test12","text":"<p>The test initializes the TV settings, iterates through defined sharpness levels, and verifies the application of each level during playback of each stream through user prompts.</p> <p>Success Criteria</p> <ul> <li>The specified Sharpness level should be set and visibly applied on the device.</li> <li>The user should confirm whether each Sharpness level has been correctly applied for each stream.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#test-steps-test12","title":"Test Steps - test12","text":"<ol> <li> <p>Initiate the Test:</p> </li> <li> <p>Run the Python file: <code>tvSettings_test12_Sharpness.py</code></p> </li> <li> <p>The test will automatically initialize the TV settings and begin playback of the designated streams.</p> </li> <li> <p>Sharpness Level Verification:</p> </li> <li> <p>For each stream, the test:</p> <ul> <li>Iterates through each defined sharpness level in the list <code>[0, 25, 50, 75, 100, 50]</code>.</li> <li>Plays the stream briefly to allow for visible confirmation of the sharpness change.</li> <li>Prompts the user with a Yes/No question to confirm the level:</li> <li>\"Has sharpness level {sharpness} applied? (Y/N):\"</li> <li>The user should respond with Y for Yes if the sharpness level is applied correctly or N for No if it is not.</li> </ul> </li> <li> <p>Logging Results:</p> </li> <li> <p>The test logs the result of each user confirmation for each sharpness level and stream.</p> </li> <li> <p>Cleanup:</p> </li> <li> <p>The test stops playback after each sharpness level verification.</p> </li> <li> <p>Test Conclusion:</p> </li> </ol> <p>After playback and verification of all sharpness levels are completed, the test concludes and logs final results based on user input.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#tvsettings_test13_saturationpy","title":"tvSettings_test13_Saturation.py","text":""},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#user-input-required-test13","title":"User Input Required - test13","text":"<p>Yes: This test requires user input to confirm if the Saturation level setting has been applied correctly. The user will be prompted with a Yes/No question to verify each saturation level for each stream.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#acceptance-criteria-test13","title":"Acceptance Criteria - test13","text":"<p>The device should apply the specified Saturation level as configured, and the user should verify that the saturation adjustment has been accurately applied.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#expected-results-test13","title":"Expected Results - test13","text":"<p>The test initializes the TV settings, iterates through defined saturation levels, and verifies the application of each level during playback of each stream through user prompts.</p> <p>Success Criteria</p> <ul> <li>The specified Saturation level should be set and visibly applied on the device.</li> <li>The user should confirm whether each Saturation level has been correctly applied for each stream.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#test-steps-test13","title":"Test Steps - test13","text":"<ol> <li> <p>Initiate the Test:</p> </li> <li> <p>Run the Python file: <code>tvSettings_test13_Saturation.py</code></p> </li> <li> <p>The test will automatically initialize the TV settings and begin playback of the designated streams.</p> </li> <li> <p>Saturation Level Verification:</p> </li> <li> <p>For each stream, the test:</p> <ul> <li>Iterates through each defined saturation level in the list <code>[0, 25, 50, 75, 100, 50]</code>.</li> <li>Plays the stream briefly to allow for visible confirmation of the saturation change.</li> <li>Prompts the user with a Yes/No question to confirm the level:</li> <li>\"Has saturation level {saturation} applied? (Y/N):\"</li> <li>The user should respond with Y for Yes if the saturation level is applied correctly or N for No if it is not.</li> </ul> </li> <li> <p>Logging Results:</p> </li> <li> <p>The test logs the result of each user confirmation for each saturation level and stream.</p> </li> <li> <p>Cleanup:</p> </li> <li> <p>The test stops playback after each saturation level verification.</p> </li> <li> <p>Test Conclusion:</p> </li> </ol> <p>After playback and verification of all saturation levels are completed, the test concludes and logs final results based on user input.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#tvsettings_test14_huepy","title":"tvSettings_test14_Hue.py","text":""},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#user-input-required-test14","title":"User Input Required - test14","text":"<p>Yes: This test requires user input to confirm if the Hue level setting has been applied correctly. The user will be prompted with a Yes/No question to verify each hue level for each stream.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#acceptance-criteria-test14","title":"Acceptance Criteria - test14","text":"<p>The device should apply the specified Hue level as configured, and the user should verify that the hue adjustment has been accurately applied.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#expected-results-test14","title":"Expected Results - test14","text":"<p>The test initializes the TV settings, iterates through defined hue levels, and verifies the application of each level during playback of each stream through user prompts.</p> <p>Success Criteria</p> <ul> <li>The specified Hue level should be set and visibly applied on the device.</li> <li>The user should confirm whether each Hue level has been correctly applied for each stream.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#test-steps-test14","title":"Test Steps - test14","text":"<ol> <li> <p>Initiate the Test:</p> </li> <li> <p>Run the Python file: <code>tvSettings_test14_Hue.py</code></p> </li> <li> <p>The test will automatically initialize the TV settings and begin playback of the designated streams.</p> </li> <li> <p>Hue Level Verification:</p> </li> <li> <p>For each stream, the test:</p> <ul> <li>Iterates through each defined hue level in the list <code>[0, 25, 50, 75, 100, 50]</code>.</li> <li>Sets the hue level and prompts the user with a Yes/No question to confirm the level:</li> <li>\"Has hue level {hue} applied? (Y/N):\"</li> <li>The user should respond with Y for Yes if the hue level is applied correctly or N for No if it is not.</li> </ul> </li> <li> <p>Logging Results:</p> </li> <li> <p>The test logs the result of each user confirmation for each hue level and stream.</p> </li> <li> <p>Cleanup:</p> </li> <li> <p>The test stops playback after verifying each hue level.</p> </li> <li> <p>Test Conclusion:</p> </li> </ol> <p>After playback and verification of all hue levels are completed, the test concludes and logs final results based on user input.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#tvsettings_test15_colortemppy","title":"tvSettings_test15_ColorTemp.py","text":""},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#user-input-required-test15","title":"User Input Required - test15","text":"<p>Yes: This test requires user input to confirm if the Color Temperature (ColorTemp) level setting has been applied correctly. The user will be prompted with a Yes/No question to verify each color temperature level for each stream.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#acceptance-criteria-test15","title":"Acceptance Criteria - test15","text":"<p>The device should apply the specified ColorTemp level as configured, and the user should verify that the color temperature adjustment has been accurately applied.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#expected-results-test15","title":"Expected Results - test15","text":"<p>The test initializes the TV settings, iterates through defined color temperature levels, and verifies the application of each level during playback of each stream through user prompts.</p> <p>Success Criteria</p> <ul> <li>The specified ColorTemp level should be set and visibly applied on the device.</li> <li>The user should confirm whether each ColorTemp level has been correctly applied for each stream.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#test-steps-test15","title":"Test Steps - test15","text":"<ol> <li> <p>Initiate the Test:</p> </li> <li> <p>Run the Python file: <code>tvSettings_test15_ColorTemp.py</code></p> </li> <li> <p>The test will automatically initialize the TV settings and begin playback of the designated streams.</p> </li> <li> <p>Color Temperature Level Verification:</p> </li> <li> <p>For each stream, the test:</p> <ul> <li>Retrieves the supported color Temperatures.</li> <li>Sets each color temperature level and prompts the user with a Yes/No question to confirm the level:</li> <li>\"Has ColorTemp level {colorTemp} applied? (Y/N):\"</li> <li>The user should respond with Y for Yes if the color temperature level is applied correctly or N for No if it is not.</li> </ul> </li> <li> <p>Logging Results:</p> </li> <li> <p>The test logs the result of each user confirmation for each color temperature level and stream.</p> </li> <li> <p>Cleanup:</p> </li> <li> <p>The test stops playback after verifying each color temperature level.</p> </li> <li> <p>It resets the color temperature level to a default setting after all verifications.</p> </li> <li> <p>Test Conclusion:</p> </li> </ol> <p>After playback and verification of all color temperature levels are completed, the test concludes and logs final results based on user input.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#tvsettings_test16_aspectratiopy","title":"tvSettings_test16_AspectRatio.py","text":""},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#user-input-required-test16","title":"User Input Required - test16","text":"<p>Yes: This test requires user input to confirm if the Aspect Ratio has been applied correctly. The user will be prompted with a Yes/No question to verify each aspect ratio setting for each stream.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#acceptance-criteria-test16","title":"Acceptance Criteria - test16","text":"<p>The device should apply the specified Aspect Ratio setting as configured, and the user should verify that the aspect ratio adjustment has been accurately applied.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#expected-results-test16","title":"Expected Results - test16","text":"<p>The test initializes the TV settings, iterates through the available aspect ratios, and verifies the application of each ratio during playback of each stream through user prompts.</p> <p>Success Criteria</p> <ul> <li>The specified Aspect Ratio should be set and visibly applied on the device.</li> <li>The user should confirm whether each Aspect Ratio has been correctly applied for each stream.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#test-steps-test16","title":"Test Steps - test16","text":"<ol> <li> <p>Initiate the Test:</p> </li> <li> <p>Run the Python file: <code>tvSettings_test16_AspectRatio.py</code></p> </li> <li> <p>The test will automatically initialize the TV settings and begin playback of the designated streams.</p> </li> <li> <p>Aspect Ratio Verification:</p> </li> <li> <p>For each stream, the test:</p> <ul> <li>Retrieves the supported Aspect Ratio.</li> <li>Sets each aspect ratio and prompts the user with a Yes/No question to confirm the setting:</li> <li>\"Has AspectRatio {aspectRatio} applied? (Y/N):\"</li> <li>The user should respond with Y for Yes if the aspect ratio is applied correctly or N for No if it is not.</li> </ul> </li> <li> <p>Logging Results:</p> </li> <li> <p>The test logs the result of each user confirmation for each aspect ratio and stream.</p> </li> <li> <p>Cleanup:</p> </li> <li> <p>The test stops playback after verifying each aspect ratio.</p> </li> <li> <p>It resets the aspect ratio to a default setting after all verifications.</p> </li> <li> <p>Test Conclusion:</p> </li> </ol> <p>After playback and verification of all aspect ratios are completed, the test concludes and logs final results based on user input.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#tvsettings_test17_dynamiccontrastpy","title":"tvSettings_test17_DynamicContrast.py","text":""},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#user-input-required-test17","title":"User Input Required - test17","text":"<p>Yes: This test requires user input to confirm if the Dynamic Contrast state (Enabled or Disabled) has been correctly applied. The user will be prompted with a Yes/No question to verify each state setting for each stream.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#acceptance-criteria-test17","title":"Acceptance Criteria - test17","text":"<p>The device should apply the specified Dynamic Contrast state as configured, and the user should verify that the adjustment has been accurately applied.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#expected-results-test17","title":"Expected Results - test17","text":"<p>The test initializes the TV settings, iterates through the available Dynamic Contrast states, and verifies the application of each state during playback of each stream through user prompts.</p> <p>Success Criteria</p> <ul> <li>The specified Dynamic Contrast state should be set and visibly applied on the device.</li> <li>The user should confirm whether each Dynamic Contrast state has been correctly applied for each stream.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#test-steps-test17","title":"Test Steps - test17","text":"<ol> <li> <p>Initiate the Test:</p> </li> <li> <p>Run the Python file: <code>tvSettings_test17_DynamicContrast.py</code></p> </li> <li> <p>The test will automatically initialize the TV settings and begin playback of the designated streams.</p> </li> <li> <p>Dynamic Contrast Verification:</p> </li> <li> <p>For each stream, the test:</p> <ul> <li>Iterates over the available Dynamic Contrast states: Enabled and Disabled.</li> <li>Sets each state and prompts the user with a Yes/No question to confirm the setting:</li> <li>\"Has Dynamic Contrast {dynamicContrast} applied? (Y/N):\"</li> <li>The user should respond with Y for Yes if the dynamic contrast is applied correctly or N for No if it is not.</li> </ul> </li> <li> <p>Logging Results:</p> </li> <li> <p>The test logs the result of each user confirmation for each Dynamic Contrast state and stream.</p> </li> <li> <p>Cleanup:</p> </li> <li> <p>The test stops playback after verifying each state for each stream.</p> </li> <li> <p>Test Conclusion:</p> </li> </ol> <p>After playback and verification of all Dynamic Contrast states are completed, the test concludes and logs final results based on user input.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#tvsettings_test18_dynamicgammapy","title":"tvSettings_test18_DynamicGamma.py","text":""},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#user-input-required-test18","title":"User Input Required - test18","text":"<p>Yes: This test requires manual verification to confirm whether the dynamic gamma levels have been applied correctly. The user must respond to a prompt indicating whether the settings are correct.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#acceptance-criteria-test18","title":"Acceptance Criteria - test18","text":"<p>The system should apply the specified dynamic gamma levels while streaming content, and the user should confirm the accuracy of the applied settings.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#expected-results-test18","title":"Expected Results - test18","text":"<p>The script initializes the TV settings, sets dynamic gamma levels for specified streams, and prompts the user to verify whether the settings were applied correctly.</p> <p>Success Criteria</p> <ul> <li>Dynamic gamma levels are applied correctly for each specified stream.</li> <li>User confirmation matches the expected dynamic gamma levels.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#test-steps-test18","title":"Test Steps - test18","text":"<ol> <li> <p>Initiate the Test:</p> </li> <li> <p>Run the Python script: <code>tvSettings_test18_DynamicGamma.py</code></p> </li> <li> <p>Set Dynamic Gamma Levels:</p> </li> <li> <p>The script initializes the TV settings module and sets dynamic gamma levels from the defined list <code>[1.80, 2.10, 2.60]</code>.</p> </li> <li> <p>Stream Playback:</p> </li> <li> <p>The script retrieves the list of streams from the test setup and plays each stream.</p> </li> <li> <p>Dynamic Gamma Verification:</p> </li> <li> <p>After playing each stream, the script verifies whether the dynamic gamma levels were set correctly:</p> <ul> <li>User is prompted with: \"Has Dynamic Gamma level {dynamicGamma} applied? (Y/N):\"</li> <li>Users respond with Y (Yes) or N (No) based on the display.</li> </ul> </li> <li> <p>Logging Results:</p> </li> <li> <p>The script logs results based on user input for each dynamic gamma setting.</p> </li> <li> <p>Cleanup:</p> </li> <li> <p>After all verifications, the script stops the stream playback.</p> </li> <li> <p>Test Conclusion:</p> </li> <li> <p>Once all dynamic gamma levels are verified, the script terminates the TV settings module and logs the final results based on user responses.</p> </li> </ol>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#tvsettings_test19_dolbyvisionpy","title":"tvSettings_test19_DolbyVision.py","text":""},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#user-input-required-test19","title":"User Input Required - test19","text":"<p>Yes: This test requires user input to confirm if each Dolby Vision level has been applied correctly. The user will be prompted with a Yes/No question to verify each level setting during each stream.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#acceptance-criteria-test19","title":"Acceptance Criteria - test19","text":"<p>The device should apply the specified Dolby Vision level as configured. The user should be able to visually confirm the application of each setting.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#expected-results-test19","title":"Expected Results - test19","text":"<p>The test initializes the TV settings, iterates through the available Dolby Vision levels, and verifies the application of each level by prompting the user for confirmation.</p> <p>Success Criteria</p> <ul> <li>The specified Dolby Vision level should be set and visibly applied on the device.</li> <li>The user should confirm whether each Dolby Vision level has been applied for each stream.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#test-steps-test19","title":"Test Steps - test19","text":"<ol> <li> <p>Initiate the Test:</p> </li> <li> <p>Run the Python file: <code>tvSettings_test19_DolbyVision.py</code></p> </li> <li> <p>The test will initialize the TV settings and begin playback of each specified stream.</p> </li> <li> <p>Dolby Vision Verification:</p> </li> <li> <p>For each stream, the test:</p> <ul> <li>Iterates over the supported Dolby Vision levels.</li> <li>Sets each level and prompts the user with a Yes/No question to confirm the setting:</li> <li>\"Has Dolby Vision level {DolbyVision} applied? (Y/N):\"</li> <li>The user should respond with Y for Yes if the Dolby Vision level is applied correctly or N for No if it is not.</li> </ul> </li> <li> <p>Logging Results:</p> </li> <li> <p>The test logs the result of each user confirmation for each Dolby Vision level and stream.</p> </li> <li> <p>Cleanup:</p> </li> <li> <p>The test stops playback after verifying each Dolby Vision level for each stream.</p> </li> <li> <p>Test Conclusion:</p> </li> <li> <p>After playback and verification of all Dolby Vision levels are completed, the test concludes and logs final results based on user input.</p> </li> </ol>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#tvsettings_test20_picturemodepy","title":"tvSettings_test20_PictureMode.py","text":""},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#user-input-required-test20","title":"User Input Required - test20","text":"<p>Yes: This test requires user input to confirm if each Picture Mode level has been correctly applied. The user will respond with Yes or No during each verification.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#acceptance-criteria-test20","title":"Acceptance Criteria - test20","text":"<p>The device should correctly apply the specified Picture Mode level for each stream. For the Picture Mode \"FMM,\" the test should verify the \"tvContentType_FMM\" callback to ensure it has been triggered.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#expected-results-test20","title":"Expected Results - test20","text":"<p>The test initializes the TV settings, iterates through the available Picture Mode levels, and verifies the application of each level through user confirmation or automated callback checks.</p> <p>Success Criteria</p> <ul> <li>The device should display the correct Picture Mode level as applied.</li> <li>The \"tvContentType_FMM\" callback should be triggered and verified when Picture Mode is set to \"FMM.\"</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#test-steps-test20","title":"Test Steps - test20","text":"<ol> <li> <p>Initiate the Test:</p> </li> <li> <p>Run the Python file: <code>tvSettings_test20_PictureMode.py</code></p> </li> <li> <p>The test will initialize TV settings and start playback of each specified stream.</p> </li> <li> <p>Picture Mode Verification:</p> </li> <li> <p>For each stream, the test:</p> <ul> <li>Iterates over the supported Picture Mode levels.</li> <li>Sets each level and prompts the user to confirm the setting with a Yes/No question:</li> <li>\"Has Picture Mode level {pictureMode} applied? (Y/N):\"</li> <li>User should respond Y for Yes if the level is applied or N for No if not.</li> </ul> </li> <li> <p>FMM Picture Mode Callback Check:</p> </li> <li> <p>If the Picture Mode is \"FMM\", the test will:</p> <ul> <li>Log and verify the presence of the \"tvContentType_FMM\".</li> <li>Log the result of this callback verification.</li> </ul> </li> <li> <p>Logging Results:</p> </li> <li> <p>The test logs the result of each Picture Mode level verification, including the callback check for \"FMM\" mode.</p> </li> <li> <p>Cleanup:</p> </li> <li> <p>The test stops playback after each Picture Mode level is verified for each stream.</p> </li> <li> <p>The test resets to the default Picture Mode level.</p> </li> <li> <p>Test Conclusion:</p> </li> <li> <p>After completing playback and verification for all Picture Mode levels, the test ends and logs final results based on user confirmations and callback status.</p> </li> </ol>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#tvsettings_test21_colortemprgainpy","title":"tvSettings_test21_ColorTempRgain.py","text":""},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#user-input-required-test21","title":"User Input Required - test21","text":"<p>Yes: This test requires manual verification of the Color Temperature and Rgain settings for both Set and Save operations.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#acceptance-criteria-test21","title":"Acceptance Criteria - test21","text":"<ul> <li>The device should successfully apply each specified Color Temperature and Rgain setting, as well as the Save/Set flag during stream playback.</li> <li>User feedback should confirm that each Color Temperature and Rgain setting is correctly applied.</li> <li>All settings should reset to the default Rgain value after testing.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#expected-results-test21","title":"Expected Results - test21","text":"<p>The test initializes the TV settings module, applies and saves multiple Color Temperature and Rgain values, and requests user feedback on application status.</p> <p>Success Criteria:</p> <ul> <li>Each specified Color Temperature and Rgain setting should apply correctly during the Set and Save operations, as verified by the user.</li> <li>Verification results are logged for each setting application to indicate successful or unsuccessful application.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#test-steps-test21","title":"Test Steps - test21","text":"<ul> <li> <p>Initiate the Test:</p> </li> <li> <p>Run the Python file: <code>tvSettings_test21_ColorTempRgain.py</code></p> </li> <li> <p>The test initializes the TV settings module, loads test streams, and begins playback.</p> </li> <li> <p>Set Operation Verification:</p> </li> <li> <p>For each stream, the test:</p> <ul> <li>Begins playback.</li> <li>Iterates through each Color Temperature value and Rgain level:</li> <li>Applies the specified Color Temperature and Rgain with the Set flag (0).</li> <li>Prompts the user to confirm if the setting is applied with a Y/N response.</li> <li>Logs the verification result for review.</li> <li>Stops playback after testing all Color Temperature and Rgain values.</li> </ul> </li> <li> <p>Save Operation Verification:</p> </li> <li> <p>For each Color Temperature and Rgain combination:</p> <ul> <li>Sets the Save flag (1) to apply the settings permanently.</li> </ul> </li> <li>For each stream:<ul> <li>Begins playback.</li> <li>Reapplies each Color Temperature to verify the saved Rgain values.</li> <li>Prompts the user to confirm correct application.</li> <li>Logs the verification result.</li> <li>Stops playback after testing all Color Temperature and Rgain values.</li> </ul> </li> <li> <p>Resets all Color Temperature values to the default Rgain (1024) after the test.</p> </li> <li> <p>Cleanup:</p> </li> <li> <p>The test terminates the tvSettings module after all verifications and resets are complete.</p> </li> <li> <p>Test Conclusion:</p> </li> </ul> <p>Upon completing all verifications for both Set and Save operations across streams, the test concludes, logging each successful or unsuccessful setting application based on user feedback.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#tvsettings_test22_colortempggainpy","title":"tvSettings_test22_ColorTempGgain.py","text":""},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#user-input-required-test22","title":"User Input Required - test22","text":"<p>Yes: This test requires manual verification of the Color Temperature and Ggain settings for both Set and Save operations.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#acceptance-criteria-test22","title":"Acceptance Criteria - test22","text":"<ul> <li>The device should successfully apply each specified Color Temperature and Ggain setting, as well as the Save/Set flag during stream playback.</li> <li>User feedback should confirm that each Color Temperature and Ggain setting is correctly applied.</li> <li>All settings should reset to the default Ggain value after testing.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#expected-results-test22","title":"Expected Results - test22","text":"<p>The test initializes the TV settings module, applies and saves multiple Color Temperature and Ggain values, and requests user feedback on application status.</p> <p>Success Criteria:</p> <ul> <li>Each specified Color Temperature and Ggain setting should apply correctly during the Set and Save operations, as verified by the user.</li> <li>Verification results are logged for each setting application to indicate successful or unsuccessful application.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#test-steps-test22","title":"Test Steps - test22","text":"<ul> <li> <p>Initiate the Test:</p> </li> <li> <p>Run the Python file: <code>tvSettings_test22_ColorTempGgain.py</code></p> </li> <li> <p>The test initializes the TV settings module, loads test streams, and begins playback.</p> </li> <li> <p>Set Operation Verification:</p> </li> <li> <p>For each stream, the test:</p> <ul> <li>Begins playback.</li> <li>Iterates through each Color Temperature value and Ggain level:</li> <li>Applies the specified Color Temperature and Ggain with the Set flag (0).</li> <li>Prompts the user to confirm if the setting is applied with a Y/N response.</li> <li>Logs the verification result for review.</li> <li>Stops playback after testing all Color Temperature and Ggain values.</li> </ul> </li> <li> <p>Save Operation Verification:</p> </li> <li> <p>For each Color Temperature and Ggain combination:</p> <ul> <li>Sets the Save flag (1) to apply the settings permanently.</li> </ul> </li> <li>For each stream:<ul> <li>Begins playback.</li> <li>Reapplies each Color Temperature to verify the saved Ggain values.</li> <li>Prompts the user to confirm correct application.</li> <li>Logs the verification result.</li> <li>Stops playback after testing all Color Temperature and Ggain values.</li> </ul> </li> <li> <p>Resets all Color Temperature values to the default Ggain (1024) after the test.</p> </li> <li> <p>Cleanup:</p> </li> <li> <p>The test terminates the tvSettings module after all verifications and resets are complete.</p> </li> <li> <p>Test Conclusion:</p> </li> </ul> <p>Upon completing all verifications for both Set and Save operations across streams, the test concludes, logging each successful or unsuccessful setting application based on user feedback.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#tvsettings_test23_colortempbgainpy","title":"tvSettings_test23_ColorTempBgain.py","text":""},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#user-input-required-test23","title":"User Input Required - test23","text":"<p>Yes: This test requires manual verification of the Color Temperature and Bgain settings for both Set and Save operations.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#acceptance-criteria-test23","title":"Acceptance Criteria - test23","text":"<ul> <li>The device should successfully apply each specified Color Temperature and Bgain setting, as well as the Save/Set flag during stream playback.</li> <li>User feedback should confirm that each Color Temperature and Bgain setting is correctly applied.</li> <li>All settings should reset to the default Bgain value after testing.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#expected-results-test23","title":"Expected Results - test23","text":"<p>The test initializes the TV settings module, applies and saves multiple Color Temperature and Bgain values, and requests user feedback on application status.</p> <p>Success Criteria:</p> <ul> <li>Each specified Color Temperature and Bgain setting should apply correctly during the Set and Save operations, as verified by the user.</li> <li>Verification results are logged for each setting application to indicate successful or unsuccessful application.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#test-steps-test23","title":"Test Steps - test23","text":"<ul> <li> <p>Initiate the Test:</p> </li> <li> <p>Run the Python file: <code>tvSettings_test23_ColorTempBgain.py</code></p> </li> <li> <p>The test initializes the TV settings module, loads test streams, and begins playback.</p> </li> <li> <p>Set Operation Verification:</p> </li> <li> <p>For each stream, the test:</p> <ul> <li>Begins playback.</li> <li>Iterates through each Color Temperature value and Bgain level:</li> <li>Applies the specified Color Temperature and Bgain with the Set flag (0).</li> <li>Prompts the user to confirm if the setting is applied with a Y/N response.</li> <li>Logs the verification result for review.</li> <li>Stops playback after testing all Color Temperature and Bgain values.</li> </ul> </li> <li> <p>Save Operation Verification:</p> </li> <li> <p>For each Color Temperature and Bgain combination:</p> <ul> <li>Sets the Save flag (1) to apply the settings permanently.</li> </ul> </li> <li>For each stream:<ul> <li>Begins playback.</li> <li>Reapplies each Color Temperature to verify the saved Bgain values.</li> <li>Prompts the user to confirm correct application.</li> <li>Logs the verification result.</li> <li>Stops playback after testing all Color Temperature and Bgain values.</li> </ul> </li> <li> <p>Resets all Color Temperature values to the default Bgain (1024) after the test.</p> </li> <li> <p>Cleanup:</p> </li> <li> <p>The test terminates the tvSettings module after all verifications and resets are complete.</p> </li> <li> <p>Test Conclusion:</p> </li> </ul> <p>Upon completing all verifications for both Set and Save operations across streams, the test concludes, logging each successful or unsuccessful setting application based on user feedback.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#tvsettings_test24_colortemprpostoffsetpy","title":"tvSettings_test24_colorTempRpostOffset.py","text":""},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#user-input-required-test24","title":"User Input Required - test24","text":"<p>Yes: This test requires manual verification of the Color Temperature and RpostOffset settings for both Set and Save operations.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#acceptance-criteria-test24","title":"Acceptance Criteria - test24","text":"<ul> <li>The device should successfully apply each specified Color Temperature and RpostOffset setting, as well as the Save/Set flag during stream playback.</li> <li>User feedback should confirm that each Color Temperature and RpostOffset setting is correctly applied.</li> <li>All settings should reset to the default RpostOffset value after testing.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#expected-results-test24","title":"Expected Results - test24","text":"<p>The test initializes the TV settings module, applies and saves multiple Color Temperature and RpostOffset values, and requests user feedback on application status.</p> <p>Success Criteria:</p> <ul> <li>Each specified Color Temperature and RpostOffset setting should apply correctly during the Set and Save operations, as verified by the user.</li> <li>Verification results are logged for each setting application to indicate successful or unsuccessful application.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#test-steps-test24","title":"Test Steps - test24","text":"<ul> <li> <p>Initiate the Test:</p> </li> <li> <p>Run the Python file: <code>tvSettings_test24_colorTempRpostOffset.py</code></p> </li> <li> <p>The test initializes the TV settings module, loads test streams, and begins playback.</p> </li> <li> <p>Set Operation Verification:</p> </li> <li> <p>For each stream, the test:</p> <ul> <li>Begins playback.</li> <li>Iterates through each Color Temperature value and RpostOffset level:</li> <li>Applies the specified Color Temperature and RpostOffset with the Set flag (0).</li> <li>Prompts the user to confirm if the setting is applied with a Y/N response.</li> <li>Logs the verification result for review.</li> <li>Stops playback after testing all Color Temperature and RpostOffset values.</li> </ul> </li> <li> <p>Save Operation Verification:</p> </li> <li> <p>For each Color Temperature and RpostOffset combination:</p> <ul> <li>Sets the Save flag (1) to apply the settings permanently.</li> </ul> </li> <li>For each stream:<ul> <li>Begins playback.</li> <li>Reapplies each Color Temperature to verify the saved RpostOffset values.</li> <li>Prompts the user to confirm correct application.</li> <li>Logs the verification result.</li> <li>Stops playback after testing all Color Temperature and RpostOffset values.</li> </ul> </li> <li> <p>Resets all Color Temperature values to the default RpostOffset (0) after the test.</p> </li> <li> <p>Cleanup:</p> </li> <li> <p>The test terminates the tvSettings module after all verifications and resets are complete.</p> </li> <li> <p>Test Conclusion:</p> </li> </ul> <p>Upon completing all verifications for both Set and Save operations across streams, the test concludes, logging each successful or unsuccessful setting application based on user feedback.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#tvsettings_test25_colortempgpostoffsetpy","title":"tvSettings_test25_ColorTempGpostOffset.py","text":""},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#user-input-required-test25","title":"User Input Required - test25","text":"<p>Yes: This test requires manual verification of the Color Temperature and GpostOffset settings for both Set and Save operations.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#acceptance-criteria-test25","title":"Acceptance Criteria - test25","text":"<ul> <li>The device should successfully apply each specified Color Temperature and GpostOffset setting, as well as the Save/Set flag during stream playback.</li> <li>User feedback should confirm that each Color Temperature and GpostOffset setting is correctly applied.</li> <li>All settings should reset to the default GpostOffset value after testing.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#expected-results-test25","title":"Expected Results - test25","text":"<p>The test initializes the TV settings module, applies and saves multiple Color Temperature and GpostOffset values, and requests user feedback on application status.</p> <p>Success Criteria:</p> <ul> <li>Each specified Color Temperature and GpostOffset setting should apply correctly during the Set and Save operations, as verified by the user.</li> <li>Verification results are logged for each setting application to indicate successful or unsuccessful application.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#test-steps-test25","title":"Test Steps - test25","text":"<ul> <li> <p>Initiate the Test:</p> </li> <li> <p>Run the Python file: <code>tvSettings_test25_ColorTempGpostOffset.py</code></p> </li> <li> <p>The test initializes the TV settings module, loads test streams, and begins playback.</p> </li> <li> <p>Set Operation Verification:</p> </li> <li> <p>For each stream, the test:</p> <ul> <li>Begins playback.</li> <li>Iterates through each Color Temperature value and GpostOffset level:</li> <li>Applies the specified Color Temperature and GpostOffset with the Set flag (0).</li> <li>Prompts the user to confirm if the setting is applied with a Y/N response.</li> <li>Logs the verification result for review.</li> <li>Stops playback after testing all Color Temperature and GpostOffset values.</li> </ul> </li> <li> <p>Save Operation Verification:</p> </li> <li> <p>For each Color Temperature and GpostOffset combination:</p> <ul> <li>Sets the Save flag (1) to apply the settings permanently.</li> </ul> </li> <li>For each stream:<ul> <li>Begins playback.</li> <li>Reapplies each Color Temperature to verify the saved GpostOffset values.</li> <li>Prompts the user to confirm correct application.</li> <li>Logs the verification result.</li> <li>Stops playback after testing all Color Temperature and GpostOffset values.</li> </ul> </li> <li> <p>Resets all Color Temperature values to the default GpostOffset (0) after the test.</p> </li> <li> <p>Cleanup:</p> </li> <li> <p>The test terminates the tvSettings module after all verifications and resets are complete.</p> </li> <li> <p>Test Conclusion:</p> </li> </ul> <p>Upon completing all verifications for both Set and Save operations across streams, the test concludes, logging each successful or unsuccessful setting application based on user feedback.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#tvsettings_test26_colortempbpostoffsetpy","title":"tvSettings_test26_ColorTempBpostOffset.py","text":""},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#user-input-required-test26","title":"User Input Required - test26","text":"<p>Yes: This test requires manual verification of the Color Temperature and BpostOffset settings for both Set and Save operations.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#acceptance-criteria-test26","title":"Acceptance Criteria - test26","text":"<ul> <li>The device should successfully apply each specified Color Temperature and BpostOffset setting, as well as the Save/Set flag during stream playback.</li> <li>User feedback should confirm that each Color Temperature and BpostOffset setting is correctly applied.</li> <li>All settings should reset to the default BpostOffset value after testing.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#expected-results-test26","title":"Expected Results - test26","text":"<p>The test initializes the TV settings module, applies and saves multiple Color Temperature and BpostOffset values, and requests user feedback on application status.</p> <p>Success Criteria:</p> <ul> <li>Each specified Color Temperature and BpostOffset setting should apply correctly during the Set and Save operations, as verified by the user.</li> <li>Verification results are logged for each setting application to indicate successful or unsuccessful application.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#test-steps-test26","title":"Test Steps - test26","text":"<ul> <li> <p>Initiate the Test:</p> </li> <li> <p>Run the Python file: <code>tvSettings_test26_ColorTempBpostOffset.py</code></p> </li> <li> <p>The test initializes the TV settings module, loads test streams, and begins playback.</p> </li> <li> <p>Set Operation Verification:</p> </li> <li> <p>For each stream, the test:</p> <ul> <li>Begins playback.</li> <li>Iterates through each Color Temperature value and BpostOffset level:</li> <li>Applies the specified Color Temperature and BpostOffset with the Set flag (0).</li> <li>Prompts the user to confirm if the setting is applied with a Y/N response.</li> <li>Logs the verification result for review.</li> <li>Stops playback after testing all Color Temperature and BpostOffset values.</li> </ul> </li> <li> <p>Save Operation Verification:</p> </li> <li> <p>For each Color Temperature and BpostOffset combination:</p> <ul> <li>Sets the Save flag (1) to apply the settings permanently.</li> </ul> </li> <li>For each stream:<ul> <li>Begins playback.</li> <li>Reapplies each Color Temperature to verify the saved BpostOffset values.</li> <li>Prompts the user to confirm correct application.</li> <li>Logs the verification result.</li> <li>Stops playback after testing all Color Temperature and BpostOffset values.</li> </ul> </li> <li> <p>Resets all Color Temperature values to the default BpostOffset (0) after the test.</p> </li> <li> <p>Cleanup:</p> </li> <li> <p>The test terminates the tvSettings module after all verifications and resets are complete.</p> </li> <li> <p>Test Conclusion:</p> </li> </ul> <p>Upon completing all verifications for both Set and Save operations across streams, the test concludes, logging each successful or unsuccessful setting application based on user feedback.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#tvsettings_test27_wbcalibrationpy","title":"tvSettings_test27_WBCalibration.py","text":""},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#user-input-required-test27","title":"User Input Required - test27","text":"<p>Yes: This test relies on manual verification for applying the White Balance Calibration Mode (WBCalibrationMode) setting. The user must confirm each mode application with Y (Yes) or N (No) based on displayed values.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#acceptance-criteria-test27","title":"Acceptance Criteria - test27","text":"<p>The system should successfully apply each WBCalibrationMode value for each tested stream and display the correct calibration mode setting.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#expected-results-test27","title":"Expected Results - test27","text":"<p>The script initializes TV settings, iterates over the available WBCalibrationMode values (1 and 0), and prompts the user to verify the setting application on the screen.</p> <p>Success Criteria</p> <ul> <li>Correct WBCalibrationMode setting is displayed based on the mode applied.</li> <li>User confirms the correct display of WBCalibrationMode for each stream and value.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#test-steps-test27","title":"Test Steps - test27","text":"<ol> <li> <p>Initiate the Test:</p> </li> <li> <p>Run the Python script: <code>tvSettings_test27_WBCalibrationMode.py</code></p> </li> <li> <p>The test initializes the TV settings module.</p> </li> <li> <p>WBCalibrationMode Setting Verification:</p> </li> <li> <p>For each stream in the test, the script iterates over WBCalibrationMode values (1 for Calibration Mode enabled, 0 for disabled):</p> <ul> <li>For each mode and stream, the system applies the WBCalibrationMode setting and prompts the user:</li> <li>\"Has WBCalibrationMode {wbCalibrationMode} applied? (Y/N):\"</li> <li>Users respond with Y (Yes) or N (No) based on the display.</li> </ul> </li> <li> <p>Logging Results:</p> </li> <li> <p>The script logs results based on user input for each WBCalibrationMode setting and stream.</p> </li> <li> <p>Cleanup:</p> </li> <li> <p>The script stops playback after each stream verification.</p> </li> <li> <p>Test Conclusion:</p> </li> <li> <p>Once playback and verification are completed, the script terminates TV settings and logs the final results based on user responses.</p> </li> </ol>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#tvsettings_test28_gammatablepy","title":"tvSettings_test28_GammaTable.py","text":""},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#user-input-required-test28","title":"User Input Required - test28","text":"<p>Yes: This test requires manual verification to confirm the settings of the Gamma Table. The user must respond to a prompt indicating whether the Gamma Table has been set correctly.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#acceptance-criteria-test28","title":"Acceptance Criteria - test28","text":"<p>The system should apply the Gamma Table settings correctly and display the respective RGB values as specified in the test combinations.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#expected-results-test28","title":"Expected Results - test28","text":"<p>The script initializes TV settings, iterates through predefined gamma combinations, and prompts the user to verify that the Gamma Table has been set as expected.</p> <p>Success Criteria</p> <ul> <li>Correct Gamma Table settings are applied for each combination.</li> <li>User confirmation matches the expected RGB values and size for the Gamma Table.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#test-steps-test28","title":"Test Steps - test28","text":"<ol> <li> <p>Initiate the Test:</p> </li> <li> <p>Run the Python script: <code>tvSettings_test28_GammaTable.py</code></p> </li> <li> <p>The test initializes the TV settings module.</p> </li> <li> <p>Gamma Table Setting Verification:</p> </li> <li> <p>For each stream in the test, the script iterates over predefined gamma combinations:</p> <ul> <li>Each combination consists of a size and lists of RGB values.</li> <li>For each combination, the system applies the Gamma Table settings and prompts the user:</li> <li>\"Is Gamma Table set with Size: {size}, R: {red}, G: {green}, B: {blue}? (Y/N):\"</li> <li>Users respond with Y (Yes) or N (No) based on the display.</li> </ul> </li> <li> <p>Logging Results:</p> </li> <li> <p>The script logs results based on user input for each Gamma Table setting.</p> </li> <li> <p>Cleanup:</p> </li> <li> <p>The script stops playback after each stream verification.</p> </li> <li> <p>Test Conclusion:</p> </li> <li> <p>Once playback and verification are completed, the script terminates TV settings and logs the final results based on user responses.</p> </li> </ol>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#tvsettings_test29_dvtmaxpy","title":"tvSettings_test29_DVTmax.py","text":""},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#user-input-required-test29","title":"User Input Required - test29","text":"<p>Yes: This test requires manual verification to confirm that the DVT max values are correctly applied. The user must respond to a prompt indicating whether the DVT max value has been set.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#acceptance-criteria-test29","title":"Acceptance Criteria - test29","text":"<p>The system should correctly apply the DVT max values and verify them against the expected values defined in the test.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#expected-results-test29","title":"Expected Results - test29","text":"<p>The script initializes the TV settings, iterates through predefined DVT max values, and prompts the user to verify that each value has been applied correctly.</p> <p>Success Criteria</p> <ul> <li>Correct DVT max values are set for each iteration.</li> <li>User confirmation matches the expected DVT max values.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#test-steps-test29","title":"Test Steps - test29","text":"<ol> <li> <p>Initiate the Test:</p> </li> <li> <p>Run the Python script: <code>tvSettings_test29_DVTmax.py</code></p> </li> <li> <p>The test initializes the TV settings module.</p> </li> <li> <p>DVT Max Value Setting Verification:</p> </li> <li> <p>For each stream in the test, the script iterates over predefined DVT max values:</p> <ul> <li>Each value is logged and set using the <code>setDvTmaxValue</code> method.</li> <li>The system prompts the user for confirmation:</li> <li>\"Has DVT max value {dvtMaxValue} applied? (Y/N):\"</li> <li>Users respond with Y (Yes) or N (No) based on the display.</li> </ul> </li> <li> <p>Logging Results:</p> </li> <li> <p>The script logs results based on user input for each DVT max value setting.</p> </li> <li> <p>Cleanup:</p> </li> <li> <p>The script stops playback after each stream verification.</p> </li> <li> <p>Test Conclusion:</p> </li> <li> <p>Once playback and verification are completed, the script terminates TV settings and logs the final results based on user responses.</p> </li> </ol>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#tvsettings_test30_componentsaturationpy","title":"tvSettings_test30_ComponentSaturation.py","text":""},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#user-input-required-test30","title":"User Input Required - test30","text":"<p>Yes: This test requires manual verification to confirm that the component saturation values are correctly applied. The user must respond to a prompt indicating whether the saturation value has been set.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#acceptance-criteria-test30","title":"Acceptance Criteria - test30","text":"<p>The system should correctly apply the component saturation values and verify them against the expected values defined in the test.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#expected-results-test30","title":"Expected Results - test30","text":"<p>The script initializes the TV settings, iterates through predefined saturation values, and prompts the user to verify that each value has been applied correctly.</p> <p>Success Criteria</p> <ul> <li>Correct component saturation values are set for each combination of color, picture mode, and video format.</li> <li>User confirmation matches the expected component saturation values.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#test-steps-test30","title":"Test Steps - test30","text":"<ol> <li> <p>Initiate the Test:</p> </li> <li> <p>Run the Python script: <code>tvSettings_test30_ComponentSaturation.py</code></p> </li> <li> <p>The test initializes the TV settings module and sets the CMS (Color Management System) state.</p> </li> <li> <p>Component Saturation Setting:</p> </li> <li> <p>The script sets the component saturation values based on the available video formats and picture modes:</p> <ul> <li>For each video format, it downloads and plays the corresponding stream.</li> <li>It applies saturation values ranging from 0 to 100 for each combination of color and picture mode.</li> </ul> </li> <li> <p>Component Saturation Verification:</p> </li> <li> <p>The script plays each stream and verifies the applied saturation values:</p> <ul> <li>User is prompted with: \"Has component saturation value {saturationValue} applied? (Y/N):\"</li> <li>Users respond with Y (Yes) or N (No) based on the display.</li> </ul> </li> <li> <p>Logging Results:</p> </li> <li> <p>The script logs results based on user input for each component saturation setting.</p> </li> <li> <p>Cleanup:</p> </li> <li> <p>After all verifications, the script resets the component saturation to a default value of 50 for all color and picture mode combinations.</p> </li> <li> <p>Test Conclusion:</p> </li> <li> <p>Once all settings are verified and reset, the script terminates the TV settings module and logs the final results based on user responses.</p> </li> </ol>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#tvsettings_test31_componenthuepy","title":"tvSettings_test31_ComponentHue.py","text":""},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#user-input-required-test31","title":"User Input Required - test31","text":"<p>Yes: This test requires manual verification to confirm that the component hue values are correctly applied. The user must respond to a prompt indicating whether the hue value has been set.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#acceptance-criteria-test31","title":"Acceptance Criteria - test31","text":"<p>The system should correctly apply the component hue values and verify them against the expected values defined in the test.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#expected-results-test31","title":"Expected Results - test31","text":"<p>The script initializes the TV settings, iterates through predefined hue values, and prompts the user to verify that each value has been applied correctly.</p> <p>Success Criteria</p> <ul> <li>Correct component hue values are set for each combination of color, picture mode, and video format.</li> <li>User confirmation matches the expected component hue values.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#test-steps-test31","title":"Test Steps - test31","text":"<ol> <li> <p>Initiate the Test:</p> </li> <li> <p>Run the Python script: <code>tvSettings_test31_ComponentHue.py</code></p> </li> <li> <p>The test initializes the TV settings module and sets the CMS (Color Management System) state.</p> </li> <li> <p>Component Hue Setting:</p> </li> <li> <p>The script sets the component hue values based on the available video formats and picture modes:</p> <ul> <li>For each video format, it downloads and plays the corresponding stream.</li> <li>It applies hue values ranging from 0 to 100 for each combination of color and picture mode.</li> </ul> </li> <li> <p>Component Hue Verification:</p> </li> <li> <p>The script plays each stream and verifies the applied hue values:</p> <ul> <li>User is prompted with: \"Has component hue value {hueValue} applied? (Y/N):\"</li> <li>Users respond with Y (Yes) or N (No) based on the display.</li> </ul> </li> <li> <p>Logging Results:</p> </li> <li> <p>The script logs results based on user input for each component hue setting.</p> </li> <li> <p>Cleanup:</p> </li> <li> <p>After all verifications, the script resets the component hue to a default value of 50 for all color and picture mode combinations.</p> </li> <li> <p>Test Conclusion:</p> </li> <li> <p>Once all settings are verified and reset, the script terminates the TV settings module and logs the final results based on user responses.</p> </li> </ol>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#tvsettings_test32_componentlumapy","title":"tvSettings_test32_ComponentLuma.py","text":""},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#user-input-required-test32","title":"User Input Required - test32","text":"<p>Yes: This test requires manual verification to confirm that the component luma values are correctly applied. The user must respond to a prompt indicating whether the luma value has been set.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#acceptance-criteria-test32","title":"Acceptance Criteria - test32","text":"<p>The system should correctly apply the component luma values and verify them against the expected values defined in the test.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#expected-results-test32","title":"Expected Results - test32","text":"<p>The script initializes the TV settings, iterates through predefined luma values, and prompts the user to verify that each value has been applied correctly.</p> <p>Success Criteria</p> <ul> <li>Correct component luma values are set for each combination of color, picture mode, and video format.</li> <li>User confirmation matches the expected component luma values.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#test-steps-test32","title":"Test Steps - test32","text":"<ol> <li> <p>Initiate the Test:</p> </li> <li> <p>Run the Python script: <code>tvSettings_test32_ComponentLuma.py</code></p> </li> <li> <p>The test initializes the TV settings module and sets the CMS (Color Management System) state.</p> </li> <li> <p>Component Luma Setting:</p> </li> <li> <p>The script sets the component luma values based on the available video formats and picture modes:</p> <ul> <li>For each video format, it downloads and plays the corresponding stream.</li> <li>It applies luma values calculated to range from 0 to 30 based on the number of video formats for each combination of color and picture mode.</li> </ul> </li> <li> <p>Component Luma Verification:</p> </li> <li> <p>The script plays each stream and verifies the applied luma values:</p> <ul> <li>User is prompted with: \"Has component luma value {lumaValue} applied? (Y/N):\"</li> <li>Users respond with Y (Yes) or N (No) based on the display.</li> </ul> </li> <li> <p>Logging Results:</p> </li> <li> <p>The script logs results based on user input for each component luma setting.</p> </li> <li> <p>Cleanup:</p> </li> <li> <p>After all verifications, the script resets the component luma to a default value of 15 for all color and picture mode combinations.</p> </li> <li> <p>Test Conclusion:</p> </li> <li> <p>Once all settings are verified and reset, the script terminates the TV settings module and logs the final results based on user responses.</p> </li> </ol>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#tvsettings_test33_enablegammamodepy","title":"tvSettings_test33_EnableGammaMode.py","text":""},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#user-input-required-test33","title":"User Input Required - test33","text":"<p>Yes: This test requires manual verification to confirm that the gamma mode has been set correctly. The user must respond to a prompt indicating whether the gamma mode is enabled or disabled.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#acceptance-criteria-test33","title":"Acceptance Criteria - test33","text":"<p>The system should correctly apply the gamma mode settings and verify them against the expected values defined in the test.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#expected-results-test33","title":"Expected Results - test33","text":"<p>The script initializes the TV settings, iterates through the predefined gamma modes, and prompts the user to verify that each mode has been applied correctly.</p> <p>Success Criteria</p> <ul> <li>Correct gamma modes (Enable: 1, Disable: 0) are set for each stream.</li> <li>User confirmation matches the expected gamma mode settings.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#test-steps-test33","title":"Test Steps - test33","text":"<ol> <li> <p>Initiate the Test:</p> </li> <li> <p>Run the Python script: <code>tvSettings_test33_EnableGammaMode.py</code></p> </li> <li> <p>The test initializes the TV settings module.</p> </li> <li> <p>Gamma Mode Setting:</p> </li> <li> <p>The script iterates through the predefined gamma modes (0: Disable, 1: Enable) for each stream:</p> <ul> <li>For each gamma mode, it starts the playback of the corresponding stream.</li> <li>It sets the gamma mode.</li> </ul> </li> <li> <p>Gamma Mode Verification:</p> </li> <li> <p>After setting the gamma mode, the script verifies whether the mode was set correctly:</p> <ul> <li>User is prompted with: \"Is gamma mode set to {gammaMode}? (Y/N):\"</li> <li>Users respond with Y (Yes) or N (No) based on the display.</li> </ul> </li> <li> <p>Logging Results:</p> </li> <li> <p>The script logs results based on user input for each gamma mode setting.</p> </li> <li> <p>Cleanup:</p> </li> <li> <p>After all verifications, the script sets the CMS state back to 0 (disabled).</p> </li> <li> <p>It terminates the TV settings module.</p> </li> <li> <p>Test Conclusion:</p> </li> <li> <p>Once all settings are verified and reset, the script logs the final results based on user responses.</p> </li> </ol>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#tvsettings_test34_setgammapatternpy","title":"tvSettings_test34_SetGammaPattern.py","text":""},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#user-input-required-test34","title":"User Input Required - test34","text":"<p>Yes: This test requires manual verification to confirm that the gamma pattern settings have been applied correctly. The user must respond to a prompt indicating whether the gamma pattern is set to the specified bit depth and color levels.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#acceptance-criteria-test34","title":"Acceptance Criteria - test34","text":"<p>The system should correctly apply the gamma pattern settings for both 10-bit and 8-bit depths and verify them against the expected values defined in the test.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#expected-results-test34","title":"Expected Results - test34","text":"<p>The script initializes the TV settings, enables gamma pattern mode, iterates through the predefined bit depths and color levels, and prompts the user to verify that the gamma pattern has been set correctly.</p> <p>Success Criteria</p> <ul> <li>Gamma pattern settings (bit depth, red level, green level, blue level) are applied for each stream.</li> <li>User confirmation matches the expected gamma pattern settings.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#test-steps-test34","title":"Test Steps - test34","text":"<ol> <li> <p>Initiate the Test:</p> </li> <li> <p>Run the Python script: <code>tvSettings_test34_SetGammaPattern.py</code></p> </li> <li> <p>The test initializes the TV settings module and enables the gamma pattern mode.</p> </li> <li> <p>Gamma Pattern Setting:</p> </li> <li> <p>The script iterates through the predefined bit depths (0 for 10-bit, 1 for 8-bit) for each stream:</p> <ul> <li>For each bit depth, it retrieves the corresponding level ranges for Red, Green, and Blue channels.</li> <li>It sets the gamma pattern.</li> </ul> </li> <li> <p>Gamma Pattern Verification:</p> </li> <li> <p>After setting the gamma pattern, the script verifies whether it was set correctly:</p> <ul> <li>User is prompted with: \"Is gamma pattern set to Bit Depth: {bitDepth}, Red Level: {redLevel}, Green Level: {greenLevel}, Blue Level: {blueLevel}? (Y/N):\"</li> <li>Users respond with Y (Yes) or N (No) based on the display.</li> </ul> </li> <li> <p>Logging Results:</p> </li> <li> <p>The script logs results based on user input for each gamma pattern setting.</p> </li> <li> <p>Cleanup:</p> </li> <li> <p>After all verifications, the script disables the gamma pattern mode.</p> </li> <li> <p>It terminates the TV settings module.</p> </li> <li> <p>Test Conclusion:</p> </li> <li> <p>Once all settings are verified and reset, the script logs the final results based on user responses.</p> </li> </ol>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#tvsettings_test35_rgbpatternpy","title":"tvSettings_test35_RGBPattern.py","text":""},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#user-input-required-test35","title":"User Input Required - test35","text":"<p>Yes: This test requires manual verification to confirm that the RGB pattern settings have been applied correctly. The user must respond to a prompt indicating whether the RGB pattern is set to the specified red, green, and blue levels.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#acceptance-criteria-test35","title":"Acceptance Criteria - test35","text":"<p>The system should correctly apply the RGB pattern settings for various predefined levels and verify them against the expected values defined in the test.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#expected-results-test35","title":"Expected Results - test35","text":"<p>The script initializes the TV settings, iterates through predefined RGB levels, sets the RGB pattern, and prompts the user to verify that the pattern has been set correctly.</p> <p>Success Criteria</p> <ul> <li>RGB pattern settings (red level, green level, blue level) are applied for each predefined sample.</li> <li>User confirmation matches the expected RGB pattern settings.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#test-steps-test35","title":"Test Steps - test35","text":"<ol> <li> <p>Initiate the Test:</p> </li> <li> <p>Run the Python script: <code>tvSettings_test35_RGBPattern.py</code></p> </li> <li> <p>The test initializes the TV settings module.</p> </li> <li> <p>RGB Pattern Setting:</p> </li> <li> <p>The script iterates through the predefined RGB levels:</p> <ul> <li>For each set of levels, it retrieves the values for red, green, and blue.</li> </ul> </li> <li> <p>RGB Pattern Verification:</p> </li> <li> <p>After setting the RGB pattern, the script verifies whether it was set correctly:</p> <ul> <li>User is prompted with: \"Is RGB pattern set to Red Level: {redLevel}, Green Level: {greenLevel}, Blue Level: {blueLevel}? (Y/N):\"</li> <li>Users respond with Y (Yes) or N (No) based on the display.</li> </ul> </li> <li> <p>Logging Results:</p> </li> <li> <p>The script logs results based on user input for each RGB pattern setting.</p> </li> <li> <p>Cleanup:</p> </li> <li> <p>After all verifications, the script terminates the TV settings module.</p> </li> <li> <p>Test Conclusion:</p> </li> <li> <p>Once all settings are verified and reset, the script logs the final results based on user responses.</p> </li> </ol>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#tvsettings_test36_graypatternpy","title":"tvSettings_test36_GrayPattern.py","text":""},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#user-input-required-test36","title":"User Input Required - test36","text":"<p>Yes: This test requires manual verification to confirm that the Gray pattern settings have been applied correctly. The user must respond to a prompt indicating whether the Gray pattern is set to the specified gray level.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#acceptance-criteria-test36","title":"Acceptance Criteria - test36","text":"<p>The system should correctly apply the Gray pattern settings for various predefined levels and verify them against the expected values defined in the test.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#expected-results-test36","title":"Expected Results - test36","text":"<p>The script initializes the TV settings, iterates through predefined gray levels, sets the Gray pattern, and prompts the user to verify that the pattern has been set correctly.</p> <p>Success Criteria</p> <ul> <li>Gray pattern settings (gray level) are applied for each predefined sample.</li> <li>User confirmation matches the expected Gray pattern settings.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#test-steps-test36","title":"Test Steps - test36","text":"<ol> <li> <p>Initiate the Test:</p> </li> <li> <p>Run the Python script: <code>tvSettings_test36_GrayPattern.py</code></p> </li> <li> <p>The test initializes the TV settings module.</p> </li> <li> <p>Gray Pattern Setting:</p> </li> <li> <p>The script iterates through the predefined gray levels:</p> <ul> <li>For each gray level, it retrieves the value.</li> </ul> </li> <li> <p>Gray Pattern Verification:</p> </li> <li> <p>After setting the Gray pattern, the script verifies whether it was set correctly:</p> <ul> <li>User is prompted with: \"Is Gray pattern set to Gray Level: {grayLevel}? (Y/N):\"</li> <li>Users respond with Y (Yes) or N (No) based on the display.</li> </ul> </li> <li> <p>Logging Results:</p> </li> <li> <p>The script logs results based on user input for each Gray pattern setting.</p> </li> <li> <p>Cleanup:</p> </li> <li> <p>After all verifications, the script terminates the TV settings module.</p> </li> <li> <p>Test Conclusion:</p> </li> <li> <p>Once all settings are verified and reset, the script logs the final results based on user responses.</p> </li> </ol>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#tvsettings_test37_enableldimpixelcompensationpy","title":"tvSettings_test37_EnableLDIMPixelCompensation.py","text":""},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#user-input-required-test37","title":"User Input Required - test37","text":"<p>Yes: This test requires manual verification to confirm that the LDIM Pixel Compensation settings have been applied correctly. The user must respond to a prompt indicating whether the LDIM Pixel Compensation is set to the specified value.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#acceptance-criteria-test37","title":"Acceptance Criteria - test37","text":"<p>The system should correctly enable or disable the LDIM Pixel Compensation settings and verify them against the expected values defined in the test.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#expected-results-test37","title":"Expected Results - test37","text":"<p>The script initializes the TV settings, iterates through predefined LDIM Pixel Compensation values, sets the compensation, and prompts the user to verify that the setting has been applied correctly.</p> <p>Success Criteria</p> <ul> <li>LDIM Pixel Compensation settings (0 or 1) are applied for each predefined sample.</li> <li>User confirmation matches the expected LDIM Pixel Compensation settings.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#test-steps-test37","title":"Test Steps - test37","text":"<ol> <li> <p>Initiate the Test:</p> </li> <li> <p>Run the Python script: <code>tvSettings_test37_EnableLDIMPixelCompensation.py</code></p> </li> <li> <p>The test initializes the TV settings module.</p> </li> <li> <p>LDIM Pixel Compensation Setting:</p> </li> <li> <p>The script iterates through the predefined LDIM Pixel Compensation values:</p> <ul> <li>For each value (0 for disabled and 1 for enabled), it retrieves the value.</li> </ul> </li> <li> <p>LDIM Pixel Compensation Verification:</p> </li> <li> <p>After setting the LDIM Pixel Compensation, the script verifies whether it was set correctly:</p> <ul> <li>User is prompted with: \"Is LDIM Pixel Compensation set to: {ldimValue}? (Y/N):\"</li> <li>Users respond with Y (Yes) or N (No) based on the display.</li> </ul> </li> <li> <p>Logging Results:</p> </li> <li> <p>The script logs results based on user input for each LDIM Pixel Compensation setting.</p> </li> <li> <p>Cleanup:</p> </li> <li> <p>After all verifications, the script terminates the TV settings module.</p> </li> <li> <p>Test Conclusion:</p> </li> <li> <p>Once all settings are verified and reset, the script logs the final results based on user responses.</p> </li> </ol>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#tvsettings_test38_enableldimpy","title":"tvSettings_test38_EnableLDIM.py","text":""},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#user-input-required-test38","title":"User Input Required - test38","text":"<p>Yes: This test requires manual verification to confirm whether the LDIM settings have been applied correctly. The user must respond to a prompt indicating whether the LDIM is set to the specified value.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#acceptance-criteria-test38","title":"Acceptance Criteria - test38","text":"<p>The system should correctly enable or disable the LDIM settings and verify them against the expected values defined in the test.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#expected-results-test38","title":"Expected Results - test38","text":"<p>The script initializes the TV settings, iterates through predefined LDIM values, sets the LDIM, and prompts the user to verify that the setting has been applied correctly.</p> <p>Success Criteria</p> <ul> <li>LDIM settings (0 for disabled and 1 for enabled) are applied for each predefined sample.</li> <li>User confirmation matches the expected LDIM settings.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#test-steps-test38","title":"Test Steps - test38","text":"<ol> <li> <p>Initiate the Test:</p> </li> <li> <p>Run the Python script: <code>tvSettings_test38_EnableLDIM.py</code></p> </li> <li> <p>The test runs prerequisites specified in the test setup configuration file.</p> </li> <li> <p>LDIM Setting:</p> </li> <li> <p>The script initializes the TV settings module.</p> </li> <li> <p>It iterates through the predefined LDIM values:</p> <ul> <li>For each value (0 for disabled and 1 for enabled), it retrieves the value.</li> </ul> </li> <li> <p>LDIM Verification:</p> </li> <li> <p>After setting the LDIM, the script verifies whether it was set correctly:</p> <ul> <li>User is prompted with: \"Is LDIM set to: {ldimValue}? (Y/N):\"</li> <li>Users respond with Y (Yes) or N (No) based on the display.</li> </ul> </li> <li> <p>Logging Results:</p> </li> <li> <p>The script logs results based on user input for each LDIM setting.</p> </li> <li> <p>Cleanup:</p> </li> <li> <p>After all verifications, the script stops the stream playback and terminates the TV settings module.</p> </li> <li> <p>Test Conclusion:</p> </li> <li> <p>Once all settings are verified and reset, the script logs the final results based on user responses.</p> </li> </ol>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#tvsettings_test39_setbacklighttestmodepy","title":"tvSettings_test39_SetBacklightTestMode.py","text":""},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#user-input-required-test39","title":"User Input Required - test39","text":"<p>Yes: This test requires manual verification to confirm whether the backlight mode has been set correctly. The user must respond to a prompt indicating whether the backlight mode is set to the specified value.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#acceptance-criteria-test39","title":"Acceptance Criteria - test39","text":"<p>The system should correctly set the backlight mode according to the available options and verify it against the expected values defined in the test.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#expected-results-test39","title":"Expected Results - test39","text":"<p>The script initializes the TV settings, iterates through available backlight modes, sets the mode, and prompts the user to verify that the setting has been applied correctly.</p> <p>Success Criteria</p> <ul> <li>Backlight modes are applied for each predefined sample.</li> <li>User confirmation matches the expected backlight settings.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#test-steps-test39","title":"Test Steps - test39","text":"<ol> <li> <p>Initiate the Test:</p> </li> <li> <p>Run the Python script: <code>tvSettings_test39_SetBacklightTestMode.py</code></p> </li> <li> <p>Backlight Mode Setting:</p> </li> <li> <p>The script initializes the TV settings module.</p> </li> <li> <p>It iterates through the Supported backlight test modes.</p> </li> <li> <p>Backlight Mode Verification:</p> </li> <li> <p>After setting the backlight mode, the script verifies whether it was set correctly:</p> <ul> <li>User is prompted with: \"Is backlight mode set to: {backlightMode}? (Y/N):\"</li> <li>Users respond with Y (Yes) or N (No) based on the display.</li> </ul> </li> <li> <p>Logging Results:</p> </li> <li> <p>The script logs results based on user input for each backlight mode setting.</p> </li> <li> <p>Cleanup:</p> </li> <li> <p>After all verifications, the script stops the stream playback and terminates the TV settings module.</p> </li> <li> <p>Test Conclusion:</p> </li> <li> <p>Once all settings are verified and reset, the script logs the final results based on user responses.</p> </li> </ol>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#tvsettings_test40_enabledynamiccontrastpy","title":"tvSettings_test40_EnableDynamicContrast.py","text":""},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#user-input-required-test40","title":"User Input Required - test40","text":"<p>Yes: This test requires manual verification to confirm whether the dynamic contrast setting has been applied correctly. The user must respond to a prompt indicating whether the dynamic contrast is set to the specified value.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#acceptance-criteria-test40","title":"Acceptance Criteria - test40","text":"<p>The system should correctly set and verify the dynamic contrast levels according to the predefined options and ensure that the user can confirm the settings.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#expected-results-test40","title":"Expected Results - test40","text":"<p>The script initializes the TV settings, iterates through available dynamic contrast levels, applies the settings, and prompts the user to verify whether the settings were applied correctly.</p> <p>Success Criteria</p> <ul> <li>Dynamic contrast levels are applied for each predefined sample.</li> <li>User confirmation matches the expected dynamic contrast settings.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#test-steps-test40","title":"Test Steps - test40","text":"<ol> <li> <p>Initiate the Test:</p> </li> <li> <p>Run the Python script: <code>tvSettings_test40_EnableDynamicContrast.py</code></p> </li> <li> <p>Dynamic Contrast Setting:</p> </li> <li> <p>The script initializes the TV settings module.</p> </li> <li> <p>It enables or disables the dynamic contrast.</p> </li> <li> <p>Dynamic Contrast Verification:</p> </li> <li> <p>After setting the dynamic contrast level, the script verifies whether it was set correctly:</p> <ul> <li>User is prompted with: \"Is Dynamic Contrast set to: {dynamicContrast}? (Y/N):\"</li> <li>Users respond with Y (Yes) or N (No) based on the display.</li> </ul> </li> <li> <p>Logging Results:</p> </li> <li> <p>The script logs results based on user input for each dynamic contrast level setting.</p> </li> <li> <p>Cleanup:</p> </li> <li> <p>After all verifications, the script stops the stream playback and terminates the TV settings module.</p> </li> <li> <p>Test Conclusion:</p> </li> <li> <p>Once all settings are verified and reset, the script logs the final results based on user responses.</p> </li> </ol>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#tvsettings_test41_enablelocalcontrastpy","title":"tvSettings_test41_EnableLocalContrast.py","text":""},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#user-input-required-test41","title":"User Input Required - test41","text":"<p>Yes: This test requires manual verification to confirm whether the local contrast setting has been applied correctly. The user must respond to a prompt indicating whether the local contrast is set to the specified value.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#acceptance-criteria-test41","title":"Acceptance Criteria - test41","text":"<p>The system should correctly set and verify the local contrast levels according to the predefined options and ensure that the user can confirm the settings.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#expected-results-test41","title":"Expected Results - test41","text":"<p>The script initializes the TV settings, iterates through available local contrast levels, applies the settings, and prompts the user to verify whether the settings were applied correctly.</p> <p>Success Criteria</p> <ul> <li>Local contrast levels are applied for each predefined sample.</li> <li>User confirmation matches the expected local contrast settings.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#test-steps-test41","title":"Test Steps - test41","text":"<ol> <li> <p>Initiate the Test:</p> </li> <li> <p>Run the Python script: <code>tvSettings_test41_EnableLocalContrast.py</code></p> </li> <li> <p>Local Contrast Setting:</p> </li> <li> <p>The script initializes the TV settings module.</p> </li> <li> <p>It enables and disables the local contrast.</p> </li> <li> <p>Local Contrast Verification:</p> </li> <li> <p>After setting the local contrast level, the script verifies whether it was set correctly:</p> <ul> <li>User is prompted with: \"Is Local Contrast set to: {localContrast}? (Y/N):\"</li> <li>Users respond with Y (Yes) or N (No) based on the display.</li> </ul> </li> <li> <p>Logging Results:</p> </li> <li> <p>The script logs results based on user input for each local contrast level setting.</p> </li> <li> <p>Cleanup:</p> </li> <li> <p>After all verifications, the script stops the stream playback and terminates the TV settings module.</p> </li> <li> <p>Test Conclusion:</p> </li> <li> <p>Once all settings are verified and reset, the script logs the final results based on user responses.</p> </li> </ol>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#tvsettings_test42_savebacklightvaluespy","title":"tvSettings_test42_SaveBacklightValues.py","text":""},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#user-input-required-test42","title":"User Input Required - test42","text":"<p>Yes: This test requires manual verification to confirm whether the backlight value has been applied correctly for various picture modes and video formats. The user must respond to a prompt indicating whether the backlight value is correctly set.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#acceptance-criteria-test42","title":"Acceptance Criteria - test42","text":"<p>The system should save the correct backlight values for all combinations of picture modes and video formats, and the user should be able to confirm the settings through manual verification.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#expected-results-test42","title":"Expected Results - test42","text":"<p>The script initializes the TV settings, saves backlight values for different formats and modes, plays the streams, and prompts the user to verify whether the settings were applied correctly.</p> <p>Success Criteria</p> <ul> <li>Backlight values are saved and applied correctly for each combination of picture mode and video format.</li> <li>User confirmation matches the expected backlight values.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#test-steps-test42","title":"Test Steps - test42","text":"<ol> <li> <p>Initiate the Test:</p> </li> <li> <p>Run the Python script: <code>tvSettings_test42_SaveBacklightValues.py</code></p> </li> <li> <p>Save Backlight Values:</p> </li> <li> <p>The script initializes the TV settings module and saves backlight values for all combinations of picture modes and video formats.</p> </li> <li> <p>Stream Playback:</p> </li> <li> <p>The script retrieves the list of video formats and corresponding stream URLs.</p> </li> <li> <p>It downloads the individual streams and plays them.</p> </li> <li> <p>Backlight Value Verification:</p> </li> <li> <p>After playing each stream, the script verifies whether the backlight values were set correctly:</p> <ul> <li>User is prompted with: \"Is backlight value {backlight} applied for Picture Mode: {pictureMode} and Video Format: {videoFormat}? (Y/N):\"</li> <li>Users respond with Y (Yes) or N (No) based on the display.</li> </ul> </li> <li> <p>Logging Results:</p> </li> <li> <p>The script logs results based on user input for each backlight value setting.</p> </li> <li> <p>Cleanup:</p> </li> <li> <p>After all verifications, the script stops the stream playback, cleans up the downloaded assets, and sets all backlight values to the default value of 50.</p> </li> <li> <p>Test Conclusion:</p> </li> <li> <p>Once all settings are verified and reset, the script logs the final results based on user responses.</p> </li> </ol>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#tvsettings_test43_savetvdimmingmodepy","title":"tvSettings_test43_SaveTVDimmingMode.py","text":""},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#user-input-required-test43","title":"User Input Required - test43","text":"<p>Yes: This test requires manual verification to confirm whether the dimming value has been applied correctly for various picture modes and video formats. The user must respond to a prompt indicating whether the dimming level is correctly set.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#acceptance-criteria-test43","title":"Acceptance Criteria - test43","text":"<p>The system should save the correct dimming values for all combinations of picture modes and video formats, and the user should be able to confirm the settings through manual verification.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#expected-results-test43","title":"Expected Results - test43","text":"<p>The script initializes the TV settings, saves dimming values for different formats and modes, plays the streams, and prompts the user to verify whether the settings were applied correctly.</p> <p>Success Criteria</p> <ul> <li>Dimming values are saved and applied correctly for each combination of picture mode and video format.</li> <li>User confirmation matches the expected dimming levels.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#test-steps-test43","title":"Test Steps - test43","text":"<ol> <li> <p>Initiate the Test:</p> </li> <li> <p>Run the Python script: <code>tvSettings_test43_SaveTVDimmingMode.py</code></p> </li> <li> <p>Save Dimming Values:</p> </li> <li> <p>The script initializes the TV settings module and saves dimming values for all combinations of picture modes and video formats.</p> </li> <li> <p>Stream Playback:</p> </li> <li> <p>The script retrieves the list of video formats and corresponding stream URLs.</p> </li> <li> <p>It downloads the individual streams and plays them.</p> </li> <li> <p>Dimming Value Verification:</p> </li> <li> <p>After playing each stream, the script verifies whether the dimming values were set correctly:</p> <ul> <li>User is prompted with: \"Is dimming value {dimmingLevel} applied for Picture Mode: {pictureMode} and Video Format: {videoFormat}? (Y/N):\"</li> <li>Users respond with Y (Yes) or N (No) based on the display.</li> </ul> </li> <li> <p>Logging Results:</p> </li> <li> <p>The script logs results based on user input for each dimming value setting.</p> </li> <li> <p>Cleanup:</p> </li> <li> <p>After all verifications, the script stops the stream playback, cleans up the downloaded assets.</p> </li> <li> <p>Test Conclusion:</p> </li> <li> <p>Once all settings are verified, the script logs the final results based on user responses.</p> </li> </ol>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#tvsettings_test44_savelocaldimminglevelpy","title":"tvSettings_test44_SaveLocalDimmingLevel.py","text":""},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#user-input-required-test44","title":"User Input Required - test44","text":"<p>Yes: This test requires manual verification to confirm whether the local dimming value has been applied correctly for various picture modes and video formats. The user must respond to a prompt indicating whether the local dimming level is correctly set.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#acceptance-criteria-test44","title":"Acceptance Criteria - test44","text":"<p>The system should save the correct local dimming values for all combinations of picture modes and video formats, and the user should be able to confirm the settings through manual verification.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#expected-results-test44","title":"Expected Results - test44","text":"<p>The script initializes the TV settings, saves local dimming values for different formats and modes, plays the streams, and prompts the user to verify whether the settings were applied correctly.</p> <p>Success Criteria</p> <ul> <li>Local dimming values are saved and applied correctly for each combination of picture mode and video format.</li> <li>User confirmation matches the expected local dimming levels.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#test-steps-test44","title":"Test Steps - test44","text":"<ol> <li> <p>Initiate the Test:</p> </li> <li> <p>Run the Python script: <code>tvSettings_test44_SaveLocalDimmingLevel.py</code></p> </li> <li> <p>Save Local Dimming Values:</p> </li> <li> <p>The script initializes the TV settings module and saves local dimming values for all combinations of picture modes and video formats.</p> </li> <li> <p>Stream Playback:</p> </li> <li> <p>The script retrieves the list of video formats and corresponding stream URLs.</p> </li> <li> <p>It downloads the individual streams and plays them.</p> </li> <li> <p>Local Dimming Value Verification:</p> </li> <li> <p>After playing each stream, the script verifies whether the local dimming values were set correctly:</p> <ul> <li>User is prompted with: \"Is local dimming value {localDimmingLevel} applied for Picture Mode: {pictureMode} and Video Format: {videoFormat}? (Y/N):\"</li> <li>Users respond with Y (Yes) or N (No) based on the display.</li> </ul> </li> <li> <p>Logging Results:</p> </li> <li> <p>The script logs results based on user input for each local dimming value setting.</p> </li> <li> <p>Cleanup:</p> </li> <li> <p>After all verifications, the script stops the stream playback and cleans up the downloaded assets.</p> </li> <li> <p>Test Conclusion:</p> </li> <li> <p>Once all settings are verified, the script logs the final results based on user responses.</p> </li> </ol>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#tvsettings_test45_savebrightnesspy","title":"tvSettings_test45_SaveBrightness.py","text":""},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#user-input-required-test45","title":"User Input Required - test45","text":"<p>Yes: This test requires manual verification to confirm whether the brightness value has been applied correctly for various picture modes and video formats. The user must respond to a prompt indicating whether the brightness level is correctly set.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#acceptance-criteria-test45","title":"Acceptance Criteria - test45","text":"<p>The system should save the correct brightness values for all combinations of picture modes and video formats, and the user should be able to confirm the settings through manual verification.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#expected-results-test45","title":"Expected Results - test45","text":"<p>The script initializes the TV settings, saves brightness values for different formats and modes, plays the streams, and prompts the user to verify whether the settings were applied correctly.</p> <p>Success Criteria</p> <ul> <li>Brightness values are saved and applied correctly for each combination of picture mode and video format.</li> <li>User confirmation matches the expected brightness levels.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#test-steps-test45","title":"Test Steps - test45","text":"<ol> <li> <p>Initiate the Test:</p> </li> <li> <p>Run the Python script: <code>tvSettings_test45_SaveBrightness.py</code></p> </li> <li> <p>Save Brightness Values:</p> </li> <li> <p>The script initializes the TV settings module and saves brightness values for all combinations of picture modes and video formats.</p> </li> <li> <p>Brightness values are distributed across the number of video formats.</p> </li> <li> <p>Stream Playback:</p> </li> <li> <p>The script retrieves the list of video formats and corresponding stream URLs.</p> </li> <li> <p>It downloads the individual streams and plays them.</p> </li> <li> <p>Brightness Value Verification:</p> </li> <li> <p>After playing each stream, the script verifies whether the brightness values were set correctly:</p> <ul> <li>User is prompted with: \"Is brightness value {brightness} applied for Picture Mode: {pictureMode} and Video Format: {videoFormat}? (Y/N):\"</li> <li>Users respond with Y (Yes) or N (No) based on the display.</li> </ul> </li> <li> <p>Logging Results:</p> </li> <li> <p>The script logs results based on user input for each brightness value setting.</p> </li> <li> <p>Cleanup:</p> </li> <li> <p>After all verifications, the script stops the stream playback and cleans up the downloaded assets.</p> </li> <li> <p>Set Default Brightness:</p> </li> <li> <p>After testing, the script sets all brightness values back to a default value of 50.</p> </li> <li> <p>Test Conclusion:</p> </li> <li> <p>Once all settings are verified and defaults restored, the script logs the final results based on user responses.</p> </li> </ol>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#tvsettings_test46_savecontrastpy","title":"tvSettings_test46_SaveContrast.py","text":""},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#user-input-required-test46","title":"User Input Required - test46","text":"<p>Yes: This test requires manual verification to confirm whether the contrast value has been applied correctly for various picture modes and video formats. The user must respond to a prompt indicating whether the contrast level is correctly set.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#acceptance-criteria-test46","title":"Acceptance Criteria - test46","text":"<p>The system should save the correct contrast values for all combinations of picture modes and video formats, and the user should be able to confirm the settings through manual verification.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#expected-results-test46","title":"Expected Results - test46","text":"<p>The script initializes the TV settings, saves contrast values for different formats and modes, plays the streams, and prompts the user to verify whether the settings were applied correctly.</p> <p>Success Criteria</p> <ul> <li>Contrast values are saved and applied correctly for each combination of picture mode and video format.</li> <li>User confirmation matches the expected contrast levels.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#test-steps-test46","title":"Test Steps - test46","text":"<ol> <li> <p>Initiate the Test:</p> </li> <li> <p>Run the Python script: <code>tvSettings_test46_SaveContrast.py</code></p> </li> <li> <p>Save Contrast Values:</p> </li> <li> <p>The script initializes the TV settings module and saves contrast values for all combinations of picture modes and video formats.</p> </li> <li> <p>Contrast values are distributed across the number of video formats.</p> </li> <li> <p>Stream Playback:</p> </li> <li> <p>The script retrieves the list of video formats and corresponding stream URLs.</p> </li> <li> <p>It downloads the individual streams and plays them.</p> </li> <li> <p>Contrast Value Verification:</p> </li> <li> <p>After playing each stream, the script verifies whether the contrast values were set correctly:</p> <ul> <li>User is prompted with: \"Is contrast value {contrast} applied for Picture Mode: {pictureMode} and Video Format: {videoFormat}? (Y/N):\"</li> <li>Users respond with Y (Yes) or N (No) based on the display.</li> </ul> </li> <li> <p>Logging Results:</p> </li> <li> <p>The script logs results based on user input for each contrast value setting.</p> </li> <li> <p>Cleanup:</p> </li> <li> <p>After all verifications, the script stops the stream playback and cleans up the downloaded assets.</p> </li> <li> <p>Set Default Contrast:</p> </li> <li> <p>After testing, the script sets all contrast values back to a default value of 50.</p> </li> <li> <p>Test Conclusion:</p> </li> <li> <p>Once all settings are verified and defaults restored, the script logs the final results based on user responses.</p> </li> </ol>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#tvsettings_test47_savesharpnesspy","title":"tvSettings_test47_SaveSharpness.py","text":""},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#user-input-required-test47","title":"User Input Required - test47","text":"<p>Yes: This test requires manual verification to confirm whether the sharpness value has been applied correctly for various picture modes and video formats. The user must respond to a prompt indicating whether the sharpness level is correctly set.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#acceptance-criteria-test47","title":"Acceptance Criteria - test47","text":"<p>The system should save the correct sharpness values for all combinations of picture modes and video formats, and the user should be able to confirm the settings through manual verification.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#expected-results-test47","title":"Expected Results - test47","text":"<p>The script initializes the TV settings, saves sharpness values for different formats and modes, plays the streams, and prompts the user to verify whether the settings were applied correctly.</p> <p>Success Criteria</p> <ul> <li>Sharpness values are saved and applied correctly for each combination of picture mode and video format.</li> <li>User confirmation matches the expected sharpness levels.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#test-steps-test47","title":"Test Steps - test47","text":"<ol> <li> <p>Initiate the Test:</p> </li> <li> <p>Run the Python script: <code>tvSettings_test47_SaveSharpness.py</code></p> </li> <li> <p>Save Sharpness Values:</p> </li> <li> <p>The script initializes the TV settings module and saves sharpness values for all combinations of picture modes and video formats.</p> </li> <li> <p>Sharpness values are distributed across the number of video formats.</p> </li> <li> <p>Stream Playback:</p> </li> <li> <p>The script retrieves the list of video formats and corresponding stream URLs.</p> </li> <li> <p>It downloads the individual streams and plays them.</p> </li> <li> <p>Sharpness Value Verification:</p> </li> <li> <p>After playing each stream, the script verifies whether the sharpness values were set correctly:</p> <ul> <li>User is prompted with: \"Is sharpness value {sharpness} applied for Picture Mode: {pictureMode} and Video Format: {videoFormat}? (Y/N):\"</li> <li>Users respond with Y (Yes) or N (No) based on the display.</li> </ul> </li> <li> <p>Logging Results:</p> </li> <li> <p>The script logs results based on user input for each sharpness value setting.</p> </li> <li> <p>Cleanup:</p> </li> <li> <p>After all verifications, the script stops the stream playback and cleans up the downloaded assets.</p> </li> <li> <p>Set Default Sharpness:</p> </li> <li> <p>After testing, the script sets all sharpness values back to a default value of 50.</p> </li> <li> <p>Test Conclusion:</p> </li> <li> <p>Once all settings are verified and defaults restored, the script logs the final results based on user responses.</p> </li> </ol>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#tvsettings_test48_savesaturationpy","title":"tvSettings_test48_SaveSaturation.py","text":""},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#user-input-required-test48","title":"User Input Required - test48","text":"<p>Yes: This test requires manual verification to confirm whether the saturation value has been applied correctly for various picture modes and video formats. The user must respond to a prompt indicating whether the saturation level is correctly set.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#acceptance-criteria-test48","title":"Acceptance Criteria - test48","text":"<p>The system should save the correct saturation values for all combinations of picture modes and video formats, and the user should be able to confirm the settings through manual verification.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#expected-results-test48","title":"Expected Results - test48","text":"<p>The script initializes the TV settings, saves saturation values for different formats and modes, plays the streams, and prompts the user to verify whether the settings were applied correctly.</p> <p>Success Criteria</p> <ul> <li>Saturation values are saved and applied correctly for each combination of picture mode and video format.</li> <li>User confirmation matches the expected saturation levels.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#test-steps-test48","title":"Test Steps - test48","text":"<ol> <li> <p>Initiate the Test:</p> </li> <li> <p>Run the Python script: <code>tvSettings_test48_SaveSaturation.py</code></p> </li> <li> <p>Save Saturation Values:</p> </li> <li> <p>The script initializes the TV settings module and saves saturation values for all combinations of picture modes and video formats.</p> </li> <li> <p>Saturation values are distributed across the number of video formats.</p> </li> <li> <p>Stream Playback:</p> </li> <li> <p>The script retrieves the list of video formats and corresponding stream URLs.</p> </li> <li> <p>It downloads the individual streams and plays them.</p> </li> <li> <p>Saturation Value Verification:</p> </li> <li> <p>After playing each stream, the script verifies whether the saturation values were set correctly:</p> <ul> <li>User is prompted with: \"Is saturation value {saturation} applied for Picture Mode: {pictureMode} and Video Format: {videoFormat}? (Y/N):\"</li> <li>Users respond with Y (Yes) or N (No) based on the display.</li> </ul> </li> <li> <p>Logging Results:</p> </li> <li> <p>The script logs results based on user input for each saturation value setting.</p> </li> <li> <p>Cleanup:</p> </li> <li> <p>After all verifications, the script stops the stream playback and cleans up the downloaded assets.</p> </li> <li> <p>Set Default Saturation:</p> </li> <li> <p>After testing, the script sets all saturation values back to a default value of 50.</p> </li> <li> <p>Test Conclusion:</p> </li> <li> <p>Once all settings are verified and defaults restored, the script logs the final results based on user responses.</p> </li> </ol>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#tvsettings_test49_savehuepy","title":"tvSettings_test49_SaveHue.py","text":""},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#user-input-required-test49","title":"User Input Required - test49","text":"<p>Yes: This test requires manual verification to confirm whether the hue value has been applied correctly for various picture modes and video formats. The user must respond to a prompt indicating whether the hue level is correctly set.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#acceptance-criteria-test49","title":"Acceptance Criteria - test49","text":"<p>The system should save the correct hue values for all combinations of picture modes and video formats, and the user should be able to confirm the settings through manual verification.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#expected-results-test49","title":"Expected Results - test49","text":"<p>The script initializes the TV settings, saves hue values for different formats and modes, plays the streams, and prompts the user to verify whether the settings were applied correctly.</p> <p>Success Criteria</p> <ul> <li>Hue values are saved and applied correctly for each combination of picture mode and video format.</li> <li>User confirmation matches the expected hue levels.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#test-steps-test49","title":"Test Steps - test49","text":"<ol> <li> <p>Initiate the Test:</p> </li> <li> <p>Run the Python script: <code>tvSettings_test49_SaveHue.py</code></p> </li> <li> <p>Save Hue Values:</p> </li> <li> <p>The script initializes the TV settings module and saves hue values for all combinations of picture modes and video formats.</p> </li> <li> <p>Hue values are distributed across the number of video formats.</p> </li> <li> <p>Stream Playback:</p> </li> <li> <p>The script retrieves the list of video formats and corresponding stream URLs.</p> </li> <li> <p>It downloads the individual streams and plays them.</p> </li> <li> <p>Hue Value Verification:</p> </li> <li> <p>After playing each stream, the script verifies whether the hue values were set correctly:</p> <ul> <li>User is prompted with: \"Is hue value {hue} applied for Picture Mode: {pictureMode} and Video Format: {videoFormat}? (Y/N):\"</li> <li>Users respond with Y (Yes) or N (No) based on the display.</li> </ul> </li> <li> <p>Logging Results:</p> </li> <li> <p>The script logs results based on user input for each hue value setting.</p> </li> <li> <p>Cleanup:</p> </li> <li> <p>After all verifications, the script stops the stream playback and cleans up the downloaded assets.</p> </li> <li> <p>Set Default Hue:</p> </li> <li> <p>After testing, the script sets all hue values back to a default value of 50.</p> </li> <li> <p>Test Conclusion:</p> </li> <li> <p>Once all settings are verified and defaults restored, the script logs the final results based on user responses.</p> </li> </ol>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#tvsettings_test50_savecolortemperaturepy","title":"tvSettings_test50_SaveColorTemperature.py","text":""},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#user-input-required-test50","title":"User Input Required - test50","text":"<p>Yes: This test requires manual verification to confirm whether the color temperature has been applied correctly for various picture modes and video formats. The user must respond to a prompt indicating whether the color temperature is correctly set.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#acceptance-criteria-test50","title":"Acceptance Criteria - test50","text":"<p>The system should save the correct color temperature values for all combinations of picture modes and video formats, and the user should be able to confirm the settings through manual verification.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#expected-results-test50","title":"Expected Results - test50","text":"<p>The script initializes the TV settings, saves color temperature values for different formats and modes, plays the streams, and prompts the user to verify whether the settings were applied correctly.</p> <p>Success Criteria</p> <ul> <li>Color temperature values are saved and applied correctly for each combination of picture mode and video format.</li> <li>User confirmation matches the expected color temperature levels.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#test-steps-test50","title":"Test Steps - test50","text":"<ol> <li> <p>Initiate the Test:</p> </li> <li> <p>Run the Python script: <code>tvSettings_test50_SaveColorTemperature.py</code></p> </li> <li> <p>Save Color Temperature Values:</p> </li> <li> <p>The script initializes the TV settings module and saves color temperature values for all combinations of picture modes and video formats.</p> </li> <li> <p>Color temperature values are assigned based on the available formats.</p> </li> <li> <p>Stream Playback:</p> </li> <li> <p>The script retrieves the list of video formats and corresponding stream URLs.</p> </li> <li> <p>It downloads the individual streams and plays them.</p> </li> <li> <p>Color Temperature Verification:</p> </li> <li> <p>After playing each stream, the script verifies whether the color temperature values were set correctly:</p> <ul> <li>User is prompted with: \"Is color temperature {colorTemperature} applied for Picture Mode: {pictureMode} and Video Format: {videoFormat}? (Y/N):\"</li> <li>Users respond with Y (Yes) or N (No) based on the display.</li> </ul> </li> <li> <p>Logging Results:</p> </li> <li> <p>The script logs results based on user input for each color temperature setting.</p> </li> <li> <p>Cleanup:</p> </li> <li> <p>After all verifications, the script stops the stream playback and cleans up the downloaded assets.</p> </li> <li> <p>Set Default Color Temperature:</p> </li> <li> <p>After testing, the script sets all color temperature values back to a default value of 'tvColorTemp_STANDARD'.</p> </li> <li> <p>Test Conclusion:</p> </li> <li> <p>Once all settings are verified and defaults restored, the script logs the final results based on user responses.</p> </li> </ol>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#tvsettings_test51_saveaspectratiopy","title":"tvSettings_test51_SaveAspectRatio.py","text":""},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#user-input-required-test51","title":"User Input Required - test51","text":"<p>Yes: This test requires manual verification to confirm whether the aspect ratio has been applied correctly for various picture modes and video formats. The user must respond to a prompt indicating whether the aspect ratio is correctly set.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#acceptance-criteria-test51","title":"Acceptance Criteria - test51","text":"<p>The system should save the correct aspect ratio values for all combinations of picture modes and video formats, and the user should be able to confirm the settings through manual verification.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#expected-results-test51","title":"Expected Results - test51","text":"<p>The script initializes the TV settings, saves aspect ratio values for different formats and modes, plays the streams, and prompts the user to verify whether the settings were applied correctly.</p> <p>Success Criteria</p> <ul> <li>Aspect ratio values are saved and applied correctly for each combination of picture mode and video format.</li> <li>User confirmation matches the expected aspect ratio levels.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#test-steps-test51","title":"Test Steps - test51","text":"<ol> <li> <p>Initiate the Test:</p> </li> <li> <p>Run the Python script: <code>tvSettings_test51_SaveAspectRatio.py</code></p> </li> <li> <p>Set Default Aspect Ratio:</p> </li> <li> <p>The script sets all aspect ratio values to a default value of 'tvDisplayMode_4x3'.</p> </li> <li> <p>Save Aspect Ratio Values:</p> </li> <li> <p>The script initializes the TV settings module and saves aspect ratio values for all combinations of picture modes and video formats.</p> </li> <li> <p>Aspect ratio values are assigned based on the available formats.</p> </li> <li> <p>Stream Playback:</p> </li> <li> <p>The script retrieves the list of video formats and corresponding stream URLs.</p> </li> <li> <p>It downloads the individual streams and plays them.</p> </li> <li> <p>Aspect Ratio Verification:</p> </li> <li> <p>After playing each stream, the script verifies whether the aspect ratio values were set correctly:</p> <ul> <li>User is prompted with: \"Is aspect ratio {aspectRatio} applied for Picture Mode: {pictureMode} and Video Format: {videoFormat}? (Y/N):\"</li> <li>Users respond with Y (Yes) or N (No) based on the display.</li> </ul> </li> <li> <p>Logging Results:</p> </li> <li> <p>The script logs results based on user input for each aspect ratio setting.</p> </li> <li> <p>Cleanup:</p> </li> <li> <p>After all verifications, the script stops the stream playback and cleans up the downloaded assets.</p> </li> <li> <p>Set Default Aspect Ratio Again:</p> </li> <li> <p>After testing, the script sets all aspect ratio values back to a default value of 'tvDisplayMode_4x3'.</p> </li> <li> <p>Test Conclusion:</p> </li> <li> <p>Once all settings are verified and defaults restored, the script logs the final results based on user responses.</p> </li> </ol>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#tvsettings_test52_savedolbyvisionpy","title":"tvSettings_test52_SaveDolbyVision.py","text":""},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#user-input-required-test52","title":"User Input Required - test52","text":"<p>Yes: This test requires manual verification to confirm whether the Dolby Vision setting has been applied correctly for various picture modes and video formats. The user must respond to a prompt indicating whether the setting is correctly applied.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#acceptance-criteria-test52","title":"Acceptance Criteria - test52","text":"<p>The system should save the correct Dolby Vision values for all combinations of picture modes and video formats, and the user should be able to confirm the settings through manual verification.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#expected-results-test52","title":"Expected Results - test52","text":"<p>The script initializes the TV settings, saves Dolby Vision values for different formats and modes, plays the streams, and prompts the user to verify whether the settings were applied correctly.</p> <p>Success Criteria</p> <ul> <li>Dolby Vision values are saved and applied correctly for each combination of picture mode and video format.</li> <li>User confirmation matches the expected Dolby Vision settings.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#test-steps-test52","title":"Test Steps - test52","text":"<ol> <li> <p>Initiate the Test:</p> </li> <li> <p>Run the Python script: <code>tvSettings_test52_SaveDolbyVision.py</code></p> </li> <li> <p>Save Dolby Vision Values:</p> </li> <li> <p>The script initializes the TV settings module and saves Dolby Vision values for all combinations of picture modes and video formats.</p> </li> <li> <p>Stream Playback:</p> </li> <li> <p>The script retrieves the list of video formats and corresponding stream URLs.</p> </li> <li> <p>It downloads the individual streams and plays them.</p> </li> <li> <p>Dolby Vision Verification:</p> </li> <li> <p>After playing each stream, the script verifies whether the Dolby Vision values were set correctly:</p> <ul> <li>User is prompted with: \"Is Dolby Vision '{dolbyVision}' applied for Picture Mode: {pictureMode} and Video Format: {videoFormat}? (Y/N):\"</li> <li>Users respond with Y (Yes) or N (No) based on the display.</li> </ul> </li> <li> <p>Logging Results:</p> </li> <li> <p>The script logs results based on user input for each Dolby Vision setting.</p> </li> <li> <p>Cleanup:</p> </li> <li> <p>After all verifications, the script stops the stream playback and cleans up the downloaded assets.</p> </li> <li> <p>Set Default Dolby Vision Again:</p> </li> <li> <p>After testing, the script sets all Dolby Vision values back to a default value of 'tvDolbyMode_Dark'.</p> </li> <li> <p>Test Conclusion:</p> </li> <li> <p>Once all settings are verified and defaults restored, the script logs the final results based on user responses.</p> </li> </ol>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#tvsettings_test53_savepicturemodepy","title":"tvSettings_test53_SavePictureMode.py","text":""},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#user-input-required-test53","title":"User Input Required - test53","text":"<p>Yes: This test requires manual verification to confirm whether the Picture Mode setting has been applied correctly for various video formats. The user must respond to a prompt indicating whether the setting is correctly applied.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#acceptance-criteria-test53","title":"Acceptance Criteria - test53","text":"<p>The system should save the correct Picture Mode values for all combinations of video formats, and the user should be able to confirm the settings through manual verification.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#expected-results-test53","title":"Expected Results - test53","text":"<p>The script initializes the TV settings, saves Picture Mode values for different formats, plays the streams, and prompts the user to verify whether the settings were applied correctly.</p> <p>Success Criteria</p> <ul> <li>Picture Mode values are saved and applied correctly for each combination of video format.</li> <li>User confirmation matches the expected Picture Mode settings.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#test-steps-test53","title":"Test Steps - test53","text":"<ol> <li> <p>Initiate the Test:</p> </li> <li> <p>Run the Python script: <code>tvSettings_test53_SavePictureMode.py</code></p> </li> <li> <p>Set Default Picture Mode:</p> </li> <li> <p>The script initializes the TV settings module and sets all Picture Modes to the default value of 'PQ_MODE_STANDARD'.</p> </li> <li> <p>Save Picture Mode Values:</p> </li> <li> <p>The script saves Picture Mode values for all combinations of video formats.</p> </li> <li> <p>Stream Playback:</p> </li> <li> <p>The script retrieves the list of video formats and corresponding stream URLs.</p> </li> <li> <p>It downloads the individual streams and plays them.</p> </li> <li> <p>Picture Mode Verification:</p> </li> <li> <p>After playing each stream, the script verifies whether the Picture Mode values were set correctly:</p> <ul> <li>User is prompted with: \"Is Picture Mode '{pictureMode}' applied for Video Format: {videoFormat}? (Y/N):\"</li> <li>Users respond with Y (Yes) or N (No) based on the display.</li> </ul> </li> <li> <p>Logging Results:</p> </li> <li> <p>The script logs results based on user input for each Picture Mode setting.</p> </li> <li> <p>Cleanup:</p> </li> <li> <p>After all verifications, the script stops the stream playback and cleans up the downloaded assets.</p> </li> <li> <p>Test Conclusion:</p> </li> <li> <p>Once all settings are verified, the script terminates the TV settings module and logs the final results based on user responses.</p> </li> </ol>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#tvsettings_test54_savecmspy","title":"tvSettings_test54_SaveCMS.py","text":""},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#user-input-required-test54","title":"User Input Required - test54","text":"<p>Yes: This test requires manual verification to confirm whether the CMS (Color Management System) values have been applied correctly for various picture modes and video formats. The user must respond to a prompt indicating whether the settings are correct.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#acceptance-criteria-test54","title":"Acceptance Criteria - test54","text":"<p>The system should save the correct CMS values for all combinations of picture modes, video formats, component types, and component colors, and the user should be able to confirm the settings through manual verification.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#expected-results-test54","title":"Expected Results - test54","text":"<p>The script initializes the TV settings, saves CMS values for different formats, plays the streams, and prompts the user to verify whether the settings were applied correctly.</p> <p>Success Criteria</p> <ul> <li>CMS values are saved and applied correctly for each combination of video format, picture mode, component type, and component color.</li> <li>User confirmation matches the expected CMS values.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#test-steps-test54","title":"Test Steps - test54","text":"<ol> <li> <p>Initiate the Test:</p> </li> <li> <p>Run the Python script: <code>tvSettings_test54_SaveCMS.py</code></p> </li> <li> <p>Save CMS Values:</p> </li> <li> <p>The script initializes the TV settings module and saves CMS values for selected formats by cycling through component types and colors.</p> </li> <li> <p>Stream Playback:</p> </li> <li> <p>The script retrieves the list of video formats and corresponding stream URLs.</p> </li> <li> <p>It downloads the individual streams and plays them.</p> </li> <li> <p>CMS Value Verification:</p> </li> <li> <p>After playing each stream, the script verifies whether the CMS values were set correctly:</p> <ul> <li>User is prompted with: \"Is CMS Value '{cmsValue}' applied for Picture Mode '{pictureMode}', Video Format '{videoFormat}', Component Type '{componentType}', and Component Color '{componentColor}'? (Y/N):\"</li> <li>Users respond with Y (Yes) or N (No) based on the display.</li> </ul> </li> <li> <p>Logging Results:</p> </li> <li> <p>The script logs results based on user input for each CMS setting.</p> </li> <li> <p>Cleanup:</p> </li> <li> <p>After all verifications, the script stops the stream playback and cleans up the downloaded assets.</p> </li> <li> <p>Log Captured Values:</p> </li> <li> <p>The script logs the captured CMS values for the video formats tested.</p> </li> <li> <p>Test Conclusion:</p> </li> <li> <p>Once all settings are verified, the script terminates the TV settings module and logs the final results based on user responses.</p> </li> </ol>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#tvsettings_test55_savegammatablepy","title":"tvSettings_test55_SaveGammaTable.py","text":""},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#user-input-required-test55","title":"User Input Required - test55","text":"<p>Yes: This test requires manual verification of gamma table settings for different color temperatures during stream playback.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#acceptance-criteria-test55","title":"Acceptance Criteria - test55","text":"<ul> <li>The device should apply the specified gamma table settings and color temperatures successfully during stream playback.</li> <li>User feedback should confirm that each gamma configuration and color temperature is applied correctly.</li> <li>All settings should reset to the default gamma values after testing.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#expected-results-test55","title":"Expected Results - test55","text":"<p>The test initializes the TV settings module, applies multiple gamma configurations with associated color temperatures, and requests user feedback on the application status.</p> <p>Success Criteria:</p> <ul> <li>Each gamma table configuration should apply correctly across different color temperatures during stream playback, as verified by the user.</li> <li>Verification results are logged for each configuration to indicate successful or unsuccessful application.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#test-steps-test55","title":"Test Steps - test55","text":"<ol> <li> <p>Initiate the Test:</p> </li> <li> <p>Run the Python file: <code>tvSettings_test55_SaveGammaTable.py</code></p> </li> <li> <p>The test initializes the TV settings module, loads test streams, and begins playback.</p> </li> <li> <p>Apply Gamma Table Settings:</p> </li> <li> <p>For each stream, the test:</p> <ul> <li>Begins playback.</li> <li>Iterates through each gamma table configuration:</li> <li>Assigns the gamma values to the color temperature.</li> <li>Logs the applied gamma values and color temperature.</li> <li>Sets the color temperature level.</li> <li>Verifies each configuration manually by prompting the user for feedback with a Y/N response.</li> <li>Logs the verification result for each gamma table configuration.</li> <li>Stops playback after testing all gamma configurations and color temperatures.</li> </ul> </li> <li> <p>Cleanup:</p> </li> <li> <p>The test terminates the <code>tvSettings</code> module after all verifications and resets.</p> </li> <li> <p>Test Conclusion:</p> </li> <li> <p>Upon completing all verifications for each gamma configuration across streams, the test concludes, logging each success or failure based on user feedback.</p> </li> </ol>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#tvsettings_test56_savedvtmaxvaluepy","title":"tvSettings_test56_SaveDvTmaxValue.py","text":""},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#user-input-required-test56","title":"User Input Required - test56","text":"<p>Yes: This test requires manual verification to confirm whether the Dolby Vision TMAX (TMAX) values have been applied correctly for various picture modes and video formats. The user must respond to prompts indicating whether the TMAX settings were correctly applied.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#acceptance-criteria-test56","title":"Acceptance Criteria - test56","text":"<p>The system should save the correct Dolby Vision TMAX values for all combinations of picture modes and video formats, and the user should be able to confirm the settings through manual verification.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#expected-results-test56","title":"Expected Results - test56","text":"<p>The script initializes the TV settings, saves TMAX values for different formats and modes, plays the streams, and prompts the user to verify whether the settings were applied correctly.</p>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#success-criteria","title":"Success Criteria","text":"<ul> <li>TMAX values are saved and applied correctly for each combination of picture mode and video format.</li> <li>User confirmation matches the expected TMAX levels.</li> </ul>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#test-steps-test56","title":"Test Steps - test56","text":"<ol> <li> <p>Initiate the Test:</p> </li> <li> <p>Run the Python script: <code>tvSettings_test56_SaveDvTmaxValue.py</code></p> </li> <li> <p>Save TMAX Values:</p> </li> <li> <p>The script initializes the TV settings module and saves TMAX values for all combinations of picture modes and video formats.</p> </li> <li> <p>TMAX values are distributed based on the number of video formats using a linear scaling approach.</p> </li> <li> <p>Stream Playback:</p> </li> <li> <p>The script retrieves the list of video formats and corresponding stream URLs.</p> </li> <li> <p>It downloads the individual streams and plays them.</p> </li> <li> <p>TMAX Verification:</p> </li> <li> <p>For each video format and picture mode combination:</p> <ul> <li>The script selects the LDIM state and picture mode based on modulus logic.</li> <li>The script sets the TMAX value and logs the operation.</li> <li>User is prompted with: \"Is TMAX value {tmaxValue} applied for Picture Mode: {pictureMode} and Video Format: {videoFormat}? (Y/N):\"</li> <li>Users respond with Y (Yes) or N (No) based on the display.</li> </ul> </li> <li> <p>Logging Results:</p> </li> <li> <p>The script logs the results of each verification step based on user input for TMAX settings.</p> </li> <li> <p>Cleanup:</p> </li> <li> <p>After all verifications, the script stops the stream playback and cleans up the downloaded assets.</p> </li> <li> <p>Set Default TMAX Value:</p> </li> <li> <p>After testing, the script sets all TMAX values back to a default value of 5000.</p> </li> <li> <p>Test Conclusion:</p> </li> <li> <p>Once all settings are verified and defaults restored, the script logs the final results based on user responses.</p> </li> </ol>"},{"location":"external_content/tvsettings_test/docs/pages/tv-settings_L3_TestProcedure/#tvsettings_l3_runallpy","title":"tvSettings_L3_Runall.py","text":"<p>This python file runs all the tests</p> <pre><code>python tvSettings_L3_Runall.py --config &lt;/PATH&gt;/ut/host/tests/configs/example_rack_config.yml --deviceConfig &lt;/PATH&gt;/ut/host/tests/configs/deviceConfig.yml\n</code></pre> <p>Note: If a test is not required on the platform, it can be added to the skipTests list.</p>"},{"location":"external_content/ut-core-wiki/1.-Standards-%26-Development-Process-Flow/","title":"1. Standards & Development Process Flow","text":""},{"location":"external_content/ut-core-wiki/1.-Standards-%26-Development-Process-Flow/#overview","title":"Overview","text":"<p>This document serves as a comprehensive guide and resource center for software development within the RDKCentral org, covering a wide range of topics from coding standards and testing methodologies to frequently asked questions and specific technology overviews.</p> <p>Here's a breakdown of the content:</p> <ul> <li>Standards &amp; Best Practices: This section provides detailed guidelines on coding standards, documentation practices, branching strategies, and interface development, ensuring consistency and quality across projects.</li> <li>Testing Methodologies:  It outlines various testing levels and frameworks, including Test-Driven Development (TDD) and system interface testing, emphasizing the importance of robust testing in the development life-cycle.</li> <li>Code Examples &amp; Advanced Topics:  This section offers practical code examples for dynamic library loading and plugin development, and delves into advanced concepts like virtual device development and control plane overviews.</li> <li>FAQ &amp; Troubleshooting:  A comprehensive FAQ section addresses common challenges and questions related to Git workflows, Vagrant setup,  C macros, testing techniques, and RDK-specific tools.</li> <li>Technology Overviews:  Provides concise explanations of key technologies and frameworks used within the organization, such as the UT-Core framework and RDK Docker tool-chain.</li> </ul> <p>By centralizing this information, the document aims to streamline development processes, reduce on boarding time for new developers, and promote best practices across the organization.</p>"},{"location":"external_content/ut-core-wiki/1.-Standards-%26-Development-Process-Flow/#10-getting-started-with-contribution","title":"1.0 Getting Started with Contribution","text":"<p>To contribute to the RDK, you'll need to choose a delivery model:</p> <p>RDK Central Partners: If you're an RDK Central partner, you might be eligible to contribute as a Tier 1 developer. Please contact [RDK Support Team](mailto:support@rdkcentral.com) to confirm your eligibility.</p> <ul> <li>1.0. Standards: Tier 1 Operator Guide: Branching for Direct Contributions</li> <li>1.0.1 Standards: Tier 2 Operator Guide: Forking for External Contributions</li> </ul>"},{"location":"external_content/ut-core-wiki/1.-Standards-%26-Development-Process-Flow/#11-coding-standards-useful-reading-on-coding-standards","title":"1.1 Coding Standards: Useful reading on coding standards","text":"<p>This section offers resources and guidelines on coding standards, including recommended reading, issue/milestone descriptions, commit message conventions, and semantic versioning.</p> <ul> <li>1.1. Standards: Principles from Code Complete</li> <li>1.2. Standards: Issue Description Guideline</li> <li>1.3. Standards: Milestone Description Guideline</li> <li>1.4. Standards: Commit Message: The 50-72 Rule: A Simple Guide</li> <li>1.5. Standards: Semantic Versioning and Testing Suite Alignment</li> </ul>"},{"location":"external_content/ut-core-wiki/1.-Standards-%26-Development-Process-Flow/#2-general-information","title":"2. General Information","text":"<p>This section provides general information on key topics like documentation standards, branching strategies, interface modification procedures, and repository access policies.</p> <ul> <li>2 Single Source of Truth - HAL Interfaces and Testing Suites</li> <li>2.1. Doxygen: Crafting Excellent Documentation</li> <li>2.2. Standards: Forking And Branching</li> <li>2.3. Standards: Performing Changes to an interface</li> <li>2.4.-Standards:-Repository-Access-and-Branch-Protection-Policy</li> <li>2.5.-Standards:-Feature-Branch-Workflow</li> </ul>"},{"location":"external_content/ut-core-wiki/1.-Standards-%26-Development-Process-Flow/#3-testing","title":"3. Testing","text":"<p>This section outlines testing standards and best practices, covering various levels and types of testing, including TDD and system interface testing.</p> <ul> <li>3.0.0 Standards: Levels of Test for Vendor Layer</li> <li>3.0.1 Standards: Testing Feedback Loops</li> <li>3.1.0 Standards: Overview of Test Driven Development (TDD)</li> <li>3.2.0 Standards: Requirements for building testing suites</li> <li>3.3.0 Standards: L4: System Interface Testing</li> <li>3.4.0 Standards: L4: Vendor Full Stack: Video Smoke Regression Test</li> </ul>"},{"location":"external_content/ut-core-wiki/1.-Standards-%26-Development-Process-Flow/#4-code-examples","title":"4. Code Examples","text":"<p>This section provides code examples demonstrating key standards like dynamic library loading and plugin implementation.</p> <ul> <li>4. Standards: Dynamic Library Loading for Vendor Abstraction</li> <li>4.1 Standards: Dynamically Installable Plug-ins In C</li> </ul>"},{"location":"external_content/ut-core-wiki/1.-Standards-%26-Development-Process-Flow/#5-virtual-device","title":"5. Virtual Device","text":"<p>This section provides an overview of the virtual device (vDevice) and its control plane.</p> <ul> <li>5.0: Standards:-vDevice Overview</li> <li>5.1: Standards: Control Plane Overview)</li> </ul>"},{"location":"external_content/ut-core-wiki/1.-Standards-%26-Development-Process-Flow/#6-training-material","title":"6. Training Material","text":"<p>This section provides resources to help you get started with contributing to the project.</p> <p>Currently available training:</p> <ul> <li>T1: Training: CODEOWNERS: Ensuring Code Quality and Governance: This training explains the <code>CODEOWNERS</code> file and its role in ensuring code quality and proper governance within the project.</li> </ul>"},{"location":"external_content/ut-core-wiki/1.-Standards-%26-Development-Process-Flow/#7-faq","title":"7. FAQ","text":"<p>The FAQ section provides quick answers to common questions, saving users time and effort. Organized by topic, it offers easy access to essential information. </p> <ul> <li>FAQ: Git Flow Support for Multiple mainlines</li> <li>FAQ: Git\u2010Flow: Developers Branching Model</li> <li>FAQ: Release Engineers: Performing a release with git flow</li> <li>FAQ:-Vagrant: Setting Up and Managing Your Vagrant-VM</li> <li>FAQ: Migrating Binaries to <code>Git-LFS</code></li> <li>FAQ: C macro that prints the function name, parameter names with values</li> <li>FAQ: C Macro that prints structure fields</li> <li>FAQ: Black-Box Testing and Code Coverage Metrics</li> <li>FAQ: RDK Docker Toolchain</li> <li>FAQ: Video and Audio Playback Performance Metrics</li> <li>FAQ: Choosing GHEC-ORG or RDKCentral</li> <li>FAQ: Comparing Python Development Platforms</li> <li>FAQ: UT-Core Framework Overview</li> <li>FAQ: Sign up for RDK Central Tier-1 Registration </li> <li>FAQ: Buildroot vs. Yocto Project vs. Bob the Builder</li> <li>FAQ: Software Post Release Development Cycle</li> </ul>"},{"location":"external_content/ut-core-wiki/1.0.-Standards%3A-Tier-1-Operator-Guide%3A-Branching-for-Direct-Contributions/","title":"1.0. Standards: Tier 1 Operator Guide: Branching for Direct Contributions","text":""},{"location":"external_content/ut-core-wiki/1.0.-Standards%3A-Tier-1-Operator-Guide%3A-Branching-for-Direct-Contributions/#tier-1-operator-guide-branching-for-direct-contributions","title":"Tier 1 Operator Guide: Branching for Direct Contributions","text":""},{"location":"external_content/ut-core-wiki/1.0.-Standards%3A-Tier-1-Operator-Guide%3A-Branching-for-Direct-Contributions/#overview-of-contributions","title":"Overview of Contributions","text":"<p>We welcome contributions from all community members, both Tier 1 (direct access) and Tier 2 (forked workflow) contributors. Your participation is vital to the project's success. Here's how you can get involved:</p> <ul> <li>Code Contributions: We invite you to contribute code, whether it's new features or bug fixes. Please follow the detailed steps below to ensure your contributions align with our project standards.</li> <li>Issue Reporting: If you discover bugs or have enhancement suggestions, please raise an issue in the repository. Your reports help us improve the project efficiently.</li> <li>Discussions and Ideas: We encourage you to initiate discussions on various topics related to the project. Your insights and feedback drive continuous improvement and innovation.</li> </ul> <p>Access Levels and Workflows</p> <ul> <li> <p>Tier 1 Operators (Direct Access): You have direct write access to the main repository. Follow the branching workflow detailed below. see the Tier 1 Registration Process</p> </li> <li> <p>Tier 2 Operators (Forked Workflow): You don't have direct write access. Contribute by forking the repository, see the Tier 2 Guide Operator Guide for detailed instructions.</p> </li> </ul>"},{"location":"external_content/ut-core-wiki/1.0.-Standards%3A-Tier-1-Operator-Guide%3A-Branching-for-Direct-Contributions/#contributor-license-agreement-cla","title":"Contributor License Agreement (CLA)","text":"<p>Before your contributions can be accepted into the project, you must sign the RDK Contributor License Agreement (CLA). This legal document ensures that you have the rights to contribute the code and that the community can use your contributions freely. First-time contributors will need to complete the license agreement before their code can be merged:</p>"},{"location":"external_content/ut-core-wiki/1.0.-Standards%3A-Tier-1-Operator-Guide%3A-Branching-for-Direct-Contributions/#getting-started-with-git-collaboration","title":"Getting Started with Git Collaboration","text":""},{"location":"external_content/ut-core-wiki/1.0.-Standards%3A-Tier-1-Operator-Guide%3A-Branching-for-Direct-Contributions/#1-clone-the-repository","title":"1. Clone the Repository","text":"<p>To start, clone the repository to your local machine: <pre><code>git clone https://github.com/rdkcentral/ut-core.git\n</code></pre></p>"},{"location":"external_content/ut-core-wiki/1.0.-Standards%3A-Tier-1-Operator-Guide%3A-Branching-for-Direct-Contributions/#2-set-up-git-flow","title":"2. Set Up Git Flow","text":"<p>We use the Git Flow branching model for managing branches. If you're new to Git Flow, please review this guide:</p> <p>Example of initialising git flow:</p> <pre><code>git flow init -d\n</code></pre>"},{"location":"external_content/ut-core-wiki/1.0.-Standards%3A-Tier-1-Operator-Guide%3A-Branching-for-Direct-Contributions/#3-create-a-feature-branch","title":"3. Create a Feature Branch","text":"<p>Create a new feature branch from the 'develop' branch for both new features and bug fixes, adhering to the naming convention: feature/gh_. The  should briefly summarize the branch's purpose. <p>Example of creating a feature branch:</p> <pre><code>git flow feature start 123_add-logging-enhancements\n</code></pre> <p>Compliance Notice: All contributors must strictly follow our Git branching guidelines. Every branch must be accurately named using the corresponding issue ID from our issue tracker, ensuring traceability and upholding automated workflow integrity. Incorrectly named or untraceable branches will fall under a retention policy, allowing for correction within 30 days before removal. This policy is crucial for maintaining the clarity and reliability of our project management processes.</p>"},{"location":"external_content/ut-core-wiki/1.0.-Standards%3A-Tier-1-Operator-Guide%3A-Branching-for-Direct-Contributions/#4-implement-changes","title":"4. Implement Changes","text":"<p>Make changes according to the project\u2019s coding guidelines.</p>"},{"location":"external_content/ut-core-wiki/1.0.-Standards%3A-Tier-1-Operator-Guide%3A-Branching-for-Direct-Contributions/#5-commit-your-changes","title":"5. Commit Your Changes","text":"<p>Ensure your commits are clear and adhere to the 50/72 rule:</p> <ul> <li>Summary: Start with an imperative verb, include the GitHub issue ID, and succinctly describe the change.</li> <li>Body: Optionally, provide a detailed explanation, keeping lines to 72 characters.</li> </ul> <p>Example of a Commit Message:</p> <pre><code>Fix #123: Update error handling in authentication module\n\nThis commit enhances error detection and adds comprehensive logging to address frequent issues reported by users.\n</code></pre>"},{"location":"external_content/ut-core-wiki/1.0.-Standards%3A-Tier-1-Operator-Guide%3A-Branching-for-Direct-Contributions/#6-push-changes","title":"6. Push Changes","text":"<p>Push your changes to the repository: <pre><code>git push origin feature/gh123_add-logging-enhancements\n</code></pre></p>"},{"location":"external_content/ut-core-wiki/1.0.-Standards%3A-Tier-1-Operator-Guide%3A-Branching-for-Direct-Contributions/#7-open-a-pull-request","title":"7. Open a Pull Request","text":"<p>Create a pull request from your branch to the <code>develop</code> branch. It will be automatically assigned for review based on the <code>CODEOWNERS</code> file.</p>"},{"location":"external_content/ut-core-wiki/1.0.-Standards%3A-Tier-1-Operator-Guide%3A-Branching-for-Direct-Contributions/#8-merge-the-pull-request","title":"8. Merge the Pull Request","text":"<p>Once approved, merge your branch using Git Flow: <pre><code>git flow feature finish gh123_add-logging-enhancements\n</code></pre></p>"},{"location":"external_content/ut-core-wiki/1.0.-Standards%3A-Tier-1-Operator-Guide%3A-Branching-for-Direct-Contributions/#9-code-ownership-and-releases","title":"9. Code Ownership and Releases","text":"<p><code>CODEOWNERS</code> are responsible for reviewing and approving changes. They also manage the release and tagging of components according to the project\u2019s schedule.</p> <p>Example of the CODEOWNERS file:</p> <pre><code># Default owners for everything in the repo\n*       @rdkcentral/ut-core_codeowner\n</code></pre>"},{"location":"external_content/ut-core-wiki/1.0.-Standards%3A-Tier-1-Operator-Guide%3A-Branching-for-Direct-Contributions/#requirements-for-contributions","title":"Requirements for Contributions","text":"<p>Please ensure your contributions meet the following: - Adherence to Git Flow - Clear and Concise Commit Messages - Peer Review Approval - Open Discussions and Contributions</p> <p>By following these guidelines, you help maintain the quality and integrity of the project while fostering an inclusive and collaborative community environment. We look forward to your contributions, and thank you for being part of our community-driven project.</p>"},{"location":"external_content/ut-core-wiki/1.0.1-Standards%3A-Tier-2-Operator-Guide%3A-Forking-for-External-Contributions/","title":"1.0.1 Standards: Tier 2 Operator Guide: Forking for External Contributions","text":""},{"location":"external_content/ut-core-wiki/1.0.1-Standards%3A-Tier-2-Operator-Guide%3A-Forking-for-External-Contributions/#tier-2-operator-guide-forking-for-external-contributions","title":"Tier 2 Operator Guide: Forking for External Contributions","text":""},{"location":"external_content/ut-core-wiki/1.0.1-Standards%3A-Tier-2-Operator-Guide%3A-Forking-for-External-Contributions/#introduction","title":"Introduction","text":"<p>Welcome to the Tier 2 Operator Guide! This guide is tailored for engineers and third-party contributors who want to enhance the project but don't have direct write access to the main repository. Forking is your key tool, enabling you to experiment and contribute without impacting the original code base.</p>"},{"location":"external_content/ut-core-wiki/1.0.1-Standards%3A-Tier-2-Operator-Guide%3A-Forking-for-External-Contributions/#what-is-forking","title":"What is Forking?","text":"<p>Forking creates a personal copy of a repository on your own GitHub account. This copy is entirely independent, allowing you to modify the code freely without affecting the original project. It's like having your own sandbox to play in!</p>"},{"location":"external_content/ut-core-wiki/1.0.1-Standards%3A-Tier-2-Operator-Guide%3A-Forking-for-External-Contributions/#why-fork","title":"Why Fork?","text":"<ul> <li>Safe Experimentation:  Explore new ideas, fix bugs, or add features without the risk of breaking the main project.</li> <li>Contribution Pathway:  Once your changes are ready, you can submit them as a pull request to the original repository for consideration.</li> <li>Open Source Collaboration:  Forking is the cornerstone of open-source contribution, empowering individuals and teams to work together.</li> </ul>"},{"location":"external_content/ut-core-wiki/1.0.1-Standards%3A-Tier-2-Operator-Guide%3A-Forking-for-External-Contributions/#step-by-step-forking-workflow","title":"Step-by-Step Forking Workflow","text":"<ol> <li>Find the Repository: Locate the project's repository on GitHub.</li> <li>Click \"Fork\":  You'll find this button at the top right corner of the repository page.</li> <li>Choose Destination: Select your GitHub account as the destination for the fork.</li> <li>Clone Your Fork: Clone your newly created fork to your local machine using Git.    <pre><code>git clone https://github.com/&lt;your-username&gt;/&lt;repository-name&gt;.git\n</code></pre></li> <li>Create a Branch: (Optional but recommended) Create a new branch for your specific changes. This keeps your work organized.    <pre><code>git checkout -b feature/my-new-feature\n</code></pre></li> <li>Make Changes: Edit, add, or remove files as needed.</li> <li>Commit Changes: Save your work regularly with clear and descriptive commit messages.    <pre><code>git commit -m \"Add new feature: &lt;description&gt;\"\n</code></pre></li> <li>Push Changes: Upload your commits to your forked repository on GitHub.    <pre><code>git push origin feature/my-new-feature\n</code></pre></li> <li>Create a Pull Request:  Navigate to the original repository and click \"New Pull Request.\" Select your fork and branch, then provide a detailed description of your changes.</li> <li>Collaboration &amp; Review: The maintainers of the original repository will review your pull request, offer feedback, and potentially merge your changes if they align with the project's goals.</li> </ol>"},{"location":"external_content/ut-core-wiki/1.0.1-Standards%3A-Tier-2-Operator-Guide%3A-Forking-for-External-Contributions/#important-considerations","title":"Important Considerations","text":"<ul> <li>Keep Your Fork Up-to-Date:  Regularly sync your fork with the original repository to avoid conflicts.</li> <li>Clear Communication: In your pull request, clearly explain the purpose and benefits of your changes.</li> <li>Be Patient: The review process might take some time.  Be open to feedback and iterate as needed.</li> <li>Respect Project Guidelines: Follow the project's coding conventions and contribution guidelines.</li> </ul> <p>Refer to the RDK Documentation how_to_contribute</p>"},{"location":"external_content/ut-core-wiki/1.1.-Standards%3A-Principles-from-Code-Complete/","title":"Standards: Principles from Code Complete (C/C++)","text":"<p>This coding standard is inspired by the principles in Steve McConnell's Code Complete, aiming for clarity, maintainability, and robustness:</p> <ul> <li>\"Effective software construction practices are crucial for maintaining code quality.\"</li> </ul>"},{"location":"external_content/ut-core-wiki/1.1.-Standards%3A-Principles-from-Code-Complete/#1-layout-and-formatting","title":"1. Layout and Formatting","text":"<ul> <li>Indentation: Use consistent indentation (spaces, not tabs) to clearly show code structure.</li> <li>Line Length: Keep lines to a reasonable length (around 80 characters).</li> <li>Whitespace: Use blank lines to separate logical sections.</li> <li>Braces: Always use braces for blocks, even for single-statement blocks. Place each brace on a new line.</li> </ul> <pre><code>// GOOD\nif (x &gt; 0)\n{\n    std::cout &lt;&lt; \"x is positive\\n\";\n}\nelse\n{\n    std::cout &lt;&lt; \"x is not positive\\n\";\n}\n\n// BAD (no braces for single-statement block)\nif (x &gt; 0)\n    std::cout &lt;&lt; \"x is positive\\n\";\n</code></pre>"},{"location":"external_content/ut-core-wiki/1.1.-Standards%3A-Principles-from-Code-Complete/#2-naming-conventions","title":"2. Naming Conventions","text":""},{"location":"external_content/ut-core-wiki/1.1.-Standards%3A-Principles-from-Code-Complete/#function-naming-rules","title":"Function Naming Rules","text":"<ol> <li>Use Descriptive Names: Names should clearly convey function intent.</li> </ol> <pre><code>// GOOD\ndouble calculateInvoiceTotal();\nvoid sendEmailNotification();\n\n// BAD\ndouble process();\nvoid doTask();\n</code></pre> <ol> <li>Prefer Verbs: Functions perform actions, so use verbs.</li> </ol> <pre><code>// GOOD\nbool validateUser(int id);\nstd::string fetchCustomerData(int customerId);\n\n// BAD\nbool checkUser(int id);\nstd::string getData(int customerId);\n</code></pre> <ol> <li>Be Consistent: Stick to uniform naming conventions across the project.</li> </ol> <pre><code>// GOOD\nstd::string fetchUserInfo();\nvoid updateUserProfile();\n\n// BAD (Inconsistent naming)\nstd::string retrieveUserInfo();\nvoid modifyUserProfile();\n</code></pre> <ol> <li>Avoid Ambiguity: Names should be precise.</li> </ol> <pre><code>// GOOD\nvoid validateUserInput(std::string input);\n\n// BAD\nvoid handleInput(std::string input);\n</code></pre> <ol> <li>Concise but Clear: Function names should be long enough for clarity but not overly verbose.</li> </ol> <pre><code>// GOOD\nvoid loadUserPreferences();\n\n// BAD\nvoid loadUserPreferencesFromDatabaseIfPresentOtherwiseUseDefaults();\n</code></pre> <ol> <li>No Generic Words: Avoid vague terms like <code>data</code> or <code>info</code>.</li> </ol> <pre><code>// GOOD\nvoid saveUserSettings();\n\n// BAD\nvoid saveData();\n</code></pre> <ol> <li>Match Behavior to Name: Boolean functions should reflect expected values.</li> </ol> <pre><code>// GOOD\nbool isValid();\n\n// BAD\nbool checkValidity();\n</code></pre> <ol> <li>Avoid Negatives: Prefer positive naming conventions.</li> </ol> <pre><code>// GOOD\nbool isAvailable();\n\n// BAD\nbool isNotAvailable();\n</code></pre> <ol> <li>Easy to Pronounce: Clear naming improves communication.</li> </ol> <pre><code>// GOOD\ndouble computeAverage();\n\n// BAD\ndouble cmpAvg();\n</code></pre> <ol> <li>Reflect Expected Output: Ensure function names indicate return values.</li> </ol> <pre><code>// GOOD\nstd::string getUserName();\nint countActiveSessions();\n\n// BAD\nstd::string fetch();\nint sessions();\n</code></pre>"},{"location":"external_content/ut-core-wiki/1.1.-Standards%3A-Principles-from-Code-Complete/#3-comments-and-documentation","title":"3. Comments and Documentation","text":""},{"location":"external_content/ut-core-wiki/1.1.-Standards%3A-Principles-from-Code-Complete/#clear-comments","title":"Clear Comments","text":"<p>Use comments to explain why a piece of code exists, rather than just describing what it does.</p> <pre><code>// Calculate average temperature to assess if heating is needed\nfloat avg_temperature = calculateAverage(temperatures, num_readings);\n</code></pre>"},{"location":"external_content/ut-core-wiki/1.1.-Standards%3A-Principles-from-Code-Complete/#doxygen-comments-c","title":"Doxygen Comments (C++)","text":"<pre><code>/**\n * Calculates the area of a circle.\n * @param radius The radius of the circle.\n * @return The computed area.\n */\ndouble calculateCircleArea(double radius) \n{\n    return M_PI * radius * radius;\n}\n</code></pre>"},{"location":"external_content/ut-core-wiki/1.1.-Standards%3A-Principles-from-Code-Complete/#4-functions-and-modules","title":"4. Functions and Modules","text":""},{"location":"external_content/ut-core-wiki/1.1.-Standards%3A-Principles-from-Code-Complete/#single-responsibility-principle-srp","title":"Single Responsibility Principle (SRP)","text":"<p>Each function should have a single well-defined responsibility.</p> <pre><code>// GOOD\ndouble calculateTax(double price, double tax_rate);\n\n// BAD (Multiple Responsibilities)\nvoid processOrder(Order* order);\n</code></pre>"},{"location":"external_content/ut-core-wiki/1.1.-Standards%3A-Principles-from-Code-Complete/#guard-clauses-for-error-handling","title":"Guard Clauses for Error Handling","text":"<pre><code>int divide(int numerator, int denominator) \n{\n    if (denominator == 0) \n    {\n        throw std::runtime_error(\"Error: Division by zero\");\n    }\n    return numerator / denominator;\n}\n</code></pre>"},{"location":"external_content/ut-core-wiki/1.1.-Standards%3A-Principles-from-Code-Complete/#5-error-handling-c","title":"5. Error Handling (C++)","text":"<pre><code>try \n{\n    int result = divide(10, 0);\n} \ncatch (const std::runtime_error&amp; e) \n{\n    std::cerr &lt;&lt; \"Error: \" &lt;&lt; e.what() &lt;&lt; std::endl;\n}\n</code></pre>"},{"location":"external_content/ut-core-wiki/1.1.-Standards%3A-Principles-from-Code-Complete/#6-object-oriented-programming","title":"6. Object-Oriented Programming","text":""},{"location":"external_content/ut-core-wiki/1.1.-Standards%3A-Principles-from-Code-Complete/#encapsulation","title":"Encapsulation","text":"<pre><code>class BankAccount \n{\nprivate:\n    double balance;\npublic:\n    void deposit(double amount) \n    {\n        balance += amount;\n    }\n    double getBalance() const \n    {\n        return balance;\n    }\n};\n</code></pre>"},{"location":"external_content/ut-core-wiki/1.1.-Standards%3A-Principles-from-Code-Complete/#inheritance-and-polymorphism","title":"Inheritance and Polymorphism","text":"<pre><code>class Animal \n{\npublic:\n    virtual void makeSound() const = 0; // Pure virtual function \n};\n\nclass Dog : public Animal \n{\npublic:\n    void makeSound() const override \n    {\n        std::cout &lt;&lt; \"Woof!\\n\";\n    }\n};\n\nclass Cat : public Animal \n{\npublic:\n    void makeSound() const override \n    {\n        std::cout &lt;&lt; \"Meow!\\n\";\n    }\n};\n</code></pre>"},{"location":"external_content/ut-core-wiki/1.1.-Standards%3A-Principles-from-Code-Complete/#7-testing-and-quality-assurance","title":"7. Testing and Quality Assurance","text":""},{"location":"external_content/ut-core-wiki/1.1.-Standards%3A-Principles-from-Code-Complete/#unit-tests","title":"Unit Tests","text":"<pre><code>// Example (using Google Test framework)\nTEST(MathTest, Addition) \n{\n    EXPECT_EQ(add(2, 3), 5);\n    EXPECT_EQ(add(-1, 1), 0);\n}\n</code></pre>"},{"location":"external_content/ut-core-wiki/1.1.-Standards%3A-Principles-from-Code-Complete/#code-reviews-and-automated-testing","title":"Code Reviews and Automated Testing","text":"<ul> <li>Use linters like Clang-Tidy for code style.</li> <li>Use static analysis tools for bug detection.</li> </ul>"},{"location":"external_content/ut-core-wiki/1.1.-Standards%3A-Principles-from-Code-Complete/#8-collaboration-and-communication","title":"8. Collaboration and Communication","text":""},{"location":"external_content/ut-core-wiki/1.1.-Standards%3A-Principles-from-Code-Complete/#clear-commit-messages-example","title":"Clear Commit Messages (Example)","text":"<pre><code>Added error handling for invalid file input in processData() function. \n</code></pre> <p>See also Commit Message: The 50/72 Rule</p>"},{"location":"external_content/ut-core-wiki/1.1.-Standards%3A-Principles-from-Code-Complete/#documentation","title":"Documentation:","text":"<ul> <li>Use comments within the code for complex logic.</li> <li>Maintain external documentation (README files, wikis, etc.).</li> </ul>"},{"location":"external_content/ut-core-wiki/1.1.-Standards%3A-Principles-from-Code-Complete/#references","title":"References","text":"<ul> <li>McConnell, S. (2004). Code Complete: A Practical Handbook of Software Construction (2nd ed.). Microsoft Press. Retrieved from GitHub Repository</li> </ul>"},{"location":"external_content/ut-core-wiki/1.2.-Standards%3A-Issue-Description-Guideline/","title":"GitHub Issue Best Practices: Writing Clear and Actionable Tasks/Bugs &amp; Feature Requests","text":""},{"location":"external_content/ut-core-wiki/1.2.-Standards%3A-Issue-Description-Guideline/#why-issue-quality-matters","title":"Why Issue Quality Matters","text":"<ul> <li>Clear Communication: Well-written issues and feature requests ensure everyone understands the requirements and context within the project.</li> <li>Efficient Collaboration: Good documentation helps developers prioritise their efforts, leading to faster resolution times.</li> <li>Trackable Progress:  Clearly defined issues and features make it easier to track progress and assess project status.</li> </ul>"},{"location":"external_content/ut-core-wiki/1.2.-Standards%3A-Issue-Description-Guideline/#core-principles-for-effective-tasksbugs-feature-requests","title":"Core Principles for Effective Tasks/Bugs &amp; Feature Requests","text":"<ol> <li>Problem or Opportunity-Focused: Describe the specific problem you're facing or the opportunity for enhancement. Be detailed and provide relevant context.</li> <li>Concise and Actionable: Clearly state what needs to be fixed or implemented to address the problem/opportunity.</li> </ol>"},{"location":"external_content/ut-core-wiki/1.2.-Standards%3A-Issue-Description-Guideline/#bug-template-recommended","title":"Bug Template (Recommended)","text":"<ul> <li>GitHub Title: <code>Bug:&lt;Short summary of the problem&gt;</code></li> <li>Set the GitHub Issue Type: <code>BUG</code></li> <li>Set the GitHub Label: e.g. <code>Bug</code></li> <li>Set the GitHub Project Field: Engineering Workflow Project Template</li> </ul> <pre><code>### Description:\n\n**Problem:** &lt;Clearly stating the problem upfront is crucial for understanding the issue..&gt;\n\n**Steps to Reproduce:** &lt;If applicable, This is essential for bugs, allowing others to replicate the problem and verify solutions.&gt;\n\n**Expected Behaviour:** &lt;Explain what should happen instead of the current behaviour.&gt;\n\n**Actual Behaviour:** &lt;Describe what is currently happening, highlighting the discrepancy with the expected behaviour.&gt;\n\n### Notes (Optional):\n\n* &lt;Any other helpful info, environment, links, screenshots, Error messages, console logs, relevant code snippets&gt;\n</code></pre>"},{"location":"external_content/ut-core-wiki/1.2.-Standards%3A-Issue-Description-Guideline/#task-template-recommended","title":"Task Template (Recommended)","text":"<ul> <li>GitHub Title: <code>Task:&lt;Short summary of the problem&gt;</code></li> <li>Set the GitHub Issue Type: <code>TASK</code></li> <li>Set the GitHub Label: e.g. <code>documentation</code> or <code>enhancement</code></li> <li>Set the GitHub Project Field: Engineering Workflow Project Template</li> </ul> <pre><code>### Description:\n\n* Goal: &lt;Clearly stating the goal of the task is crucial for understanding the requirement..&gt;\n\n### Notes (Optional):\n\n* &lt;Any other helpful info, environment, links&gt;\n</code></pre>"},{"location":"external_content/ut-core-wiki/1.2.-Standards%3A-Issue-Description-Guideline/#feature-request-template-recommended","title":"Feature Request Template (Recommended):","text":"<ul> <li>GitHub Issue Title: <code>Feature: &lt;Short summary of the problem&gt;</code></li> <li>Set the GitHub Issue Type: <code>FEATURE</code></li> <li>Set the GitHub Label: <code>Documentation</code>, <code>Enhancement</code>, <code>Bug</code> etc.</li> <li>Set the GitHub Project Field: Engineering Workflow Project Template</li> </ul> <pre><code>### Description:\n\n**Problem/Opportunity:** &lt;Describe the user need or problem this feature solves/improves.&gt;\n\n**Proposed Solution:** &lt;Explain your idea for the feature and how it addresses the problem/opportunity.&gt;\n\n### Acceptance Criteria: (Optional)\n\n* &lt;Specific condition 1&gt;\n* &lt;Specific condition 2&gt;\n* ...\n\n### Additional Notes (Optional):\n* &lt;Mockups, sketches, wireframes, etc.&gt;\n</code></pre>"},{"location":"external_content/ut-core-wiki/1.2.-Standards%3A-Issue-Description-Guideline/#examples-of-good-and-bad-feature-requests","title":"Examples of Good and Bad Feature Requests","text":"Bad Feature Request Good Feature Request Title: \"Add more stuff\" Title: \"Add a \"Dark Mode\" toggle to the user interface\" Description: \"We need more features.\" Description:  Many users have requested a dark mode option to reduce eye strain, especially during nighttime usage. This feature would improve accessibility and user experience."},{"location":"external_content/ut-core-wiki/1.2.-Standards%3A-Issue-Description-Guideline/#additional-tips","title":"Additional Tips","text":"<ul> <li>Prioritise: Not all features can be implemented at once. Discuss and prioritise requests based on their impact and feasibility.</li> <li>Collaborate: Encourage feedback and discussion from the team and stakeholders to refine feature requests.</li> <li>Keep it Updated: As development progresses, update feature requests with new information or changes in scope.</li> </ul>"},{"location":"external_content/ut-core-wiki/1.2.-Standards%3A-Issue-Description-Guideline/#lets-write-better-issues-and-feature-requests-together","title":"Let's Write Better Issues and Feature Requests Together!","text":"<p>By following these guidelines, we can improve our communication and collaboration, leading to more focused development and successful project outcomes.  </p> <p>Questions? Feedback? Reach out to your team lead or project manager for assistance.</p>"},{"location":"external_content/ut-core-wiki/1.3.-Standards%3A-Milestone-Description-Guideline/","title":"GitHub Milestone Description Guideline","text":"<p>This guide exists to empower teams using GitHub to communicate project progress clearly and effectively.  By standardizing the way milestones are described, including the use of semantic versioning, it ensures that everyone involved (developers, project managers, stakeholders) has a shared understanding of the project's trajectory. This leads to better coordination, informed decision-making, and ultimately, a higher likelihood of successful project delivery.</p>"},{"location":"external_content/ut-core-wiki/1.3.-Standards%3A-Milestone-Description-Guideline/#1-title-for-release-milestone-with-semantic-version-tag","title":"1. Title for Release Milestone (with Semantic Version Tag):","text":"<ul> <li>Use a brief, action-oriented title that summarizes the milestone's core purpose.</li> <li>Include a semantic version tag at the beginning of the title. This tag should follow the Major.Minor.Patch/Bugfix format (e.g., 1.2.0, 0.1.3).</li> <li>Include repository name in milestone titles to streamline planning.</li> </ul>"},{"location":"external_content/ut-core-wiki/1.3.-Standards%3A-Milestone-Description-Guideline/#examples","title":"Examples:","text":"<pre><code>1.0.0 - ut_core: Initial Release\n</code></pre> <pre><code>0.3.1 - ut_core: Beta Testing\n</code></pre> <pre><code>2.5.0 - ut_core: Major Feature Upgrade.\n</code></pre>"},{"location":"external_content/ut-core-wiki/1.3.-Standards%3A-Milestone-Description-Guideline/#11-title-for-internal-milestone","title":"1.1 Title for Internal Milestone:","text":"<ul> <li>Use a brief, descriptive title that highlights the phased delivery nature of the milestone and its focus on progressively merging code into the main development branch.</li> <li>Include the repository name in the milestone title to streamline planning.</li> </ul>"},{"location":"external_content/ut-core-wiki/1.3.-Standards%3A-Milestone-Description-Guideline/#examples_1","title":"Examples:","text":"<pre><code>ut_core: Phased Integration - Part 1\n</code></pre> <pre><code>ut_core: Rolling Integration - Feature X\n</code></pre> <pre><code>ut_core: Pre-Release Integration\n</code></pre>"},{"location":"external_content/ut-core-wiki/1.3.-Standards%3A-Milestone-Description-Guideline/#2-goals-1-3-sentences","title":"2. Goals (1-3 sentences):","text":"<ul> <li>Explain the \"why\" behind the milestone. What overall goal does it serve within the project?</li> <li>Briefly mention the target audience or impact area if relevant.</li> </ul>"},{"location":"external_content/ut-core-wiki/1.3.-Standards%3A-Milestone-Description-Guideline/#example","title":"Example:","text":"<pre><code>## Goals\n\nThis milestone focuses on improving user retention by enhancing the on-boarding experience for new customers.\n</code></pre>"},{"location":"external_content/ut-core-wiki/1.3.-Standards%3A-Milestone-Description-Guideline/#3-key-deliverables-bulleted-list","title":"3. Key Deliverables (Bulleted List)","text":"<ul> <li>List the 3-5 most significant features, functionalities, or outcomes that define the milestone's success.</li> <li>Use <code>[ ]</code> - This allows in the github UI to click on tasks completed</li> <li>Use clear, specific language that aligns with your project's terminology, this should be the title of your task</li> <li>Optionally, link each deliverable to its corresponding GitHub issue or pull request (e.g., \"Implement user profile customization (#123)\").</li> <li>This information (including links), can be mirrored in Project Management Tracking tools, e.g. Jira as User Stores.</li> </ul>"},{"location":"external_content/ut-core-wiki/1.3.-Standards%3A-Milestone-Description-Guideline/#example_1","title":"Example","text":"<pre><code>## Key Deliverables (Bulleted List)\n\n  * [ ] Implement basic user authentication and authorization (#45)\n  * [ ] Build core product functionality for content creation and sharing (#52)\n  * [ ] Design and launch initial user interface (#68)\n  * [ ] Set up analytics tracking for key user actions (#71)\n</code></pre>"},{"location":"external_content/ut-core-wiki/1.3.-Standards%3A-Milestone-Description-Guideline/#4-exit-criteria","title":"4. Exit Criteria:","text":"<ul> <li>If applicable, mention measurable targets that will indicate whether the milestone is achieved.</li> <li>These could be quantitative (e.g., \"Reduce user churn by 15%\") or qualitative (e.g., \"Positive feedback from beta testers\").</li> </ul>"},{"location":"external_content/ut-core-wiki/1.3.-Standards%3A-Milestone-Description-Guideline/#example_2","title":"Example:","text":"<pre><code>## Exit Criteria\n\n * At least 50 beta users actively using the platform\n * Positive feedback on core features from at least 75% of beta users\n</code></pre>"},{"location":"external_content/ut-core-wiki/1.3.-Standards%3A-Milestone-Description-Guideline/#5-timeline-or-due-date","title":"5. Timeline or Due Date:","text":"<ul> <li>Include a target completion date or a general timeframe if known.</li> <li>This helps communicate expectations and urgency.</li> <li>This should be reflected in the github meta data for the milestone.</li> </ul>"},{"location":"external_content/ut-core-wiki/1.3.-Standards%3A-Milestone-Description-Guideline/#example_3","title":"Example","text":"<pre><code>## Due Date (GitHub MetaData)\n\nSeptember 30, 2024\n</code></pre>"},{"location":"external_content/ut-core-wiki/1.3.-Standards%3A-Milestone-Description-Guideline/#6-additional-notes-optional","title":"6. Additional Notes (Optional):","text":"<ul> <li>Briefly mention any dependencies on external factors, other teams, or specific technologies.</li> <li>Highlight any known risks or challenges that might impact the milestone.</li> </ul>"},{"location":"external_content/ut-core-wiki/1.3.-Standards%3A-Milestone-Description-Guideline/#example_4","title":"Example","text":"<pre><code>## Additional Notes\n\n  * Dependent on completion of API backend by the development team.\n  * Potential risk: Limited resources for user testing and feedback collection.\n</code></pre>"},{"location":"external_content/ut-core-wiki/1.3.-Standards%3A-Milestone-Description-Guideline/#why-semantic-versioning-in-milestone-titles","title":"Why Semantic Versioning in Milestone Titles?","text":"<ul> <li>Clear Communication:  It instantly signals the stage and scale of the release (major, minor, or patch).</li> <li>Organized Tracking: It makes it easy to track the evolution of your project through milestones.</li> <li>Consistent Expectations:  It sets clear expectations for what kind of changes users can anticipate. </li> </ul>"},{"location":"external_content/ut-core-wiki/1.3.-Standards%3A-Milestone-Description-Guideline/#7-template-paste-able","title":"7. Template (Paste-able)","text":"<p>Below is the text that can be pasted in as a template.</p>"},{"location":"external_content/ut-core-wiki/1.3.-Standards%3A-Milestone-Description-Guideline/#github-metadata-fields","title":"GitHub Metadata Fields","text":"<ul> <li>Title: <code>&lt;Semantic Version Tag&gt; - &lt;GitHub Project&gt;: &lt;Milestone Title&gt;</code></li> <li>Due date (optional): <code>dd/mm/yyyy</code></li> <li>Description:</li> </ul> <pre><code>## Goals\n\n*Briefly describe the purpose of the milestone and its impact on the project.*\n\n## Key Deliverables\n\n* [ ] &lt;Deliverable 1&gt; (Issue/PR #)\n* [ ] &lt;Deliverable 2&gt; (Issue/PR #)\n* [ ] &lt;Deliverable 3&gt; (Issue/PR #)\n* [ ] ...\n\n## Exit Criteria\n\n* &lt;Metric 1&gt;\n* &lt;Metric 2&gt;\n* ...\n\n## Additional Notes (Optional)\n\n### Dependencies\n\n* &lt;Metric 1&gt;\n\n### Risks\n\n* &lt;Metric 1&gt;\n\n### Challenges\n\n* &lt;Metric 1&gt;\n\n### Up-link Data\n\n* **Jira:** &lt;project&gt;-&lt;id&gt;  \n    * This Jira issue details the user story that directly aligns with this milestone's goals and deliverables.\n    * Include the Jira ID for easy reference and tracking.\n</code></pre>"},{"location":"external_content/ut-core-wiki/1.3.-Standards%3A-Milestone-Description-Guideline/#example-populated-template","title":"Example populated template","text":""},{"location":"external_content/ut-core-wiki/1.3.-Standards%3A-Milestone-Description-Guideline/#github-fields","title":"GitHub Fields","text":"<ul> <li>Title: <code>1.0.0 - ut-core: Initial Release</code></li> <li>Due date (optional): <code>30/10/2024</code></li> <li>Description:</li> </ul> <pre><code>## Goals\n\nThis milestone marks the official launch of our product, introducing core features and functionality to the market. \n\n### Key Deliverables\n\n* [ ] Implement basic user authentication and authorization (#45)\n* [ ] Build core product functionality for content creation and sharing (#52)\n* [ ] Design and launch initial user interface (#68)\n* [ ] Set up analytics tracking for key user actions (#71)\n\n## Exit Criteria\n\n* At least 50 beta users actively using the platform\n* Positive feedback on core features from at least 75% of beta users\n\n## Additional Notes:\n\n### Dependencies\n\n* Dependent on completion of API back-end by the development team.\n\n### Risks\n\n* Potential risk: Limited resources for user testing and feedback collection.\n\n### Up-link Data\n\n* **Jira:** RDK-1234\n</code></pre>"},{"location":"external_content/ut-core-wiki/1.4.-Standards%3A-Commit-Message%3A-The-50%E2%80%9072-Rule%3A-A-Simple-Guide/","title":"1.4. Standards: Commit Message: The 50\u201072 Rule: A Simple Guide","text":"<p>The 50/72 rule is a widely adopted convention for formatting Git commit messages. It provides a clear and concise structure that makes it easier to understand the changes made in each commit. The rule breaks down as follows:</p> <ol> <li>Subject Line (50 Characters or Less):</li> <li>Summarize the key change in a brief, imperative sentence (e.g., \"Fix typo in README,\" \"Add new user registration feature\").</li> <li>Use the present tense.</li> <li>Avoid vague or overly general messages.</li> <li> <p>Use imperative verbs:</p> <ul> <li>Add (e.g., \"Add a change to the code.\")</li> <li>Clean (e.g., \"Cleaned unwanted files\")</li> <li>Fix (e.g., \"Fix the broken build.\")</li> <li>Improve (e.g., \"Improve the code documentation.\")</li> <li>Merge (e.g., \"Merge the branch into develop.\")</li> <li>Refactor (e.g., \"Refactor the class for better readability.\")</li> <li>Remove (e.g., \"Remove the duplicate files.\")</li> <li>Test (e.g., \"Test the new feature thoroughly.\")</li> <li>Update (e.g., \"Update the dependencies.\")</li> </ul> </li> <li> <p>Body (72 Characters per Line, Optional):</p> </li> <li>Provide more context and details about the change. Explain the motivation behind the change, the problem it solves, and any relevant implementation details.</li> <li>Use complete sentences.</li> <li> <p>Wrap lines at 72 characters to ensure readability in various environments (e.g., terminals, code editors).</p> </li> <li> <p>Blank Line:</p> </li> <li>Separate the subject line and body with a single blank line.</li> </ol> <p>Example Overview:</p> <pre><code>Update user profile validation (50 characters)\n\nImplement stricter validation rules for user profile fields to prevent invalid data entry. Added checks for:\n\n* Minimum password length (8 characters)\n* Valid email format\n* Unique username\n\nUpdated the UI to display appropriate error messages. (72 characters)\n</code></pre> <p>Example Reality:</p> <pre><code>Fix #123: Update error handling in authentication module\n\nThis commit enhances error detection and adds comprehensive logging to address frequent issues reported by users.\n</code></pre> <p>Why the 50/72 Rule Matters:</p> <ul> <li>Readability: Makes commit history easier to scan and understand.</li> <li>Maintainability: Helps future developers (including yourself) grasp the reasoning behind past changes.</li> <li>Collaboration: Provides context for code reviews and discussions.</li> <li>Automation: Well-formatted commit messages can be used by tools for automated changelog generation or issue tracking integration.</li> </ul> <p>Tips for Writing Great Commit Messages:</p> <ul> <li>Be Specific: Avoid vague messages like \"Update code\" or \"Fix bug.\"</li> <li>Explain Why, Not Just What: Describe the problem the commit solves and the motivation behind the change.</li> <li>Focus on One Change: Each commit should ideally represent a single, logical change.</li> <li>Review Your Message: Before committing, double-check that your message is clear, concise, and accurately describes the change.</li> </ul>"},{"location":"external_content/ut-core-wiki/1.5.-Standards%3A-Semantic-Versioning-and-Testing-Suite-Alignment/","title":"1.5. Standards: Semantic Versioning and Testing Suite Alignment","text":""},{"location":"external_content/ut-core-wiki/1.5.-Standards%3A-Semantic-Versioning-and-Testing-Suite-Alignment/#semantic-versioning-and-testing-suite-alignment","title":"Semantic Versioning and Testing Suite Alignment","text":"<p>This document outlines how to use semantic versioning SemVer in conjunction with a the testing suite strategy. We'll follow the <code>major.minor.bugfix/doc</code> format and establish clear guidelines for versioning and testing.</p>"},{"location":"external_content/ut-core-wiki/1.5.-Standards%3A-Semantic-Versioning-and-Testing-Suite-Alignment/#semantic-versioning-semver","title":"Semantic Versioning (SemVer)","text":"<p>SemVer is a widely adopted versioning system that uses a three-part version number: <code>MAJOR.MINOR.BUGFIX</code>.</p> <ul> <li>MAJOR: Increased when you make incompatible API changes.</li> <li>MINOR: Increased when you add functionality in a backwards-compatible manner.</li> <li>BUGFIX/DOC: Increased when you make backwards-compatible bug fixes or documentation upgrades.</li> </ul>"},{"location":"external_content/ut-core-wiki/1.5.-Standards%3A-Semantic-Versioning-and-Testing-Suite-Alignment/#versioning-guidelines","title":"Versioning Guidelines","text":"<ol> <li> <p>Interface Extension:</p> <ul> <li>If you extend an interface without requiring the caller to rebuild, it's a MINOR change.</li> <li>If the caller needs to rebuild due to the interface extension, it's a MAJOR change.</li> </ul> </li> <li> <p>Bug Fixes and Documentation:</p> <ul> <li>Bug fixes and documentation changes are considered BUGFIX or DOC changes, respectively.</li> </ul> </li> </ol>"},{"location":"external_content/ut-core-wiki/1.5.-Standards%3A-Semantic-Versioning-and-Testing-Suite-Alignment/#testing-suite-alignment","title":"Testing Suite Alignment","text":"<ol> <li> <p>Major and Minor Alignment:</p> <ul> <li>Testing suites should be aligned with MAJOR.MINOR versions.</li> <li>Each testing suite should comprehensively test all functions within that specific <code>MAJOR.MINOR</code> version.</li> </ul> </li> <li> <p>Bugfix/Doc Update Ingestion:</p> <ul> <li>BUGFIX and DOC upgrades should be automatically ingested into the testing suite to ensure compatibility with the existing interface.</li> </ul> </li> <li> <p>Minor Upgrade and Testing Suite:</p> <ul> <li>When a MINOR upgrade introduces new functionality, the corresponding testing suite must also be upgraded to support and test that new functionality.</li> </ul> </li> <li> <p>Testing Suite Cloning:</p> <ul> <li>Testing suites should be cloned and aligned with MAJOR.MINOR versions to maintain separate test coverage for each distinct interface.</li> </ul> </li> </ol>"},{"location":"external_content/ut-core-wiki/1.5.-Standards%3A-Semantic-Versioning-and-Testing-Suite-Alignment/#ut-core-template-scripts-and-version-selection","title":"UT-Core Template Scripts and Version Selection","text":"<p>UT-Core template scripts allow for selecting the new version before the testing suite is released. </p> <ul> <li>The HALIF <code>build_ut.sh</code> script automatically selects the next highest version number.</li> <li>This enables releases with a fixed tag ahead of testing suite implementation.</li> <li>Testing suites must be selected via tags, facilitating a streamlined release process.</li> </ul>"},{"location":"external_content/ut-core-wiki/1.5.-Standards%3A-Semantic-Versioning-and-Testing-Suite-Alignment/#example-workflow-hal-interface-upgrade","title":"Example Workflow: HAL Interface Upgrade","text":"<ol> <li>Development: You add a new backwards-compatible feature to your HAL interface.</li> <li>Versioning: Increment the MINOR version (e.g., from 1.2.5 to 1.3.0).</li> <li>Testing Suite:  Prepare the corresponding testing suite (e.g., <code>1.3.x</code>) to include tests for the new feature. This might involve creating a new branch or updating configuration files.  (The testing suite itself will be released later.)</li> <li>Release: <ul> <li>Release the new version (1.3.0) of your HAL interface. </li> <li>Update the <code>build_ut.sh</code> script in the HAL implementation to set <code>UT_PROJECT_VERSION=\"1.3.\"</code>. This ensures that when the 1.3.x testing suite is released, it will be automatically selected.</li> </ul> </li> </ol>"},{"location":"external_content/ut-core-wiki/1.5.-Standards%3A-Semantic-Versioning-and-Testing-Suite-Alignment/#example-workflow-hal-testing-suite-upgrade","title":"Example Workflow: HAL Testing Suite Upgrade","text":"<ol> <li>Development:  Develop new functions or upgrades for the testing suite to accommodate the new features in the released HAL interface (e.g., 1.3.0).</li> <li>Versioning: Increment the MINOR version of the testing suite (e.g., from 1.2.x to 1.3.0).</li> <li>Release: Release the new version of your testing suite (1.3.0). The <code>build_ut.sh</code> scripts in the HAL implementation, which were previously updated to <code>UT_PROJECT_VERSION=\"1.3.\"</code>, will now automatically select this new testing suite version.</li> </ol>"},{"location":"external_content/ut-core-wiki/1.5.-Standards%3A-Semantic-Versioning-and-Testing-Suite-Alignment/#example-workflow-bug-fix-in-testing-suite","title":"Example Workflow: Bug Fix in Testing Suite","text":"<ol> <li>Bug Fix: You discover and fix a bug in the released testing suite.</li> <li>Versioning: Increment the BUGFIX version of the testing suite (e.g., from 1.3.0 to 1.3.1).</li> <li>Release: Release the bug fix version of the testing suite. The <code>build_ut.sh</code> scripts will automatically use this updated version.</li> </ol>"},{"location":"external_content/ut-core-wiki/1.5.-Standards%3A-Semantic-Versioning-and-Testing-Suite-Alignment/#benefits-of-this-approach","title":"Benefits of this Approach","text":"<ul> <li>Clear Versioning: Ensures consistent and predictable versioning practices.</li> <li>Comprehensive Testing: Guarantees thorough testing of all functionalities for each interface version.</li> <li>Streamlined Release Process: Facilitates efficient release cycles with automated version selection and testing suite alignment.</li> <li>Improved Code Quality: Reduces the risk of regressions and ensures compatibility across versions.</li> </ul>"},{"location":"external_content/ut-core-wiki/2.-Standards%3A-Single-Source-of-Truth-%E2%80%90-HAL-Interfaces-and-Testing-Suites/","title":"2. Standards: Single Source of Truth \u2010 HAL Interfaces and Testing Suites","text":""},{"location":"external_content/ut-core-wiki/2.-Standards%3A-Single-Source-of-Truth-%E2%80%90-HAL-Interfaces-and-Testing-Suites/#introduction","title":"Introduction","text":"<p>This document details our transition to a centralized, transparent approach for managing HAL interfaces and testing suites. This change aims to enhance development, boost collaboration, and resolve past issues with fragmented repositories and outdated practices.</p>"},{"location":"external_content/ut-core-wiki/2.-Standards%3A-Single-Source-of-Truth-%E2%80%90-HAL-Interfaces-and-Testing-Suites/#challenges-of-the-previous-system","title":"Challenges of the Previous System","text":"<p>Our previous development landscape faced several challenges:</p> <ul> <li>Fragmented repositories: Interfaces and testing suites were scattered across different locations, making access and collaboration difficult.</li> <li>Outdated version control: Manual syncing and inconsistent branching led to discrepancies and errors.</li> <li>Limited accessibility: Vendors and third parties lacked proper access to essential resources.</li> <li>Multiple code locations: Internal, collaboration, and final code locations caused confusion and maintenance overhead.</li> <li>Rewritten commit histories: Login credential changes forced commit history rewrites, obscuring development history.</li> </ul>"},{"location":"external_content/ut-core-wiki/2.-Standards%3A-Single-Source-of-Truth-%E2%80%90-HAL-Interfaces-and-Testing-Suites/#introducing-the-single-source-of-truth-approach","title":"Introducing the Single Source of Truth Approach","text":"<p>To address the challenges of scattered documentation and inconsistent information, we're adopting a single source of truth model.</p> <p>This means:</p> <ul> <li>Centralised repository: All interfaces, testing suites, and documentation will be housed in a central repository, either publicly or privately on rdkcentral.</li> <li>High-Quality Documentation:  We are committed to providing comprehensive, up-to-date documentation, including:<ul> <li>Conceptual documentation:  Explaining the architecture, design principles, and key concepts.</li> <li>API Documentation with Doxygen:  Detailed API references generated with Doxygen, ensuring accuracy and consistency.</li> <li>Tutorials and Examples: Practical guides and examples to help developers get started quickly.</li> </ul> </li> <li>Transparent access: Vendors and third parties will have clear, consistent access to all resources, including all documentation.</li> <li>Semantic versioning: We'll use semantic versioning to ensure compatibility between old and new interfaces and keep documentation aligned with each version.</li> <li>Fixed version usage: Components will use fixed interface versions for stability, referencing the corresponding documentation version.</li> <li>Upgraded interfaces and testing suites: We'll upgrade the interfaces and the testing suites in the open, with documentation updated simultaneously.</li> </ul>"},{"location":"external_content/ut-core-wiki/2.-Standards%3A-Single-Source-of-Truth-%E2%80%90-HAL-Interfaces-and-Testing-Suites/#benefits-of-the-new-system","title":"Benefits of the New System","text":"<p>This new system provides numerous benefits:</p> <ul> <li>Simplified development process: Clear visibility and access to resources, including easy-to-find documentation, streamline workflows.</li> <li>Enhanced collaboration: Shared knowledge and resources, along with a common understanding fostered by consistent documentation, improve collaboration.</li> <li>Reduced errors and inconsistencies: A single reference point for code and documentation minimises discrepancies and errors.</li> <li>Improved efficiency and time savings: Streamlined workflows and readily available documentation increase efficiency and save time.</li> <li>Increased transparency and trust: Open access to information, including all documentation for all parties, fosters trust and transparency.</li> <li>Improved developer experience: High-quality documentation makes it easier for developers to understand, use, and integrate with our platform.</li> <li>Reduced support costs: Clear and comprehensive documentation reduces the need for support requests.</li> </ul>"},{"location":"external_content/ut-core-wiki/2.-Standards%3A-Single-Source-of-Truth-%E2%80%90-HAL-Interfaces-and-Testing-Suites/#conclusion","title":"Conclusion","text":"<p>This transition to a single source of truth is a significant advancement in HAL interface development. We're dedicated to continuous improvement and welcome participation and feedback from all stakeholders. Through open communication and collaboration, we can ensure the success of this initiative and provide an enhanced development experience for everyone.</p>"},{"location":"external_content/ut-core-wiki/2.1.-Standards%3A-Doxygen%3A-Crafting-Excellent-Documentation/","title":"2.1. Standards: Doxygen: Crafting Excellent Documentation","text":""},{"location":"external_content/ut-core-wiki/2.1.-Standards%3A-Doxygen%3A-Crafting-Excellent-Documentation/#doxygen-governance-manual-crafting-excellent-documentation","title":"Doxygen Governance Manual: Crafting Excellent Documentation","text":""},{"location":"external_content/ut-core-wiki/2.1.-Standards%3A-Doxygen%3A-Crafting-Excellent-Documentation/#introduction","title":"Introduction","text":"<p>Clear and well-structured documentation is essential for code maintainability, readability, and collaboration. Doxygen is a powerful tool that generates documentation from source code comments. This manual aims to establish best practices and guidelines for writing Doxygen comments that enhance the understanding and usability of your codebase.</p>"},{"location":"external_content/ut-core-wiki/2.1.-Standards%3A-Doxygen%3A-Crafting-Excellent-Documentation/#core-principles","title":"Core Principles","text":"<ul> <li>Clarity: Write comments that are easy to understand, even for developers who are not familiar with the specific codebase. Avoid jargon, ambiguity, and unnecessary technical details.</li> <li>Conciseness: Be brief and to the point. Avoid long, rambling sentences and paragraphs. Use clear, concise language to convey essential information.</li> <li>Consistency: Follow a consistent style and formatting throughout your Doxygen comments. This includes indentation, spacing, tag usage, and the level of detail provided.</li> <li>Completeness: Ensure your comments cover all the essential aspects of the code element being documented. Include information on the purpose, parameters, return values, possible errors, and any relevant side effects.</li> <li>Accuracy: Double-check your comments for technical correctness and ensure they accurately reflect the code's behavior and functionality.</li> </ul>"},{"location":"external_content/ut-core-wiki/2.1.-Standards%3A-Doxygen%3A-Crafting-Excellent-Documentation/#best-practices","title":"Best Practices","text":"<ul> <li>Use <code>/**! */</code> for Single-Line Comments: This is the preferred format for brief descriptions, eliminating the need for the <code>@brief</code> tag:</li> </ul> <pre><code>/**! Retrieves the current Ethernet WAN interface name. */\n</code></pre> <ul> <li>Use <code>/** ... */</code> for Multi-Line Comments: For functions with parameters, return values, or more detailed explanations, use multi-line comments to maintain readability:</li> </ul> <pre><code>/**\n * @brief Initiates a firmware update and factory reset.\n * \n * This function updates the device's firmware (optionally from a specified URL) \n * and then performs a factory reset.\n *\n * ... (more details)\n */\n</code></pre> <ul> <li> <p>Focused <code>@brief</code> Tags:  Keep the <code>@brief</code> description concise and action-oriented, summarizing the core purpose of the function or data structure.</p> </li> <li> <p>Informative <code>@param</code> and <code>@returns</code>:</p> <ul> <li><code>@param</code>: Clearly state the parameter's purpose, expected type, and any constraints or valid values. Use <code>-</code> to separate the parameter name from its description.</li> <li><code>@returns</code>: Provide a general overview of the return value and its meaning.</li> </ul> </li> <li> <p>Detailed <code>@retval</code>s: List each possible return value, followed by a hyphen and a clear explanation.</p> </li> <li> <p>Use Additional Tags: Leverage other Doxygen tags like <code>@note</code>, <code>@warning</code>, <code>@see</code>, and <code>@deprecated</code> to provide supplementary information, warnings, references, or deprecation notices.</p> </li> <li> <p>Error Handling (TODO):  Prioritize moving away from generic <code>RETURN_ERR</code> values. Instead, define and use an enum for specific error codes to enhance debugging and clarity.</p> </li> </ul>"},{"location":"external_content/ut-core-wiki/2.1.-Standards%3A-Doxygen%3A-Crafting-Excellent-Documentation/#example-well-documented-function","title":"Example: Well-Documented Function","text":"<pre><code>/**!\n * @brief Retrieves the current DOCSIS registration status.\n *\n * This function populates a provided `CMMGMT_CM_DOCSIS_INFO` structure with DOCSIS registration details. \n *\n * @param[out] pinfo - Pointer to a pre-allocated `CMMGMT_CM_DOCSIS_INFO` structure.\n *\n * @returns Status of the operation:\n * @retval RETURN_OK - On success.\n * @retval RETURN_ERR - On failure (e.g., retrieval error, invalid input).\n *\n * @note The caller is responsible for providing the `PCMMGMT_CM_DOCSIS_INFO` structure.\n */\nINT docsis_GetDOCSISInfo(PCMMGMT_CM_DOCSIS_INFO pinfo);\n</code></pre>"},{"location":"external_content/ut-core-wiki/2.1.-Standards%3A-Doxygen%3A-Crafting-Excellent-Documentation/#common-pitfalls-to-avoid","title":"Common Pitfalls to Avoid","text":"<ul> <li>Repetition: Avoid repeating information that is already clear from the code element's name or type.</li> <li>Vague Language: Be as specific as possible in your descriptions.</li> <li>Incorrect Information: Double-check your comments for technical accuracy.</li> <li>Overly Long Comments: Keep comments concise and focused on the most important details.</li> </ul>"},{"location":"external_content/ut-core-wiki/2.2.-Standards%3A-Forking-And-Branching/","title":"2.2. Standards: Forking And Branching","text":"<p>Forking and branching in Git are distinct tools, each with its own purpose:</p> <ul> <li>Forking: Creating an independent copy of a repository on your own account, typically for personal experimentation or contributions to external projects.</li> <li>Branching: Creating parallel versions within the same repository, ideal for collaborative development and managing feature work.</li> </ul> <p>Importantly, forking and branching are not mutually exclusive. You can still fork a repository and create branches within your fork. However, it's crucial to choose the right collaboration model for the project's specific needs.</p>"},{"location":"external_content/ut-core-wiki/2.2.-Standards%3A-Forking-And-Branching/#forking-vs-branching-choosing-the-right-path-for-collaboration","title":"Forking vs. Branching \u2013 Choosing the Right Path for Collaboration","text":"<p>GitHub defines forking and branching as follows:</p> <ul> <li>Fork: \"A fork is a personal copy of another user's repository that lives on your account. Forks allow you to freely make changes to a project without affecting the original upstream repository.\"</li> <li>Branch: \"A branch is a parallel version of a repository. It is contained within the repository, but does not affect the primary or main branch, allowing you to work freely without disrupting the 'live' version.\"</li> </ul> <p>Collaboration Models:</p> <ul> <li>Divergence (Forking): <ul> <li>Best suited for scenarios where you want to experiment, create your own variations, or contribute back to an open-source project where you don't have direct write access.</li> <li>Your fork is a completely separate entity from the original repository, allowing you to explore new ideas without risk.</li> </ul> </li> <li>Convergence (Branching):<ul> <li>Ideal for collaborative development within a single project or team.</li> <li>Branches allow multiple contributors to work on different features simultaneously, with the intention of merging their changes back into the main branch.</li> <li>Facilitates code review, testing, and controlled integration of changes.</li> </ul> </li> </ul>"},{"location":"external_content/ut-core-wiki/2.2.-Standards%3A-Forking-And-Branching/#rdk-collaboration-a-case-for-branching","title":"RDK Collaboration: A Case for Branching","text":"<p>Given the collaborative nature of RDK development, the branching model aligns more closely with the goals:</p> <ol> <li>Shared Codebase: All contributors work on the same repository, ensuring everyone is on the same page.</li> <li>Controlled Contributions: Changes are made on branches, subjected to code reviews, and then merged into the main branch upon approval, maintaining quality and consistency.</li> <li>Streamlined Integration: Merging branches is less cumbersome than merging forks, making the integration process smoother.</li> </ol> <p>When Forking Might Be Useful in RDK:</p> <ul> <li>Initial Exploration: If you're new to a project and want to experiment without immediately contributing, you might fork the repository to get a feel for the codebase.</li> <li>Major Divergence: If you have a fundamentally different vision for a project, a fork can allow you to explore that path independently.</li> </ul>"},{"location":"external_content/ut-core-wiki/2.2.-Standards%3A-Forking-And-Branching/#key-points","title":"Key Points:","text":"<ul> <li>Forking: Individual work, experimentation, contributing to external projects.</li> <li>Branching: Collaborative work within a team, controlled integration of changes.</li> <li>RDK Collaboration: Favours branching for its streamlined collaboration and code integration benefits.</li> </ul>"},{"location":"external_content/ut-core-wiki/2.3.-Standards%3A-Performing-Changes-to-an-interface/","title":"2.3. Standards: Performing Changes to an interface","text":""},{"location":"external_content/ut-core-wiki/2.3.-Standards%3A-Performing-Changes-to-an-interface/#scope","title":"Scope","text":"<p>This document outlines the procedures for making changes to the interface. </p> <p>Please also refer to the 2. Standards: Single Source of Truth - HAL Interfaces and Testing Suites document.</p>"},{"location":"external_content/ut-core-wiki/2.3.-Standards%3A-Performing-Changes-to-an-interface/#executive-summary","title":"Executive Summary","text":"<p>Modifying the interface is a controlled process requiring collaboration, approval, and meticulous documentation. All changes must be proposed and tracked through GitHub issues, reviewed by the component owner and architecture team, and validated with updated testing suites.  This ensures alignment with architectural standards, maintains interface consistency, and preserves backward compatibility.</p>"},{"location":"external_content/ut-core-wiki/2.3.-Standards%3A-Performing-Changes-to-an-interface/#introduction","title":"Introduction","text":"<p>Modifications to the interface should generally be avoided unless approved by the design and architecture teams. Pre-approved design changes are required before starting work, with final authorization granted upon completion.</p>"},{"location":"external_content/ut-core-wiki/2.3.-Standards%3A-Performing-Changes-to-an-interface/#architecture-discussions","title":"Architecture Discussions","text":"<ul> <li>Create an issue ticket in github on the goals &amp; requirements that need to be met with clear requirements</li> <li>Discuss any proposed code changes with the architecture team to ensure alignment with current and future needs.</li> <li>Document in the issue ticket, </li> <li>Maintain interface consistency across all components, as design decisions impact the entire interface, not just individual parts.</li> </ul>"},{"location":"external_content/ut-core-wiki/2.3.-Standards%3A-Performing-Changes-to-an-interface/#change-process","title":"Change Process","text":"<p>Any interface modification involves the following steps, managed through GitHub:</p> <ol> <li> <p>Define and Discuss:</p> <ul> <li>Raise an issue ticket in GitHub to outline the goals and proposed changes to the interface. Clearly define the requirements and reasons for the modification.</li> <li>Discuss the proposed changes with the component owner and the architecture team within the issue ticket. This ensures alignment with current and future architectural needs and maintains interface consistency across all components.</li> </ul> </li> <li> <p>Develop and Document:</p> <ul> <li>Create a branch from <code>develop</code> based on the issue ticket ID (e.g., <code>issue-123-interface-update</code>). </li> <li>In this branch, implement the interface changes and update the corresponding documentation. Ensure the documentation accurately reflects the modified functionality.</li> </ul> </li> <li> <p>Review and Approve:</p> <ul> <li>Raise a Pull Request (PR) for the changes in your branch. </li> <li>Request review and sign-off from the component owner and the architecture team. Address any feedback or concerns raised during the review process.</li> <li>Once approved, merge the PR into <code>develop</code>.</li> </ul> </li> <li> <p>Update Testing Suite:</p> <ul> <li>Raise a separate issue ticket for any required changes or upgrades to the testing suite due to the interface modification. Define the new testing requirements within this ticket.</li> <li>Create a new branch (e.g., <code>issue-124-testing-update</code>) for modifying the testing suite.</li> <li>Implement the testing suite changes to validate the updated interface functionality. </li> <li>Raise a PR for the testing suite changes. Request review and sign-off from the architecture team and code owners.</li> <li>Merge the PR into <code>develop</code> after approval.</li> </ul> </li> <li> <p>Release:</p> </li> </ol> <p>The component owner manages the release of the updated interface and testing suite, adhering to the following guidelines:</p> <ul> <li>Release Cadence: Releases follow a defined cadence methodology to ensure regular updates.</li> <li>Semantic Versioning: Both the header file and testing suite utilize semantic versioning (MAJOR.MINOR.BUGFIX) to indicate the nature of changes.<ul> <li>Major interface changes require a major version bump in both the header file and the testing suite.</li> <li>Minor, binary-compatible interface changes result in a minor version bump for both.</li> <li>Bugfix, either in the testing suites or the header file, will have no effect on the binary</li> </ul> </li> <li>Version Alignment: The testing suite version is aligned with the header file version to ensure compatibility.</li> <li> <p>Automated Upgrades:  Consideration should be given to how the testing suite can automatically upgrade to accommodate minor interface changes, potentially through mechanisms provided by HALIF.</p> </li> <li> <p>Vendor Integration:</p> <ul> <li>Communicate the interface changes to vendors.  Vendors must adjust their code and ensure compliance with the updated testing suite.</li> </ul> </li> </ul> <p>Important Notes:</p> <ul> <li>Peer review will automatically fail if the GitHub process outlined above is not followed.</li> <li>Maintain backward compatibility with existing code whenever possible.</li> <li>Clearly document all changes and justifications within the relevant GitHub issues and PRs.</li> </ul>"},{"location":"external_content/ut-core-wiki/2.3.-Standards%3A-Performing-Changes-to-an-interface/#testing","title":"Testing","text":"<ul> <li>All code must undergo manual testing before commitment.</li> <li>Engineering teams must perform iterative testing for validation and approval before merging changes.</li> <li>Code merges are gated by successful tests.</li> </ul>"},{"location":"external_content/ut-core-wiki/2.3.-Standards%3A-Performing-Changes-to-an-interface/#requirements","title":"Requirements","text":"<ul> <li>Changes must maintain backward compatibility.</li> <li>All modifications should be controlled and documented meticulously.</li> <li>Legacy platforms may run older interface versions.</li> <li>Future changes will be managed through dynamic discovery.</li> </ul> <p>When functions or structures are updated, but the interface is deemed insufficient, upgrades are allowed but must be marked with a comment:</p> <pre><code>/* TODO: This &lt;functionality/structure/etc&gt; is deprecated, and future modifications will require a redesign. */\n</code></pre>"},{"location":"external_content/ut-core-wiki/2.3.-Standards%3A-Performing-Changes-to-an-interface/#conclusion","title":"Conclusion","text":"<p>Interface stability should be maintained across all platforms and versions. The architecture team has sole authority over change decisions, and any modifications require design approval and final sign-off.</p>"},{"location":"external_content/ut-core-wiki/2.4.-Standards%3A-Repository-Access-and-Branch-Protection-Policy/","title":"2.4. Standards: Repository Access and Branch Protection Policy","text":""},{"location":"external_content/ut-core-wiki/2.4.-Standards%3A-Repository-Access-and-Branch-Protection-Policy/#purpose","title":"Purpose","text":"<p>This policy establishes a structured and secure workflow for code changes, defining distinct roles for the Layer Release Team, Contributors, and CodeOwners (typically architects). It utilises the GitFlow branching model to maintain code quality and control releases, with CodeOwners playing a key role in planning and release cadence.</p> <p>This project employs a layered architecture where the image assembly is divided into distinct functional components, each potentially managed by an independent layer release teams. Each component team is responsible for the development, testing, and release of their specific component.</p> <p>Where common functionality exists, the component team proposing a change will request review from the <code>CODEOWNERS</code>, once approved they will merge the change in accordance with an agreed process. <code>CODEOWNERS</code> will then perform the release process.</p> <ul> <li>Image Layers:</li> <li>Vendor Layer:  Contains vendor specific implementation and configurations.</li> <li>Middleware Layer: Provides core common services and functionality.</li> <li> <p>Application Layer: Implements the applications.</p> </li> <li> <p>Independent Release Teams:</p> </li> <li>Autonomy: Each team maintains a high degree of autonomy over their layer, allowing independent release cadence.</li> <li>Coordination: Teams collaborate and synchronise when changes affect shared functionalities or dependencies.</li> </ul>"},{"location":"external_content/ut-core-wiki/2.4.-Standards%3A-Repository-Access-and-Branch-Protection-Policy/#actors-and-roles","title":"Actors and Roles","text":"<ol> <li>Contributors Team (Engineers):</li> <li>Responsibilities:<ul> <li>Develop new features and bug fixes.</li> <li>Create feature branches from <code>develop</code>.<ul> <li>Can use the UI to create branches. </li> <li>Use CLI <code>git-flow feature start \"branch name\"</code></li> </ul> </li> <li>Submit pull requests (PRs) for code review.</li> <li>Merge from feature branches to <code>develop</code><ul> <li>Can use the UI to merge</li> <li>Use CLI <code>git-flow feature finish</code></li> </ul> </li> </ul> </li> <li> <p>Permissions:</p> <ul> <li>Write access to feature branches.</li> <li>Write access to <code>develop</code> for approved feature branches.</li> <li>Read access to <code>main</code></li> <li>No direct merge access to <code>main</code>.</li> </ul> </li> <li> <p>CodeOwners Team (Architects):</p> </li> <li>Responsibilities:<ul> <li>Review and approve PRs.</li> <li>Plan milestones and determine release cadence.</li> <li>Release authority (decide when to merge to <code>main</code>).</li> <li>Note: May not directly make code changes.</li> </ul> </li> <li>Permissions:<ul> <li>Write access to <code>develop</code> for approved feature branches.</li> <li>Read access to all branches.</li> </ul> </li> <li> <p>Configuration:</p> <ul> <li>Defined in the <code>./github/CODEOWNERS</code> file.</li> </ul> </li> <li> <p>Layer Release Team:</p> </li> <li>Responsibilities:<ul> <li>Release Content: Determine the specific versions of previously released components to be incorporated into the new layer release.</li> <li>Update Configuration: Modify configuration files to reference the selected component versions.</li> <li>Create the layer release branch from <code>develop</code><ul> <li>Use CLI <code>git-flow release start \"semantic version\"</code></li> </ul> </li> <li>Merge code from <code>release branch</code> to <code>main</code>.<ul> <li>Use CLI <code>git-flow release finish \"semantic version\"</code></li> </ul> </li> <li>Tag are created on <code>main</code> caused  by <code>git-flow</code></li> <li>Merge from <code>main</code> to <code>develop</code> caused by <code>git-flow</code></li> <li>Push changes to <code>main</code> and <code>develop</code>, including <code>tags</code>.</li> </ul> </li> <li>Permissions:<ul> <li>Write access to <code>main</code> &amp; <code>develop</code>.</li> <li>Read access to all branches.</li> </ul> </li> </ol>"},{"location":"external_content/ut-core-wiki/2.4.-Standards%3A-Repository-Access-and-Branch-Protection-Policy/#branch-protection","title":"Branch Protection","text":"<ul> <li> <p>main:</p> <ul> <li>Strictly protected.</li> <li>Only the Release Team can merge.</li> <li>Tags used to mark releases.</li> <li>Maintains a history of feature releases.</li> </ul> </li> <li> <p>develop:</p> <ul> <li>Protected.</li> <li>Requires a pull request from a feature branch with approval from CodeOwners to merge. </li> <li>Release team bypass this requirement</li> <li>Contributors and CodeOwners can merge.</li> <li>Maintains a history of feature integrations.</li> </ul> </li> </ul>"},{"location":"external_content/ut-core-wiki/2.4.-Standards%3A-Repository-Access-and-Branch-Protection-Policy/#workflow","title":"Workflow","text":"<ol> <li>Planning: CodeOwners plan milestones and determine the release cadence.</li> <li>Branching: Contributors create feature branches from <code>develop</code>.</li> <li>Development:  Contributors work on their feature branches.</li> <li>Pull Request: Contributors submit PRs for review, automatically assigning CodeOwners.</li> <li>Code Review: CodeOwners (architects) review code and provide feedback.</li> <li>Approval: CodeOwners approve PRs that meet quality standards.</li> <li>Merge to develop: Approved PRs are merged into <code>develop</code> (by Contributors or CodeOwners).</li> <li>Release: CodeOwners determine the release cadence.</li> <li>Release Team:: Create a release via a <code>release</code> branch and merges to <code>main</code> and <code>develop</code>.</li> </ol>"},{"location":"external_content/ut-core-wiki/2.4.-Standards%3A-Repository-Access-and-Branch-Protection-Policy/#appendix","title":"Appendix","text":"<ul> <li>FAQ: Release Engineers: Performing a release with git-flow</li> <li>FAQ: Git\u2010Flow: Developers Branching Model</li> </ul>"},{"location":"external_content/ut-core-wiki/2.5.-Standards%3A-Feature-Branch-Workflow/","title":"2.5. Standards: Feature Branch Workflow","text":"<p>Feature Branch Workflow</p> <ul> <li> <p>Core Principle:  All feature development occurs on separate branches (feature branches) that are isolated from the <code>develop</code> branch. Quality control is a priority at every stage of the process.</p> </li> <li> <p>Process:</p> <ol> <li>Branch Creation: A new short-lived branch is created from the <code>develop</code> branch for each feature.</li> <li>Requirements and Design:  Key requirements are clearly defined in an issue tracker. Rough solutions are discussed with architecture/engineering leads before implementation to align on design and approach.</li> <li>Development: Code changes are made on the feature branch.</li> <li>Testing: (Often Manual) The developer thoroughly tests their changes on the feature branch, ensuring quality standards are met.</li> <li>Early Pull Request (PR): A PR is created early in the development process to solicit feedback and facilitate early integration.</li> <li>Code Review: <code>CodeOwners</code>review the changes in the PR, ensuring adherence to coding standards, design principles, and overall quality.</li> <li>Merge: If approved and tests pass, the feature branch is merged into the <code>develop</code> branch. Merge conflicts are minimized through the use of git-flow branching strategies and short-lived branches.</li> </ol> </li> <li> <p>Benefits:</p> <ul> <li>Isolation: Protects the <code>develop</code> branch from unstable code.</li> <li>Clear History: Feature-specific changes are easily tracked.</li> <li>Easier Collaboration: Multiple developers can work on different features concurrently.</li> <li>Quality Assurance:  Prioritizing quality control at all stages minimizes the risk of introducing errors into the <code>develop</code> branch.</li> <li>Early Feedback: Early PRs and discussions with leads enable faster feedback and course correction if needed.</li> <li>Reduced Merge Conflicts: Git-flow and short-lived branches help mitigate merge conflicts.</li> <li>Controlled Integration: Slower, more deliberate integration ensures thorough testing and quality before merging into the <code>develop</code> branch.</li> </ul> </li> <li> <p>Drawbacks:</p> <ul> <li>Potential for Delays: If early PRs are not reviewed promptly or if extensive changes are required after review, the development cycle might be extended.</li> <li>Requires Discipline: The team needs to adhere to the defined workflow and prioritize quality control practices.</li> </ul> </li> </ul> <p>For more information on the commands to use see FAQ: Git-Flow: Developers Branching Model</p>"},{"location":"external_content/ut-core-wiki/3.-Standards%3A-Levels-of-Test-for-Vendor-Layer/","title":"Level of Test for the Vendor Layer","text":"<p>This document defines the testing requirements for the Vendor Layer, categorized into levels to facilitate phased delivery and vendor participation. These levels collectively form the Vendor Testing Suite (VTS).</p>"},{"location":"external_content/ut-core-wiki/3.-Standards%3A-Levels-of-Test-for-Vendor-Layer/#level-1-component-function-testing-isolated-component-environment-pre-commit-vendor-testing","title":"Level 1: Component Function Testing (Isolated Component Environment, Pre-Commit) \u2013 Vendor Testing","text":"<ul> <li>Purpose: API Function testing of individual components + requirements documentation.</li> <li>Scope: Thorough testing of each function and parameter.</li> <li>Execution: Performed by component engineers during initial pre-commit interface development or when modifying existing components, before commit.</li> </ul>"},{"location":"external_content/ut-core-wiki/3.-Standards%3A-Levels-of-Test-for-Vendor-Layer/#level-2-component-unit-testing-no-upper-stack-layers-pre-commit-vendor-test","title":"Level 2: Component Unit Testing (No upper stack layers, Pre-Commit) - Vendor Test","text":"<ul> <li>Purpose: Focused testing of individual modules in a component, aligned with requirements documentation. Scope: Independent component testing.</li> <li>Scope: Verifies the functionality of the component.</li> <li>Execution: Performed by component engineers pre-commit during initial development or when implementing changes. </li> </ul>"},{"location":"external_content/ut-core-wiki/3.-Standards%3A-Levels-of-Test-for-Vendor-Layer/#level-3-component-stimulus-testing-no-upper-stack-layers-pre-commit-vendor-test","title":"Level 3: Component Stimulus Testing (No Upper Stack Layers, Pre-Commit) - Vendor Test","text":"<ul> <li>Purpose: Pre-commit testing using external stimuli to validate component responses and adherence to requirements.</li> <li>Scope:</li> <li>May trigger both Level 1 (Component Function) and Level 2 (Component Unit) tests for deeper verification.</li> <li>Includes specific tests designed to interact with external devices and evaluate component behavior.</li> <li>May involve interactions with other, pre-tested components to simulate real-world scenarios.</li> <li>Infrastructure: May require specialized setup, either on engineers' desks or in dedicated racks, and runs on vendor-provided equipment.</li> </ul>"},{"location":"external_content/ut-core-wiki/3.-Standards%3A-Levels-of-Test-for-Vendor-Layer/#level-4-layer-system-testing","title":"Level 4: Layer &amp; System Testing","text":"<p>Level 4 encompasses a comprehensive range of system-level tests focused on validating the performance, stability, and integration capabilities of the vendor layer within the ecosystem.</p>"},{"location":"external_content/ut-core-wiki/3.-Standards%3A-Levels-of-Test-for-Vendor-Layer/#l4-system-performance-profiling-vsp","title":"L4 - System Performance Profiling (VSP)","text":"<ul> <li>Purpose: To monitor and analyse system resource usage during key operations.</li> <li>Scope:</li> <li>CPU Load: Measure CPU utilization during activities like video playback, app launch, and channel switching. Continuous monitoring via a C application with logging capabilities.</li> <li>Memory Usage: Track memory consumption patterns to identify potential leaks or areas for optimization.</li> <li>Stress Testing: Push the device to its limits to identify bottlenecks and stability issues.</li> <li>Power Consumption: Testing: Measure power usage under different conditions.</li> <li>Tools/Methods: Utilize profiling tools like <code>perf</code>, <code>valgrind</code>, or other suitable frameworks for performance data collection.</li> <li>Metrics and Reporting:  Collect and analyse performance metrics (CPU usage, memory allocation, frame rates) and generate reports to pinpoint bottlenecks and areas for improvement.</li> </ul> <p>Related: (TBC)</p>"},{"location":"external_content/ut-core-wiki/3.-Standards%3A-Levels-of-Test-for-Vendor-Layer/#l4-ad-hoc-analysis-vah","title":"L4 - Ad hoc Analysis (VAH)","text":"<ul> <li>Purpose: To conduct deep-dive investigations into specific issues or performance bottlenecks.</li> <li>Scope:</li> <li>Triggered by: Field issues, complex bugs, performance bottlenecks, or customer escalations.</li> <li>Methodology: Employ in-depth analysis using debugging tools (e.g., <code>gdb</code>), specialized logs, and code inspection.</li> <li>Collaboration: Work closely with development teams to identify root causes and implement solutions.</li> </ul> <p>Related: (TBC)</p>"},{"location":"external_content/ut-core-wiki/3.-Standards%3A-Levels-of-Test-for-Vendor-Layer/#l4-system-interface-testing-vsi","title":"L4 - System Interface Testing (VSI)","text":"<ul> <li>Purpose: To validate interactions with external interfaces and devices.</li> <li>Scope:</li> <li>Key Interfaces:<ul> <li>Bluetooth (Bluez): Verify connectivity, pairing, and data transfer.</li> <li>WiFi (WPA-supplicant): Test connection stability, roaming, and security.</li> <li>OpenGLES, OpenGL, Graphics, Vulcan: Validate graphics rendering, performance, and compliance. (Video Only)</li> <li>Kernel Headers, SysFS: Verify kernel interface compatibility and system information access.</li> </ul> </li> <li>Testing Approach: Utilize unit tests, integration tests, and functional testing to ensure proper communication and data exchange.</li> </ul> <p>Related: 3.3. Standards: L4 \u2010 System Interface Testing</p>"},{"location":"external_content/ut-core-wiki/3.-Standards%3A-Levels-of-Test-for-Vendor-Layer/#l4-qa-layer-smoke-testing","title":"L4 - QA / Layer Smoke Testing","text":"<ul> <li>Purpose: To guard against regressions and ensure basic functionality before release.</li> <li>Scope:</li> <li>Release Checks: Prevent new L4 releases from breaking functionality in higher layers (MW and APP).</li> <li>Smoke Tests: Execute essential tests of the upper layer to quickly assess core functions.</li> <li>Application-Level Checks: Test video playback (if applicable) (e.g., Netflix) and full-stack scenarios to meet release criteria.</li> <li>Test Specification:  Reference the existing specification document for detailed test cases and expected results.</li> </ul> <p>Related: 3.4. Standards: L4: Vendor Full Stack \u2010 Video \u2010 Smoke Regression Test</p>"},{"location":"external_content/ut-core-wiki/3.-Standards%3A-Levels-of-Test-for-Vendor-Layer/#l4-deep-dive-testing","title":"L4 - Deep Dive Testing","text":"<ul> <li>Purpose: To perform comprehensive functional and performance validation.</li> <li>Scope: (Video)</li> <li>Audio Quality: Test audio playback across various output interfaces, measuring fidelity, latency, and synchronization.</li> <li>Video Quality: Evaluate video playback across supported codecs, assessing smoothness, artefacts, and colour accuracy.</li> <li>A/V Synchronization: Verify audio-video sync across different content and codecs.</li> <li>Graphics Performance: Conduct end-to-end testing, measuring frame rates, rendering quality, and resource usage.</li> <li>Mixing A/V + Display Scaling: Test scenarios like picture-in-picture to ensure correct scaling and display of multiple video planes.</li> <li>Trick Modes: Evaluate seeking accuracy and responsiveness, and test video plane scaling during trick modes.</li> </ul> <p>Related: (TBC)</p>"},{"location":"external_content/ut-core-wiki/3.0.1-Standards%3A-Testing-Feedback-Loops/","title":"3.0.1 Standards: Testing Feedback Loops","text":""},{"location":"external_content/ut-core-wiki/3.0.1-Standards%3A-Testing-Feedback-Loops/#testing-feedback-loops-and-issue-reproduction","title":"Testing Feedback Loops and Issue Reproduction","text":"<p>This document outlines the process for handling issues detected in the field and emphasizes the importance of reproducing these issues at the lowest possible level for efficient investigation and resolution.</p> <p>Key Principles:</p> <ul> <li>Reproducibility:  Issues found in higher-level testing or in the field should be reproducible at lower layers using dedicated testing suites. This allows the responsible team to effectively investigate and resolve the issue.</li> <li>Collaboration:  Testing suites should be accessible to all relevant parties, including internal teams and third-party vendors, to facilitate collaborative debugging and resolution.</li> <li>Continuous Improvement:  Testing suites should be continuously updated to reflect new issues and fixes. This ensures comprehensive test coverage and prevents regressions.</li> </ul> <p>Feedback Loop Process:</p> <ol> <li>Issue Detection: Issues may be identified through Level 4 or Level 5 testing, or reported from the field.</li> <li>Initial Triage: Determine whether the issue originates from the assembled product or a specific component delivery.</li> <li>Investigation (Component Level):<ul> <li>Attempt to reproduce the issue in lower-level tests (L2, L3).</li> <li>Extend existing test scenarios or create new tests to reproduce the issue at the component level.</li> <li>Commit these new tests to the relevant testing suite.</li> <li>Provide the new test suite to the vendor for further investigation.</li> </ul> </li> <li>Investigation (System Level):<ul> <li>Extend L4 and L5 test cases to reproduce and narrow down the issue.</li> <li>Commit new tests to the suite.</li> <li>Provide the updated test suite to the appropriate team for investigation.</li> </ul> </li> <li>Extending Coverage:<ul> <li>Regularly review test coverage to identify gaps.</li> <li>Extend testing suites at any level as needed to address new features or potential problem areas.</li> </ul> </li> </ol> <p>Testing Suite Management:</p> <ul> <li>All parties can contribute to the improvement of testing suites by submitting new tests or updates.</li> <li>Component owners are responsible for reviewing and approving changes to their respective testing suites.</li> <li>Testing suites are maintained with independent cadence and versioning to ensure flexibility and avoid conflicts.</li> <li>Comprehensive documentation is required for all tests, outlining the test objectives, procedures, and expected results.</li> </ul>"},{"location":"external_content/ut-core-wiki/3.1.-Standards%3A-Overview-of-Test%E2%80%90Driven-Development/","title":"3.1. Standards: Overview of Test\u2010Driven Development","text":"<p>What is Test-Driven Development?</p> <p>Test-Driven Development (TDD) is a software development approach where automated tests are written before the actual code that makes the tests pass. It's a cyclical process with these core steps:</p> <ol> <li>Red: Write a test that initially fails because the functionality it's testing doesn't exist yet.</li> <li>Green: Write the minimum amount of code necessary to make the test pass.</li> <li>Refactor: Improve the code's design and structure while ensuring the test remains green.</li> </ol> <p>The TDD Cycle</p> <p>This \"Red-Green-Refactor\" cycle is repeated continuously, with each iteration adding a small piece of functionality and its corresponding test.</p> <p>Why Use TDD?</p> <ul> <li>Confidence: TDD provides high confidence in your code's correctness. If all tests pass after changes, you're more assured the software is working as intended.</li> <li>Better Design:  Writing tests first forces you to think about how your code will be used and leads to cleaner, more modular designs.</li> <li>Living Documentation: The tests act as living documentation of the code's expected behavior.</li> <li>Reduced Debugging Time: When tests fail, you know exactly where to look for the problem, saving debugging effort.</li> <li>Faster Feedback Loop:  TDD gives quick feedback about the code's functionality, helping catch errors early.</li> </ul> <p>Key Concepts</p> <ul> <li>Unit Tests: TDD primarily focuses on unit tests, which test individual components of your software in isolation.</li> <li>Test Coverage:  TDD encourages high test coverage, meaning a large portion of your code is executed by tests.</li> <li>Refactoring: Refactoring is essential to maintain clean code and avoid accumulating technical debt.</li> </ul> <p>Benefits of TDD</p> <ul> <li>Higher Quality Code: TDD leads to more robust, reliable, and maintainable code.</li> <li>Reduced Defects:  Catching errors early in the development cycle saves time and money.</li> <li>Increased Productivity: While TDD might seem to slow down initial development, it can speed up the overall process by reducing debugging and rework.</li> <li>Improved Team Collaboration: TDD fosters collaboration between developers and testers as they work together to define test cases and ensure quality.</li> </ul> <p>Challenges of TDD</p> <ul> <li>Learning Curve: TDD requires a shift in mindset and may take time for developers to get comfortable with the process.</li> <li>Test Maintenance: Keeping tests up-to-date can be time-consuming, especially as code evolves.</li> <li>Not Always Suitable:  TDD might not be the best fit for every project or type of code.</li> </ul> <p>Is TDD Right for You?</p> <p>TDD is a valuable tool for many software development projects. Consider these factors to decide if it's suitable for your situation:</p> <ul> <li>Project Size: TDD shines in medium to large-sized projects where testing and maintenance are crucial.</li> <li>Team Experience: TDD is easier to adopt if your team has experience with testing or is open to learning new methodologies.</li> <li>Project Type: TDD is well-suited for projects with well-defined requirements and a focus on quality.</li> </ul>"},{"location":"external_content/ut-core-wiki/3.2.-Standards%3A-Requirements-for-building-testing-suites/","title":"3.2. Standards: Requirements for building testing suites","text":""},{"location":"external_content/ut-core-wiki/3.2.-Standards%3A-Requirements-for-building-testing-suites/#overview","title":"Overview","text":"<p>This details the requirements for generating and building testing suites for the RDK-E Project for the vendor layer</p> <ul> <li>L1 / L2 testing suites will use the <code>ut-core</code> testing framework</li> <li>L3/L4 levels will add the use <code>python-raft</code> infrastructure and the <code>ut-raft</code> framework and <code>ut-core</code> will still be expected to be used as required.</li> <li>It must adhere to the setup/layout guide provided here: https://github.com/rdkcentral/ut-raft/wiki/Guide-for-Setting-up-the-Python-RAFT-Testing-Suite</li> <li>Developers are expected to understand and utilize the <code>ut-raft</code> classes documented here: https://github.com/rdkcentral/ut-raft/wiki</li> <li>Examples of <code>python_raft</code> configuration and setup can be found in the aforementioned resources.</li> </ul> <p>A document outlining the tests for external interfaces will be created. This document will detail how to use the <code>python_raft</code> infrastructure to test the following:</p> <ul> <li>Selecting testing suite requirements from the platform-specific <code>deviceSettings.yaml</code>.</li> <li>Defining module-specific options for downloading assets required for testing.</li> <li>Building the necessary components for testing.</li> <li>Utilizing <code>sc docker</code> to access the toolchain.</li> <li>Tests should be designed to be platform independent, and driven by yaml configuration / profiles (see example: https://github.com/rdk-e/hal/wiki/Validation-Profiles).</li> </ul> <p>The module must be build-able and testable using the specified methods. A phased delivery model with collaboration between Tata and Sky teams is required.</p> <p>It should be noted that Vendor Layer testing is Black Box Testing.</p>"},{"location":"external_content/ut-core-wiki/3.2.-Standards%3A-Requirements-for-building-testing-suites/#levels-of-test","title":"Levels of Test","text":"<p>The levels of test to be implemented are defined here:</p> <p>https://github.com/rdkcentral/ut-core/wiki/3.-Standards:-Levels-of-Test-for-Vendor-Layer</p> <p>Testing Frameworks:</p> <ul> <li>L1/L2: <code>ut-core</code> wrapper for <code>gtest</code> (https://github.com/rdkcentral/ut-core) will be used for L1/L2 testing.</li> <li>L3: A combination of C++ and C, utilizing both <code>ut-core</code> and <code>python-raft</code> (https://github.com/rdkcentral/python-raft), will be used for L3 testing.</li> </ul> <p>See also FAQ:-UT-Core-Framework-Overview</p> <p>Phased Delivery:</p> <p>The team will follow the phased delivery which defines git tasks and review checkpoints.</p> <p>See also 3.2.1: Standards: Phased Delivery with Checkpoints</p>"},{"location":"external_content/ut-core-wiki/3.2.1%3A-Standards%3A-Phased-Delivery-with-Checkpoints/","title":"3.2.1: Standards: Phased Delivery with Checkpoints","text":""},{"location":"external_content/ut-core-wiki/3.2.1%3A-Standards%3A-Phased-Delivery-with-Checkpoints/#rrdir-research-review-design-implement-releasereview","title":"RRDIR (Research, Review, Design, Implement, Release/Review)","text":"<p>The following phases will be followed for delivery, with checkpoints at each stage. Tasks will be grouped into GitHub features, which will coordinate the release of multiple phases of delivery. GitHub project plans should be used to track and update progress throughout the workflow.  </p>"},{"location":"external_content/ut-core-wiki/3.2.1%3A-Standards%3A-Phased-Delivery-with-Checkpoints/#1-research-github-task-for-researchdesigndocumentation","title":"1. Research (GitHub Task for Research/Design/Documentation)","text":"<ul> <li>A GitHub task will be created to track research activities.  </li> <li>Each component team will provide a list of suggested tests.  </li> <li>The team will research the requirements and document findings.  </li> <li>A proposal will be generated based on the research.  </li> </ul> <p>Checkpoint: Completed research and proposal documented in the GitHub task.</p>"},{"location":"external_content/ut-core-wiki/3.2.1%3A-Standards%3A-Phased-Delivery-with-Checkpoints/#2-review-discussion-documentation","title":"2. Review (Discussion &amp; Documentation)","text":"<ul> <li>The Architecture team will review the findings either in the GitHub task or the discussion forum, as required.  </li> <li>Feedback from the Architecture team will be used to revise and refine the proposal.  </li> <li>The revised proposal will be written up for formal review.  </li> </ul> <p>Checkpoint: Written-up and approved proposal, moving towards finalization.</p>"},{"location":"external_content/ut-core-wiki/3.2.1%3A-Standards%3A-Phased-Delivery-with-Checkpoints/#3-design-wiki-documentation-for-review","title":"3. Design (Wiki Documentation for Review)","text":"<ul> <li>Based on the initial discussions, the design will be created to solidify the requirements.  </li> <li>The design will be documented on a Wiki page for review.  </li> <li>The Architecture team will review, provide feedback, and approve the design.  </li> <li>Once the design is approved, the corresponding GitHub task for the design phase will be closed, as the task is now complete.  </li> </ul> <p>Checkpoint: Design approved, documented on the Wiki page, and the design task closed.</p>"},{"location":"external_content/ut-core-wiki/3.2.1%3A-Standards%3A-Phased-Delivery-with-Checkpoints/#4-implement-github-task-for-implementation","title":"4. Implement (GitHub Task for Implementation)","text":"<ul> <li>Once the design is approved, a new GitHub task will be created to track the implementation.  </li> <li>The task will refer to the finalised design Wiki, which provides clear requirements for implementation.  </li> <li>The new task will clearly define goals, acceptance criteria, and branch name.  </li> <li>The Engineering team will begin implementation based on the design and raise a Pull Request (PR) for review.  </li> <li>The Architecture team will review the PR, provide feedback, and ensure it meets the acceptance criteria.  </li> <li>Once approved, the PR will be merged into the <code>develop</code> branch, and the implementation ticket will be closed.  </li> </ul> <p>Checkpoint: Completed implementation in the GitHub task, with the PR merged to <code>develop</code> and the implementation ticket closed.</p>"},{"location":"external_content/ut-core-wiki/3.2.1%3A-Standards%3A-Phased-Delivery-with-Checkpoints/#5-review-and-release","title":"5. Review and Release","text":"<ul> <li>The Release Team will handle the release process during the release cadence.  </li> <li>The Release Team will review the final merged code, tag it as required, and follow the release process outlined in the FAQ: Release Engineers: Performing a release with git flow.  </li> </ul> <p>Checkpoint: Release tagged and ready for deployment.</p>"},{"location":"external_content/ut-core-wiki/3.3.-Standards%3A-L4-%E2%80%90-System-Interface-Testing/","title":"3.3. Standards: L4 \u2010 System Interface Testing","text":""},{"location":"external_content/ut-core-wiki/3.3.-Standards%3A-L4-%E2%80%90-System-Interface-Testing/#overview-vsi","title":"Overview (VSI)","text":"<p>This document outlines the testing requirements and strategy for the Vendor System Interfaces (VSI) in the RDK framework.</p>"},{"location":"external_content/ut-core-wiki/3.3.-Standards%3A-L4-%E2%80%90-System-Interface-Testing/#implementing-the-testing-suite-a-proposed-approach","title":"Implementing the Testing Suite: A Proposed Approach","text":"<p>This document outlines a proposed approach for implementing a comprehensive testing suite, leveraging the <code>raft</code> framework and adhering to the RRDI (Research, Review, Design, Implement) methodology.</p> <p>Current Status: This plan is currently a work in progress and will be further refined as more information becomes available.</p> <p>Target Environment Assumptions:</p> <ul> <li>Base Image: The testing suite can assume that the target device has been programmed with a valid vendor image.</li> <li>Driver Installation: All necessary drivers are fully installed and operational on the target device.</li> <li>Clean Slate: No middleware or application layer exists on the target device. This allows for testing the vendor layer in isolation and ensures that tests are not influenced by pre-existing software components.</li> </ul> <p>Proposed Steps:</p> <p>1. Research and Review:</p> <ul> <li>Identify and Evaluate: Conduct thorough research to identify suitable open-source testing suites that align with the module's testing requirements. Consider factors like:<ul> <li>Test Coverage: Does the suite cover the necessary protocols, functionalities, and edge cases?</li> <li>Maturity and Support: Is the suite actively maintained with a strong community or support channels?</li> <li>Licensing: Is the licensing compatible with the project?</li> <li>Integration: How easily can the suite be integrated with the <code>raft</code> framework and the target environment?</li> </ul> </li> <li>Deep Dive: Review the selected testing suite's documentation and codebase to understand its capabilities, limitations, and potential integration challenges.</li> <li>Best Practices: Refer to the RRDI guidelines provided in the https://github.com/rdkcentral/ut-core/wiki/3.2.-Standards:-Requirements-for-building-testing-suites document for best practices.</li> </ul> <p>2. Design:</p> <ul> <li>Test Strategy: Based on the research and review findings, design a comprehensive testing strategy, including:<ul> <li>Test Cases: Define specific test cases to be implemented, prioritizing \"big ticket\" checks for core functionality.</li> <li>Test Data:  Outline how test data will be generated and managed. Consider using pre-defined datasets or dynamic generation techniques.</li> <li>Validation Classes: Design L4-wide validation classes to abstract the validation mechanisms, allowing for phased automation (human-assisted initially, progressing to fully automated).</li> <li><code>raft</code> Integration: Detail how the testing suite will be integrated with the <code>raft</code> framework for test execution, result collection, and reporting.</li> </ul> </li> <li>Phased Automation:  Incorporate a plan for the gradual transition from human-assisted validation to automated checks within the validation classes.</li> </ul> <p>3. Implementation:</p> <ul> <li>Leverage <code>raft</code>: Utilize the <code>raft</code> framework throughout the implementation process:<ul> <li>Download: Download a specific version of the chosen open-source testing suite using <code>raft</code>.</li> <li>Build: Build the testing suite using the toolchain provided by the <code>sc docker</code> environment, ensuring compatibility with the target platform.</li> <li>Deploy: Copy the built testing suite to the target device/environment using <code>raft</code>.</li> <li>Orchestrate: Utilize <code>raft</code> to orchestrate the execution of the test suite on the target, including setup, execution, and teardown.</li> <li>Remote Execution: Enable the capability to download and execute the test suite on a running device/environment using <code>raft</code>.</li> <li>Result Collation: Utilize <code>raft</code> to collect and collate the test results for analysis and reporting.</li> </ul> </li> <li>Debugging Support: Ensure the implementation allows for easy debugging by enabling single-stepping through <code>raft</code> scripts and providing seamless access to the target device for engineers.</li> </ul> <p>Key Considerations:</p> <ul> <li>Module Requirements: Clearly define the testing requirements and goals for the module under test. This will guide the selection of the testing suite and the design of specific test cases.</li> <li><code>raft</code> Integration: Ensure seamless integration with the <code>raft</code> framework throughout the entire testing process, from downloading and building the suite to executing tests and collecting results.</li> <li>Target Environment: Consider the specific characteristics of the target environment (e.g., hardware limitations, operating system) when selecting and building the testing suite. These will be driven by platform-specific input profiles fed into <code>raft</code> and the build process.</li> <li>Scalability and Maintainability: Design the testing suite and its integration with <code>raft</code> for scalability and maintainability, allowing for easy expansion and updates in the future.</li> </ul> <p>By following this approach and incorporating the principles outlined in the previous document, we can create a robust and efficient testing suite that effectively validates the functionality and stability of the stack.</p>"},{"location":"external_content/ut-core-wiki/3.3.-Standards%3A-L4-%E2%80%90-System-Interface-Testing/#key-interfaces","title":"Key Interfaces","text":"<p>Here's the list of main modules that require dedicated testing:</p> <ul> <li> <p>Bluetooth (Bluez)</p> <ul> <li>Requirements Definition:  Clearly define the requirements for Bluetooth functionality within RDK.</li> <li>Collaboration:  Architecture experts need to review and confirm these requirements.</li> </ul> </li> <li> <p>WiFi (wpa-supplicant)</p> </li> <li>API Testing: Utilize an open-source testing suite to conduct comprehensive API testing of wpa-supplicant.</li> <li> <p>Clear set of requirements needs to be defined</p> </li> <li> <p>OpenGLES / EGL</p> <ul> <li>Compliance and Performance:<ol> <li>Gather Vendor Test Data: Obtain a detailed description of the testing performed by the SoC vendor, including compliance tests and performance benchmarks. Request evidence (test results, reports) to support.</li> <li>Performance Benchmarking:  Establish performance benchmarks using OpenGLES benchmarking tools (e.g., glbenchmark).</li> <li>Cross-Platform Comparison: It must be possible to run the same benchmarks across all supported platforms to establish a baseline and ensure new deliveries from vendors meet the minimum performance requirements. Therefore the data output will be in a format that can be used per platform to compare.</li> </ol> </li> </ul> </li> <li> <p>Kernel Testing</p> <ul> <li>Kernel Configuration Requirements: Define specific kernel configuration requirements for RDK in collaboration with the vendor team. These requirements will guide the selection of appropriate validation testing suites from LFS.</li> <li>LFS Testing System: Leverage the Linux Foundation System (LFS) testing infrastructure for kernel-level testing.</li> </ul> </li> </ul>"},{"location":"external_content/ut-core-wiki/3.4.-Standards%3A-L4%3A-Vendor-Full-Stack-%E2%80%90-Video-%E2%80%90-Smoke-Regression-Test/","title":"3.4. Standards: L4: Vendor Full Stack \u2010 Video \u2010 Smoke Regression Test","text":""},{"location":"external_content/ut-core-wiki/3.4.-Standards%3A-L4%3A-Vendor-Full-Stack-%E2%80%90-Video-%E2%80%90-Smoke-Regression-Test/#overview-vst","title":"Overview (VST)","text":"<p>This document outlines the automated test plan for L4 (Vendor Full Stack) testing of RDK Video releases. These tests focus on verifying the stability and functionality of the RDK Video stack by testing the integration of the vendor, application (APP), and middleware (MW) layers.</p> <p>Goal: To automate the execution of smoke and regression tests that are currently performed manually, improving efficiency and reducing testing time.</p> <p>Scope: These tests are designed as \"big ticket\" checks, focusing on core functionality:</p> <ul> <li>Is video running?</li> <li>Is audio running?</li> <li>Is video/audio sync operating correctly?</li> <li>Are trick modes operational? (Including checks for black screens, display movement, and errors) </li> </ul> <p>These tests are not intended to be deep-dive device analysis tests. Those are covered by other testing activities. The focus here is on smoke testing to validate that main functionality is still operational after:</p> <ul> <li>Integrating a new vendor layer with the existing APP/MW.</li> <li>Integrating a new APP/MW layer with the existing vendor layer.</li> </ul> <p>This ensures that any new layer introduced does not break the core functionality of the stack.</p> <p>Framework: <code>python_raft</code> will be used to automate these tests, enabling engineers and Jenkins to trigger them as needed.</p> <p>Test Approach:</p> <ul> <li>Build: A full stack image is created using the relevant combination of\u00a0 APP/MW and Vendor layers.</li> <li>Automation: <code>python_raft</code> scripts will be developed to automate the test cases described below.</li> <li>Execution: Tests can be triggered by engineers or integrated into the Jenkins CI/CD pipeline.</li> <li>Reporting: <code>python_raft</code> will provide test results and logs for analysis.</li> </ul> <p>Important: These tests are designed as a pre-release quality gate, ensuring no regressions are introduced before a new layer (vendor, APP, or MW) is released.</p> <p>Target Environment Assumptions:</p> <ul> <li>Full Stack Image: The testing suite can assume that the target device has been programmed with a valid full stack image (vendor, middleware, and application layers).</li> <li>System Ready: Tests should wait for the system to be fully operational before commencing. <code>python_raft</code> already provides mechanisms to achieve this (e.g., by monitoring system logs or specific services, see <code>waitForBoot()</code> ).</li> </ul> <p>Configuration and Platform Independence:</p> <ul> <li>Configuration-driven: The testing suites will be driven by configuration information on the CPE and the image that's running. This includes details about the platform, software version, and available features. To be clear <code>python_raft</code> already supports this, and has methods to extend based on requirements.</li> <li>Platform Abstraction: Tests should prioritize launching applications from the command line whenever possible. This approach offers several advantages:<ul> <li>Consistency: Command-line interfaces tend to be more stable across platforms and software versions compared to graphical interfaces and remote control key sequences.</li> <li>Speed: Launching applications from the command line is generally faster than navigating through menus using a remote control.</li> <li>Reliability:  Command-line launching eliminates potential issues with IR/Bluetooth signal interference or key sequence misinterpretations.</li> </ul> </li> <li>Key Playback Classes (for specific scenarios): While command-line launching is preferred, there might be scenarios where using IR/Bluetooth keys is unavoidable. In such cases:<ul> <li>Wrap platform-specific key sequences in key playback classes. These classes will abstract the underlying key sequences, providing a consistent interface for test scripts.</li> <li>Drive the testing suites by <code>versioned profiles</code> based on the platform. These profiles will contain the necessary configuration data for each platform and software version, ensuring that the correct key sequences and navigation paths are used.</li> </ul> </li> </ul> <p>By prioritizing command-line application launching and utilizing key playback classes and versioned profiles when necessary, the testing suite can achieve a high degree of platform independence and resilience to changes in the user interface and remote control configurations.</p> <p>Requirements:</p> <ol> <li>Integration with L4-wide Validation Classes: The L4 testing suite shall integrate with common L4-wide classes that perform validation checks. These classes will abstract the underlying validation mechanisms, allowing for a phased approach to automation:</li> <li>Phase 1: Human-assisted Validation: Initially, these classes may prompt a human tester with a simple yes/no question to confirm the expected behaviour.</li> <li> <p>Phase 2: Automated Validation:\u00a0 These classes will be progressively upgraded to perform automated validation by directly interacting with the system, e.g., checking proc files for decoder activity, analysing log output, or querying system states. This allows for a gradual transition from manual to automated testing.</p> </li> <li> <p>Engineering-focused Debugging: This test suite is primarily intended for use by engineers. When test failures occur, the framework should facilitate debugging by:</p> </li> <li>Single-stepping through Python Orchestration:\u00a0 Engineers should be able to easily single-step through the <code>python_raft</code> scripts to understand the test flow and pinpoint the failing steps.</li> <li>Seamless Access to Target Device: The framework should provide mechanisms for engineers to readily access the target device (e.g., via SSH) for debugging purposes. This allows them to analyse C code, examine driver data, and inspect system logs in parallel with the test execution.</li> </ol> <p>By adhering to these requirements, the L4 automated testing suite will not only provide a robust quality gate but also empower engineers to efficiently identify and resolve issues across the entire stack.</p>"},{"location":"external_content/ut-core-wiki/3.4.-Standards%3A-L4%3A-Vendor-Full-Stack-%E2%80%90-Video-%E2%80%90-Smoke-Regression-Test/#test-suites","title":"Test Suites","text":""},{"location":"external_content/ut-core-wiki/3.4.-Standards%3A-L4%3A-Vendor-Full-Stack-%E2%80%90-Video-%E2%80%90-Smoke-Regression-Test/#a-linear-channels-vod","title":"A. Linear Channels &amp; VOD","text":"Test Case Description Status (Pass/Fail) Remarks A1 General Sanity on APP Playchannels: Play channels for 5 minutes, changing channels via remote. A2 Sanity on Linear SDR Channel: Test channel 101/501. A3 Sanity on Linear UHD Channel: Test channel 406. A4 Sanity on Linear Channel Requiring PIN: Test channels 301, 302. A5 Sanity on VOD (SDR): Test SDR VOD content. A6 Sanity on VOD (UHD): Test UHD VOD content."},{"location":"external_content/ut-core-wiki/3.4.-Standards%3A-L4%3A-Vendor-Full-Stack-%E2%80%90-Video-%E2%80%90-Smoke-Regression-Test/#b-apps-testing","title":"B. Apps Testing","text":"Test Case Description Status (Pass/Fail) Remarks B1 APPS - YouTube - SDR: Test YouTube with SDR content. B2 APPS - YouTube - HLG: Test YouTube with HLG content. B3 APPS - YouTube - HDR10: Test YouTube with HDR10 content. B4 APPS - Netflix - SDR: Test Netflix with SDR content. B5 APPS - Netflix - DV: Test Netflix with Dolby Vision content. B6 APPS - Disney+ - SDR: Test Disney+ with SDR content. B7 APPS - Disney+ - DV: Test Disney+ with Dolby Vision content. B8 APPS - Amazon Prime - SDR: Test Amazon Prime with SDR content. B9 APPS - Amazon Prime - HDR10: Test Amazon Prime with HDR10 content. B10 APPS - Amazon Prime - DV: Test Amazon Prime with Dolby Vision content. B11 APPS - Apple TV - DV: Test Apple TV with Dolby Vision content. B12 APPS - Paramount+ - SDR: Test Paramount+ with SDR content. B13 APPS - YouTube Kids - SDR: Test YouTube Kids with SDR content. B14 APPS - BBC iPlayer - SDR: Test BBC iPlayer with SDR content. B15 APP - Peacock: Test Peacock app."},{"location":"external_content/ut-core-wiki/3.4.-Standards%3A-L4%3A-Vendor-Full-Stack-%E2%80%90-Video-%E2%80%90-Smoke-Regression-Test/#c-switching-between-apps","title":"C. Switching Between Apps","text":"Test Case Description Status Remarks C1 YouTube to: Netflix, Amazon Prime, Disney+, Apple TV, Paramount+, YouTube Kids, Peacock. C2 Netflix to: YouTube, Amazon Prime, Disney+, Apple TV, Paramount+, YouTube Kids, Peacock. C3 Disney+ to: YouTube, Amazon Prime, Netflix, Apple TV, Paramount+, YouTube Kids, Peacock. C4 Apple TV to: YouTube, Amazon Prime, Netflix, Disney+, Paramount+, YouTube Kids, Peacock. C5 Paramount+ to: YouTube, Amazon Prime, Netflix, Disney+, Apple TV, YouTube Kids, Peacock. C6 YouTube Kids to: YouTube, Amazon Prime, Netflix, Disney+, Apple TV, Paramount+, Peacock. C7 Peacock to: YouTube, Amazon Prime, Netflix, Disney+, Apple TV, Paramount+, YouTube Kids. C8 Amazon Prime to: YouTube, Netflix, Disney+, Apple TV, Paramount+, YouTube Kids, Peacock."},{"location":"external_content/ut-core-wiki/3.4.-Standards%3A-L4%3A-Vendor-Full-Stack-%E2%80%90-Video-%E2%80%90-Smoke-Regression-Test/#d-wi-fi-ethernet-test","title":"D. Wi-Fi / Ethernet Test","text":"Test Case Description Status(Pass/Fail) Remarks D1 Factory Reset and Connect: Factory reset the panel and connect to 5GHz/2.4GHz SSID during setup. D2 Connect Ethernet: Connect Ethernet while the panel is on 5GHz/2.4GHz Wi-Fi. D3 Disconnect Ethernet: Disconnect Ethernet and check if it resumes the last Wi-Fi connection. D4 Verify IP Address: Check if the panel's IP address matches the one assigned by the router. D5 Play/Stream Videos: Play/stream 4K/HDR/UHD videos on 5GHz/2.4GHz network. D6 Soft Reboot (Wi-Fi): Soft reboot the panel while connected to 5GHz/2.4GHz and ensure reconnection. D7 Boot Up Time (Wi-Fi): Check boot-up time when connected to 5GHz/2.4GHz. D8 Hard Reboot (Wi-Fi): Hard reboot the panel while connected to 5GHz/2.4GHz and ensure reconnection. D9 Boot Up Time (Wi-Fi): Check boot-up time when connected to 5GHz/2.4GHz. D10 Reset Network: Reset the network while the panel is on 5GHz/2.4GHz. D11 Soft Reboot (No Internet): Soft reboot after network reset and ensure the panel boots with no internet. D12 Boot Up Time (No Internet): Check boot-up time with no internet. D13 Hard Reboot (No Internet): Hard reboot after network reset and ensure the panel boots with no internet. D14 Boot Up Time (No Internet): Check boot-up time with no internet. D15 Disable Wi-Fi: Disable Wi-Fi via settings and ensure the \"no internet\" screen appears. D16 Hard Reboot (No Internet): Hard reboot and ensure the panel boots with no internet. D17 Disable Wi-Fi: Disable Wi-Fi via settings and ensure the \"no internet\" screen appears. D18 Soft Reboot (No Internet): Soft reboot and ensure the panel boots with no internet. D19 Enable Wi-Fi: Enable Wi-Fi and ensure the panel connects to the last Wi-Fi connection. D20 Power Cycle Router: While connected to 5GHz/2.4GHz, power cycle the router and ensure the panel reconnects. ... ... ... ..."},{"location":"external_content/ut-core-wiki/3.4.-Standards%3A-L4%3A-Vendor-Full-Stack-%E2%80%90-Video-%E2%80%90-Smoke-Regression-Test/#e-motion-deep-sleep-test","title":"E. Motion &amp; Deep Sleep Test","text":"Test Case Description Status (Pass/Fail) Remarks E1 Verify Motion Events: Verify motion events are detected. E2 HDMI Content and Motion: Play HDMI content and verify motion events. E3 Linear Channel and Motion: Play linear channels and verify motion events. E4 Apps and Motion: Play apps like YouTube/Netflix/Disney+ and verify motion events. E5 Power Cycle and Motion: Power cycle the panel and check motion events. E6 Standby and Motion: Put the panel in standby, wake it up, and check motion events. E7 Deepsleep and Motion: Put the panel in deep sleep, wake it up, and check motion events. E8 Auto-Standby: Ensure the panel enters standby mode after 50 minutes of inactivity. E9 Banner Removal: Check if the banner is removed by generating motion at the 51st minute. E10 Linear Channel and No Banner: Ensure no banner appears after 50 minutes of activity on linear channels. ... ... ... ..."},{"location":"external_content/ut-core-wiki/3.4.-Standards%3A-L4%3A-Vendor-Full-Stack-%E2%80%90-Video-%E2%80%90-Smoke-Regression-Test/#f-led-behaviour-test","title":"F. LED Behaviour Test","text":"Test Case Description Status (Pass/Fail) Remarks F1 Checking LED behaviour on power cycle from ON state F2 Checking LED behaviour on power cycle from standby mode state F3 Checking LED behaviour on power cycle from Deepsleep mode state F4 Checking LED behaviour on Soft reboot the panel from ON state F5 Checking LED behaviour on Soft reboot the panel from standby state ... ... ... ..."},{"location":"external_content/ut-core-wiki/3.4.-Standards%3A-L4%3A-Vendor-Full-Stack-%E2%80%90-Video-%E2%80%90-Smoke-Regression-Test/#g-remote-test","title":"G. Remote Test","text":"Test Case Description Status (Pass/Fail) Remarks G1 Wake panel via IR remote --HOME button G2 Wake panel via IR remote --Power button G3 Wake panel via IR remote --PRIME Button G4 Wake panel via IR remote -NETFLIX button G5 Navigate the EPG page, try trick modes &amp; different buttons on remote (IR) G6 Pair the remote on BT G7 Unpair the remote &amp; pair it again G8 Navigate the EPG page, try trick modes &amp; different buttons on remote (BT) G9 Wake panel from standby mode via BT remote --HOME button G10 Wake panel from standby mode via BT remote --Power button G11 Wake panel from deep sleep mode via BT remote --HOME button G12 Wake panel from deep sleep mode via BT remote --Power button"},{"location":"external_content/ut-core-wiki/3.4.-Standards%3A-L4%3A-Vendor-Full-Stack-%E2%80%90-Video-%E2%80%90-Smoke-Regression-Test/#h-ffv-test","title":"H. FFV Test","text":"Test Case Description Status (Pass/Fail) Remarks H1 Mic enable via side button - Launch channel, apps, volume etc via FFV H2 Mic enable via side button - Put panel in standby via FFV H3 Mic enable via side button - Wake panel via FFV from standby H4 Mic enable via side button - Put panel in deep sleep &amp; wake it via FFV H5 Mic enable via side button - Soft reboot panel &amp; check if MIC status remains persistent H6 Mic enable via side button - Hard reboot panel &amp; check if MIC status remains persistent H7 Mic disable via side button - Launch channel, apps, volume etc via FFV H8 Mic disable via side button - Put panel in standby via FFV H9 Mic disable via side button - Wake panel via FFV from standby H10 Mic disable via side button - Put panel in deep sleep &amp; wake it via FFV H11 Mic disable via side button - Soft reboot panel &amp; check if MIC status remains persistent H12 Mic disable via side button - Hard reboot panel &amp; check if MIC status remains persistent ... ... ... ..."},{"location":"external_content/ut-core-wiki/3.4.-Standards%3A-L4%3A-Vendor-Full-Stack-%E2%80%90-Video-%E2%80%90-Smoke-Regression-Test/#i-hdmi-source-firetv-chromecast-appletv","title":"I. HDMI Source - FireTV / Chromecast / AppleTV","text":"Test Case Description Status (Pass/Fail) Remarks I1 Launch HDMI source via HDMI Source remote I2 Play any content on HDMI source &amp; check AV I3 Change different resolution on HDMI source I4 When panel is in standby, wake panel via HDMI source I5 When panel in deep sleep, wake panel via HDMI source I6 Hot plug HDMI source I7 Switch between HDMI source, APPS"},{"location":"external_content/ut-core-wiki/3.4.-Standards%3A-L4%3A-Vendor-Full-Stack-%E2%80%90-Video-%E2%80%90-Smoke-Regression-Test/#j-hdmi-audio-device","title":"J. HDMI Audio Device","text":"Test Case Description Status (Pass/Fail) Remarks J1 Connect HDMI speaker on HDMI &amp; check sound coming from speakers J2 Hot plug HDMI speakers &amp; make sure Audio switches back properly J3 Check any AV sync issue J4 Check audio for contents on HDMI source when HDMI speakers connected J5 Put panel in standby &amp; wake it up, check the audio coming from HDMI speakers J6 Put panel in deep sleep &amp; wake it up, check the audio coming from HDMI speakers"},{"location":"external_content/ut-core-wiki/3.4.-Standards%3A-L4%3A-Vendor-Full-Stack-%E2%80%90-Video-%E2%80%90-Smoke-Regression-Test/#k-bt-audio-device","title":"K. BT Audio Device","text":"Test Case Description Status (Pass/Fail) Remarks K1 Pair BT speakers &amp; check sound coming from speakers K2 Check any AV sync issue on BT speakers while playing apps, HDMI, linear channel K3 Check audio for contents on HDMI source when BT speakers connected K4 Change the output of audio via quick menu K5 Put panel in standby &amp; wake it up, check the audio coming from BT speakers K6 Put panel in deep sleep &amp; wake it up, check the audio coming from BT speakers"},{"location":"external_content/ut-core-wiki/3.4.-Standards%3A-L4%3A-Vendor-Full-Stack-%E2%80%90-Video-%E2%80%90-Smoke-Regression-Test/#l-dtt-channels","title":"L. DTT Channels","text":"Test Case Description Status (Pass/Fail) Remarks L1 Checking AV of DTT channel (SD &amp; HD channels) L2 Scanning DTT channels L3 Switch between DTT channels &amp; HDMI source L4 Browsing TV guide, signal information, audio etc in DTT channels option"},{"location":"external_content/ut-core-wiki/3.4.-Standards%3A-L4%3A-Vendor-Full-Stack-%E2%80%90-Video-%E2%80%90-Smoke-Regression-Test/#m-boot-up-time","title":"M. Boot Up Time","text":"Test Case Description Status (Pass/Fail) Remarks M1 Hard reboot (power cycle) 1 M2 Hard reboot (power cycle) 2 M3 Hard reboot (power cycle) 3 M4 Soft reboot (/rebootNow.sh) 1 M5 Soft reboot (/rebootNow.sh) 2 M6 Soft reboot (/rebootNow.sh) 3"},{"location":"external_content/ut-core-wiki/4.-Standards%3A-Dynamic-Library-Loading-for-Vendor-Abstraction/","title":"Dynamic Library Loading for Vendor Abstraction","text":""},{"location":"external_content/ut-core-wiki/4.-Standards%3A-Dynamic-Library-Loading-for-Vendor-Abstraction/#description","title":"Description","text":"<p>This example demonstrates how to use dynamic library loading to abstract vendor-specific code in a Hardware Abstraction Layer (HAL). This approach allows you to:</p> <ul> <li>Remove build time dependancies isolating vendor specific library requirements into the wrapper.</li> <li>Maintain a consistent interface for interacting with hardware from different vendors.</li> <li>Improve code modularity and maintainability by separating vendor-specific code from the HAL.</li> </ul> <pre><code>// --- hal_interface.h ---\n\n#ifndef HAL_INTERFACE_H\n#define HAL_INTERFACE_H\n\n// Define the HAL interface (concrete functions). \n// These functions provide a consistent interface to the application, \n// regardless of the underlying vendor implementation.\nint hal_init(void);                      // Initialise the HAL\nint hal_read_sensor(int sensor_id);      // Read from a sensor using the HAL\nvoid hal_write_actuator(int actuator_id, int value); // Write to an actuator using the HAL\n\n#endif // HAL_INTERFACE_H\n\n// --- hal_impl.c ---\n\n#include \"hal_interface.h\"\n#include &lt;dlfcn.h&gt;\n#include &lt;stdio.h&gt;\n\n// Define the vendor interface. This structure holds function pointers\n// to functions that will be implemented in the vendor-specific library.\ntypedef struct \n{\n  int (*vendor_init)(void);              // Initialise the vendor hardware\n  int (*vendor_read_sensor)(int sensor_id);  // Read data from a sensor\n  void (*vendor_write_actuator)(int actuator_id, int value); // Write a value to an actuator\n} vendor_interface_t;\n\n// Function to load a shared library at runtime.\n// This function uses dlopen to load the specified library file.\nvoid* load_dependency(const char* dependency_path) \n{\n  void* handle = dlopen(dependency_path, RTLD_LAZY);\n  if (!handle) {\n    fprintf(stderr, \"Error loading dependency: %s\\n\", dlerror());\n    return NULL;\n  }\n  return handle;\n}\n\n// Global variable to hold the vendor interface. This variable will \n// store the function pointers loaded from the vendor library.\nvendor_interface_t vendor;\n\n// Function to initialize the HAL and load the vendor library.\n// This function is responsible for loading the vendor-specific \n// library and initializing the HAL with the vendor's functions.\nint hal_init(void) \n{\n  // Load the vendor library (e.g., vendor_lib.so)\n  void* vendor_lib_handle = load_dependency(\"./vendor_lib.so\");\n  if (!vendor_lib_handle) \n  {\n    return -1;\n  }\n\n  // Get the 'get_vendor_interface' function from the vendor library.\n  // This function will return a populated vendor_interface_t structure.\n  vendor_interface_t (*get_vendor_interface_fn)(void) = \n      (vendor_interface_t (*)(void))dlsym(vendor_lib_handle, \"get_vendor_interface\");\n  if (!get_vendor_interface_fn) \n  {\n    fprintf(stderr, \"Error getting symbol: %s\\n\", dlerror());\n    dlclose(vendor_lib_handle);\n    return -1;\n  }\n\n  // Get the vendor interface and store it in the global variable.\n  vendor = get_vendor_interface_fn();\n\n  // Initialize the vendor library using the loaded function.\n  if (vendor.vendor_init() != 0) \n  {\n    fprintf(stderr, \"Error initializing vendor library\\n\");\n    dlclose(vendor_lib_handle);\n    return -1;\n  }\n\n  return 0;\n}\n\n// HAL function implementations using the vendor interface.\n// These functions call the corresponding functions in the \n// dynamically loaded vendor library.\nint hal_read_sensor(int sensor_id) \n{\n  return vendor.vendor_read_sensor(sensor_id);\n}\n\nvoid hal_write_actuator(int actuator_id, int value) \n{\n  vendor.vendor_write_actuator(actuator_id, value);\n}\n\n// --- vendor_lib_a.c (Example vendor implementation) ---\n\n#include \"hal_interface.h\"\n\n// Vendor A specific implementations of the functions defined in vendor_interface_t\nint vendor_init(void) \n{\n  // ... vendor A initialization ...\n  printf(\"Vendor A initialized\\n\");\n  return 0;\n}\n\nint vendor_read_sensor(int sensor_id) \n{\n  // ... vendor A sensor reading ...\n  printf(\"Vendor A reading sensor %d\\n\", sensor_id);\n  return sensor_id * 10;\n}\n\nvoid vendor_write_actuator(int actuator_id, int value) \n{\n  // ... vendor A actuator writing ...\n  printf(\"Vendor A writing %d to actuator %d\\n\", value, actuator_id);\n}\n\n// Export the 'get_vendor_interface' function. This function returns \n// a vendor_interface_t structure populated with the vendor's function pointers.\nvendor_interface_t get_vendor_interface(void) \n{\n  static vendor_interface_t vendor = \n  {\n    .vendor_init = vendor_init,\n    .vendor_read_sensor = vendor_read_sensor,\n    .vendor_write_actuator = vendor_write_actuator\n  };\n  return vendor;\n}\n\n// --- main.c (Example application) ---\n\n#include \"hal_interface.h\"\n#include &lt;stdio.h&gt;\n\nint main() \n{\n  // Initialize the HAL. This will load the vendor library and initialize\n  // the vendor-specific hardware.\n  if (hal_init() != 0) \n  {\n    fprintf(stderr, \"HAL initialization failed\\n\");\n    return 1;\n  }\n\n  // Use the HAL functions to interact with the hardware.\n  printf(\"Sensor value: %d\\n\", hal_read_sensor(5));\n  hal_write_actuator(2, 100);\n\n  return 0;\n}\n</code></pre>"},{"location":"external_content/ut-core-wiki/4.-Standards%3A-Dynamic-Library-Loading-for-Vendor-Abstraction/#code-structure","title":"Code Structure","text":"<ul> <li> <p><code>hal_interface.h</code>: Defines the vendor and HAL interfaces.</p> <ul> <li><code>vendor_interface_t</code>: Structure holding function pointers for vendor-specific functions.</li> <li>HAL functions: Concrete functions providing a consistent interface to the application.</li> </ul> </li> <li> <p><code>hal_impl.c</code>: Implements the HAL and dynamically loads the vendor library.</p> <ul> <li><code>load_dependency()</code>: Loads a shared library at runtime using <code>dlopen</code>.</li> <li><code>hal_init()</code>: Initialises the HAL, loads the vendor library, and retrieves the vendor interface.</li> <li>HAL functions: Implementations using the loaded vendor functions.</li> </ul> </li> <li> <p><code>vendor_lib_a.c</code>: Example vendor library implementation.</p> <ul> <li>Vendor functions: Implementations of the functions defined in <code>vendor_interface_t</code>.</li> <li><code>get_vendor_interface()</code>: Returns a populated <code>vendor_interface_t</code> structure.</li> </ul> </li> <li> <p><code>main.c</code>: Example application using the HAL.</p> <ul> <li><code>hal_init()</code>: Initialises the HAL.</li> <li>HAL functions: Calls to interact with the hardware through the HAL.</li> </ul> </li> </ul>"},{"location":"external_content/ut-core-wiki/4.-Standards%3A-Dynamic-Library-Loading-for-Vendor-Abstraction/#benefits","title":"Benefits","text":"<ul> <li>Abstraction: Provides a consistent HAL interface for different vendors.</li> <li>Modularity: Isolates vendor-specific code.</li> <li>Flexibility: Enables easy switching between vendors.</li> </ul>"},{"location":"external_content/ut-core-wiki/4.-Standards%3A-Dynamic-Library-Loading-for-Vendor-Abstraction/#example-output","title":"Example Output:","text":"<pre><code>Vendor A initialised\nVendor A reading sensor 5\nVendor A writing 100 to actuator 2\nSensor value: 50\n</code></pre>"},{"location":"external_content/ut-core-wiki/4.-Standards%3A-Dynamic-Library-Loading-for-Vendor-Abstraction/#faq-what-happens-if-the-library-thats-being-loaded-has-dependancies","title":"FAQ: What happens if the library that's being loaded has dependancies","text":"<p>When you use <code>dlopen</code> to load a shared library, the dynamic linker also takes care of loading any other shared libraries that the loaded library depends on. This process is called dependency resolution.</p> <p>Here's how it works:</p> <ol> <li> <p>Dependency List: Every shared library contains a list of its dependencies (other shared libraries it needs to function). This information is stored within the library file itself.</p> </li> <li> <p>Recursive Loading: When you load a library with <code>dlopen</code>, the dynamic linker examines its dependency list. For each dependency:</p> <ul> <li>It checks if the dependency is already loaded. If it is, it's reused.</li> <li>If not, it recursively loads the dependency using the same <code>dlopen</code> process, which may in turn load further dependencies.</li> </ul> </li> <li> <p>Symbol Resolution: Once all dependencies are loaded, the dynamic linker resolves symbols (function names, variables) between the libraries. This ensures that calls from one library to another are correctly linked.</p> </li> <li> <p>Search Path: The dynamic linker uses a search path to locate dependencies. This path is typically defined by the <code>LD_LIBRARY_PATH</code> environment variable and/or the <code>rpath</code> (runtime path) embedded in the library.</p> </li> </ol> <p>Example:</p> <p>If <code>libA.so</code> depends on <code>libB.so</code> and <code>libC.so</code>, and you call <code>dlopen(\"libA.so\", ...)</code>, the following will happen:</p> <ol> <li><code>libA.so</code> is loaded.</li> <li>The dynamic linker sees that <code>libA.so</code> needs <code>libB.so</code> and <code>libC.so</code>.</li> <li><code>libB.so</code> and <code>libC.so</code> are loaded (if they weren't already).</li> <li>Symbols between <code>libA.so</code>, <code>libB.so</code>, and <code>libC.so</code> are resolved.</li> </ol> <p>Important Considerations:</p> <ul> <li>Circular Dependencies: If you have circular dependencies (e.g., <code>libA.so</code> depends on <code>libB.so</code>, and <code>libB.so</code> depends on <code>libA.so</code>), the dynamic linker may not be able to resolve them, leading to errors.</li> <li>Versioning: Different versions of a library might exist. The dynamic linker needs to ensure that the correct versions are loaded to avoid compatibility issues. This is usually handled through sonames (e.g., <code>libmylib.so.1</code>).</li> <li>Error Handling: If a dependency cannot be found or loaded, <code>dlopen</code> will fail, and you should handle the error appropriately.</li> </ul> <p>In summary, <code>dlopen</code> not only loads the specified library but also automatically handles the loading and linking of its dependencies, ensuring that the library can function correctly. This makes it easier to manage complex applications with multiple shared libraries.</p>"},{"location":"external_content/ut-core-wiki/4.0.1%3A-Standards%3A-Dynamic-Library-Search-Order/","title":"4.0.1: Standards: Dynamic Library Search Order","text":"<p>The <code>dlopen</code> function in C is used to dynamically load shared libraries at runtime. Here's how it searches for libraries and how <code>LD_LIBRARY_PATH</code> plays a role:</p> <p>Search Order</p> <p>When you call <code>dlopen</code> with a library name, it follows a specific search order to locate the library:</p> <ol> <li> <p>Absolute Path: If the filename provided to <code>dlopen</code> includes a slash (\"/\"), it's treated as an absolute or relative path, and the dynamic linker will try to load the library directly from that location.</p> </li> <li> <p>RPATH: If the executable file contains a <code>DT_RPATH</code> tag (and no <code>DT_RUNPATH</code> tag), the directories listed in the <code>DT_RPATH</code> tag are searched. This allows embedding paths to dependencies within the executable itself.</p> </li> <li> <p>LD_LIBRARY_PATH: If the environment variable <code>LD_LIBRARY_PATH</code> is set when the program starts, the directories listed in it are searched. However, this is ignored for security reasons if the program has set-user-ID or set-group-ID permissions.</p> </li> <li> <p>RUNPATH: If the executable file contains a <code>DT_RUNPATH</code> tag, the directories listed in that tag are searched. This is similar to <code>DT_RPATH</code> but is often preferred because it allows more flexibility in how libraries are found.</p> </li> <li> <p>ld.so.cache: The dynamic linker checks the file <code>/etc/ld.so.cache</code> (maintained by <code>ldconfig</code>) to see if it contains an entry for the library. This cache speeds up library loading.</p> </li> <li> <p>Default Directories: Finally, the directories <code>/lib</code> and <code>/usr/lib</code> are searched.</p> </li> </ol> <p>LD_LIBRARY_PATH</p> <p><code>LD_LIBRARY_PATH</code> is an environment variable that can be used to specify additional directories where the dynamic linker should look for shared libraries. It can be useful for:</p> <ul> <li>Testing: You can temporarily add a directory with your test libraries to <code>LD_LIBRARY_PATH</code> without having to install them in the system directories.</li> <li>Development:  If you're working on a library that's not yet installed in a standard location, you can use <code>LD_LIBRARY_PATH</code> to tell your program where to find it.</li> <li>Deployment: In some cases, you might need to use <code>LD_LIBRARY_PATH</code> to point to libraries installed in non-standard locations.</li> </ul> <p>Security Considerations</p> <p>While <code>LD_LIBRARY_PATH</code> can be helpful, it's important to use it with caution:</p> <ul> <li>Security Risks: If <code>LD_LIBRARY_PATH</code> is set to include untrusted directories, it can make your program vulnerable to attacks where malicious libraries are loaded instead of the legitimate ones.</li> <li>Maintainability Issues: Overusing <code>LD_LIBRARY_PATH</code> can make your program harder to deploy and maintain, as it relies on a specific environment variable being set correctly.</li> </ul> <p>Best Practices</p> <ul> <li>Use RPATH or RUNPATH: Whenever possible, use <code>RPATH</code> or <code>RUNPATH</code> to encode the library search paths directly into your executable. This is generally a more secure and reliable approach than relying on <code>LD_LIBRARY_PATH</code>.</li> <li>Limit Use of LD_LIBRARY_PATH: If you must use <code>LD_LIBRARY_PATH</code>, try to limit its use to development and testing environments, and avoid setting it globally.</li> <li>Be Mindful of Security: Always be cautious about setting <code>LD_LIBRARY_PATH</code> to include directories that you don't fully trust.</li> </ul>"},{"location":"external_content/ut-core-wiki/4.1.-Standards%3A-Dynamically-Installable-Plugins-In-C/","title":"4.1. Standards: Dynamically Installable Plugins In C","text":"<p>Here are some ideas on how to implement a modular C program that can load optional submodules or plugins at runtime or compile-time. The approach will ensure the main module can call these plugins conditionally based on their presence.</p>"},{"location":"external_content/ut-core-wiki/4.1.-Standards%3A-Dynamically-Installable-Plugins-In-C/#step-by-step-guide","title":"Step-by-Step Guide","text":"<ol> <li>Define Plugin Interface:    Define a common interface that all plugins must implement. This could be a set of function pointers within a struct.</li> </ol> <pre><code>// plugin.h\n#ifndef PLUGIN_H\n#define PLUGIN_H\n\ntypedef struct {\n    void (*initialize)(void);\n    void (*perform_action)(void);\n    void (*cleanup)(void);\n} PluginInterface;\n\n#endif // PLUGIN_H\n</code></pre> <ol> <li>Implement Plugin:    Implement a sample plugin following the defined interface.</li> </ol> <pre><code>// plugin_impl.c\n#include \"plugin.h\"\n#include &lt;stdio.h&gt;\n\nvoid plugin_initialize(void) {\n    printf(\"Plugin initialized.\\n\");\n}\n\nvoid plugin_perform_action(void) {\n    printf(\"Plugin action performed.\\n\");\n}\n\nvoid plugin_cleanup(void) {\n    printf(\"Plugin cleaned up.\\n\");\n}\n\nPluginInterface plugin = {\n    .initialize = plugin_initialize,\n    .perform_action = plugin_perform_action,\n    .cleanup = plugin_cleanup\n};\n</code></pre> <ol> <li>Dynamic Loading (Runtime):    Use dynamic loading to load the plugin at runtime. On Linux, you can use <code>dlopen</code> and <code>dlsym</code>.</li> </ol> <pre><code>// main.c\n#include &lt;stdio.h&gt;\n#include &lt;dlfcn.h&gt;\n#include \"plugin.h\"\n\nint main(void) {\n    void *handle;\n    PluginInterface *plugin = NULL;\n\n    // Attempt to load the plugin dynamically\n    handle = dlopen(\"./plugin_impl.so\", RTLD_LAZY);\n    if (handle) {\n        plugin = (PluginInterface *)dlsym(handle, \"plugin\");\n        if (plugin) {\n            plugin-&gt;initialize();\n            plugin-&gt;perform_action();\n            plugin-&gt;cleanup();\n        }\n        dlclose(handle);\n    } else {\n        printf(\"Plugin not found. Running without plugin.\\n\");\n    }\n\n    // Main module logic\n    printf(\"Main module running.\\n\");\n\n    return 0;\n}\n</code></pre> <ol> <li>Compile-Time Loading:    Alternatively, you can conditionally compile the plugin code based on a macro definition.</li> </ol> <pre><code>// main.c\n#include &lt;stdio.h&gt;\n#include \"plugin.h\"\n\n#ifdef USE_PLUGIN\nextern PluginInterface plugin;\n#endif\n\nint main(void) {\n    PluginInterface *plugin_ptr = NULL;\n\n#ifdef USE_PLUGIN\n    plugin_ptr = &amp;plugin;\n#endif\n\n    if (plugin_ptr) {\n        plugin_ptr-&gt;initialize();\n        plugin_ptr-&gt;perform_action();\n        plugin_ptr-&gt;cleanup();\n    } else {\n        printf(\"Plugin not included. Running without plugin.\\n\");\n    }\n\n    // Main module logic\n    printf(\"Main module running.\\n\");\n\n    return 0;\n}\n</code></pre> <ol> <li>Compiling the Code:    For dynamic loading, compile the plugin as a shared library.</li> </ol> <pre><code>gcc -shared -o plugin_impl.so -fPIC plugin_impl.c\ngcc -o main main.c -ldl\n</code></pre> <p>For compile-time loading, compile with a macro definition.</p> <pre><code>gcc -DUSE_PLUGIN -o main main.c plugin_impl.c\n</code></pre>"},{"location":"external_content/ut-core-wiki/4.1.-Standards%3A-Dynamically-Installable-Plugins-In-C/#key-points","title":"Key Points:","text":"<ul> <li>Plugin Interface: Clearly define the interface the plugins must adhere to.</li> <li>Dynamic Loading: Use <code>dlopen</code> and <code>dlsym</code> to load the plugin at runtime if it is available.</li> <li>Compile-Time Option: Use conditional compilation to include the plugin if it is available at compile-time.</li> <li>Null Check: Always check if the plugin function pointers are NULL before calling them to avoid crashes if the plugin is not available.</li> </ul> <p>By following these steps, you can create a flexible C module that can optionally load and use additional functionality from plugins, either at runtime or compile-time, ensuring robust and modular design.</p>"},{"location":"external_content/ut-core-wiki/5.0.1%3A-Standards%3A-vDevice-Architecture-Overview/","title":"Architecture Overview","text":""},{"location":"external_content/ut-core-wiki/5.0.1%3A-Standards%3A-vDevice-Architecture-Overview/#architecture-overview","title":"Architecture Overview","text":"<p>The vDevice enables flexible and efficient interaction with diverse hardware platforms. It acts as an abstraction layer, decoupling the software from the underlying hardware specifics. This approach offers several key advantages:</p> <ul> <li>Hardware Agnostic Software:  By interacting with a standardized HAL API, the software remains independent of the specific hardware implementation. This allows us to develop and deploy software across different platforms without modification.</li> <li>Modular and Adaptable: The use of vComponents provides a high degree of modularity.  Each vComponent represents a specific hardware function, allowing for easy customization and adaptation to new or evolving hardware.</li> <li>Dynamic Platform Mimicking: The vDevice can dynamically configure the vComponents at boot time to match the target platform's characteristics. This enables seamless switching between different platform configurations without code changes.</li> <li>Enhanced Testability:  The vDevice facilitates runtime testing control.  Testing suites can interact with the vDevice (or individual vComponents) through a REST API to modify system behaviour and simulate various scenarios.</li> </ul> <p>The diagram illustrates the key components and interactions within the vDevice architecture:</p> <pre><code>block-beta\n    block: modules\n        columns 2\n        vhal(\"Vendor Hal Interface(API)\")\n        vsi(\"Vendor System Interface - (VSI)\")\n        vc(\"vComponents\")\n        sl(\"vSystem Libraries\")\n        osl(\"Open Source Libraries &amp; utils \"):2\n        ub(\"Ubuntu+Binder\"):2\n    end\n  style vhal fill:#87CEFA,stroke:#1E90FF,stroke-width:4px;\n    style vsi fill:#87CEFA,stroke:#1E90FF,stroke-width:4px;\n    style sl fill:#FFA07A,stroke:#FA8072,stroke-width:4px;\n    style ub fill:#FFA07A,stroke:#FA8072,stroke-width:4px;\n    style vc fill:#87CEFA,stroke:#1E90FF,stroke-width:4px;\n    style osl fill:#FFA07A,stroke:#FA8072,stroke-width:4px;</code></pre> <ul> <li>Vendor HAL Interface (API): This standardised interface defines how the software interacts with the underlying hardware.</li> <li>Virtualized Components (vComponents): These modular components represent various hardware functions within the HAL implementation.</li> <li>Vendor System Interface (VSI):  A collection of vendor-provided libraries and tools used by the system (e.g., OpenGL, Bluetooth drivers).</li> <li>vSystem Libraries: These libraries organise and package the VSI components into functional groups for easier use.</li> <li>Open Source Libraries &amp; utils:  Common open-source libraries and utilities used within the system.</li> <li>Ubuntu+Binder: The underlying operating system and inter-process communication mechanism.</li> </ul>"},{"location":"external_content/ut-core-wiki/5.0%3A-Standards%3A-vDevice-Overview/","title":"vDevice Overview for TV and STB Development","text":"<p>This document explains the concept of vDevices and their role in developing software for TV and STB (Set-Top Box) platforms.</p>"},{"location":"external_content/ut-core-wiki/5.0%3A-Standards%3A-vDevice-Overview/#what-is-a-virtual-machine","title":"What is a Virtual Machine?","text":"<p>A virtual machine (VM) is essentially a computer within a computer. It's a software-based replica of a physical machine, with its own virtual CPU, memory, storage, and network interfaces. This \"virtual hardware\" is managed by the hypervisor, a software layer that sits between the VM and the actual physical hardware. The hypervisor allows multiple VMs to share the physical resources of a single machine while keeping them isolated from one another.</p> <p>Think of it like this: the hypervisor is like a landlord who owns a building (the physical server). Each VM is like a tenant who rents an apartment (a portion of the server's resources). The landlord (hypervisor) controls how much space (CPU, memory, etc.) each tenant (VM) gets, but the tenants can decorate and use their apartments (VMs) however they like.</p>"},{"location":"external_content/ut-core-wiki/5.0%3A-Standards%3A-vDevice-Overview/#key-characteristics-of-virtual-machines","title":"Key Characteristics of Virtual Machines:","text":"<ul> <li>Hardware Virtualization:  The number of virtual CPUs, their architecture, memory size, and even the availability of virtual hardware devices are all defined in software. These settings can be adjusted as required, providing flexibility and scalability.</li> <li>Software Transparency: From the perspective of the software running inside the VM, the underlying hardware is transparent. Applications and services operate as if they were running on a physical machine, unaware of the virtualization layer.</li> <li>Vendor Abstraction: While the software inside the VM interacts with virtual hardware, the vendor layer (e.g., device drivers) is responsible for abstracting the specific capabilities of the underlying physical hardware. This allows the same software to run on different virtualization platforms.</li> </ul>"},{"location":"external_content/ut-core-wiki/5.0%3A-Standards%3A-vDevice-Overview/#booting-a-linux-image-from-emmc","title":"Booting a Linux Image from eMMC","text":"<p>In the world of TVs and STBs, the software that brings these devices to life is typically a Linux-based image stored on an eMMC (embedded MultiMediaCard). When the device powers on, it loads this image from the eMMC into memory and begins executing the instructions, similar to how a computer boots up its operating system.</p> <p>Development teams concentrate on building and optimizing these Linux images. They ensure the image includes all the necessary drivers, libraries, and configurations for the target device, whether it's a physical TV or STB or a VM. This allows the software to interact correctly with the hardware, regardless of its underlying implementation.</p>"},{"location":"external_content/ut-core-wiki/5.0%3A-Standards%3A-vDevice-Overview/#why-simulation-is-essential-for-tv-and-stb-development","title":"Why Simulation is Essential for TV and STB Development","text":"<p>TVs and STBs often include specialized hardware components not typically found in standard computer systems. These components might include tuners for receiving broadcast signals, video decoders, and graphics processors optimized for displaying high-quality video.</p> <p>Since a virtual machine doesn't inherently support these TV-specific hardware components, they must be simulated in software. This is where simulators and vDevices come into play.</p>"},{"location":"external_content/ut-core-wiki/5.0%3A-Standards%3A-vDevice-Overview/#understanding-software-layers-and-vdevices","title":"Understanding Software Layers and vDevices","text":"<p>It's important to distinguish between the different software layers within a TV or STB system:</p> <ul> <li>Application Layer: This layer comprises the software that end-users interact with directly (e.g., Electronic Program Guide (EPG), streaming apps).</li> <li>Middleware Layer: This layer provides services and functionalities to the application layer, such as multimedia frameworks, network communication, and security.</li> <li>Vendor Layer: This layer interacts directly with the hardware. It contains drivers and other software components that translate hardware-specific requirements into a format that the upper layers can understand.</li> </ul> <p>Platform Independence</p> <p>A key principle in software development is platform independence. This means that the application and middleware layers should be designed to run on any platform without modification. The vendor layer is responsible for handling the specific requirements of the underlying hardware, shielding the upper layers from these details.</p>"},{"location":"external_content/ut-core-wiki/5.0%3A-Standards%3A-vDevice-Overview/#vdevice-clarification","title":"vDevice Clarification","text":"<p>A vDevice is essentially a virtualized vendor layer running within a VM. It comprises:</p> <ul> <li>Simulated Hardware: The hypervisor creates virtual representations of the target hardware, such as a vTuner or vDecoder, mimicking the behaviour of their physical counterparts as Virtual Components (vComponents).</li> <li>Simulated Device Drivers: Instead of interacting with real hardware, the vendor layer utilizes simulated device drivers specifically designed for the virtual environment. These drivers translate commands and data between the virtual hardware and the upper software layers.</li> <li>Hardware Profiles: To further enhance the simulation, vDevices are started with a hardware profile. This profile defines the specific capabilities and configurations of the simulation device, such as tuner type, supported video formats, and memory capacity. This allows developers to simulate a wide range of TV or STB models with varying hardware configurations using a single vDevice implementation.</li> </ul> <p>By incorporating hardware profiles, developers can:</p> <ul> <li>Test compatibility: Ensure their software functions correctly across different device models with varying hardware capabilities.</li> <li>Simulate specific scenarios: Recreate specific hardware configurations to test edge cases and debug issues.</li> <li>Optimize performance:  Fine-tune their software for optimal performance on different hardware profiles.</li> </ul>"},{"location":"external_content/ut-core-wiki/5.0%3A-Standards%3A-vDevice-Overview/#key-takeaways","title":"Key Takeaways","text":"<ul> <li>vDevice = Virtualized Vendor Layer: A vDevice primarily focuses on simulating the vendor layer's interaction with hardware within a VM.</li> <li>Simulation is Key: Simulated hardware and drivers are crucial for simulating TV-specific components not natively supported by VMs.</li> <li>Platform Independence is Preserved: The application and middleware layers remain platform-agnostic, unaware of the underlying hardware or virtualization.</li> <li>Swapping Between Environments is Seamless: Switching between simulation and real hardware involves simply rebuilding the image with the appropriate vendor layer.</li> </ul>"},{"location":"external_content/ut-core-wiki/5.0%3A-Standards%3A-vDevice-Overview/#benefits-of-using-simulators-in-tv-and-stb-development","title":"Benefits of using Simulators in TV and STB Development","text":"<ul> <li>Early testing: Enables software testing early in the development cycle, even before hardware prototypes are available.</li> <li>Cost-effectiveness: Reduces the need for expensive hardware and lab setups.</li> <li>Reproducibility: Provides a controlled and consistent environment for testing, ensuring reproducible results.</li> <li>Flexibility: Allows for easy manipulation of the simulated environment to test various scenarios and corner cases.</li> <li>Hardware Abstraction: Allows developers to focus on the software logic without being bogged down by hardware specifics.</li> </ul>"},{"location":"external_content/ut-core-wiki/5.0%3A-Standards%3A-vDevice-Overview/#key-components","title":"Key Components","text":"<p>The vDevice comprises of core components:</p> <ul> <li>vDevice Architecture Overview: Overview of the vDevice architecture and its role in enabling hardware abstraction and platform flexibility.</li> <li>vDevice Controller: The central orchestrator responsible for managing vComponents and the control plane.</li> <li>Control Plane: Enabling control and configuration of the running environment.</li> </ul>"},{"location":"external_content/ut-core-wiki/5.1.0%3A-Standards%3A-vDevice-Controller/","title":"Controller","text":"<p>Purpose:</p> <p>Provides a software-based vDevice for simulating the environment of the target platform. Designed to be modular and flexible, allowing for the testing and development of various components.</p> <p>Key Components:</p> <ul> <li>vDevice Controller:<ul> <li>The central orchestrator of the virtualised system.</li> <li>Manages the lifecycle of vComponent instances (initialising, starting, and stopping).</li> <li>Handles the control plane socket, routing control messages to appropriate vComponent instances.</li> </ul> </li> <li>vComponent:<ul> <li>Represents a specific HAL / Operational module within the software stack.</li> <li>Receives and processes control plane messages and will extract information relevant to its specific domain.</li> <li>Can optionally run in standalone mode with their own control plane sockets.</li> </ul> </li> <li>Control Plane:<ul> <li>Provides a WebSocket interface for sending control messages to alter the behaviour of internal components.</li> <li>Allows external users or systems to control, configure, or trigger actions in vComponents.</li> <li>Supports communication across multiple modules using YAML-based messages, enabling flexible and scalable control.</li> </ul> </li> </ul> <p>Architecture:</p> <ul> <li>Modular Design: vComponent instances are packaged as component libraries, ideally moving towards <code>opkg</code> for easier integration.</li> <li>Centralized Control: The vDevice Controller acts as the main coordinator.</li> <li>Unified Control Plane: The vDevice Controller provides a common control plane socket for all modules.</li> </ul> <p>System Workflow (Boot Sequence)</p> <ol> <li>Initialization: vDevice Controller starts up and loads configuration.</li> <li>Component Registration: Initialization and exit functions of each vComponent instance are registered with the vDevice Controller.</li> <li>Control Plane Activation: vDevice Controller initiates the control plane socket.</li> <li>Component Startup: vDevice Controller triggers the initialization (<code>init()</code> function) of all registered vComponent instances based on the provided platform profile.</li> </ol> <p>Considerations:</p> <ul> <li>Platform Profile: Ensure that the <code>platformProfile.yaml</code> format is well-defined, enabling flexible configuration of vComponent instances during startup.</li> <li>Control Plane Messages: Clearly define the structure and types of control plane messages that the system will use.</li> <li>Documentation: Thoroughly document each vComponent instance's API, supported control messages, and configuration options.</li> </ul> <pre><code>graph TD\n    subgraph System\n        subgraph High Level Overview\n          EmulatorController[vDevice] --&gt; |Initializes/Terminates| ModuleEmulator1[vComponent 1]\n          EmulatorController --&gt; |Initializes/Terminates| ModuleEmulator2[vComponent 2] \n          EmulatorController --&gt; |Initializes/Terminates| ModuleEmulatorN[vComponent N]\n         end \n         subgraph Starting/Stopping\n          EmulatorController --&gt; |Starts/Stops| ModuleEmulator1\n          EmulatorController --&gt; |Starts/Stops| ModuleEmulator2 \n          EmulatorController --&gt; |Starts/Stops| ModuleEmulatorN\n         end \n        EmulatorController --&gt; |Control Plane Socket| ControlPlane[Control Plane]\n        subgraph MessageSending\n           ControlPlane -- Sends Messages --&gt; ModuleEmulator1\n           ControlPlane -- Sends Messages --&gt; ModuleEmulator2\n           ControlPlane -- Sends Messages --&gt; ModuleEmulatorN\n         end \n    end</code></pre>"},{"location":"external_content/ut-core-wiki/5.1.1%3A-Standards%3A-vDevice-Control-Plane/","title":"Control Plane","text":"<p>The Control Plane is a central component responsible for facilitating interaction between external users or systems and the internal behaviour of both virtual devices (vComponents) and physical rack setups. Control messages are used to configure and control devices, whether they're virtual or physically connected racks, depending on the platform configuration.\u00a0</p>"},{"location":"external_content/ut-core-wiki/5.1.1%3A-Standards%3A-vDevice-Control-Plane/#key-points","title":"Key Points","text":"<ul> <li>WebSocket Interface (for vDevices):</li> <li>When dealing with virtual devices (vComponents), the Control Plane exposes a WebSocket server that provides a connection for external stimulus.</li> <li> <p>Test users, automation tools, or other systems use this WebSocket interface to send control messages to virtual components in real-time.</p> </li> <li> <p>Control for Physical Rack Setups:</p> </li> <li> <p>In a physical rack setup, the WebSocket is not used. Instead, the ControlPlaneClass interprets the control messages, determining whether they are intended for a virtual device or a physical rack, and converts them into commands that control the physical rack via python_raft control classes. \u00a0 - If the message involves controlling external hardware, the ControlPlaneClass uses the python_raft control classes to handle the necessary configurations and manage the rack\u2019s hardware interactions.</p> </li> <li> <p>Control Messages:</p> </li> <li>Control messages are structured using YAML format and are designed to control both virtual and physical setups based on the system configuration.</li> <li>The same message format can apply to both virtual and physical environments. For instance, a command to power on a device could either trigger an action on a virtual HDMI device or, if connected externally to a rack, control the actual hardware via python_raft.</li> <li> <p>The ControlPlaneClass interprets each message and routes it to the appropriate target\u2014either via a WebSocket to a virtual device or through python_raft to a physical rack.</p> </li> <li> <p>Unified Message Handling:</p> </li> <li> <p>The Control Plane seamlessly handles both virtual and physical environments by using the same control message structure. The ControlPlaneClass decides whether the message is targeting a virtual device or a physical rack, ensuring flexible and unified control. \u00a0 - For virtual devices, the control message is routed through a WebSocket to the relevant vComponent. \u00a0 - For physical racks, the control message is processed by the ControlPlaneClass, which converts it into commands for the python_raft control classes to configure and control the hardware directly.</p> </li> <li> <p>Python Raft Integration:</p> </li> <li>When using python_raft, the system sends control messages to the ControlPlaneClass, which interprets them and interacts with the python_raft control classes to manage the physical hardware. \u00a0 - If the system is configured for virtual devices, the ControlPlaneClass will instead forward the message via the WebSocket to the relevant vComponent.</li> </ul>"},{"location":"external_content/ut-core-wiki/5.1.1%3A-Standards%3A-vDevice-Control-Plane/#control-plane-workflow","title":"Control Plane Workflow","text":""},{"location":"external_content/ut-core-wiki/5.1.1%3A-Standards%3A-vDevice-Control-Plane/#1-message-reception","title":"1. Message Reception","text":"<p>The ControlPlaneClass receives control messages. Depending on the nature of the message and the platform configuration, it determines whether the message is targeting a virtual device or an external rack setup.</p> <ul> <li>vDevice Setup: The control message is sent through the WebSocket and processed by the vDevice Controller, which forwards the message to the appropriate vComponent.</li> <li>Rack Setup: If the message requires controlling external hardware, the ControlPlaneClass converts the message into specific commands for the python_raft control classes, which then control the rack hardware.</li> </ul>"},{"location":"external_content/ut-core-wiki/5.1.1%3A-Standards%3A-vDevice-Control-Plane/#2-message-routing","title":"2. Message Routing","text":"<ul> <li>For virtual components, the message is routed through the WebSocket to the relevant vComponent, which processes the message and acts accordingly.</li> <li>For rack setups, the ControlPlaneClass uses the python_raft control classes to control the hardware directly, without the need for a WebSocket.</li> </ul>"},{"location":"external_content/ut-core-wiki/5.1.1%3A-Standards%3A-vDevice-Control-Plane/#3-component-or-rack-response","title":"3. Component or Rack Response","text":"<ul> <li> <p>vComponents interpret and execute the control message, triggering actions such as powering on a device, switching inputs, or sending callbacks.</p> </li> <li> <p>Rack setups receive the control commands from python_raft, and the hardware is configured or controlled based on the instructions in the message (e.g., powering on, connecting devices, etc.).</p> </li> </ul>"},{"location":"external_content/ut-core-wiki/5.1.1%3A-Standards%3A-vDevice-Control-Plane/#considerations-for-control-plane-messages","title":"Considerations for Control Plane Messages","text":"<ul> <li>Unified Message Structure: Control messages for both virtual and physical environments are unified and pre-defined. The ControlPlaneClass interprets these messages and determines the target (virtual or physical) based on the platform configuration.</li> <li>Platform Configuration: The ControlPlaneClass determines the appropriate actions based on the nature of the message and the system\u2019s platform configuration\u2014whether it's a virtual or physical (rack) environment.</li> <li>Logging and Debugging: Debugging tools will capture control messages and their processing outcomes to ensure smooth operation and easy diagnosis in both virtual and physical setups.</li> </ul>"},{"location":"external_content/ut-core-wiki/5.1.1%3A-Standards%3A-vDevice-Control-Plane/#advantages-of-using-the-control-plane","title":"Advantages of Using the Control Plane","text":"<ul> <li>Unified Control for Mixed Environments: The same control plane can manage both virtual devices and physical racks, ensuring seamless control across environments.</li> <li>Modular and Scalable: New vComponents or additional physical rack configurations can easily be integrated into the system using the same control message structure.</li> <li>Real-time Configuration: The WebSocket interface (for vDevices) and the python_raft control classes (for racks) allow real-time control of both virtual and physical systems.</li> <li>Platform-agnostic Flexibility: The Control Plane adapts to the environment, whether it\u2019s controlling virtual test environments or physical hardware, making it a versatile tool for a wide range of deployment scenarios.</li> </ul>"},{"location":"external_content/ut-core-wiki/5.1.1%3A-Standards%3A-vDevice-Control-Plane/#overview-of-expected-operation","title":"Overview of expected operation","text":"<pre><code>graph TD\n    subgraph ControlPlaneClass\n        A(Control Plane) --&gt;|Message Routing| B{Platform Configuration}\n    end\n\n    B --&gt;|vDevice| C[WebSocket Interface]\n    B --&gt;|Rack Setup| D[python_raft Control Classes]\n\n    subgraph vDevice Setup\n        C --&gt; E[vComponent 1]\n        C --&gt; F[vComponent 2]\n        C --&gt; G[vComponent N]\n    end\n\n    subgraph Rack Setup\n        D --&gt; M[Control Component 1]\n        D --&gt; N[Control Component 2]\n        D --&gt; O[Control Component N]\n        M --&gt; H[Rack Hardware 1]\n        N --&gt; I[Rack Hardware 2]\n        O --&gt; J[Rack Hardware N]\n    end\n\n    A -. External stimulus .-&gt; K[Test User]\n    K --&gt; A</code></pre>"},{"location":"external_content/ut-core-wiki/FAQ%3A--QEMU-vs-Vagrant/","title":"When to Use QEMU","text":"<p>QEMU is a low-level virtualization tool that provides flexible control over virtual machines. It\u2019s best for situations where you need to: 1. Run custom configurations:    - Boot kernels directly (<code>uImage</code>, <code>zImage</code>, etc.).    - Simulate specific hardware architectures (ARM, x86, RISC-V, etc.).    - Configure low-level aspects like CPU type, machine type, or device emulation. 2. Support Embedded/IoT Development:    - QEMU is often used in embedded development for ARM-based or custom hardware simulations. 3. Run Lightweight Virtual Machines:    - You don\u2019t need Vagrant\u2019s higher-level management or provisioning capabilities. 4. Fine-Tuned Performance:    - QEMU allows advanced optimizations, especially with KVM for near-native speeds on x86 or Apple Silicon.</p>"},{"location":"external_content/ut-core-wiki/FAQ%3A--QEMU-vs-Vagrant/#pros-of-qemu","title":"Pros of QEMU:","text":"<ul> <li>Flexibility: Full control over the visualized hardware and kernel-level configuration.</li> <li>Architecture Support: Wide compatibility with architectures (ARMv7, ARM64, x86, RISC-V, etc.).</li> <li>Lightweight: No dependency on additional layers (like Vagrant) if you\u2019re scripting everything.</li> <li>Hardware Simulation: Emulates peripherals, GPUs, and devices, making it ideal for embedded development.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A--QEMU-vs-Vagrant/#cons-of-qemu","title":"Cons of QEMU:","text":"<ul> <li>Steeper Learning Curve: Requires manually configuring VM settings via CLI or scripts.</li> <li>Manual Management: Lacks built-in features for orchestrating multiple VMs or managing dependencies.</li> <li>No Provisioning Framework: You\u2019ll need custom scripts to install software/apps.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A--QEMU-vs-Vagrant/#best-use-cases-for-qemu","title":"Best Use Cases for QEMU:","text":"<ul> <li>You\u2019re working with custom hardware configurations (e.g., ARMv7, ARM64, or specific machine types).</li> <li>You need a lightweight, low-level VM without external tools.</li> <li>You\u2019re developing or testing embedded systems, kernels, or OS images.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A--QEMU-vs-Vagrant/#when-to-use-vagrant","title":"When to Use Vagrant","text":"<p>Vagrant is a higher-level tool designed to manage and automate virtual machine workflows. It abstracts much of the low-level VM setup and provides features like provisioning, networking, and multi-VM orchestration.</p>"},{"location":"external_content/ut-core-wiki/FAQ%3A--QEMU-vs-Vagrant/#pros-of-vagrant","title":"Pros of Vagrant:","text":"<ul> <li>Ease of Use: Automates VM creation and provisioning (installing apps, configuring environments).</li> <li>Provisioning: Built-in support for provisioning tools like Shell scripts, Ansible, Puppet, or Chef.</li> <li>Multi-VM Support: Easily define and manage multiple VMs in a single <code>Vagrantfile</code>.</li> <li>Cross-Provider Support: Works with VirtualBox, VMware, QEMU (via <code>libvirt</code>), and cloud providers like AWS.</li> <li>Portability: Shareable <code>Vagrantfile</code> makes it easy to replicate environments across systems.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A--QEMU-vs-Vagrant/#cons-of-vagrant","title":"Cons of Vagrant:","text":"<ul> <li>Resource Overhead: Adds an abstraction layer, which may slightly increase resource usage compared to QEMU alone.</li> <li>Dependency on Providers: Requires a supported provider like VirtualBox, libvirt, or VMware.</li> <li>Less Flexibility: While configurable, it abstracts many low-level options available in QEMU.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A--QEMU-vs-Vagrant/#best-use-cases-for-vagrant","title":"Best Use Cases for Vagrant:","text":"<ul> <li>You need to deploy multiple VMs with defined roles (e.g., database server, web server, etc.).</li> <li>You want to automate application installations and VM configuration.</li> <li>You need consistency across environments (e.g., development, testing, staging).</li> <li>You\u2019re working with a team and want a shareable, reproducible VM setup.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A--QEMU-vs-Vagrant/#comparison-table","title":"Comparison Table","text":"Feature QEMU Vagrant Ease of Use CLI or custom scripts required High-level abstraction, easy to use Multi-VM Management Manual setup via scripting Built-in support in <code>Vagrantfile</code> Provisioning Requires custom scripts Supports Shell, Ansible, Puppet, etc. Performance Lightweight, minimal overhead Slightly more overhead Architecture Support ARM, x86, RISC-V, custom hardware Depends on provider (e.g., libvirt, VirtualBox) Flexibility Full control over low-level config Less control, but easier to use Team Collaboration Requires sharing scripts manually Shareable, portable <code>Vagrantfile</code> Application Setup Manual installation/scripts Automates via provisioning"},{"location":"external_content/ut-core-wiki/FAQ%3A--QEMU-vs-Vagrant/#recommendations","title":"Recommendations","text":""},{"location":"external_content/ut-core-wiki/FAQ%3A--QEMU-vs-Vagrant/#use-qemu-if","title":"Use QEMU if:","text":"<ol> <li>You\u2019re working with custom hardware architectures or embedded systems (e.g., ARMv7/ARM64 development).</li> <li>You want lightweight and fine-grained control over virtual machine setup.</li> <li>You\u2019re comfortable writing and maintaining custom scripts for managing VMs and provisioning.</li> </ol>"},{"location":"external_content/ut-core-wiki/FAQ%3A--QEMU-vs-Vagrant/#use-vagrant-if","title":"Use Vagrant if:","text":"<ol> <li>You need to manage multiple VMs with predefined roles and configurations (e.g., app server, database server).</li> <li>You want to automate application installation and environment setup via provisioning.</li> <li>You work in a team environment and need shareable, consistent VM setups.</li> <li>You value simplicity and portability for managing VMs.</li> </ol>"},{"location":"external_content/ut-core-wiki/FAQ%3A--QEMU-vs-Vagrant/#hybrid-approach-qemu-vagrant","title":"Hybrid Approach: QEMU + Vagrant","text":"<p>If you want the flexibility of QEMU and the automation capabilities of Vagrant, you can combine both: 1. Use QEMU as the virtualization backend with the <code>vagrant-libvirt</code> plugin. 2. Manage multiple VMs and application installations through Vagrant\u2019s provisioning system.</p> <p>Example: Vagrantfile for Multiple ARMv7 VMs Using QEMU</p> <pre><code>Vagrant.configure(\"2\") do |config|\n  # VM 1: Web Server\n  config.vm.define \"web\" do |web|\n    web.vm.provider \"libvirt\" do |libvirt|\n      libvirt.arch = \"arm\"\n      libvirt.machine_type = \"virt\"\n      libvirt.cpus = 2\n      libvirt.memory = 1024\n      libvirt.kernel = \"/path/to/web_kernel/zImage\"\n      libvirt.initrd = \"/path/to/web_initrd.img\"\n      libvirt.cmd_line = \"console=ttyAMA0 root=/dev/vda rw\"\n    end\n    web.vm.provision \"shell\", inline: \"sudo apt-get install -y nginx\"\n  end\n\n  # VM 2: Database Server\n  config.vm.define \"db\" do |db|\n    db.vm.provider \"libvirt\" do |libvirt|\n      libvirt.arch = \"arm\"\n      libvirt.machine_type = \"virt\"\n      libvirt.cpus = 2\n      libvirt.memory = 2048\n      libvirt.kernel = \"/path/to/db_kernel/zImage\"\n      libvirt.initrd = \"/path/to/db_initrd.img\"\n      libvirt.cmd_line = \"console=ttyAMA0 root=/dev/vda rw\"\n    end\n    db.vm.provision \"shell\", inline: \"sudo apt-get install -y mariadb-server\"\n  end\nend\n</code></pre>"},{"location":"external_content/ut-core-wiki/FAQ%3A--QEMU-vs-Vagrant/#conclusion","title":"Conclusion","text":"<ul> <li>For low-level control, QEMU is better, but it requires more effort for multi-VM setups and application provisioning.</li> <li>For multi-VM orchestration and ease of app installation, Vagrant is a better choice.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A--Video-and-Audio-Playback-Performance-Metrics/","title":"Video and Audio Playback Performance Metrics Overview","text":""},{"location":"external_content/ut-core-wiki/FAQ%3A--Video-and-Audio-Playback-Performance-Metrics/#purpose","title":"Purpose","text":"<p>This document provides a standardized set of metrics for monitoring and evaluating playback performance across video and audio streams on various platforms. These metrics help assess synchronization between the display and audio pipelines, efficiency in frame and audio buffer handling, and overall playback quality. This approach enables consistent performance analysis and identification of playback issues for both video and audio-only playback.</p>"},{"location":"external_content/ut-core-wiki/FAQ%3A--Video-and-Audio-Playback-Performance-Metrics/#core-metrics-for-video-playback","title":"Core Metrics for Video Playback","text":""},{"location":"external_content/ut-core-wiki/FAQ%3A--Video-and-Audio-Playback-Performance-Metrics/#1-vsync-frame-rate","title":"1. VSync Frame Rate","text":"<ul> <li>Definition: The frame rate of the display, representing the refresh rate at which frames are displayed.</li> <li>Use: Determines the frequency of display refreshes, crucial for synchronizing video playback.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A--Video-and-Audio-Playback-Performance-Metrics/#2-number-of-vsyncs","title":"2. Number of VSyncs","text":"<ul> <li>Definition: Total count of vertical synchronization (VSync) events during playback.</li> <li>Use: Tracks display refresh occurrences over a specific playback duration.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A--Video-and-Audio-Playback-Performance-Metrics/#3-number-of-displayed-frames","title":"3. Number of Displayed Frames","text":"<ul> <li>Definition: The count of decoded frames successfully displayed on the screen.</li> <li>Use: Indicates the number of frames processed and displayed, which should typically align with the number of VSyncs or half of them, depending on the playback rate.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A--Video-and-Audio-Playback-Performance-Metrics/#4-number-of-frame-rate-conversions-frc","title":"4. Number of Frame Rate Conversions (FRC)","text":"<ul> <li>Definition: Occurs when the encoded frame rate differs from the display refresh rate, necessitating frame rate adjustments.</li> <li>Use: Measures the proportion of frame rate conversions to displayed frames. For example:<ul> <li>A 24fps encoded stream shown at 48fps should maintain a 50:50 FRC-to-displayed frames ratio.</li> <li>A 60fps encoded stream displayed at 60fps should have an FRC-to-displayed frames ratio of 0:100.</li> </ul> </li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A--Video-and-Audio-Playback-Performance-Metrics/#5-number-of-repeated-frames","title":"5. Number of Repeated Frames","text":"<ul> <li>Definition: Count of frames repeated due to the next frame\u2019s presentation timestamp (PTS) arriving too early, or video pause.</li> <li>Use: Indicates frame repetition instances, often due to timing issues where frames are displayed more than once because of early frame arrival or playback pauses.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A--Video-and-Audio-Playback-Performance-Metrics/#6-number-of-dropped-frames","title":"6. Number of Dropped Frames","text":"<ul> <li>Definition: Count of frames discarded because their PTS was behind the system\u2019s presentation clock (STC).</li> <li>Use: Indicates frame drops, often caused by performance lags, impacting playback smoothness.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A--Video-and-Audio-Playback-Performance-Metrics/#7-number-of-underruns-video","title":"7. Number of Underruns (Video)","text":"<ul> <li>Definition: Count of times the video pipeline was empty, meaning the display frame queue size was one frame or lower.</li> <li>Use: Tracks pipeline starvation, where playback cannot keep up with display demands, causing playback interruptions.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A--Video-and-Audio-Playback-Performance-Metrics/#expected-metric-behavior-for-video-playback","title":"Expected Metric Behavior for Video Playback","text":"<p>During playback, the following metric behaviors are expected:</p> <ul> <li> <p>VSync Events: The number of VSync events should match the playback duration when divided by the VSync frame rate.</p> </li> <li> <p>Displayed Frames: Should correspond to the encoded frame rate in relation to the VSync rate. For example, 10 seconds of playback at a 60Hz VSync rate should yield around 600 VSync events, with displayed frames aligning proportionally.</p> </li> <li> <p>Frame Rate Conversions: Frame rate conversions should match the ratio expected based on the encoded vs. display frame rates.</p> </li> <li> <p>Repeated, Dropped Frames, and Underruns: These values should remain at zero for optimal playback. Non-zero values highlight issues like timing (repeated frames), performance (dropped frames), or pipeline delays (underruns).</p> </li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A--Video-and-Audio-Playback-Performance-Metrics/#core-metrics-for-audio-playback","title":"Core Metrics for Audio Playback","text":"<p>For audio playback, where the stream is audio-only or audio is being decoded alongside video, the focus is on buffer management and pipeline stability:</p>"},{"location":"external_content/ut-core-wiki/FAQ%3A--Video-and-Audio-Playback-Performance-Metrics/#1-audio-underruns","title":"1. Audio Underruns","text":"<ul> <li>Definition: The count of times the audio buffer was empty, causing interruptions in audio playback.</li> <li>Use: Indicates situations where the audio playback pipeline fails to maintain a continuous stream, often due to decoding or buffer management issues, causing gaps or stutters in audio.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A--Video-and-Audio-Playback-Performance-Metrics/#2-audio-overruns","title":"2. Audio Overruns","text":"<ul> <li>Definition: The count of instances where the audio buffer exceeded its maximum capacity, typically causing delays or blocking further processing until the buffer is cleared.</li> <li>Use: Reveals audio buffer overflows, potentially indicating a blockage or backpressure within the pipeline. This may occur if the buffer fills up faster than it can be processed, leading to stalled playback or delayed audio.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A--Video-and-Audio-Playback-Performance-Metrics/#expected-metric-behavior-for-audio-playback","title":"Expected Metric Behavior for Audio Playback","text":"<ul> <li> <p>Free-Running Audio: Typically, in non-broadcast environments, audio is expected to be the master clock and run freely, without frame drops or repeats. Video playback adjusts to remain in sync with the audio, ideally by adjusting the display clock to align with the audio playback.</p> </li> <li> <p>Underruns and Overruns: For audio playback, underruns and overruns should ideally be zero. Frequent underruns indicate that the audio decoding process cannot supply data quickly enough, resulting in gaps or interruptions. Overruns suggest buffer management issues, possibly due to a backlog in audio processing or timing delays.</p> </li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A--Video-and-Audio-Playback-Performance-Metrics/#regression-testing-for-playback-verification","title":"Regression Testing for Playback Verification","text":"<p>When using these metrics to validate playback performance and check for regressions, a set of standardized test streams should be used. For each test stream, baseline metrics (expected values for VSyncs, displayed frames, FRC, underruns, overruns, etc.) should be predefined. The measured values during playback can then be compared against these baselines to determine if the build passes or fails the playback test.</p> <p>By establishing known output values for these metrics, you can: - Quickly identify deviations from expected behavior, which may indicate performance or synchronization regressions. - Verify that the latest build maintains playback quality and stability across video and audio metrics.</p>"},{"location":"external_content/ut-core-wiki/FAQ%3A--Video-and-Audio-Playback-Performance-Metrics/#additional-considerations-for-implementation","title":"Additional Considerations for Implementation","text":"<p>The initial design for these generic hardware abstraction layer (HAL) metrics collection is intended to provide a unified approach for gathering video and audio playback performance metrics across platforms ensuring standardized collection across hardware could enhance cross-platform testing and optimization.</p> <p>Author: S.Webster</p>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Black%E2%80%90Box-Testing-and-Code-Coverage-Metrics/","title":"Black-box vs White-box","text":"<p>Black-box testing and white-box testing are two fundamental approaches to software testing. They differ primarily in their focus and the level of access to the internal workings of the system under test. Here's a breakdown of their key differences:</p> <p>Black-box Testing</p> <ul> <li>Focus: Functionality and external behaviour of the software.</li> <li>Internal knowledge: Testers do not need knowledge of the internal code, structure, or implementation details.</li> <li>Techniques:  Equivalence partitioning, boundary value analysis, decision table testing, state transition testing, use case testing.</li> <li>Advantages:<ul> <li>Simulates user perspective.</li> <li>Unbiased testing, as testers are not influenced by the code.</li> <li>Can be conducted by a separate testing team.</li> </ul> </li> <li>Disadvantages: <ul> <li>Potential for redundant testing.</li> <li>May miss certain code paths or logic errors.</li> <li>Difficult to design test cases without understanding the internal workings.</li> </ul> </li> </ul> <p>White-box Testing</p> <ul> <li>Focus: Internal structure, code, and logic of the software.</li> <li>Internal knowledge: Testers require detailed knowledge of the code base.</li> <li>Techniques: Statement coverage, branch coverage, path coverage, condition coverage, mutation testing.</li> <li>Advantages:<ul> <li>Thorough testing of all code paths and logic.</li> <li>Helps identify hidden errors and vulnerabilities.</li> <li>Can be performed early in the development cycle.</li> </ul> </li> <li>Disadvantages: <ul> <li>Requires programming skills and knowledge.</li> <li>Can be time-consuming and complex.</li> <li>May not identify issues related to user experience or usability.</li> </ul> </li> </ul> <p>In essence:</p> <ul> <li>Black-box testing treats the software as a \"black box,\" focusing on what it does rather than how it does it.</li> <li>White-box testing opens the \"black box,\" allowing testers to examine the internal workings and ensure that the code functions as intended.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Black%E2%80%90Box-Testing-and-Code-Coverage-Metrics/#black-box-testing-code-coverage","title":"Black Box Testing Code Coverage","text":"<p>In black-box testing, you don't have access to the internal code, so achieving complete code path coverage is not possible. </p> <p>Here's why:</p> <ul> <li>Lack of Visibility: Black-box testing focuses on the external behavior of the software. Testers provide inputs and observe outputs without knowing how the system processes those inputs internally. This means they can't directly target specific code paths.</li> <li>Input-Output Focus: Black-box testing relies on various techniques like equivalence partitioning, boundary value analysis, and state transition testing to design test cases. These techniques aim to cover a wide range of input scenarios and system behaviors, but they don't guarantee that all code paths will be executed.</li> <li>Complexity:  Software can have numerous code paths, including complex conditional statements and loops. Without code access, it's incredibly difficult to design test cases that guarantee the execution of every possible path.</li> </ul> <p>However, while full code path coverage isn't achievable, black-box testing can still provide good coverage in terms of:</p> <ul> <li>Functionality: Black-box testing can effectively uncover functional defects and ensure the software meets its requirements from a user perspective.</li> <li>Usability: It can help identify usability issues and ensure the software is user-friendly.</li> <li>Performance: Black-box testing can be used to assess performance characteristics like response time and resource usage.</li> <li>Security:  It can help uncover security vulnerabilities by testing different attack vectors.</li> </ul> <p>To maximize coverage in black-box testing, it's important to:</p> <ul> <li>Have clear and comprehensive requirements: This helps in designing effective test cases.</li> <li>Use a variety of testing techniques: Combining different black-box techniques can increase the chances of covering more scenarios.</li> <li>Prioritize critical functionalities: Focus on testing the most important and frequently used parts of the software.</li> </ul> <p>In summary: While black-box testing cannot guarantee full code path coverage, it remains a valuable approach for testing software from a user's perspective and uncovering a wide range of defects. To achieve broader coverage, it's often combined with white-box testing techniques that directly analyze the code.</p>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Buildroot-vs.-Yocto-Project-vs.-Bob-the-Builder/","title":"Building Code Modules for Embedded Linux: A Comparison of Build Systems","text":"<p>This comparison focuses exclusively on the best methods for developers to build a single code module (e.g., a library or application) for an embedded Linux system. We are not concerned with building complete system images. Instead, we'll examine how each tool helps a developer compile, link, and prepare code for an embedded target.</p> <p>Key Principle: The module's build system should be triggered independently and not rely on the framework itself to initiate the build. This ensures the module remains portable and can be built on different systems without depending on the specific framework.</p>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Buildroot-vs.-Yocto-Project-vs.-Bob-the-Builder/#buildroot","title":"Buildroot","text":"<ul> <li>Relevance for module development:  Buildroot can be adapted to build individual modules, leveraging its cross-compilation toolchain and dependency management. However, it may require extra effort to separate module builds from the Buildroot build process.</li> <li>Developer Experience: Provides a pre-configured environment, but integration with external build systems might require workarounds.</li> <li>Customization: Limited flexibility for integrating with existing build systems.</li> <li>Learning Curve: Relatively easy for basic usage.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Buildroot-vs.-Yocto-Project-vs.-Bob-the-Builder/#yocto-project","title":"Yocto Project","text":"<ul> <li>Relevance for module development: While powerful for building components, Yocto should be used to configure existing build scripts (Makefiles, CMake) rather than directly building the module. This ensures the module remains independent.</li> <li>Developer Experience:  Can be complex to integrate with external build systems due to its layered structure and BitBake.</li> <li>Customization: Highly customizable, but this can add complexity when integrating with existing build scripts.</li> <li>Learning Curve: Steep.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Buildroot-vs.-Yocto-Project-vs.-Bob-the-Builder/#bob-the-builder","title":"Bob the Builder","text":"<ul> <li>Relevance for module development: Well-suited for building modules in isolated environments. You can define dependencies and trigger builds independently.</li> <li>Developer Experience:  Modern approach with declarative configuration and containerization. Aims for ease of use and reproducibility.</li> <li>Customization:  Offers a balance between flexibility and ease of use for integrating with existing build systems.</li> <li>Learning Curve: Moderate.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Buildroot-vs.-Yocto-Project-vs.-Bob-the-Builder/#cmakemakescripts","title":"CMake/Make/Scripts","text":"<ul> <li>Relevance for module development: The most direct and independent approach. You have full control over the build process and can easily integrate with any distribution.</li> <li>Developer Experience:  Familiar tools for many developers, but requires manual configuration and scripting.</li> <li>Customization:  Highly customizable.</li> <li>Learning Curve:  Can range from moderate to steep.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Buildroot-vs.-Yocto-Project-vs.-Bob-the-Builder/#bazel","title":"Bazel","text":"<ul> <li>Relevance for module development: Excellent for building complex projects with many dependencies. Strong support for hermetic builds and remote caching.</li> <li>Developer Experience: Can have a steeper learning curve, but offers powerful features and good performance.</li> <li>Customization: Highly customizable through <code>BUILD</code> files.</li> <li>Key Considerations: May require more effort to set up initially.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Buildroot-vs.-Yocto-Project-vs.-Bob-the-Builder/#meson","title":"Meson","text":"<ul> <li>Relevance for module development: Good for building C/C++ modules. Simpler syntax and faster build times compared to CMake.</li> <li>Developer Experience: Generally considered easier to learn and use than CMake.</li> <li>Customization: Provides good customization options.</li> <li>Key Considerations: Growing in popularity, but the community might not be as large as CMake's.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Buildroot-vs.-Yocto-Project-vs.-Bob-the-Builder/#scons","title":"SCons","text":"<ul> <li>Relevance for module development: Can be used to build C/C++ modules. Offers more flexibility than Make and integrates well with Python.</li> <li>Developer Experience: Python knowledge can be helpful.</li> <li>Customization: Highly customizable due to its Python foundation.</li> <li>Key Considerations: Not as widely used as CMake or Make.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Buildroot-vs.-Yocto-Project-vs.-Bob-the-Builder/#platformio","title":"PlatformIO","text":"<ul> <li>Relevance for module development: Provides a simplified way to build modules for various embedded platforms. Can handle cross-compilation and dependencies.</li> <li>Developer Experience: User-friendly with good IDE support.</li> <li>Customization: Offers a good level of customization for embedded projects.</li> <li>Key Considerations: More focused on microcontroller-based platforms.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Buildroot-vs.-Yocto-Project-vs.-Bob-the-Builder/#custom-shell-scripts","title":"Custom Shell Scripts","text":"<ul> <li>Relevance for module development: Provides maximum flexibility and control. You can use any tools and commands you need.</li> <li>Developer Experience: Requires good shell scripting knowledge.</li> <li>Customization: Completely customizable.</li> <li>Key Considerations: Best for simple modules or when you need very specific control.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Buildroot-vs.-Yocto-Project-vs.-Bob-the-Builder/#summary-table","title":"Summary Table","text":"Feature Buildroot Yocto Bob CMake/Make Bazel Meson SCons PlatformIO Custom Scripts Focus Root filesystem Component building Streamlined builds Code building Complex builds C/C++ modules Flexible builds Embedded ecosystem Maximum control Author/Origin Peter Korsgaard Yocto Project Sony Kitware (CMake) Google Jussi Pakkanen Steven Knight PlatformIO N/A Configuration <code>menuconfig</code> Layers/recipes YAML <code>CMakeLists.txt</code>, Makefiles <code>BUILD</code> files Meson files Python scripts PlatformIO config Shell scripts Build System Makefile-based BitBake Docker CMake/Make + custom Bazel Meson SCons PlatformIO Custom Customization Limited High Balanced High High Good High Good Complete Independent Builds Requires effort Configure, not build Well-suited Ideal Excellent Good Good Good Ideal Community Active Large Growing Massive Growing Growing Moderate Growing N/A Learning Curve Moderate Steep Moderate Moderate/Steep Steep Moderate Moderate Moderate Moderate/Steep Dev Experience Less flexible Complex Modern Familiar but manual Powerful but steep User-friendly Python-based User-friendly Requires scripting Strengths Pre-configured Dependency management Reproducible builds Flexibility Hermetic builds Speed, simplicity Flexibility Simplified workflow Maximum control Weaknesses Not for modules Overkill, integration Relatively new Can be complex Initial setup Community size Less widely used Microcontroller focus Can be complex"},{"location":"external_content/ut-core-wiki/FAQ%3A-Buildroot-vs.-Yocto-Project-vs.-Bob-the-Builder/#which-one-to-choose-for-developing-code-modules","title":"Which one to choose (for developing code modules)?","text":"<ul> <li>Quick cross-compilation with standard libraries: Buildroot (with adaptation)</li> <li>Manage complex dependencies, configure build scripts: Yocto (configure, not build)</li> <li>Modern, reproducible environment, good developer experience: Bob the Builder</li> <li>Flexibility, control, portability, comfortable with scripting: CMake/Make/Scripts</li> <li>Complex projects, hermetic builds, remote caching: Bazel</li> <li>User-friendly build system for C/C++ modules: Meson</li> <li>Flexibility and Python integration: SCons</li> <li>Simplified workflow for embedded platforms: PlatformIO</li> <li>Maximum control and customization: Custom Shell Scripts</li> </ul> <p>Choosing the right tool depends on your module's complexity, your team's expertise, and your desired level of customization. Prioritize independent module builds to ensure portability and avoid unnecessary dependencies on the build framework.</p>"},{"location":"external_content/ut-core-wiki/FAQ%3A-C-Macro-that-prints-structure-fields/","title":"FAQ: C Macro that prints structure fields","text":"<p>This macro prints the structure name, field names, and their corresponding values:</p> <pre><code>#include &lt;stdio.h&gt;\n\n#define LOG_STRUCT(structVar) \\\n    do { \\\n        printf(\"Structure: %s\\n\", #structVar); \\\n        _log_struct_helper(structVar); \\\n    } while (0)\n\n#define _log_struct_helper(structVar) \\\n    _log_struct_fields_helper(structVar, _get_struct_fields(structVar))\n\n#define _get_struct_fields(structVar) \\\n    _get_struct_fields_helper(0, structVar)\n\n#define _get_struct_fields_helper(index, structVar) \\\n    _Generic((structVar), \\\n        default: _get_struct_fields_helper(index + 1, structVar), \\\n        char: #structVar.index, \\\n        int: #structVar.index, \\\n        float: #structVar.index, \\\n        double: #structVar.index, \\\n        char *: #structVar.index, \\\n        int *: #structVar.index, \\\n        float *: #structVar.index, \\\n        double *: #structVar.index \\\n    )\n\n#define _log_struct_fields_helper(structVar, fieldName, ...) \\\n    do { \\\n        printf(\"  %s = \", fieldName); \\\n        _print_field_value(structVar.index); \\\n        if (sizeof((int[]){__VA_ARGS__})/sizeof(int) &gt; 0) { \\\n            printf(\"\\n\"); \\\n            _log_struct_fields_helper(structVar, __VA_ARGS__); \\\n        } \\\n    } while (0)\n\n#define _print_field_value(fieldValue) \\\n    _Generic((fieldValue), \\\n        char: printf(\"%c\", fieldValue), \\\n        int: printf(\"%d\", fieldValue), \\\n        float: printf(\"%f\", fieldValue), \\\n        double: printf(\"%lf\", fieldValue), \\\n        char *: printf(\"%s\", fieldValue), \\\n        default: printf(\"%p\", (void*)fieldValue) \\\n    )\n</code></pre> <p>Explanation</p> <ul> <li><code>LOG_STRUCT</code>: This is the main macro that you'll use. It takes the structure variable as input and prints the structure's name.</li> <li><code>_log_struct_helper</code>: This helper function recursively processes the structure fields.</li> <li><code>_get_struct_fields</code>: This helper function uses <code>_Generic</code> to determine the types of fields in the structure and generates a list of field names.</li> <li><code>_log_struct_fields_helper</code>: This helper function iterates over the list of field names, prints each field name and its value using <code>_print_field_value</code>.</li> <li><code>_print_field_value</code>: This helper function uses <code>_Generic</code> to print the field value based on its type. It handles basic types like <code>char</code>, <code>int</code>, <code>float</code>, <code>double</code>, and pointers to these types. For other types, it prints the memory address.</li> </ul> <p>Example Usage</p> <pre><code>typedef struct {\n    int id;\n    char name[50];\n    float price;\n} Product;\n\nint main() {\n    Product p = {1, \"Sample Product\", 9.99};\n    LOG_STRUCT(p);\n    return 0;\n}\n</code></pre> <p>Output</p> <pre><code>Structure: p\n  id = 1\n  name = Sample Product\n  price = 9.990000\n</code></pre> <p>Key Points:</p> <ul> <li>Limited Type Support: The macro currently supports basic types (<code>char</code>, <code>int</code>, <code>float</code>, <code>double</code>) and pointers to these types. You can extend it to handle other types by adding more cases to the <code>_Generic</code> expressions in <code>_get_struct_fields_helper</code> and <code>_print_field_value</code>.</li> <li>Nested Structures: The macro does not currently handle nested structures. You would need to add more logic to recursively process nested structures if required.</li> <li>Arrays: The macro handles arrays of basic types by printing their memory address. To print the individual elements of an array, you'll need to add custom logic.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A-C-macro-that-prints-the-function-name%2C-parameter-names-with-values/","title":"FAQ: C macro that prints the function name, parameter names with values","text":"<p>C macro that prints the function name, parameter names, and their corresponding values for debugging purposes. </p> <p>It uses the <code>__func__</code> identifier to get the function name and variadic macros to handle a variable number of parameters.</p> <pre><code>#include &lt;stdio.h&gt;\n\n#define LOG_PARAMS(...) \\\n    do { \\\n        printf(\"%s(\", __func__); \\\n        _log_params_helper(__VA_ARGS__); \\\n        printf(\")\\n\"); \\\n    } while (0)\n\n#define _log_params_helper(param, ...) \\\n    do { \\\n        printf(#param \" = %p\", (void*)param); \\\n        if (sizeof((int[]){__VA_ARGS__})/sizeof(int) &gt; 0) { \\\n            printf(\", \"); \\\n            _log_params_helper(__VA_ARGS__); \\\n        } \\\n    } while (0)\n</code></pre> <p>Explanation:</p> <ul> <li><code>LOG_PARAMS</code>: This is the main macro that you'll use in your functions. <ul> <li>It uses <code>__func__</code> to print the function name.</li> <li>It calls <code>_log_params_helper</code> to handle the actual parameter logging.</li> </ul> </li> <li><code>_log_params_helper</code>: This is a recursive helper macro.<ul> <li>It takes a parameter name and its value, prints them in the format <code>param = value</code>.</li> <li>It uses a clever trick with <code>sizeof</code> and an array to check if there are more parameters to log. If so, it recursively calls itself with the remaining parameters.</li> </ul> </li> </ul> <p>Example Usage:</p> <pre><code>void myFunction(int x, float y, char* z) {\n    LOG_PARAMS(x, y, z); \n    // ... rest of your function code\n}\n\nint main() {\n    myFunction(10, 3.14, \"hello\");\n    return 0;\n}\n</code></pre> <p>Output:</p> <pre><code>myFunction(x = 0x7ff... , y = 0x7ff..., z = 0x7ff...)\n</code></pre> <p>Key Points:</p> <ul> <li>Pointers: This macro prints the memory addresses (pointers) of the parameters. For basic types like <code>int</code> or <code>float</code>, you'll see their values directly. For more complex types (structs, arrays), you'll see their memory addresses. You might need to add custom logic within the macro to handle specific types if you want to print their contents directly.</li> <li>Error Handling: This macro doesn't include extensive error handling (e.g., checking for NULL pointers). You might want to add such checks if your code requires them.</li> <li>Portability: <code>__func__</code> is widely supported, but its exact behavior might vary slightly across compilers.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Choosing-GHEC%E2%80%90ORG-or-RDKCentral/","title":"FAQ: Choosing GHEC\u2010ORG or RDKCentral","text":""},{"location":"external_content/ut-core-wiki/FAQ%3A-Choosing-GHEC%E2%80%90ORG-or-RDKCentral/#choosing-the-right-github-organisation-and-access-level","title":"Choosing the Right GitHub Organisation and Access Level","text":"<p>This document outlines the decision-making process for selecting the appropriate GitHub organisation and repository access level for code storage and collaboration.</p>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Choosing-GHEC%E2%80%90ORG-or-RDKCentral/#github-organisations","title":"GitHub Organisations","text":"<ul> <li> <p>rdkcentral (Github Teams Plan):</p> <ul> <li>Primarily for open-source projects with public read access.</li> <li>Private repositories require a paid licence for write access.</li> <li>No Comcast login required for public access (Read Only)</li> <li>Cost: Free for public repositories. Paid licences for write access, or private repositories.<ul> <li>Teams plan costs $4 dollars per user per month.</li> </ul> </li> </ul> </li> <li> <p>ghec-org (GHEC - GitHub Enterprise Cloud):</p> <ul> <li>Controlled by Internal DevX.</li> <li>Designed for internal and private repositories.</li> <li>Offers \"private\" (team-based access) and \"internal\" (wider access) repository settings.</li> <li>Cost: Paid enterprise license <ul> <li>GHEC Plan costs $21 dollars per user per month. (Comcast may have a discounted rate due to volume)</li> </ul> </li> </ul> </li> </ul> <p>https://github.com/pricing</p>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Choosing-GHEC%E2%80%90ORG-or-RDKCentral/#decision-tree","title":"Decision Tree","text":"<p>The flowchart below illustrates the decision-making process. Here's a breakdown of the key considerations:</p> <ul> <li>Public vs. Controlled Access: If the code needs to be publicly accessible or in the future will be publically accessible , <code>rdkcentral</code> is the appropriate choice. If controlled access is required, <code>ghec-org</code> is preferred.</li> <li> <p>rdkcentral Access Levels:</p> <ul> <li>Public:  Free, read-only access for everyone.</li> <li>Private: Paid licence for write access, restricted to team members.</li> <li>Write: Paid licence for write access, restricted to team members.</li> </ul> </li> <li> <p>ghec-org Access Levels:</p> <ul> <li>Internal: Visible to all users within the <code>ghec-org</code> domain.</li> <li>Private: High security, restricted to specific teams.</li> <li>Partner:  Access for external partners, requiring onboarding to Comcast enterprise.</li> </ul> </li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Choosing-GHEC%E2%80%90ORG-or-RDKCentral/#key-factors","title":"Key Factors","text":"<ul> <li>Open Source: For new/current or future, open-source projects, <code>rdkcentral</code> with public repositories is ideal.</li> <li>Collaboration with Partners:  If partners need write access, <code>rdkcentral</code> (private) offers a simpler and potentially more cost-effective solution compared to onboarding them to Comcast's GHEC.</li> <li>Security: For highly sensitive code, <code>ghec-org</code> (private) provides the highest level of security.</li> <li>Cost: Consider the costs associated with each option, including paid licences and potential onboarding expenses.</li> </ul> <p>By carefully evaluating these factors and following the decision tree, you can select the most suitable GitHub organisation and access level for your project.</p> <pre><code>graph TD\n    A[Start] --&gt; C{Public or Controlled Access?};\n    C -- Public --&gt; E{rdkcentral};\n    C -- Controlled --&gt; F{ghec-org};\n    E --&gt; G{Read-Only or Write Access?};\n    G -- Read-Only --&gt; H[rdkcentral-public - Tier 2 Engineers];\n    G -- Write Access --&gt; I{rdkcentral-private - Tier 1 Engineers};\n    F --&gt; J{Access Level?};\n    J -- Internal --&gt; K[ghec-org internal];\n    J -- Private --&gt; L[ghec-org private];\n    J -- Partner --&gt; M[ghec-org partner];\n\n    H --&gt; N(Can read all public repos&lt;br&gt;No paid license&lt;br&gt;Changes in personal forks&lt;br&gt;PRs from forks possible&lt;br&gt;Issues &amp; discussions allowed);\n    I --&gt; O(Future public release possible&lt;br&gt;Easy external sharing&lt;br&gt;Lower write access cost&lt;br&gt;No DevX onboarding&lt;br&gt;Branching &amp; PRs allowed&lt;br&gt;Read all public repos&lt;br&gt;Paid license for Tier 1 engineers&lt;br&gt;Issues &amp; discussions allowed);\n    K --&gt; P(Internal, not shared externally&lt;br&gt;All ghec-org users can see);\n    L --&gt; Q(High security&lt;br&gt;No vendor access by default);\n    M --&gt; R(Partner access possible with DevX onboarding&lt;br&gt;Internal DevX codebase access);\n\n    style N fill:#ccf,stroke:#333,stroke-width:2px\n    style O fill:#ccf,stroke:#333,stroke-width:2px\n    style P fill:#ccf,stroke:#333,stroke-width:2px\n    style Q fill:#ccf,stroke:#333,stroke-width:2px\n    style R fill:#ccf,stroke:#333,stroke-width:2px</code></pre>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Comparing-Python-Development-Platforms/","title":"FAQ: Comparing Python Development Platforms","text":"<p>When developing Python applications, your choice of operating system\u2014Mac, Windows, or Linux\u2014can affect the development process in terms of setup, environment management, compatibility, and available tools. Here's a concise comparison of Python development across these three platforms:</p>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Comparing-Python-Development-Platforms/#1-setup-and-installation","title":"1. Setup and Installation","text":"<ul> <li>Mac:</li> <li>macOS comes with Python 2.x pre-installed, but Python 3 needs to be installed separately.</li> <li>Installation via Homebrew is recommended for managing multiple versions of Python.</li> <li> <p>Smooth setup for most Python tools and libraries.</p> </li> <li> <p>Windows:</p> </li> <li>Python isn't pre-installed on Windows, so you need to download and install it from the official Python website.</li> <li>The installer now includes an option to add Python to your system's PATH, simplifying setup.</li> <li> <p>Use Windows Subsystem for Linux (WSL) to run Linux-based Python workflows within Windows.</p> </li> <li> <p>Linux:</p> </li> <li>Python is often pre-installed on most Linux distributions (typically Python 3.x).</li> <li>Package managers like apt, yum, or dnf can easily handle Python installation and version management.</li> <li>Linux is closely aligned with Unix-like systems, so Python libraries related to server and system programming often have fewer compatibility issues.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Comparing-Python-Development-Platforms/#2-environment-management","title":"2. Environment Management","text":"<ul> <li>Mac:</li> <li>Homebrew simplifies the installation of Python and related tools.</li> <li>Tools like pyenv and virtualenv are commonly used for managing multiple Python versions and virtual environments.</li> <li> <p>Most Python tools work seamlessly with macOS due to its Unix foundation.</p> </li> <li> <p>Windows:</p> </li> <li>Managing Python versions can be done using pyenv-win or Anaconda.</li> <li>Virtual environments are supported, but sometimes require extra configuration due to Windows path handling.</li> <li> <p>WSL can be used for Linux-like environment management if needed.</p> </li> <li> <p>Linux:</p> </li> <li>Environment management with pyenv, virtualenv, and Anaconda is straightforward due to Python's tight integration with Linux.</li> <li>Linux provides the most natural environment for Python development, especially for DevOps, web development, and system-level programming.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Comparing-Python-Development-Platforms/#3-development-tools-and-ides","title":"3. Development Tools and IDEs","text":"<ul> <li>Mac:</li> <li>Popular IDEs like PyCharm, Visual Studio Code, and Sublime Text work well.</li> <li>Mac also supports terminal-based development with tools like vim or Emacs.</li> <li> <p>Native support for tools like Docker and Kubernetes simplifies cloud and containerized development.</p> </li> <li> <p>Windows:</p> </li> <li>PyCharm and Visual Studio Code work well on Windows.</li> <li>Command-line tools are less consistent across environments, but PowerShell and WSL help.</li> <li> <p>GUI-based Python tools and IDEs are more commonly used on Windows due to its focus on GUI applications.</p> </li> <li> <p>Linux:</p> </li> <li>PyCharm, VS Code, and terminal-based editors like vim or Emacs are highly popular.</li> <li>Full compatibility with command-line development and system-level tools.</li> <li>Linux is ideal for server-side and cloud development, with Docker and containerization tools natively integrated.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Comparing-Python-Development-Platforms/#4-package-and-dependency-management","title":"4. Package and Dependency Management","text":"<ul> <li>Mac:</li> <li>pip and pipenv work smoothly.</li> <li>Some libraries with system-level dependencies may require additional installations via Homebrew (e.g., C libraries).</li> <li> <p>Fewer compatibility issues than Windows, but some packages may still need custom configurations.</p> </li> <li> <p>Windows:</p> </li> <li>pip works well for pure Python packages, but some libraries with C extensions (like NumPy or SciPy) may require pre-built binaries or additional configuration.</li> <li> <p>Package managers like Chocolatey or Conda can help with more complex dependencies.</p> </li> <li> <p>Linux:</p> </li> <li>Linux is ideal for managing Python packages with system-level dependencies due to easy integration with C/C++ compilers and package managers (like apt).</li> <li>pip, pipenv, and conda work seamlessly with native system dependencies.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Comparing-Python-Development-Platforms/#5-compatibility-with-python-libraries","title":"5. Compatibility with Python Libraries","text":"<ul> <li>Mac:</li> <li>Mac has good compatibility with most Python libraries, particularly those related to web development and data science.</li> <li> <p>Occasionally, there are issues with libraries that have system-level dependencies (e.g., requiring Xcode command-line tools).</p> </li> <li> <p>Windows:</p> </li> <li>Some Python libraries, especially those with C extensions or system-level dependencies, can be challenging to install or configure.</li> <li>Tools like Microsoft Visual C++ Build Tools are often required to compile C extensions.</li> <li> <p>WSL helps with Linux-native libraries, but native Windows compatibility can still be hit or miss.</p> </li> <li> <p>Linux:</p> </li> <li>Most libraries, especially system-level or server-oriented libraries, work out of the box on Linux.</li> <li>Linux is the default development environment for many Python projects, particularly in the open-source world, so compatibility is rarely an issue.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Comparing-Python-Development-Platforms/#6-performance-and-stability","title":"6. Performance and Stability","text":"<ul> <li>Mac:</li> <li>Generally offers good performance and stability for Python development.</li> <li> <p>macOS is Unix-based, so it provides a stable environment for Python development, especially for server and web-related tasks.</p> </li> <li> <p>Windows:</p> </li> <li>Python performance on Windows is solid for most tasks, but you may encounter occasional compatibility issues, especially with libraries that rely heavily on Unix-like behavior.</li> <li> <p>WSL can help with Linux-based workflows, but native Windows performance for Python remains slightly behind Linux.</p> </li> <li> <p>Linux:</p> </li> <li>Python development on Linux is highly stable and often provides the best performance, especially for system-level tasks and web development.</li> <li>Linux is the closest environment to production for many Python applications, particularly those deployed on cloud infrastructure.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Comparing-Python-Development-Platforms/#7-best-use-cases","title":"7. Best Use Cases","text":"<ul> <li> <p>Mac: Great for developers who need a Unix-like environment but also want access to mainstream software and development tools. Ideal for web development, data science, and mobile development.</p> </li> <li> <p>Windows: Best for developers who work primarily with desktop applications or GUI-based tools. WSL helps for more Linux-like development workflows.</p> </li> <li> <p>Linux: The go-to platform for server-side, DevOps, cloud, and system programming. Ideal for open-source projects and environments that closely match production.</p> </li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Comparing-Python-Development-Platforms/#summary-table","title":"Summary Table","text":"Feature Mac Windows Linux Installation Pre-installed (Python 2.x), Homebrew Requires manual install Pre-installed, easy package manager Environment Management Homebrew, pyenv pyenv-win, Anaconda, WSL pyenv, virtualenv, Anaconda Development Tools PyCharm, VS Code, Sublime, CLI tools PyCharm, VS Code, WSL, PowerShell PyCharm, VS Code, vim, Emacs Package Management Smooth with pip and Homebrew Challenges with C extensions Seamless with pip and apt/yum Library Compatibility Good, with minor system dependency issues Some challenges with certain packages Excellent, minimal compatibility issues Performance High performance, stable Good, but sometimes needs extra configuration High performance, best for system-level tasks Best For Web, data science, mobile GUI apps, general Python development Server, system programming, open-source development <p>Each platform has strengths depending on your project\u2019s requirements. Linux is ideal for server-side and system programming, macOS offers a balance with Unix-like tools and GUI development, and Windows is improving rapidly, especially with WSL.</p>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Git-Flow-Support-for-Multiple-mainlines/","title":"FAQ: Git Flow Support for Multiple mainlines","text":""},{"location":"external_content/ut-core-wiki/FAQ%3A-Git-Flow-Support-for-Multiple-mainlines/#git-flow-supporting-for-multiple-mainlines","title":"Git Flow Supporting for Multiple mainlines","text":"<p>Git Flow enhances the Git workflow by standardizing branching conventions and providing helpful commands for managing features, releases, and hotfixes. This manual guides you through understanding and automating Git Flow configuration, where you can use this to re-configure your development mainline and have multiple configurations.</p>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Git-Flow-Support-for-Multiple-mainlines/#understanding-git-flow-variables","title":"Understanding Git Flow Variables","text":"<p>Git Flow operates by storing configuration variables within each repository's Git configuration. When you initialize Git Flow using <code>git flow init -d</code> (with defaults), it sets up these variables in the <code>.git/config</code> file.</p> <p>Viewing Configuration:</p> <p>You can inspect the current configuration in two ways:</p> <ol> <li> <p>Using Git: <pre><code>git config --list | grep gitflow \n</code></pre>    This will output lines like:    <pre><code>gitflow.branch.master=main\ngitflow.branch.develop=develop\ngitflow.prefix.feature=feature/\n...\n</code></pre></p> </li> <li> <p>Using Git Flow: <pre><code>git flow config\n</code></pre>    This provides a more user-friendly display:    <pre><code>Branch name for production releases: main\nBranch name for \"next release\" development: develop\nFeature branch prefix: feature/\n...\n</code></pre></p> </li> </ol>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Git-Flow-Support-for-Multiple-mainlines/#automating-configuration-with-shared-file","title":"Automating Configuration with Shared File","text":"<p>1. Create the Shared Configuration File (<code>&lt;project_root&gt;/.gitflowconfig</code>):</p> <p>This file defines your Git Flow settings. Here's an example supporting dual <code>main</code>/<code>develop</code> branches:</p> <p><code>&lt;project_root&gt;/.gitflowconfig</code></p> <pre><code>master=main  \ndevelop=develop \nfeature=feature/\nbugfix=bugfix/  \nrelease=release/\nhotfix=hotfix/\nsupport=support/ \nversiontag=\n</code></pre> <p><code>&lt;project_root&gt;/.gitflowconfig2</code></p> <pre><code>master=main2\ndevelop=develop2\nfeature=feature/\nbugfix=bugfix/  \nrelease=release/\nhotfix=hotfix/\nsupport=support/ \nversiontag=\n</code></pre> <p>2. Write the Automation Script (<code>init_gitflow.sh</code>):</p> <pre><code>#!/bin/bash\n\n# Optionally specify a custom Git Flow configuration file path\ncustom_config_file=\"\"\nif [[ $# -gt 0 ]]; then\n  custom_config_file=$1\nfi\n\n# Check if Git Flow is already initialized \nif [[ $(git config --get gitflow.branch.master) ]]; then\n  echo \"Git Flow is already initialized.\"\n  exit 0  # Exit successfully if already initialized\nfi\n\n# Load configuration from .gitflowconfig or the specified file\nif [[ -n \"$custom_config_file\" ]]; then\n  if [[ -f \"$custom_config_file\" ]]; then\n    source \"$custom_config_file\"\n    echo \"Using custom Git Flow configuration from $custom_config_file\"\n  else\n    echo \"Error: Custom configuration file not found: $custom_config_file\"\n    exit 1\n  fi\nelse\n  if [[ -f .gitflowconfig ]]; then\n    source .gitflowconfig\n    echo \"Using default Git Flow configuration from .gitflowconfig\"\n  else\n    echo \"Error: Neither default nor custom Git Flow configuration file found.\"\n    exit 1\n  fi\nfi\n\n# Initialize Git Flow using defaults (-d)\ngit flow init -d\n\n# Set the configuration parameters from .gitflowconfig or the specified file\ngit config gitflow.branch.master $master\ngit config gitflow.branch.develop $develop\ngit config gitflow.prefix.feature $feature\ngit config gitflow.prefix.bugfix $bugfix         # Set bugfix prefix\ngit config gitflow.prefix.release $release       # Set release prefix\ngit config gitflow.prefix.hotfix $hotfix         # Set hotfix prefix\ngit config gitflow.prefix.support $support       # Set support prefix\ngit config gitflow.prefix.versiontag $versiontag # Set versiontag prefix\n\necho \"Git Flow initialized successfully!\"\n</code></pre> <p>3. Make the Script Executable:</p> <pre><code>chmod +x init_gitflow.sh\n</code></pre> <p>4. Run the Script: (using default configuration)</p> <pre><code>./init_gitflow.sh\n</code></pre> <p>or specify a global / alternative configuration</p> <pre><code>./init_gitflow.sh ~/.gitflowconfig2\n</code></pre>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Git-Flow-Support-for-Multiple-mainlines/#leveraging-git-flow-in-your-workflow","title":"Leveraging Git Flow in Your Workflow","text":"<p>The variables <code>develop</code> and <code>main</code> are setup based on configuration, allowing multiple mainlines to be supported.</p> <p>Using Feature Branches</p> <pre><code># Start a new feature branch from variable 'develop'\ngit checkout $(git config --get gitflow.branch.develop)\ngit flow feature start &lt;feature_name&gt; \n# ... (develop your feature)\n# Finish the feature branch, merging it into 'develop'\ngit flow feature finish &lt;feature_name&gt; \n</code></pre> <p>Release Branches:</p> <pre><code># Start a new release branch from variable 'develop'\ngit checkout $(git config --get gitflow.branch.develop)\ngit flow release start &lt;version_number&gt;\n# ... (perform final testing)\nautochange-log -v &lt;version_number&gt; # generates release notes\n# Finish the release branch, merging into both variable 'develop' AND variable 'main', and pushing changes\ngit flow release finish &lt;version_number&gt; \ngit push \ngit push --tags\ngit checkout $(git config --get gitflow.branch.main) # push to variable `main`\ngit push\ngit checkout $(git config --get gitflow.branch.develop) # push to variable `develop`\n</code></pre>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Git-Flow-Support-for-Multiple-mainlines/#scaling-git-flow-initialization-with-og-optional","title":"Scaling Git Flow Initialization with <code>og</code> (Optional)","text":"<p>If you have the <code>sc</code> (Source Control) scripts installed, you can leverage the <code>og</code> (Operate on Git) command to effortlessly initialize Git Flow across multiple repositories within your project's directory structure. </p> <p>Here's how it works:</p> <ol> <li>Prerequisites:</li> <li><code>sc</code> Scripts: Ensure you have the <code>sc</code> scripts installed. You can find them on GitHub or package managers for your system.</li> <li> <p><code>init_gitflow.sh</code> and <code>.gitflowconfig</code>: Make sure these files are located in your home directory (<code>~</code>).</p> </li> <li> <p>Run the <code>og</code> Command:</p> </li> </ol> <pre><code>og cmd \"~/init_gitflow.sh ~/.gitflowconfig\"\n</code></pre> <p>This command does the following:</p> <ul> <li>Starting Point: Begins at your current directory.</li> <li>Recursive Search: Looks for all Git repositories within the current directory and its subdirectories.</li> <li>Execution: In each found repository, it runs the <code>~/init_gitflow.sh</code> script.  The script will use the shared configuration file <code>~/.gitflowconfig</code> to set up Git Flow consistently.</li> </ul> <p>Example Usage:</p> <p>Let's say your project has the following structure:</p> <pre><code>my_project/\n\u251c\u2500\u2500 frontend/\n\u2502   \u2514\u2500\u2500 .git\n\u251c\u2500\u2500 backend/\n\u2502   \u2514\u2500\u2500 .git\n\u2514\u2500\u2500 docs/\n</code></pre> <p>By running <code>og cmd \"~/init_gitflow.sh ~/.gitflowconfig\"</code> from within <code>my_project/</code>, you'll initialize Git Flow in both the <code>frontend</code> and <code>backend</code> repositories, applying the settings from your shared configuration file.</p>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Git%E2%80%90Flow%3A-Developers-Branching-Model/","title":"FAQ: Git\u2010Flow: Developers Branching Model","text":""},{"location":"external_content/ut-core-wiki/FAQ%3A-Git%E2%80%90Flow%3A-Developers-Branching-Model/#1-clone-the-repository","title":"1. Clone the Repository","text":"<p>To start, clone the repository to your local machine:</p> <pre><code>git clone https://github.com/rdkcentral/ut-core.git\n</code></pre>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Git%E2%80%90Flow%3A-Developers-Branching-Model/#2-set-up-git-flow","title":"2. Set Up Git Flow","text":"<p>We use the Git Flow branching model for managing branches. If you're new to Git Flow, please review this guide:</p> <p>Example of initialising git flow:</p> <pre><code>git flow init -d\n</code></pre>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Git%E2%80%90Flow%3A-Developers-Branching-Model/#3-create-a-feature-branch","title":"3. Create a Feature Branch","text":"<p>Create a new feature branch from the 'develop' branch for both new features and bug fixes, adhering to the naming convention: </p> <pre><code>feature/gh&lt;issue-number&gt;_&lt;brief-description&gt;\n</code></pre> <p>or</p> <pre><code>feature/&lt;issue-number&gt;_&lt;brief-description&gt;\n</code></pre> <p>The  should briefly summarize the branch's purpose. <p>Example of creating a feature branch:</p> <pre><code>git flow feature start 123_add-logging-enhancements\n</code></pre> <p>GUI from github.com/rdkcentral: It's possible to create the branch from the GUI also.</p> <p>Compliance Notice: All contributors must strictly follow our Git branching guidelines. Every branch must be accurately named using the corresponding issue ID from our issue tracker, ensuring traceability and upholding automated workflow integrity. Incorrectly named or untraceable branches will fall under a retention policy, allowing for correction within 30 days before removal. This policy is crucial for maintaining the clarity and reliability of our project management processes.</p>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Git%E2%80%90Flow%3A-Developers-Branching-Model/#4-implement-changes","title":"4. Implement Changes","text":"<p>Make changes according to the project\u2019s coding guidelines.</p>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Git%E2%80%90Flow%3A-Developers-Branching-Model/#5-commit-your-changes","title":"5. Commit Your Changes","text":"<p>Ensure your commits are clear and adhere to the 50/72 rule: - Summary: Start with an imperative verb (Fix, Update, Add, Improve, Merge, Refactor etc) include the GitHub issue ID, and succinctly describe the change. - Body: Optionally, provide a detailed explanation, keeping lines to 72 characters.</p> <p>Example of a Commit Message:</p> <pre><code>Fix #123: Update error handling in authentication module\n\nThis commit enhances error detection and adds comprehensive logging to address frequent issues reported by users.\n</code></pre> <p>For more detailed information on the 50/72 Rule: follow this link </p>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Git%E2%80%90Flow%3A-Developers-Branching-Model/#6-push-changes","title":"6. Push Changes","text":"<p>Push your changes to the repository:</p> <pre><code>git push origin feature/123_add-logging-enhancements\n</code></pre>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Git%E2%80%90Flow%3A-Developers-Branching-Model/#7-open-a-pull-request","title":"7. Open a Pull Request","text":"<p>Create a pull request from your branch to the <code>develop</code> branch. It will be automatically assigned for review based on the <code>CODEOWNERS</code> file.</p>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Git%E2%80%90Flow%3A-Developers-Branching-Model/#8-testing-and-validation","title":"8. Testing and Validation","text":"<p>As part of the input and review requirements for the pull request, the engineer is responsible for:</p> <p>a. Execute Testing Suites: Run all applicable test suites provided by the interface. If necessary, upgrade test suites and documentation to support new use cases (following the standard process for upgrades).</p> <p>Note: Interface upgrades are outside the scope of this task and require a separate architecture change request. Any module changes are dependent on the successful release of updated test suites.</p> <p>b. Document &amp; Attach Results: Include comprehensive test results in the pull request, detailing any errors, warnings, or unexpected behaviour encountered during testing.</p> <p>c. Submit for Review (Upon Success): Once all tests pass, submit the code for review via a pull request.</p>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Git%E2%80%90Flow%3A-Developers-Branching-Model/#9-codeowner-review-and-approval","title":"9. CODEOWNER Review and Approval","text":"<p>The pull request must be reviewed and explicitly approved by the designated <code>CODEOWNERS</code>. This review should include:</p> <ul> <li>Verification of test results.</li> <li>Assessment of code quality and adherence to standards.</li> <li>Discussion and resolution of any concerns or questions.</li> </ul> <p>Only after <code>CODEOWNERS</code> approval can the pull request proceed to the merge stage.</p>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Git%E2%80%90Flow%3A-Developers-Branching-Model/#10-merge-the-pull-request","title":"10. Merge the Pull Request","text":"<p>Once the code has been tested and approved by reviewers, the engineer is free to merge the branch using Git Flow:</p> <pre><code>git flow feature finish gh123_add-logging-enhancements\n</code></pre>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Git%E2%80%90Flow%3A-Developers-Branching-Model/#11-code-ownership-and-releases","title":"11. Code Ownership and Releases","text":"<p><code>CODEOWNERS</code> are responsible for reviewing and approving changes. They also manage the release and tagging of components according to the project\u2019s schedule.</p>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Git%E2%80%90Flow%3A-Developers-Branching-Model/#requirements-for-contributions","title":"Requirements for Contributions","text":"<p>Please ensure your contributions meet the following:</p> <ul> <li>Adherence to Git Flow</li> <li>Clear and Concise Commit Messages</li> <li>Peer Review Approval</li> <li>Open Discussions and Contributions</li> <li>Thorough Testing and Validation (including test results)</li> </ul> <p>By following these guidelines, you help maintain the quality and integrity of the project while fostering an inclusive and collaborative community environment. We look forward to your contributions, and thank you for being part of our community-driven project.</p> <p>Refer also to FAQ: Release Engineers: Performing a release with git-flow</p>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Migrating-Binaries-to-%60Git-LFS%60/","title":"FAQ: Migrating Binaries to `Git LFS`","text":"<p>Here's an overview of migrating binaries to Git LFS (Large File Storage) from the current tip of your branch, along with considerations and best practices:</p> <p>Understanding Git LFS</p> <p>Git LFS is a Git extension designed to handle large files more efficiently. Instead of storing the entire file contents directly in your Git repository (which can bloat it over time), LFS replaces large files with small text pointers. The actual file content is stored in a separate LFS store, typically on a remote server.</p> <p>Why Migrate to LFS?</p> <ul> <li>Smaller Repository Size:  LFS drastically reduces the size of your repository, making cloning, fetching, and pushing much faster.</li> <li>Improved Performance: Since Git only needs to manage lightweight pointers, common operations are more efficient.</li> <li>Storage Optimization: LFS servers often have storage optimizations specifically for large files.</li> </ul> <p>Migration Steps</p> <ol> <li> <p>Install Git LFS:  Ensure Git LFS is installed and set up on your system.</p> </li> <li> <p>Track File Types: Tell Git LFS which file types to track. Create or update your <code>.gitattributes</code> file in the root of your repository:</p> </li> </ol> <p><pre><code>*.jpg filter=lfs diff=lfs merge=lfs -text\n*.png filter=lfs diff=lfs merge=lfs -text\n*.zip filter=lfs diff=lfs merge=lfs -text\n</code></pre>    (Replace the examples with your specific binary file types)</p> <ol> <li>Migrate Existing Files: </li> </ol> <pre><code>git lfs migrate import --include=\"*.jpg\" --include=\"*.png\" --include=\"*.zip\"\n</code></pre> <p>(Replace the examples with the file types you want to migrate)</p> <ol> <li>Commit Changes: </li> </ol> <pre><code>git add .gitattributes\ngit commit -m \"Migrate binaries to LFS\"\n</code></pre> <ol> <li>Push to Remote: Push your changes, including the updated <code>.gitattributes</code> file, to your remote repository.</li> </ol> <p>Important Considerations</p> <ul> <li> <p>Existing Clones: Collaborators who have already cloned the repository will need to fetch the LFS pointers and the actual files from the LFS store after you've migrated. They might need to run <code>git lfs fetch</code> and <code>git lfs checkout</code>.</p> </li> <li> <p>Large Repositories: If you have a very large repository, the migration might take some time.  You can use the <code>--verbose</code> flag to see progress:</p> </li> </ul> <pre><code> git lfs migrate import --verbose --include=\"*.jpg\"\n</code></pre> <ul> <li> <p>File Locking: Consider using Git LFS file locking (<code>git lfs locks</code>) if you have large binary files that are often edited concurrently by multiple people. This can prevent merge conflicts.</p> </li> <li> <p>Bandwidth Considerations: Be mindful of the potential network traffic involved in transferring large files to the LFS store.</p> </li> </ul> <p>Example: Migrating a Single File</p> <p>If you only want to migrate a single file from the current tip of your branch, you can use:</p> <pre><code>git lfs track \"your_file.bin\" \ngit add your_file.bin\ngit commit -m \"Add your_file.bin to LFS\"\n</code></pre>"},{"location":"external_content/ut-core-wiki/FAQ%3A-RDK-Docker-Toolchain/","title":"FAQ: RDK Docker Toolchain","text":""},{"location":"external_content/ut-core-wiki/FAQ%3A-RDK-Docker-Toolchain/#launching-the-toolchain-docker-container","title":"Launching the Toolchain Docker Container","text":"<p>This manual guides you through the process of using the RDK Docker Toolchain to build projects targeted for ARM architecture, using Docker.</p> <p>Note: At the time of writing this has yet to be published opensource, but will be soon</p> <p>To start the Docker container and open a bash shell within it, use the following command:</p> <pre><code>sc docker run &lt;docker&gt; /bin/bash\n</code></pre>"},{"location":"external_content/ut-core-wiki/FAQ%3A-RDK-Docker-Toolchain/#expected-dockers","title":"Expected Dockers","text":"<ul> <li>rdk-dunfell</li> <li>rdk-kirkstone</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A-RDK-Docker-Toolchain/#setting-up-the-environment","title":"Setting Up the Environment","text":"<p>Once inside the Docker container, follow these steps to set up the environment:</p> <ol> <li>Navigate to the toolchain directory:</li> </ol> <pre><code>cd /opt/toolchains/rdk-glibc-x86_64-arm-toolchain/\n</code></pre> <ol> <li>Source &amp; Activate the environment setup for ARMv7:</li> </ol> <pre><code>. environment-setup-armv7at2hf-neon-oe-linux-gnueabi\n</code></pre> <ol> <li>To verify that the compiler (CC) is set correctly in the environment, execute:</li> </ol> <pre><code>echo $CC\n</code></pre> <p>The output should start with <code>arm-oe-linux-gnueabi-gcc</code> followed by various compiler switches.</p>"},{"location":"external_content/ut-core-wiki/FAQ%3A-RDK-Docker-Toolchain/#building-the-project","title":"Building the Project","text":"<p>To build your project using the ARM toolchain, follow these steps:</p> <ul> <li>Change to your project directory (replace  with your actual project directory name): <pre><code>cd &lt;project&gt;\n</code></pre> <ul> <li>Start the build process by specifying the target:</li> </ul> <pre><code>make TARGET=arm\n</code></pre>"},{"location":"external_content/ut-core-wiki/FAQ%3A-RDK-Docker-Toolchain/#optional-single-command-execution","title":"Optional Single Command Execution","text":"<p>Alternatively, you can combine all the steps into a single command to set up the environment and build your project directly. Here\u2019s how:</p> <p>e.g.</p> <pre><code>sc docker run rdk-dunfell \"/bin/bash -c '. /opt/toolchains/rdk-glibc-x86_64-arm-toolchain/environment-setup-armv7at2hf-neon-oe-linux-gnueabi; cd &lt;project&gt;; make TARGET=arm'\"\n</code></pre> <p>Make sure to replace  with your actual project directory. This command facilitates running everything in one go inside the Docker container."},{"location":"external_content/ut-core-wiki/FAQ%3A-Release-Engineers%3A-Performing-a-release-with-git-flow/","title":"FAQ: Release Engineers: Performing a release with git flow","text":"<p>Git Flow provides a structured branching model for managing software releases. Here's how you can use it to create a fixed tag release:</p>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Release-Engineers%3A-Performing-a-release-with-git-flow/#start-a-release-branch","title":"Start a Release Branch","text":"<ul> <li>Use <code>git flow release start &lt;release-name&gt;</code> (e.g., <code>git flow release start 1.2.0</code>)</li> <li>This creates a new branch (e.g., <code>release/1.2.0</code>) from the <code>develop</code> branch.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Release-Engineers%3A-Performing-a-release-with-git-flow/#work-on-the-release","title":"Work on the Release","text":"<ul> <li>This branch is dedicated to finalizing the release, fixing bugs, and preparing release notes.</li> <li>Do not add new features here; those should be targeted to <code>develop</code> for the next release.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Release-Engineers%3A-Performing-a-release-with-git-flow/#finish-the-release","title":"Finish the Release","text":"<ul> <li>When the release is ready, use <code>git flow release finish &lt;release-name&gt;</code>, (note:<code>&lt;release-name</code> is optional)</li> <li>This performs several actions:<ul> <li>Merges <code>release/1.2.0</code> into <code>main</code></li> <li>Tags the <code>main</code> commit with the release name (e.g., <code>1.2.0</code>)</li> <li>Merges <code>release/1.2.0</code> back into <code>develop</code> to keep it up-to-date</li> <li>Deletes the <code>release/1.2.0</code> branch</li> </ul> </li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Release-Engineers%3A-Performing-a-release-with-git-flow/#push-changes","title":"Push Changes","text":"<ul> <li>Assuming your default remote is <code>origin</code>, and you're on <code>main</code> branch</li> <li>Use <code>git push --tags</code> to push the tag and <code>main</code> branch to your remote repository.</li> <li>Use <code>git checkout develop</code> to check out the develop branch</li> <li>Use <code>git push</code> to push the develop branch</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Release-Engineers%3A-Performing-a-release-with-git-flow/#example","title":"Example","text":"<pre><code># Start the release\ngit flow release start 1.2.0 \n\n# Work on the release (fix bugs, update docs, etc.)\n# ...\n\n## Generate a change log see (https://github.com/cookpete/auto-changelog)\nautochange-log -v 1.2.0\ngit add CHANGELOG.md\ngit commit -m \"Bumped CHANGELOG.md for release\"\n\n# Finish the release\ngit flow release finish 1.2.0\n\n# Code should be merged to both develop &amp; main\n# If successful &amp; not merge errors the branch will be `develop`\n# If merge errors, follow instructions and re-run etc.\n\n# Merge has occurred to develop\ngit push  # pushes develop\ngit push --tags # pushes the tags\ngit checkout main # swaps branch to main\ngit push # pushes main\n</code></pre>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Release-Engineers%3A-Performing-a-release-with-git-flow/#benefits-of-using-git-flow-release","title":"Benefits of Using Git Flow Release","text":"<ul> <li>Clear Structure: Provides a well-defined workflow for managing releases.</li> <li>Dedicated Branch:  The <code>release</code> branch isolates release-related work from ongoing development.</li> <li>Version Tracking:  Tags make it easy to identify and roll back to specific releases.</li> <li>Automation: Git Flow commands automate the merging and tagging process.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Release-Engineers%3A-Performing-a-release-with-git-flow/#additional-tips","title":"Additional Tips","text":"<ul> <li>Hotfixes: Use <code>git flow hotfix</code> to quickly address critical issues in production releases.</li> <li>Support Branches: Use <code>git flow support</code> to maintain older releases.</li> </ul> <p>By following this approach, you can streamline your release process, ensure consistent versioning, and maintain a clean Git history.</p> <p>Refer also to FAQ: Git-Flow: Developers Branching Model</p>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Sign-up-for-RDK-Central-%E2%80%90-Tier-1-Registration/","title":"FAQ: Sign up for RDK Central \u2010 Tier 1 Registration","text":"<p>In order to be able to access private repositories, you need to be added to teams in GitHub. For this, we will need to know your GitHub Public-ids and store them in LDAP on RDKCentral.</p> <p>So, please follow the following steps to maintain your access to migrated repos:</p> <ol> <li>If you already have a rdkcentral account, skip to step 4.</li> <li>Create a rdkcentral account. sign up here: https://wiki.rdkcentral.com/signup.action</li> <li>Wait at least 15 minutes for LDAP to be updated</li> <li>If you already have a Public GitHub account, skip to step 6</li> <li>Create a Public GitHub account, Navigate to https://github.com/ and click Sign up (Ensure you have logged out of your GitHub enterprise cloud account when performing these steps). Follow the prompts to create your personal account)</li> <li>Update your rdkcentral user profile to add your GitHub credentials (follow the instructions here: https://wiki.rdkcentral.com/display/CMF/RDK+Central+Github+Profile+Setup+for+Private+Repository+Access )</li> <li>Accept the rdkcentral GitHub team invite, sent to the email associated with your GitHub personal account.</li> </ol>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Software-Post-Release-Development-Cycle/","title":"FAQ: Software Post Release Development Cycle","text":""},{"location":"external_content/ut-core-wiki/FAQ%3A-Software-Post-Release-Development-Cycle/#post-release-development-an-active-phase-of-software-evolution","title":"Post-Release Development: An Active Phase of Software Evolution","text":"<p>Post-Release Development refers to the continuous, active process of improving, adapting, and enhancing software after it has been deployed. It ensures that the software remains functional, secure, and aligned with evolving user needs and technological advancements. Far from being a passive stage, this phase involves ongoing development to maintain the software's value and relevance over time.</p>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Software-Post-Release-Development-Cycle/#types-of-post-release-development","title":"Types of Post-Release Development","text":"<ol> <li>Corrective Enhancements:</li> <li>Focus: Addressing bugs, defects, or errors discovered after deployment.</li> <li> <p>Example: Fixing an issue that causes unexpected behavior or crashes during specific user actions.</p> </li> <li> <p>Adaptive Changes:</p> </li> <li>Focus: Updating software to ensure compatibility with changing environments or technologies.</li> <li> <p>Example: Adjusting the software to work seamlessly with a new operating system or hardware platform.</p> </li> <li> <p>Perfective Improvements:</p> </li> <li>Focus: Enhancing existing features, performance, or usability based on user feedback and analytics.</li> <li> <p>Example: Adding new functionality or streamlining the user interface to improve the experience.</p> </li> <li> <p>Preventive Adjustments:</p> </li> <li>Focus: Proactively addressing potential future issues or improving code structure to enhance maintainability.</li> <li>Example: Refactoring legacy code to align with modern development practices.</li> </ol>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Software-Post-Release-Development-Cycle/#activities-involved-in-post-release-development","title":"Activities Involved in Post-Release Development","text":"<ul> <li>Bug Fixes: Resolving known issues to ensure stability and reliability.</li> <li>Performance Tuning: Optimizing speed, resource usage, and scalability.</li> <li>Feature Enhancements: Adding or upgrading functionality to meet changing user needs.</li> <li>Security Updates: Addressing vulnerabilities to safeguard data and operations.</li> <li>Compatibility Updates: Ensuring the software works with new devices, platforms, or standards.</li> <li>Code Refinement: Regularly reviewing and improving the codebase for clarity and efficiency.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Software-Post-Release-Development-Cycle/#importance-of-post-release-development","title":"Importance of Post-Release Development","text":"<ol> <li>Ongoing Value Delivery: Ensures that the software continues to meet user expectations and business requirements.</li> <li>Adaptability to Change: Keeps the software relevant in the face of evolving technology and user demands.</li> <li>Enhanced User Satisfaction: Addresses user-reported issues and requests to improve the experience.</li> <li>Risk Mitigation: Proactively reduces the likelihood of security breaches or system failures.</li> <li>Longevity: Extends the lifecycle of the software by keeping it functional and up to date.</li> </ol>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Software-Post-Release-Development-Cycle/#challenges-of-post-release-development","title":"Challenges of Post-Release Development","text":"<ul> <li>Managing Technical Debt: Legacy code and shortcuts taken during initial development can complicate updates.</li> <li>Resource Allocation: Balancing efforts between new feature development and maintaining existing software.</li> <li>Compatibility Issues: Adapting software for new environments without disrupting functionality.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Software-Post-Release-Development-Cycle/#best-practices-for-effective-post-release-development","title":"Best Practices for Effective Post-Release Development","text":"<ul> <li>Continuous Feedback Loop: Gather and act on user feedback to prioritize improvements.</li> <li>Automated Testing: Ensure new changes do not introduce regressions or bugs.</li> <li>Comprehensive Documentation: Maintain clear and up-to-date documentation to streamline future updates.</li> <li>Version Control: Track all changes to ensure transparency and accountability.</li> <li>Proactive Planning: Identify and address potential issues before they impact users.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Software-Post-Release-Development-Cycle/#conclusion","title":"Conclusion","text":"<p>Post-Release Development is a dynamic and ongoing phase of the software lifecycle, integral to ensuring that the software remains valuable and effective in the long term. By treating this stage as an active development process, teams can continually deliver improvements, address issues, and adapt to an ever-changing technological landscape. This commitment to evolution not only satisfies users but also protects the investment in the software over time. </p>"},{"location":"external_content/ut-core-wiki/FAQ%3A-UT-Core-Framework-Overview/","title":"Level Actors","text":""},{"location":"external_content/ut-core-wiki/FAQ%3A-UT-Core-Framework-Overview/#excerpt-from-32-standards-requirements-for-building-testing-suites","title":"Excerpt from 3.2. Standards: Requirements for Building Testing Suites","text":"<ul> <li>L1/L2 testing suites will use the <code>ut-core</code> testing framework.</li> <li>L3/L4 testing suites will incorporate the <code>python-raft</code> infrastructure and the <code>ut-raft</code> framework while continuing to utilize <code>ut-core</code> as required.</li> <li>The testing system must adhere to the guidelines outlined in the Setup/Layout Guide.</li> <li>Developers are expected to familiarize themselves with the <code>ut-raft</code> classes, documented in the ut-raft wiki.</li> <li>Examples of <code>python-raft</code> configuration and setup can be found in the aforementioned resources.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A-UT-Core-Framework-Overview/#levels-of-test","title":"Levels of Test","text":"<p>The levels of testing to be implemented are described in detail here: Standards: Levels of Test for Vendor Layer</p>"},{"location":"external_content/ut-core-wiki/FAQ%3A-UT-Core-Framework-Overview/#testing-frameworks","title":"Testing Frameworks","text":"<ul> <li>L1/L2: <code>ut-core</code> (ut-core repository)</li> <li>L3: Combination of C++ and C, utilizing both <code>ut-core</code> and <code>python-raft</code> (python-raft repository)</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A-UT-Core-Framework-Overview/#actors-involved","title":"Actors Involved","text":"<ul> <li>Automation</li> <li>QA Team</li> <li>Engineering Team</li> <li>DUT (Device Under Test)</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A-UT-Core-Framework-Overview/#engineering-testing","title":"Engineering Testing","text":"<ul> <li>Engineers and third-party developers will use Levels 1 to 3 to validate and test changes to individual components or groups of components.</li> <li>Level 4 testing expands to multi-component testing, ensuring end-to-end validation.</li> <li>Pre-commit testing is covered under Levels 1 - 3, requiring manual review of results but not necessarily automation.</li> </ul> Test Suite Actors Level 1 - 3 Component Tests Engineers L4 System Performance Engineers L4 Ad-hoc Analysis Engineers L4 Smoke Testing Layer Release Engineers, QA Team L4 System Interface Testing Engineers L4 Deep Dive Testing Engineers"},{"location":"external_content/ut-core-wiki/FAQ%3A-UT-Core-Framework-Overview/#qa-testing","title":"QA Testing","text":"<ul> <li>QA primarily focuses on L4 Smoke Testing to ensure compatibility throughout the layer release cycle.</li> <li>The full stack image includes Vendor, MW, and Application Layers, enabling test binaries to be run using previous versions to identify regressions.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A-UT-Core-Framework-Overview/#system-architecture-overview","title":"System Architecture Overview","text":""},{"location":"external_content/ut-core-wiki/FAQ%3A-UT-Core-Framework-Overview/#testing-system-flow","title":"Testing System Flow","text":"<pre><code>graph LR\n    subgraph Actors\n        subgraph \"Python Raft / UT-Raft\"\n            Python_Raft --&gt; device(DUT)\n        end\n        subgraph \"XTS Tools\"\n            xTS --&gt; Python_Raft\n            xTS &lt;--&gt; allocator[xTS Allocator]\n            allocator --&gt; rackConfig\n            rackConfig --&gt; Python_Raft\n        end\n        subgraph \"Automation\"\n            auto1[Github Actions / Review Approval] --&gt; xTS\n        end\n        subgraph \"QA Team\"\n            QASmoke[L4 Smoke Testing] --&gt; xTS\n        end\n        subgraph \"Engineer - Component / Layer / Vendor\"\n            L4Smoke[L4 Testing] --&gt; Python_Raft\n            EngineerComponentTesting[L3 Component Testing] --&gt; Python_Raft\n            EngineerComponentTesting --&gt; device\n            L4Smoke --&gt; localRackConfig\n            EngineerComponentTesting --&gt; localRackConfig\n            localRackConfig --&gt; Python_Raft\n        end\n    end</code></pre>"},{"location":"external_content/ut-core-wiki/FAQ%3A-UT-Core-Framework-Overview/#host-machine-high-level-tests","title":"Host Machine (High-Level Tests)","text":"<p>L3 Component Stimulus Testing and L4 System Testing are executed from the Host Machine, utilizing the <code>ut-raft</code> framework to extend <code>python-raft</code> capabilities.</p> <pre><code>graph LR\n    subgraph \"Host Machine (High Level Tests)\"\n        deviceConfig --&gt; Python_Test\n        rackConfig --&gt; Python_Test\n        Python_Test[Python Test] --&gt; ut_raft\n        ut_raft --&gt; python_raft\n        python_raft --&gt; console\n        console --&gt; DUT\n        python_raft --&gt; webPageControl --&gt; DUT\n        python_raft --&gt; OutboundClient --&gt; DUT\n    end\n    subgraph \"Rack Slot\"\n        python_raft --&gt; PowerSwitch --&gt; DUT\n        python_raft --&gt; IR --&gt; DUT\n        python_raft --&gt; CECAdaptor --&gt; DUT\n        python_raft --&gt; VideoCapture --&gt; DUT\n        VideoCapture --&gt; HostHDD\n    end</code></pre>"},{"location":"external_content/ut-core-wiki/FAQ%3A-UT-Core-Framework-Overview/#dut-target-architecture","title":"DUT Target Architecture","text":"<p><code>Python Raft</code> connects to the DUT via a console session, ensuring platform-independent testing with automated configurations.</p> <pre><code>graph LR\n    subgraph \"DUT (Target)\"\n        console &lt;--&gt; test_binary(Test Code)\n        platform_profile --&gt; test_binary\n        test_binary --&gt; state_machine\n        state_machine --&gt; code(Code Under Test)\n        test_binary --&gt; ut_core\n        ut_core --&gt; ut_control\n        webSocket --&gt; ut_control\n        ut_control --&gt; state_machine\n    end</code></pre>"},{"location":"external_content/ut-core-wiki/FAQ%3A-UT-Core-Framework-Overview/#summary","title":"Summary","text":"<ul> <li>The testing system is divided into multiple levels, utilizing <code>ut-core</code>, <code>python-raft</code>, and <code>ut-raft</code> for different types of testing.</li> <li>Engineering Teams perform pre-commit testing at Levels 1 - 3, while QA Teams focus on L4 Smoke Testing.</li> <li>Automation integrates with testing through <code>GitHub Actions</code> and other tools.</li> <li>DUT Target Testing ensures platform-independent configuration and verification of vendor-layer compatibility.</li> </ul> <p>This document provides a graphical overview of the testing system, ensuring that all stakeholders have a clear understanding of the testing flow and responsibilities.</p>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Vagrant%3A-Setting-Up-and-Managing-Your-Vagrant-VM/","title":"FAQ: Vagrant: Setting Up and Managing Your Vagrant VM","text":""},{"location":"external_content/ut-core-wiki/FAQ%3A-Vagrant%3A-Setting-Up-and-Managing-Your-Vagrant-VM/#setting-up-and-managing-your-vagrant-vm","title":"Setting Up and Managing Your Vagrant VM","text":"<p>Link to Vagrant </p>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Vagrant%3A-Setting-Up-and-Managing-Your-Vagrant-VM/#overview","title":"Overview","text":"<p>This guide provides a comprehensive solution for managing a remote Vagrant image with a configuration file held in a Git repository. It includes steps for downloading and provisioning the VM, resetting it to its original state, and automatically detecting changes in provisioning.</p>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Vagrant%3A-Setting-Up-and-Managing-Your-Vagrant-VM/#solution","title":"Solution","text":"<ol> <li> <p>Remote Vagrant Image and Configuration:</p> <ul> <li>The Vagrant configuration file (<code>Vagrantfile</code>) and necessary provisioning scripts are stored in a Git repository.</li> <li>When developers clone the repository, they get the <code>Vagrantfile</code> and provisioning scripts.</li> <li>The <code>Vagrantfile</code> includes instructions to download and provision the VM using <code>apt-get</code> and other necessary configurations.</li> </ul> </li> <li> <p>Resetting the VM:</p> <ul> <li>Developers can reset the VM back to its original state by destroying and recreating it using a provided script.</li> </ul> </li> <li> <p>Automatic Provisioning Detection:</p> <ul> <li>When developers pull the latest changes from the Git repository, the setup detects any changes in the provisioning scripts and prompts for a VM rebuild if needed.</li> </ul> </li> </ol>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Vagrant%3A-Setting-Up-and-Managing-Your-Vagrant-VM/#git-repository-structure","title":"Git Repository Structure","text":"<pre><code>&lt;repository-root&gt;\n\u251c\u2500\u2500 Vagrantfile\n\u251c\u2500\u2500 provision.sh\n\u251c\u2500\u2500 check_provisioning.sh\n\u251c\u2500\u2500 vm_reset.sh\n\u2514\u2500\u2500 vm_start.sh\n</code></pre>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Vagrant%3A-Setting-Up-and-Managing-Your-Vagrant-VM/#scripts-and-configuration","title":"Scripts and Configuration","text":""},{"location":"external_content/ut-core-wiki/FAQ%3A-Vagrant%3A-Setting-Up-and-Managing-Your-Vagrant-VM/#vagrantfile","title":"Vagrantfile","text":"<pre><code>Vagrant.configure(\"2\") do |config|\n  config.vm.box = \"ubuntu/bionic64\"\n\n  # Run the provisioning check script before starting the VM\n  config.trigger.before :up do\n    run \"bash check_provisioning.sh\"\n  end\n\n  config.vm.provision \"shell\", path: \"provision.sh\"\n\n  config.vm.synced_folder \".\", \"/vagrant\"\nend\n</code></pre>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Vagrant%3A-Setting-Up-and-Managing-Your-Vagrant-VM/#provisionsh","title":"provision.sh","text":"<pre><code>#!/bin/bash\n\n# Update package lists\nsudo apt-get update\n\n# Install necessary packages\nsudo apt-get install -y git curl vim\n</code></pre>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Vagrant%3A-Setting-Up-and-Managing-Your-Vagrant-VM/#check_provisioningsh","title":"check_provisioning.sh","text":"<pre><code>#!/bin/bash\n\n# Path to the stored hash file\nHASH_FILE=\".provision_hash\"\n\n# Generate a new hash for the provisioning script\nNEW_HASH=$(sha256sum provision.sh | awk '{ print $1 }')\n\n# Check if the hash file exists\nif [ -f \"$HASH_FILE\" ]; then\n  OLD_HASH=$(cat \"$HASH_FILE\")\n  if [ \"$NEW_HASH\" != \"$OLD_HASH\" ]; then\n    echo \"Provisioning script has changed. Please run './vm_reset.sh' to rebuild the VM.\"\n  fi\nfi\n\n# Store the new hash\necho \"$NEW_HASH\" &gt; \"$HASH_FILE\"\n</code></pre>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Vagrant%3A-Setting-Up-and-Managing-Your-Vagrant-VM/#vm_resetsh","title":"vm_reset.sh","text":"<pre><code>#!/bin/bash\n\n# Destroy the current VM\nvagrant destroy -f\n\n# Recreate and provision the VM\nvagrant up\n</code></pre>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Vagrant%3A-Setting-Up-and-Managing-Your-Vagrant-VM/#vm_startsh","title":"vm_start.sh","text":"<pre><code>#!/bin/bash\n\n# Start the VM\nvagrant up\n</code></pre>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Vagrant%3A-Setting-Up-and-Managing-Your-Vagrant-VM/#instructions-for-manual","title":"Instructions for Manual","text":""},{"location":"external_content/ut-core-wiki/FAQ%3A-Vagrant%3A-Setting-Up-and-Managing-Your-Vagrant-VM/#setting-up-and-managing-your-vagrant-vm_1","title":"Setting Up and Managing Your Vagrant VM","text":""},{"location":"external_content/ut-core-wiki/FAQ%3A-Vagrant%3A-Setting-Up-and-Managing-Your-Vagrant-VM/#1-clone-the-repository","title":"1. Clone the Repository","text":"<p>First, clone the repository containing the Vagrant configuration and scripts:</p> <pre><code>git clone &lt;repository-url&gt;\ncd &lt;repository-directory&gt;\n</code></pre>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Vagrant%3A-Setting-Up-and-Managing-Your-Vagrant-VM/#2-start-the-vm","title":"2. Start the VM","text":"<p>To start the VM, simply run the provided <code>vm_start.sh</code> script:</p> <pre><code>./vm_start.sh\n</code></pre> <p>This script will: - Check for changes in the provisioning script using <code>check_provisioning.sh</code>. - Start the VM and apply the provisioning defined in <code>provision.sh</code>.</p>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Vagrant%3A-Setting-Up-and-Managing-Your-Vagrant-VM/#3-reset-the-vm","title":"3. Reset the VM","text":"<p>If you need to reset the VM to its original state, run the <code>vm_reset.sh</code> script:</p> <pre><code>./vm_reset.sh\n</code></pre> <p>This script will: - Destroy the current VM. - Recreate and re-provision the VM from scratch.</p>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Vagrant%3A-Setting-Up-and-Managing-Your-Vagrant-VM/#4-pull-the-latest-changes","title":"4. Pull the Latest Changes","text":"<p>To update your local repository with the latest changes from the remote repository, run:</p> <pre><code>git pull\n</code></pre>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Vagrant%3A-Setting-Up-and-Managing-Your-Vagrant-VM/#5-check-for-provisioning-changes","title":"5. Check for Provisioning Changes","text":"<p>Before the VM starts, the <code>check_provisioning.sh</code> script will automatically run to detect any changes in the provisioning script. If changes are detected, you will see a message prompting you to reset the VM using <code>./reset.sh</code>.</p>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Vagrant%3A-Setting-Up-and-Managing-Your-Vagrant-VM/#scripts-overview","title":"Scripts Overview","text":"<ul> <li>Vagrantfile: Defines the VM configuration and provisioning.</li> <li>provision.sh: Contains commands to install required packages and configurations.</li> <li>check_provisioning.sh: Checks if the provisioning script has changed and prompts for a VM reset if needed.</li> <li>vm_reset.sh: Destroys and recreates the VM.</li> <li>vm_start.sh: Starts the VM.</li> </ul>"},{"location":"external_content/ut-core-wiki/Home/","title":"UT-Core Framework","text":"<p>ut-core is a modular unit testing framework designed to streamline and simplify the process of developing and executing tests within the RDK Central ecosystem. It provides a collection of tools, utilities, and conventions to help you build robust and reliable tests for your software components.</p>"},{"location":"external_content/ut-core-wiki/Home/#objectives-for-the-framework","title":"Objectives for the framework","text":"<p>Testing suites serve as engineering tools that scrutinise individual components, groups or layers of components during the development and debugging process. Such tests ascertain quality by running multiple rounds on locally revised code before its final commit. </p>"},{"location":"external_content/ut-core-wiki/Home/#primary-objectives","title":"Primary Objectives:","text":"<ul> <li>Pre-commit: Validation of local changes, build and execute the relevant testing suite for the desired component group or layer </li> <li>Debugging: Tests must enable debugging for better variable examination and solitary step execution.</li> <li>Sharing: Enable sharing and execution of tests by third-party vendors, ensuring completion before their delivery.</li> <li>Independence: Permit deployment and execution on vendor boards and prototype hardware.</li> </ul>"},{"location":"external_content/ut-core-wiki/Home/#secondary-objectives","title":"Secondary Objectives","text":"<p>To test the exposed low-level interfaces of components or groups of components - Initial Development: Develop &amp; perform testing of the component during its initial development. - Change Management: Allow engineers to validate code changes on the components. - Validation: To test and validate interface upgrades which will cause upgrades to the testing suites, and documentation.  - Isolated: Isolated components must run in clean environments and with minimised influences on the system. - Leverage: Leverage the low-level tests to build more complex requirements. - Repeatable: Provide a repeatable engineering environment for low-level control via a high-level language</p> <p>High-level Host Framework Compatible: ut-raft can be used to provide prerequisites, interpret logs, perform analysis of data, draw graphs, formulate, conclusions, trends and results these will adapt based on findings and engineering analysis and requirements. </p>"},{"location":"external_content/ut-core-wiki/Home/#key-features","title":"Key Features","text":"<ul> <li>Modular Design: ut-core is built with a modular architecture, allowing you to select and use the components that best suit your specific testing needs.</li> <li>Flexible Test Definition: Define test cases and configurations using human-readable formats like YAML or JSON, making it easy to create and manage your tests.</li> <li>Data-Driven Testing: Drive your tests with <code>yaml/json</code> input data to cover a wide range of scenarios and edge cases.</li> <li>Rich Assertion Library:  Validate your test results using a comprehensive set of built-in assertions, or create your own custom assertions.</li> <li>Test Reporting: Generate detailed test reports to easily identify and diagnose issues.</li> <li>Integration with CI/CD: Seamlessly integrate <code>ut-core</code> into your continuous integration and continuous delivery pipelines for automated testing.</li> <li>Extensibility: Extend <code>ut-core's</code> functionality by developing custom modules or plugins.</li> <li>Variants: Supports both C and C++ (as a direct swap for GTEST)</li> <li>Black Box Testing: Primary designed as a black box testing framework Black-Box vs White-Box</li> <li>Automatic Framework Generation: Engineers can Leverage the autogenerate.sh script to streamline framework generation, enabling rapid test setup and reducing manual configuration efforts.</li> </ul>"},{"location":"external_content/ut-core-wiki/Home/#documentation","title":"Documentation","text":"<p>Here are some of the key modules within ut-core that you can explore in more detail:</p> <ul> <li>Build System Integration: Useful to understand the overall concepts</li> <li>Core: Concept Overview: Core and Engineering Suites Integration</li> <li>Core: How to Build and Run a HAL Testing Suite </li> <li>Standards: Useful reading on coding standards used</li> <li>Standards &amp; Development Process Flow</li> <li>ut_kvp_profile: A flexible profile extension to check kvp values</li> <li>[ut_kvp_profile: Key\u2010Value Pair Profile for Unit Testing]</li> <li>FAQ: Frequently Asked Questions</li> <li>Question and Answers</li> </ul> <p>The ut-core unit testing framework incorporates features from the <code>ut-control</code> module. You can find detailed information about <code>ut-control</code> on its wiki page: ut-control</p>"},{"location":"external_content/ut-core-wiki/Home/#ut-control","title":"ut-control","text":"<p>Control features have moved to a separate repo ut-control</p> <ul> <li>ut_kvp  - [ut_kvp: A Flexible Key-Value Pair Framework]</li> <li>ut_control_plane - ut_control_plane: Overview (ut_control_plane.h)</li> <li>ut_log.h - ut-log: Overview: UT-Log</li> </ul>"},{"location":"external_content/ut-core-wiki/Home/#getting-started","title":"Getting Started","text":"<ol> <li>Installation: Follow the installation instructions in the ut-core repository to set up the framework in your development environment.</li> <li>Explore the Modules: Familiarize yourself with the different modules available in ut-core, each catering to specific testing needs.</li> <li>Define Your Tests:  Use YAML or JSON to create test case definitions, input data, and expected results.</li> <li>Execute Your Tests: Run your tests using the ut-core test runner.</li> <li>Analyse Results:  Review test reports to identify any failures or issues.</li> </ol>"},{"location":"external_content/ut-core-wiki/Home/#running-tests","title":"Running Tests","text":"<p>To execute your tests using the <code>ut-core</code> framework, the main argument features will be linked into your test. This executable provides various command-line switches to customize how your tests are run:</p>"},{"location":"external_content/ut-core-wiki/Home/#example-of-the-unit-test","title":"Example of the unit test","text":"<p>The unit tests are also a combined binary with ut-core, therefore it also has the switches.</p> <pre><code>./tests/bin/ut-test -h\nHelp\n-a - Automated Mode\n-b - Basic Mode\n-f - &lt;filename&gt; - set the output filename for automated mode\n-t - List all tests run to a file\n-l - Set the log Path\n-p - &lt;profile_filename&gt; - specify the profile to load YAML or JSON, also used by kvp_profile\n-h - Help\n</code></pre>"},{"location":"external_content/ut-core-wiki/Home/#using-the-p-profile_filename-switch","title":"Using the <code>-p profile_filename</code> switch","text":"<ul> <li> <p>hdmiProfile.yml <pre><code>hdmicec:\n  config:\n    extendedEnumsSupported: false\n</code></pre></p> </li> <li> <p>Passing a profile into the testing suite <pre><code>./hdmi_cec -p hdmiProfile.yml\n</code></pre></p> </li> </ul> <p>then in the testing code you would perform</p> <pre><code>bool extendedEnumsSupported = UT_KVP_PROFILE_GET_BOOL( \"hdmicec/config/extendedEnumsSupported\" ); \nif ( extendedEnumsSupported == false )\n{\n   /* Complete suite is disabled due to supportExtendedEnums == false */\n    pSuite = UT_add_suite(\"test extended functions \", NULL, NULL );\n\n    UT_add_test(pSuite, \"test extended bool\", test_bool);\n    UT_add_test(pSuite, \"test extended string\", test_string);\n    UT_add_test(pSuite, \"test extended uint32\", test_uint32);\n}\n</code></pre> <p>Refer to the documentation for more information ut_kvp_profile: Key Value Pair Assertions for Unit Testing</p>"},{"location":"external_content/ut-core-wiki/Home/#contributing","title":"Contributing","text":"<p>We welcome contributions to ut-core! If you have ideas for new features, bug fixes, or improvements to the documentation, please open an issue or submit a pull request on our GitHub repository.</p> <p>Let us know if you have any questions or feedback!</p>"},{"location":"external_content/ut-core-wiki/T1%3A-Training%3A-CODEOWNERS%3A-Ensuring-Code-Quality-and-Governance/","title":"CODEOWNERS Training: Ensuring Code Quality and Governance","text":""},{"location":"external_content/ut-core-wiki/T1%3A-Training%3A-CODEOWNERS%3A-Ensuring-Code-Quality-and-Governance/#1-introduction","title":"1. Introduction","text":"<ul> <li>Objective of the Training</li> <li>Equip CODEOWNERS with a clear understanding of their responsibilities in maintaining code quality.</li> <li>Enable CODEOWNERS to effectively enforce coding standards during pull request (PR) reviews.</li> <li> <p>Provide a practical checklist to guide reviews and ensure compliance with standards.</p> </li> <li> <p>Why Standards Matter</p> </li> <li>Consistency across codebases improves maintainability and scalability.</li> <li>Standards promote readability and ease onboarding for new contributors.</li> <li>Clear processes streamline governance and ensure smooth project progress.</li> </ul>"},{"location":"external_content/ut-core-wiki/T1%3A-Training%3A-CODEOWNERS%3A-Ensuring-Code-Quality-and-Governance/#2-standards-overview","title":"2. Standards Overview","text":"<ol> <li>Coding Standards: Principles from Code Complete</li> <li>Prioritize simplicity, clarity, and maintainability in code.</li> <li>Enforce meaningful naming conventions, modular design, and reusable code.</li> <li>Promote thorough testing and debugging.</li> </ol> <p>\ud83d\udd17 Read More</p> <ol> <li>Issue Description Guidelines</li> <li>Ensure issues are clearly described with:<ul> <li>Summary of the problem.</li> <li>Steps to reproduce and expected outcomes.</li> <li>Labels, assignees, and related milestones.</li> </ul> </li> </ol> <p>\ud83d\udd17 Read More</p> <ol> <li>Milestone Description Guidelines</li> <li>Define SMART (Specific, Measurable, Achievable, Relevant, Time-bound) milestones.</li> <li>Outline scope and objectives clearly to align with project goals.</li> </ol> <p>\ud83d\udd17 Read More</p> <ol> <li>Commit Messages: The 50-72 Rule</li> <li>Use concise, clear subject lines (50 characters).</li> <li>Wrap the body at 72 characters per line.</li> <li>Separate subject and body with a blank line.</li> <li>Use the imperative mood (e.g., \"Fix bug\" instead of \"Fixed bug\").</li> </ol> <p>\ud83d\udd17 Read More</p> <ol> <li>Semantic Versioning and Testing Suite Alignment</li> <li>Follow the <code>MAJOR.MINOR.PATCH</code> format:<ul> <li>MAJOR: Incompatible API changes.</li> <li>MINOR: Backward-compatible feature additions.</li> <li>PATCH: Backward-compatible bug fixes.</li> </ul> </li> <li>Ensure alignment between version updates and test suites.</li> </ol> <p>\ud83d\udd17 [Read More</p>"},{"location":"external_content/ut-core-wiki/T1%3A-Training%3A-CODEOWNERS%3A-Ensuring-Code-Quality-and-Governance/#3-codeowners-responsibilities","title":"3. CODEOWNERS Responsibilities","text":"<ul> <li>Primary Role</li> <li>Review PRs for compliance with standards and governance processes.</li> <li> <p>Act as gatekeepers for ensuring code quality and project integrity.</p> </li> <li> <p>Key Actions During PR Reviews</p> </li> <li>Validate adherence to coding standards and principles.</li> <li>Confirm issues, milestones, and commit messages meet guidelines.</li> <li>Ensure versioning aligns with the changes made and associated tests are updated.</li> <li>Provide clear and actionable feedback to contributors.</li> </ul>"},{"location":"external_content/ut-core-wiki/T1%3A-Training%3A-CODEOWNERS%3A-Ensuring-Code-Quality-and-Governance/#4-pr-review-checklist","title":"4. PR Review Checklist","text":"<p>Use this checklist to enforce standards and ensure consistency during PR reviews:</p> <ol> <li>Code Quality</li> <li>Is the code simple, clear, and maintainable?</li> <li>Are naming conventions consistent and meaningful?</li> <li> <p>Is the code modular and reusable?</p> </li> <li> <p>Issue Descriptions</p> </li> <li>Are issues well-defined and labelled appropriately?</li> <li> <p>Do they include steps to reproduce and expected vs. actual outcomes?</p> </li> <li> <p>Milestones</p> </li> <li>Are milestones SMART and aligned with project goals?</li> <li> <p>Is the scope clearly outlined?</p> </li> <li> <p>Commit Messages</p> </li> <li>Do commit messages follow the 50-72 rule?</li> <li> <p>Are they written in the imperative mood and appropriately formatted?</p> </li> <li> <p>Semantic Versioning</p> </li> <li>Is the version number updated correctly (MAJOR, MINOR, PATCH)?</li> <li> <p>Are test suites updated to reflect new changes?</p> </li> <li> <p>Documentation</p> </li> <li>Is new functionality or significant change documented?</li> <li> <p>Are README files or wikis updated as necessary?</p> </li> <li> <p>Testing</p> </li> <li>Are new features covered with adequate tests?</li> <li> <p>Do all tests pass, including regression tests?</p> </li> <li> <p>Feedback</p> </li> <li>Is feedback constructive, actionable, and specific?</li> <li>Are necessary changes clearly communicated?</li> </ol>"},{"location":"external_content/ut-core-wiki/T1%3A-Training%3A-CODEOWNERS%3A-Ensuring-Code-Quality-and-Governance/#5-governance-in-pull-request-reviews","title":"5. Governance in Pull Request Reviews","text":"<ul> <li>Goals</li> <li>Maintain a collaborative and respectful review process.</li> <li>Encourage knowledge sharing and improvement across the team.</li> <li> <p>Build trust by ensuring high-quality and consistent contributions.</p> </li> <li> <p>Best Practices</p> </li> <li>Use comments to guide contributors on improving their code.</li> <li>Align reviews with project goals and technical roadmaps.</li> <li>Ensure that governance decisions are documented for future reference.</li> </ul>"},{"location":"external_content/ut-core-wiki/T1%3A-Training%3A-CODEOWNERS%3A-Ensuring-Code-Quality-and-Governance/#6-closing","title":"6. Closing","text":"<ul> <li>Key Takeaways</li> <li>CODEOWNERS play a critical role in maintaining code quality and enforcing standards.</li> <li>The checklist ensures a structured and thorough review process.</li> <li> <p>Consistent application of standards improves project quality and team collaboration.</p> </li> <li> <p>Resources for Continuous Learning</p> </li> <li>RDK Central Coding Standards</li> <li>Code Complete (Summary)</li> </ul>"},{"location":"external_content/ut-core-wiki/UT-Core-Building-using-Docker-or-Vagrant/","title":"UT Core Building using Docker or Vagrant","text":""},{"location":"external_content/ut-core-wiki/UT-Core-Building-using-Docker-or-Vagrant/#problem","title":"Problem","text":"<p>It has been reported that the ut-core building process encounters a zstd dependency issue when configuring cURL. While this issue is commonly observed on Linux PCs, users can easily bypass it by using Docker or Vagrant to build ut-core in a controlled environment.</p> <p>This page provides detailed installation instructions for Docker and Vagrant, along with a basic script to install essential packages required for ut-core.</p>"},{"location":"external_content/ut-core-wiki/UT-Core-Building-using-Docker-or-Vagrant/#install-procedure-for-docker","title":"Install procedure for docker","text":""},{"location":"external_content/ut-core-wiki/UT-Core-Building-using-Docker-or-Vagrant/#install-docker","title":"Install Docker","text":"<pre><code>sudo apt update &amp;&amp; sudo apt upgrade -y\nsudo apt install -y ca-certificates curl gnupg\nsudo install -m 0755 -d /etc/apt/keyrings\ncurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg\nsudo chmod a+r /etc/apt/keyrings/docker.gpg\necho \\\n\"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \\`\n`$(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null\n\nsudo apt update\nsudo apt install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin\n\ndocker --version\n</code></pre>"},{"location":"external_content/ut-core-wiki/UT-Core-Building-using-Docker-or-Vagrant/#pull-the-ubuntu-2204-docker-image","title":"Pull the Ubuntu 22.04 Docker Image","text":"<pre><code>sudo docker pull ubuntu:22.04\nsudo docker images\n</code></pre>"},{"location":"external_content/ut-core-wiki/UT-Core-Building-using-Docker-or-Vagrant/#steps-to-access-files-from-docker-to-your-pc-and-vice-versa","title":"Steps to access Files from Docker to Your PC and vice versa","text":"<pre><code>mkdir -p /host/data\ncp install.sh to /host/data/.\nchmod +x /host/data/install.sh\n</code></pre>"},{"location":"external_content/ut-core-wiki/UT-Core-Building-using-Docker-or-Vagrant/#run-docker","title":"Run Docker","text":"<pre><code>sudo docker run -it -v /host/data:/container/data ubuntu:22.04\n</code></pre> <p>once inside docker:</p> <pre><code>cd  /container/data\n</code></pre> <p>run install script:</p> <pre><code>./install.sh\n</code></pre> <p>generate ssh keys and add the public key to rdkcentral</p> <pre><code>git clone &lt;repo url&gt;\n</code></pre>"},{"location":"external_content/ut-core-wiki/UT-Core-Building-using-Docker-or-Vagrant/#copy-the-binary-and-libraries-generated-to-containerdata-and-the-same-will-be-available","title":"copy the binary and libraries generated to /container/data and the same will be available","text":"<p>to you in /host/data of your PC.</p> <p>Note: Every time you will need to do this install and other procedure on docker unlike  vagrant, as vagrant is virtual box and docker isn't, its just a container to do your work and exit</p>"},{"location":"external_content/ut-core-wiki/UT-Core-Building-using-Docker-or-Vagrant/#install-procedure-for-vagrant","title":"Install procedure for vagrant","text":""},{"location":"external_content/ut-core-wiki/UT-Core-Building-using-Docker-or-Vagrant/#install-virtualbox-for-vagrant","title":"Install Virtualbox for vagrant","text":"<pre><code>sudo apt update &amp;&amp; sudo apt upgrade -y\nsudo apt install virtualbox -y\nVBoxManage --version\n</code></pre>"},{"location":"external_content/ut-core-wiki/UT-Core-Building-using-Docker-or-Vagrant/#install-vagrant","title":"Install vagrant","text":"<pre><code>wget -O - https://apt.releases.hashicorp.com/gpg | sudo gpg --dearmor -o /usr/share/keyrings/hashicorp-archive-keyring.gpg\necho \"deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/hashicorp-archive-keyring.gpg] https://apt.releases.hashicorp.com $(lsb_release -cs) main\" | sudo tee /etc/apt/sources.list.d/hashicorp.list\nsudo apt update &amp;&amp; sudo apt install vagrant\nvagrant --help\nvagrant --version\n</code></pre>"},{"location":"external_content/ut-core-wiki/UT-Core-Building-using-Docker-or-Vagrant/#create-vagrant-environment","title":"create vagrant environment","text":"<pre><code>mkdir vagrant-ubuntu2204\ncd vagrant-ubuntu2204\nvagrant init generic/ubuntu2204\nmv Vagrantfile Vagrantfile_orig\n\n\ncat Vagrantfile\nVagrant.configure(\"2\") do |config|\n  config.vm.box = \"generic/ubuntu2204\"\n  config.vm.network \"private_network\", type: \"dhcp\"\n  config.vm.provider \"virtualbox\" do |vb|\n    vb.memory = \"1024\" # Reduce memory\n    vb.cpus = 1        # Use fewer CPUs\n  end\nend\n</code></pre>"},{"location":"external_content/ut-core-wiki/UT-Core-Building-using-Docker-or-Vagrant/#start-using-vagrant","title":"start using vagrant","text":"<pre><code>vagrant up; vagrant ssh\n</code></pre> <p>=&gt; You should see the prompt like this:</p> <pre><code>Last login: Wed Jan 22 14:22:43 2025 from 10.0.2.2\nvagrant@ubuntu2204:~$\n</code></pre>"},{"location":"external_content/ut-core-wiki/UT-Core-Building-using-Docker-or-Vagrant/#script-for-installing-basic-packages-for-ut-core","title":"Script for installing basic packages for ut-core","text":"<pre><code>cat install.sh \n</code></pre> <pre><code>#!/bin/bash\n\n# Update package list\necho \"Updating package list...\"\napt-get update -y\n\n# Install required packages\necho \"Installing required packages...\"\napt-get install -y \\\n    file \\\n    git \\\n    gcc \\\n    g++ \\\n    zip \\\n    bzip2 \\\n    tar \\\n    libssl-dev \\\n    cmake \\\n    make \\\n    wget\n\n# Verify installation of packages\necho \"Verifying installed packages...\"\nfile --version\ngit --version\ngcc --version\ng++ --version\nzip --version\nbzip2 --version\ntar --version\ncmake --version\nmake --version\nwget --version\n\necho \"All packages installed successfully!\"\n</code></pre>"},{"location":"external_content/ut-core-wiki/UTCore%3A-Test-Group-Support/","title":"Overview","text":"<p>Test suite grouping in UT Core enables efficient and targeted testing. It allows developers to organise tests by level enabling them to run only relevant tests, saving time and resources. This improves organisation, supports phased testing, simplifies regression testing, and facilitates test automation, ultimately leading to higher quality software and faster development.</p> <pre><code>typedef enum\n{\n    UT_TESTS_L1 = 1,     /*!&lt; Level 1 basic tests are expected to be in this group */\n    UT_TESTS_L2,         /*!&lt; Level 2 advanced tests are expected to be in this group */\n    UT_TESTS_L3,         /*!&lt; Level 3 module tests are expected to be in this group */\n    UT_TESTS_L4,         /*!&lt; Level 4 module control functions (e.g., start/stop module), not part of a testing suite */\n    UT_TESTS_HUMAN_L2,   /*!&lt; Level 2 suite requires human interaction */\n    UT_TESTS_HUMAN_L3,   /*!&lt; Level 3 suite requires human interaction */\n    UT_TESTS_HUMAN_L4,   /*!&lt; Level 4 suite requires human interaction */\n    UT_TESTS_VDEVICE,    /*!&lt; Level 3 suite for setup-specific tests, not runnable on a real device */\n    UT_TESTS_UNKNOWN,    /*!&lt; Placeholder for existing suites */\n    UT_TESTS_MAX         /*!&lt; Out-of-range marker (not a valid status) */\n} UT_groupID_t;\n</code></pre> <p>With this feature, users can register a suite under a specific group and enable/disable groups at runtime using command-line switches:</p> <pre><code>-d to disable a group\n-e to enable a group\n\nFor example, to disable a test group:\n\n&lt;binary&gt; -d 1\n</code></pre> <p>Since UT Core supports both C and C++ (CPP) variants, the registration process differs slightly for each. The details for both are provided below.</p>"},{"location":"external_content/ut-core-wiki/UTCore%3A-Test-Group-Support/#c-variant","title":"C Variant","text":"<p>Registering a Test Suite in C</p> <p>The following example demonstrates how to register a test suite with a group in the C variant:</p> <pre><code>#include &lt;string.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;ut.h&gt;\n\nvoid test_l1_function1(void)\n{\n    UT_FAIL(\"Need to implement\");\n    /* Positive */\n    /* Negative */\n} \n\nvoid test_l1_function2(void)\n{\n    UT_FAIL(\"Need to implement\");\n    /* Positive */\n    /* Negative */\n} \n\nstatic UT_test_suite_t *pSuite = NULL;\n\n/**\n * @brief Register the main tests for this module\n * \n * @return int - 0 on success, otherwise failure\n */\nint main(int argc, char *argv[])\n{\n    UT_init(argc, argv);\n\n    /* Add a suite to the registry with a group ID */\n    pSuite = UT_add_suite_withGroupID(\"[L1 test_Example]\", NULL, NULL, UT_TESTS_L1);\n\n    if (pSuite == NULL) \n    {\n        return -1;\n    }\n\n    UT_add_test(pSuite, \"blah_level1_test_function\", test_l1_function1);\n    UT_add_test(pSuite, \"blah_level1_test_function\", test_l1_function2);\n\n    UT_run_tests();\n\n    return 0;\n}\n</code></pre>"},{"location":"external_content/ut-core-wiki/UTCore%3A-Test-Group-Support/#cpp-variant","title":"CPP Variant","text":"<p>Registering a Test Suite in C++</p> <p>The following example demonstrates how to register a test suite with a group in the C++ variant:</p> <pre><code>#include &lt;ut.h&gt;\n\nclass TestL1Example : public UTCore\n{\npublic:\n    TestL1Example() : UTCore() {}\n\n    ~TestL1Example() override = default;\n\n    void SetUp() override\n    {\n        // Code to set up resources before each test\n    }\n\n    void TearDown() override\n    {\n        // Code to clean up resources after each test\n    }\n};\n\n// Automatically register the test suite before execution\nUT_ADD_TEST_TO_GROUP(TestL1Example, UT_TESTS_L1)\n\nUT_ADD_TEST(TestL1Example, TestL1Equal)\n{\n    UT_ASSERT_EQUAL(1, 1); // Basic test case\n}\n\nUT_ADD_TEST(TestL1Example, TestL1NotEqual)\n{\n    UT_ASSERT_NOT_EQUAL(1, 2);\n}\n</code></pre>"},{"location":"external_content/ut-core-wiki/UTCore%3A-Test-Group-Support/#enablingdisabling-test-groups-at-runtime","title":"Enabling/Disabling Test Groups at Runtime","text":"<p>After compilation, users can enable or disable test groups using command-line arguments.</p> <p>For example, to disable a test group:</p> <pre><code>&lt;binary&gt; -d 1\n\nThis will disable:\n    \u2022   C Variant: [L1 test_Example] suite\n    \u2022   CPP Variant: TestL1Example suite\n</code></pre> <p>All other test suites will continue to run when the executable is launched.</p> <p>Note : by default all tests are enabled </p>"},{"location":"external_content/ut-core-wiki/UT%E2%80%90Core%3A-Concept-Overview%3A-UT%E2%80%90Core-and-Engineering-Suites-Integration/","title":"UT\u2010Core: Concept Overview: UT\u2010Core and Engineering Suites Integration","text":""},{"location":"external_content/ut-core-wiki/UT%E2%80%90Core%3A-Concept-Overview%3A-UT%E2%80%90Core-and-Engineering-Suites-Integration/#versioning-and-synchronization","title":"Versioning and Synchronization","text":"<p>UT-Core and UT-Control components are versioned using static releases and tags. This consistent versioning allows releases to be synchronized with UT-Core and UT-Control builds, ensuring compatibility across various environments. Version alignment can be managed either by directly integrating it into the component build system or through recipe files that maintain compatibility during builds</p>"},{"location":"external_content/ut-core-wiki/UT%E2%80%90Core%3A-Concept-Overview%3A-UT%E2%80%90Core-and-Engineering-Suites-Integration/#purpose-of-ut-core-dynamic-cloning-and-building","title":"Purpose of UT-Core Dynamic Cloning and Building","text":"<p>UT-Core dynamically clones and builds its dependencies based on the latest specifications. This process supports ongoing improvements, such as feature additions, while providing flexibility to meet the specific needs of each release. This approach allows UT-Core to remain responsive to evolving requirements without manual updates or dependency conflicts.</p>"},{"location":"external_content/ut-core-wiki/UT%E2%80%90Core%3A-Concept-Overview%3A-UT%E2%80%90Core-and-Engineering-Suites-Integration/#engineering-suites-and-build-systems","title":"Engineering Suites and Build Systems","text":"<p>The engineering suites are designed to operate independently of framework build systems (e.g. Yocto, Buildroot). By keeping engineering suites separate, pre-commit testing can occur independently, enabling engineers to verify code locally in a controlled environment before it reaches a repository. This approach also allows vendors to test their components on development boards of their choosing, without dependence on specific hardware or build framework.</p>"},{"location":"external_content/ut-core-wiki/UT%E2%80%90Core%3A-Concept-Overview%3A-UT%E2%80%90Core-and-Engineering-Suites-Integration/#testing-workflow-and-pre-commit-verification","title":"Testing Workflow and Pre-commit Verification","text":"<p>The intended testing workflow is pre-commit, meaning that all code undergoes thorough local testing before it is committed. This workflow ensures:    - Engineers verify and debug their code locally with full control over testing environments.    - Vendors have the flexibility to test their HAL components on any compatible development board, independent of platform requirements.</p>"},{"location":"external_content/ut-core-wiki/UT%E2%80%90Core%3A-Concept-Overview%3A-UT%E2%80%90Core-and-Engineering-Suites-Integration/#multi-platform-compatibility-and-version-management","title":"Multi-platform Compatibility and Version Management","text":"<p>Managing different versions of vendor code across platforms can introduce complexity. To address this, each component, including testing suites, is designed with an independent release cadence, allowing updates without dependencies affecting other components. This independence allows for flexibility across environments and simplifies multi-platform compatibility.</p>"},{"location":"external_content/ut-core-wiki/UT%E2%80%90Core%3A-Concept-Overview%3A-UT%E2%80%90Core-and-Engineering-Suites-Integration/#future-distribution-as-installable-binaries","title":"Future Distribution as Installable Binaries","text":"<p>Looking forward, the engineering suites are expected to be delivered as binaries, enabling installation via package managers such as <code>opkg</code>. This approach will allow teams to easily install specific versions of testing suites to match the version of each component, reducing manual dependency management and ensuring compatibility. </p>"},{"location":"external_content/ut-core-wiki/UT%E2%80%90Core%3A-Concept-Overview%3A-UT%E2%80%90Core-and-Engineering-Suites-Integration/#component-version-control-and-build-automation","title":"Component Version Control and Build Automation","text":"<p>Component versions are managed through automated builds. Engineers can clone the required header files and trigger the build with a simple command:</p> <pre><code> ./build_ut.sh TARGET=arm\n</code></pre> <p>This process automatically pulls the correct versions of dependencies and components, creating a consistent and compatible build environment without requiring manual version tracking.</p>"},{"location":"external_content/ut-core-wiki/UT%E2%80%90Core%3A-How-to-Build-and-Run-a-HAL-Testing-Suite/","title":"How to Build and Run a HAL Testing Suite","text":"<p>This guide shows you how to build and run a testing suite, using the <code>ut-core</code> framework.</p> <p>Think of <code>ut-core</code> as a set of tools for generating a framework for building your tests. This guide focuses on how to use those tools, but the underlying principles how to structure your tests, is defined by your own requirements.</p> <p>Essentially, we're using <code>ut-core</code> to demonstrate a general approach to testing. You can adapt this approach to your own needs and preferences, even if you're using a different testing framework. In this case we've created template scripts that use <code>ut-core</code> in a HAL interface testing scenario.</p>"},{"location":"external_content/ut-core-wiki/UT%E2%80%90Core%3A-How-to-Build-and-Run-a-HAL-Testing-Suite/#1-navigate-to-the-header-file","title":"1. Navigate to the Header File","text":"<p>First, navigate to the directory containing the header file you want to test.</p> <p>For example:</p> <p>If you want to run the testing suite against the <code>rdk-halif-hdmi_cec</code> repository, you would first clone the repository and then navigate into the newly created directory:</p> <pre><code>git clone git@github.com:rdkcentral/rdk-halif-hdmi_cec.git\ncd rdk-halif-hdmi_cec \n</code></pre>"},{"location":"external_content/ut-core-wiki/UT%E2%80%90Core%3A-How-to-Build-and-Run-a-HAL-Testing-Suite/#2-build-the-testing-suite","title":"2. Build the Testing Suite","text":"<p>From this directory, execute the following command in your terminal:</p> <pre><code>build_ut.sh TARGET=arm\n</code></pre> <p>This script will create a new directory named <code>ut</code> where your testing suite will be created. </p> <p>Note: Running <code>build_ut.sh</code> without specifying a target will build a Linux version of the testing suite, which can be useful for debugging the structure of your tests.</p> <p>All binaries to be transferred to the platform will be created under <code>ut/bin</code></p>"},{"location":"external_content/ut-core-wiki/UT%E2%80%90Core%3A-How-to-Build-and-Run-a-HAL-Testing-Suite/#3-build-environment-requirements","title":"3.  Build Environment Requirements","text":"<p>Building the testing suite requires a tool-chain. This can be a vendor-independent tool-chain, an SDK, or any other tool-chain as required.</p> <p>Requirements for building </p> <p>The <code>unitTest(ut)</code> for a module is triggered from scripts, which inturn that clone the <code>ut-core</code> framework (at a fixed version) and builds the defined tests. This allows for independent upgrades to the <code>ut-core</code> framework if desired.</p> <p>Script templates are provided in the <code>template</code> directory to illustrate the necessary files for each layer, starting from the HAL. See template/README.md</p> <p>The testing relationship is as follows:</p> <pre><code>erDiagram\n\u00a0 \u00a0 \u00a0 \u00a0 HAL }|..|{ hal_ut: triggers\n\u00a0 \u00a0 \u00a0 \u00a0 hal_ut }|--o{ ut_core: uses</code></pre>"},{"location":"external_content/ut-core-wiki/UT%E2%80%90Core%3A-How-to-Build-and-Run-a-HAL-Testing-Suite/#4-core-ut-framework","title":"4. Core UT Framework","text":"<p>The unit testing core subsystem can be cloned from:</p> <pre><code>git clone git@github.com:rdkcentral/ut-core\n</code></pre> <p>Recommended Reading:</p> <ul> <li>https://github.com/rdkcentral/ut-core/blob/master/README.md</li> <li>https://github.com/rdkcentral/ut-core/blob/master/docs/pages/hal_unit_testing_requirements.md</li> </ul> <p>Note: C++ Support is available after Version 4.0.0</p> <p>The <code>ut-core</code> directory structure is as follows:</p> <pre><code>.\n\u251c\u2500\u2500 docs\n\u2502   \u2514\u2500\u2500 pages\n\u2502       \u2514\u2500\u2500 images\n\u251c\u2500\u2500 framework\n\u2502   \u2514\u2500\u2500 cunit\n\u2502       \u251c\u2500\u2500 arm-rdk-linux-gnueabi -&gt; Arm prebuild version of cunit.so\n\u2502       \u2514\u2500\u2500 i686-pc-linux-gnu -&gt; -&gt; Linux prebuild version of cunit.so\n\u2502   \u2514\u2500\u2500 xxx -&gt; Other framework as required\n\u251c\u2500\u2500 include -&gt; ut-core header files\n\u251c\u2500\u2500 src     -&gt; ut-core source files\n\u251c\u2500\u2500 template\n\u2502   \u251c\u2500\u2500 hal_template -&gt; example files for the top level hal directories\n\u2502   \u2514\u2500\u2500 ut_template -&gt; example files for the ut directories\n\u2514\u2500\u2500 tools\n    \u251c\u2500\u2500 libs -&gt; (Vendor .so)\n    \u2514\u2500\u2500 Makefile\n</code></pre>"},{"location":"external_content/ut-core-wiki/UT%E2%80%90Core%3A-How-to-Build-and-Run-a-HAL-Testing-Suite/#5-vendor-or-developer-requirements","title":"5.  Vendor or Developer Requirements","text":"<p>Vendors or developers must provide one of the following:</p> <ol> <li>Prebuilt libraries included in the SDK.</li> <li>Prebuilt libraries in the <code>libs</code> directory to link against.</li> <li>Link the <code>libs</code> directory to libraries being worked on in the RDK tree.</li> </ol> <p>The <code>libs</code> directory can be linked to prebuilt libraries generated by the vendor or the RDK build system. Symbolic links can be used to set up these directories.</p>"},{"location":"external_content/ut-core-wiki/UT%E2%80%90Core%3A-How-to-Build-and-Run-a-HAL-Testing-Suite/#7-toolchain","title":"7. Toolchain","text":"<p>The toolchain is provided by the vendor or through an SDK built with the Yocto build system. It's recommended to install the toolchain in the <code>./tools/2.0</code> directory.</p>"},{"location":"external_content/ut-core-wiki/UT%E2%80%90Core%3A-How-to-Build-and-Run-a-HAL-Testing-Suite/#71-how-to-use-the-sdk-toolchain","title":"7.1. How to Use the SDK Toolchain","text":"<pre><code>./rdk-glibc-x86_64-arm-toolchain-2.0.sh\n</code></pre> <p>This script installs the toolchain and <code>sysroots</code> (typically in <code>/opt/rdk/2.0</code>, but it's recommended to change this to <code>${PWD}../2.0</code>).</p> <p>To use the cross-development toolchain, source the environment setup script:</p> <pre><code>chmod +x /opt/rdk/2.0/environment-setup-cortexa9t2-vfp-rdk-linux-gnueabi\nsource /opt/rdk/2.0/environment-setup-cortexa9t2-vfp-rdk-linux-gnueabi\necho $CC\n</code></pre>"},{"location":"external_content/ut-core-wiki/UT%E2%80%90Core%3A-How-to-Build-and-Run-a-HAL-Testing-Suite/#72-docker-based-toolchain","title":"7.2. Docker Based Toolchain","text":"<p>The tool-chain and common environment can be launched by the following <code>sc</code> commands see :- FAQ:-RDK-Docker-Toolchain</p> <pre><code>sc docker rdk-dunfell /bin/bash\n. /opt/toolchains/rdk-glibc-x86_64-arm-toolchain/environment-setup-armv7at2hf-neon-oe-linux-gnueabi\n</code></pre> <pre><code>sc docker list\n</code></pre> <p>will list out the environments available (from outside the docker).</p>"},{"location":"external_content/ut-core-wiki/UT%E2%80%90Core%3A-How-to-Build-and-Run-a-HAL-Testing-Suite/#8-testing-environment-and-making-the-code","title":"8. Testing Environment and Making the Code","text":"<p>There are two platform targets:</p> <ul> <li><code>linux</code> (default): Builds all tests, the test application, and stubs.</li> <li><code>arm</code> (<code>TARGET=arm</code>): Builds all tests and the test application for the target.</li> </ul>"},{"location":"external_content/ut-core-wiki/UT%E2%80%90Core%3A-How-to-Build-and-Run-a-HAL-Testing-Suite/#9-build-the-linux-environment-with-c-language","title":"9. Build the <code>linux</code> environment with C language","text":"<pre><code>make\n</code></pre> <p>This builds the <code>src/*.c</code> files, core functions from <code>ut-core/src/c_source</code>, and links against libraries in <code>ut-core/framework</code>. The <code>skeletons/src</code> directory is included for stub compilation.</p>"},{"location":"external_content/ut-core-wiki/UT%E2%80%90Core%3A-How-to-Build-and-Run-a-HAL-Testing-Suite/#10-build-the-target-arm-environment-with-c-language","title":"10. Build the target <code>arm</code> environment with C language","text":"<p>Ensure the toolchain is sourced.</p> <pre><code>make TARGET=arm\n</code></pre> <p>This builds the <code>src/*.c</code> files, core functions from <code>ut-core/src/c_source</code>, links against libraries in <code>ut-core/framework</code>, and links against libraries in the <code>libs</code> directory or the SDK <code>sysroot</code>. The final binary (<code>hal_test</code>) is located in the <code>bin</code> directory.</p>"},{"location":"external_content/ut-core-wiki/UT%E2%80%90Core%3A-How-to-Build-and-Run-a-HAL-Testing-Suite/#11-build-the-linux-environment-with-cpp-language","title":"11. Build the <code>linux</code> environment with CPP language","text":"<p><pre><code>make VARIANT=CPP\n</code></pre> This builds the <code>src/*.c</code> files, core functions from <code>ut-core/src/cpp_source</code>, and links against libraries in <code>ut-core/framework</code>. The <code>skeletons/src</code> directory is included for stub compilation.</p>"},{"location":"external_content/ut-core-wiki/UT%E2%80%90Core%3A-How-to-Build-and-Run-a-HAL-Testing-Suite/#12-build-the-target-arm-environment-with-cpp-language","title":"12. Build the target <code>arm</code> environment with CPP language","text":"<p>Ensure the toolchain is sourced.</p> <p><pre><code>make VARIANT=CPP TARGET=arm\n</code></pre> This builds the <code>src/*.c</code> files, core functions from <code>ut-core/src/cpp_source</code>, links against libraries in <code>ut-core/framework</code>, and links against libraries in the <code>libs</code> directory or the SDK <code>sysroot</code>. The final binary (<code>hal_test</code>) is located in the <code>bin</code> directory.</p>"},{"location":"external_content/ut-core-wiki/UT%E2%80%90Core%3A-How-to-Build-and-Run-a-HAL-Testing-Suite/#13-running-on-the-target","title":"13. Running on the Target","text":"<p>Copy the files from the <code>bin</code> directory to the target.</p> <p>On the target, set the <code>LD_LIBRARY_PATH</code> environment variable:</p> <pre><code>export LD_LIBRARY_PATH=/usr/lib:/lib:/home/root:./\n</code></pre> <p>Alternatively, use the <code>run.sh</code> script in the <code>bin</code> directory.</p> <p>Execute the <code>hal_test</code> application:</p> <pre><code>./hal_test -h \n</code></pre>"},{"location":"external_content/ut-core-wiki/UT%E2%80%90Core%3A-How-to-Build-and-Run-a-HAL-Testing-Suite/#14-modes-of-operation","title":"14. Modes of Operation","text":"<p>The following flags will only work in C Mode</p> <ul> <li>Console Mode (<code>-c</code>): Opens an interactive console.</li> <li>Automated Mode (<code>-a</code>): Outputs results in xUnit format as an XML file.</li> <li>Basic Mode (<code>-b</code>): Runs all tests and redirects output to the shell.</li> </ul>"},{"location":"external_content/ut-core-wiki/UT%E2%80%90Core%3A-How-to-Build-and-Run-a-HAL-Testing-Suite/#15-source-tree-ut-unit-test-directory","title":"15. Source Tree <code>UT</code> Unit Test Directory","text":"<p>The tests follow the structure defined in <code>template/ut_template/</code>:</p> <pre><code>\u251c\u2500\u2500 bin\n\u2502   \u2514\u2500\u2500 run.sh\n\u251c\u2500\u2500 build.sh\n\u251c\u2500\u2500 docs\n\u2502   \u251c\u2500\u2500 generate_docs.sh\n\u2502   \u2514\u2500\u2500 pages\n\u2502       \u251c\u2500\u2500 L1_TestSpecification.md\n\u2502       \u251c\u2500\u2500 L2_TestSpecification.md\n\u2502       \u2514\u2500\u2500 README.md -&gt; ../../README.md\n\u251c\u2500\u2500 Makefile\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 skeletons\n\u2502   \u2514\u2500\u2500 src\n\u251c\u2500\u2500 src\n\u2502   \u251c\u2500\u2500 main.c\n\u2502   \u251c\u2500\u2500 test_l1_test_example.c\n\u2502   \u2514\u2500\u2500 test_l2_tests_example.c\n\u2514\u2500\u2500 tools\n</code></pre> <p>The <code>main.c</code> file in the <code>src</code> directory is the main launch point for the test application.</p>"},{"location":"external_content/ut-core-wiki/UT%E2%80%90Core%3A-How-to-Build-and-Run-a-HAL-Testing-Suite/#16-choosing-a-major-version-of-the-ut-core","title":"16. Choosing a Major Version of the UT-Core","text":"<p>Since the ut-core interfaces will change over time, and in order to be consistant when creating tests engineers should select the major release they wish to fixed too. (Although it's recommended to periodically upgrade to a later revision )</p> <p>The interface will not change between minor versions, but the most recent bugfix version should be selected.</p> <p>The versioning format for the testing suites is therefore <code>&lt;major.minor.bugfix/patch/documentation&gt;</code></p> <p>In the file <code>ut_template/build.sh</code> you can see the template version of the script.</p> <p>This is selected via <code>UT_CORE_PROJECT_VERSION</code> variable as an input in the default build script for the tests suite e.g. <code>ut/build.sh UT_CORE_PROJECT_VERSION=2.0.0</code> or by changing the fixed version set in your unit testing <code>build.sh</code> trigger script.</p> <p>For best practice and receive bug fixes define <code>UT_PROJECT_MAJOR_VERSION</code> in <code>ut/build.sh</code> to choose the major revision that the testing suite should compile against. <code>ut-core</code> will assure backwards compatibility in major versions. This means that the bugfixes and minor changes you will automatically acquire on the next test run.</p> <pre><code># Change this to upgrade your UT-Core Major versions. Non ABI Changes 1.x.x are supported, between major revisions\nUT_PROJECT_MAJOR_VERSION=\"1.\"\n</code></pre>"},{"location":"external_content/ut-core-wiki/UT%E2%80%90Core%3A-How-to-Build-and-Run-a-HAL-Testing-Suite/#17-example-of-registering-test-functions","title":"17. Example of Registering Test Functions","text":"<p>The main test app will register all the tests and kick off the framework.</p> <pre><code>#include &lt;string.h&gt;\n#include &lt;stdlib.h&gt;\n\n#include &lt;ut.h&gt;\n\nvoid test_l1_function1(void)\n{\n  UT_FAIL(\"Need to implement\");\n  /* Positive */\n  /* Negative */\n} \n\nvoid test_l1_function2(void)\n{\n  UT_FAIL(\"Need to implement\");\n  /* Positive */\n  /* Negative */\n} \n\nstatic UT_test_suite_t *pSuite = NULL;\n\n/**\n * @brief Register the main tests for this module\n * \n * @return int - 0 on success, otherwise failure\n */\nint test_l1_register( void )\n{\n    /* add a suite to the registry */\n    pSuite = UT_add_suite(\"[L1 test_Example]\", NULL, NULL);\n    if (NULL == pSuite) \n    {\n        return -1;\n    }\n\n    UT_add_test( pSuite, \"blah_level1_test_function\", test_l1_function1);\n    UT_add_test( pSuite, \"blah_level1_test_function\", test_l1_function2);\n\n    return 0;\n}\n</code></pre> <p>Each module has a optional <code>init</code> and <code>clean</code> function, which can be setup via UT_add_suite(), in the above example these are defaulted to <code>NULL</code>, since in this example case they are not used.</p>"},{"location":"external_content/ut-core-wiki/autogenerate.sh%3A-Running-the-Framework-Generation-Script/","title":"autogenerate.sh: Running the Framework Generation Script","text":""},{"location":"external_content/ut-core-wiki/autogenerate.sh%3A-Running-the-Framework-Generation-Script/#instructions-running-the-framework-generation-script","title":"Instructions: Running the Framework Generation Script","text":""},{"location":"external_content/ut-core-wiki/autogenerate.sh%3A-Running-the-Framework-Generation-Script/#overview","title":"Overview","text":"<p>These instructions guide engineering teams on using the <code>autogenerate.sh</code> script to automatically generate Level 1 (L1) and Level 2 (L2) testing suite frameworks.</p>"},{"location":"external_content/ut-core-wiki/autogenerate.sh%3A-Running-the-Framework-Generation-Script/#purpose-of-the-autogen-script","title":"Purpose of the Autogen Script","text":"<p>The primary purpose of the <code>autogenerate.sh</code> script is to streamline the initial setup and integration of unit tests for API definitions, allowing engineers to quickly build a complete and fully integrated testing framework with the <code>ut-core</code> testing structure. The script takes input header files and generates all necessary components to create a Linux-compatible, buildable test suite, including:</p> <ul> <li>Directory Structure: Automatically creates subdirectories and organizes files as required by the <code>ut-core</code> framework for a seamless integration.</li> <li>Stub Generation: Generates all necessary stubs for functions referenced in the headers, allowing immediate compilation and functionality within the test suite.</li> <li>Usable Testing Suite: Provides engineers with a ready-to-use test framework that can be customized and expanded to meet specific testing requirements.</li> </ul> <p>This tool accelerates the creation of a complete testing framework from scratch, enabling engineers to go from 0% to a fully functional, buildable test suite. Engineers can then fill out this framework to test individual functions or groups of functions according to their testing needs.</p>"},{"location":"external_content/ut-core-wiki/autogenerate.sh%3A-Running-the-Framework-Generation-Script/#autogen-command","title":"Autogen Command","text":"<p>To run the autogen script, use:</p> <pre><code>./autogenerate.sh &lt;api-def-repo-url/-c/-clean/-b/-branch/-h/-help&gt;\n</code></pre>"},{"location":"external_content/ut-core-wiki/autogenerate.sh%3A-Running-the-Framework-Generation-Script/#autogen-options-explained","title":"Autogen Options Explained","text":"Argument Optional? Description Examples <code>api-def-repo-url</code> No URL of the API definitions repo to be cloned or the directory path to be copied <code>git@github.com:rdkcentral/hal-deepsleepmanager.git</code> or <code>/home/user/workspace/RdkWanManager</code> <code>-clean</code> or <code>-c</code> Yes Deletes the workspace directory (including cloned repos) <code>-clean</code>, <code>-c</code> <code>-branch</code> or <code>-b</code> Yes Checks out a specific branch in the API definitions repo, applicable only with urls <code>-branch hal-review</code>, <code>-b main</code> <code>-help</code> or <code>-h</code> Yes Shows usage information for the script <code>-help</code>, <code>-h</code> <p>Note: To include debug statements, set the environment variable <code>AGT_DEBUG</code> before running the script:</p> <pre><code>export AGT_DEBUG=1\n</code></pre>"},{"location":"external_content/ut-core-wiki/autogenerate.sh%3A-Running-the-Framework-Generation-Script/#use-cases-supported-by-autogeneratesh","title":"Use Cases Supported by autogenerate.sh","text":"<p>The <code>autogenerate.sh</code> script supports various use cases for generating test frameworks, providing flexibility for repository URLs, user-specified directories, and custom header file locations.</p> <ol> <li> <p>API Definition Repository URL    The API definition URL can be any accessible Git repository URL or directory path. Example commands:    <pre><code>./autogenerate.sh git@github.com:rdkcentral/rdk-halif-device_settings.git\n./autogenerate.sh https://github.com/rdkcentral/RdkWanManager.git\n./autogenerate.sh /home/user/workspace/RdkWanManager\n</code></pre></p> </li> <li> <p>Unit Test Directory    The unit test directory can be either:</p> </li> <li>Cloned from a user-provided URL.</li> <li>Specified as an absolute directory path by the user.  </li> </ol> <p>When prompted, enter the URL or absolute path, or leave blank to skip:    <pre><code># URL input example\nPlease input the URL (or leave blank to skip): https://github.com/comcast-sky/skysr213-platform-hal.git\n\n# Absolute path input example\nPlease input the directory (absolute) path (or leave blank to skip):    /home/user/workspace/RdkWanManager\n</code></pre></p> <ol> <li>Header File Location    The script can generate tests for header files located within the <code>include</code> folder or any other location within the API Definition directory cloned or copied by the script.</li> </ol>"},{"location":"external_content/ut-core-wiki/autogenerate.sh%3A-Running-the-Framework-Generation-Script/#example-commands","title":"Example Commands","text":"<ol> <li>Generate Test Framework    Generates L1 and L2 test frameworks for the <code>deepsleepmanager</code> repo, including template directories and files in the API definition and <code>ut</code> directories, and skeletons if needed:</li> </ol> <pre><code>./autogenerate.sh git@github.com:rdkcentral/hal-deepsleepmanager.git\n</code></pre> <ol> <li>Generate Test Framework on Specific Branch    Generates the L1 and L2 test frameworks for <code>deepsleepmanager</code> on the <code>hal-review</code> branch of the API definition repo:</li> </ol> <pre><code>./autogenerate.sh git@github.com:rdkcentral/hal-deepsleepmanager.git -b hal-review\n</code></pre> <ol> <li>Delete Workspace Directory    Deletes the workspace directory if it exists:</li> </ol> <pre><code>./autogenerate.sh git@github.com:rdkcentral/hal-powermanager.git -c\n</code></pre> <ol> <li>Display Script Usage    Shows the usage information for the autogen script:</li> </ol> <pre><code>./autogenerate.sh -h\n</code></pre>"},{"location":"external_content/ut-core-wiki/autogenerate.sh%3A-Running-the-Framework-Generation-Script/#terminology-index","title":"Terminology Index","text":"Term Definition Relative Location Created Workspace Directory created to clone repos and build the test framework <code>[ut-core-dir]/workspace</code> API Definitions Main repo where header files (e.g., HAL repo) reside <code>[ut-core-dir]/workspace/[API-definitions-dir]</code> UT Directory under API definition in <code>workspace</code> for Unit Tests (e.g., HALTest repo) <code>[ut-core-dir]/workspace/[API-definitions-dir]/ut</code> Skeletons Generated skeleton code for header files in the API Definition <code>[ut-core-dir]/workspace/[API-definitions-dir]/ut/skeletons/src</code> Tests L1 and L2 tests generated for header files in the API Definition <code>[ut-core-dir]/workspace/[API-definitions-dir]/ut/src</code> L1 Tests Functional tests for each function in header files <code>[ut-core-dir]/workspace/[API-definitions-dir]/ut/src/test_L1_*</code> L2 Tests Operational tests for module functionality <code>[ut-core-dir]/workspace/[API-definitions-dir]/ut/src/test_L2_*</code>"},{"location":"external_content/ut-core-wiki/ut_kvp%3A-A-Flexible-Key%E2%80%90Value-Pair-Framework/","title":"ut kvp: A Flexible Key\u2010Value Pair Framework","text":"<p>This page has moved to ut_control ut_kvp:-A-Flexible-KeyValue-Pair-Framework</p>"},{"location":"external_content/ut-core-wiki/ut_kvp_profile%3A-Key%E2%80%90Value-Pair-Assertions-for-Unit-Testing/","title":"ut kvp profile: Key\u2010Value Pair Assertions for Unit Testing","text":"<p>The <code>ut_kvp_profile.h</code> header is an extension of the <code>ut_kvp</code> framework, specifically designed for streamlined assertions within unit tests. It leverages the key-value pair (KVP) structure to simplify the validation of test results against expected outcomes.</p>"},{"location":"external_content/ut-core-wiki/ut_kvp_profile%3A-Key%E2%80%90Value-Pair-Assertions-for-Unit-Testing/#key-features","title":"Key Features","text":"<ul> <li>Simplified Assertions: Provides a concise syntax for common assertions (equality checks, string comparisons, etc.) using KVPs.</li> <li>Test Case Configuration: Enables loading of expected test results from YAML/JSON files for easy management and maintenance.</li> <li>Error Reporting: Integrates with the <code>ut_log</code> module to provide clear and informative error messages upon assertion failures.</li> <li>Integration with ut-core: ut_kvp_profile support is provided by default when using ut-core via the <code>-p</code> switch.</li> </ul>"},{"location":"external_content/ut-core-wiki/ut_kvp_profile%3A-Key%E2%80%90Value-Pair-Assertions-for-Unit-Testing/#example-usage","title":"Example Usage","text":"<ol> <li>Create a Configuration File:</li> </ol> <pre><code>test_case_1:\n  expected_result: true\ntest_case_2:\n  expected_result: 12345\n</code></pre> <ol> <li> <p>Start the test and specify the profile file</p> </li> <li> <p>Passing a profile into the testing suite, will automatically open the profile</p> </li> </ol> <pre><code>./hdmi_cec -p hdmi_one_port_no_extendedEnums.yml\n</code></pre> <ol> <li>Use Assertions:</li> </ol> <p>Macro's are now active and available for use in the test suite.</p> <pre><code>bool result = my_function();\nUT_ASSERT_EQUAL_KVP_PROFILE_BOOL(result, \"test_case_1/expected_result\");\n</code></pre>"},{"location":"external_content/ut-core-wiki/ut_kvp_profile%3A-Key%E2%80%90Value-Pair-Assertions-for-Unit-Testing/#detail-on-how-it-works","title":"Detail on how it works.","text":""},{"location":"external_content/ut-core-wiki/ut_kvp_profile%3A-Key%E2%80%90Value-Pair-Assertions-for-Unit-Testing/#integration-with-ut_log","title":"Integration with ut_log","text":"<p>The <code>ut_kvp_profile</code> module seamlessly integrates with the <code>ut_log</code> module to provide informative logging upon assertion failures. For example, the following code:</p> <pre><code>UT_ASSERT_EQUAL_KVP_PROFILE_BOOL(false, \"test_case_1/expected_result\");\n</code></pre> <p>would result in a log message similar to:</p> <pre><code>Assertion failed: test_case_1/expected_result (expected: true, actual: false)\n</code></pre>"},{"location":"external_content/ut-core-wiki/ut_kvp_profile%3A-Key%E2%80%90Value-Pair-Assertions-for-Unit-Testing/#assertion-macros","title":"Assertion Macros","text":"<p>The header defines several macros for common assertion types:</p> <ul> <li><code>UT_ASSERT_EQUAL_KVP_PROFILE_BOOL(checkValue, key)</code></li> <li><code>UT_ASSERT_EQUAL_KVP_PROFILE_UINT8(checkValue, key)</code></li> <li><code>UT_ASSERT_EQUAL_KVP_PROFILE_UINT16(checkValue, key)</code></li> <li><code>UT_ASSERT_EQUAL_KVP_PROFILE_UINT32(checkValue, key)</code></li> <li><code>UT_ASSERT_EQUAL_KVP_PROFILE_UINT64(checkValue, key)</code></li> <li><code>UT_ASSERT_EQUAL_KVP_PROFILE_STRING(checkValue, key)</code></li> </ul> <p>These macros compare a given <code>checkValue</code> against the value associated with the specified <code>key</code> in the KVP data structure. If the values don't match, an assertion failure is triggered.</p>"},{"location":"external_content/ut-core-wiki/ut_kvp_profile%3A-Key%E2%80%90Value-Pair-Assertions-for-Unit-Testing/#get-field-marcos","title":"Get Field Marcos","text":"<p>The header defines several macros for common get types:</p> <ul> <li><code>UT_KVP_PROFILE_GET_BOOL(key)</code></li> <li><code>UT_KVP_PROFILE_GET_UINT8(key)</code></li> <li><code>UT_KVP_PROFILE_GET_UINT16(key)</code></li> <li><code>UT_KVP_PROFILE_GET_UINT32(key)</code></li> <li><code>UT_KVP_PROFILE_GET_UINT64(key)</code></li> <li><code>UT_KVP_PROFILE_GET_LIST_COUNT(key)</code></li> <li><code>UT_KVP_PROFILE_GET_STRING(key, pszReturnedString )</code></li> </ul> <p>For more detailed information of operation see the header file ut_kvp_profile.h</p> <ul> <li><code>!include</code> is supported in the yaml files see ut_kvp: Support for Includes in YAML files, it is extremely important that shared features are segmented into independent files.</li> <li>Upgrades to the system are coming to allow multiple profile support e.g. <code>-p a.yaml -p b.yaml</code> See: #78 </li> <li>For detailed information on the <code>ut_kvp</code> module see ut_kvp: A Flexible Key-Value-Pair Framework</li> </ul>"},{"location":"external_content/ut-core-wiki/vDevice%3A-Overview/","title":"vDevice: Overview","text":"<p>Moved to https://github.com/rdkcentral/ut-core/wiki/5.0:-Standards:-vDevice-Overview</p>"},{"location":"python_venv/lib/python3.10/site-packages/Markdown-3.7.dist-info/LICENSE/","title":"LICENSE","text":"<p>BSD 3-Clause License</p> <p>Copyright 2007, 2008 The Python Markdown Project (v. 1.7 and later) Copyright 2004, 2005, 2006 Yuri Takhteyev (v. 0.2-1.6b) Copyright 2004 Manfred Stienstra (the original version)</p> <p>Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:</p> <ol> <li> <p>Redistributions of source code must retain the above copyright notice, this    list of conditions and the following disclaimer.</p> </li> <li> <p>Redistributions in binary form must reproduce the above copyright notice,    this list of conditions and the following disclaimer in the documentation    and/or other materials provided with the distribution.</p> </li> <li> <p>Neither the name of the copyright holder nor the names of its    contributors may be used to endorse or promote products derived from    this software without specific prior written permission.</p> </li> </ol> <p>THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.</p>"},{"location":"python_venv/lib/python3.10/site-packages/idna-3.10.dist-info/LICENSE/","title":"LICENSE","text":"<p>BSD 3-Clause License</p> <p>Copyright (c) 2013-2024, Kim Davies and contributors. All rights reserved.</p> <p>Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:</p> <ol> <li> <p>Redistributions of source code must retain the above copyright    notice, this list of conditions and the following disclaimer.</p> </li> <li> <p>Redistributions in binary form must reproduce the above copyright    notice, this list of conditions and the following disclaimer in the    documentation and/or other materials provided with the distribution.</p> </li> <li> <p>Neither the name of the copyright holder nor the names of its    contributors may be used to endorse or promote products derived from    this software without specific prior written permission.</p> </li> </ol> <p>THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.</p>"},{"location":"python_venv/lib/python3.10/site-packages/mkdocs_get_deps-0.2.0.dist-info/licenses/LICENSE/","title":"LICENSE","text":"<p>MIT License</p> <p>Copyright (c) 2023 Oleh Prypin oleh@pryp.in</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>"},{"location":"python_venv/lib/python3.10/site-packages/mkdocs_material_extensions-1.3.1.dist-info/licenses/LICENSE/","title":"LICENSE","text":"<p>MIT License</p> <p>Copyright (c) 2021 Isaac Muse</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>"},{"location":"python_venv/lib/python3.10/site-packages/pymdown_extensions-10.14.3.dist-info/licenses/LICENSE/","title":"License","text":""},{"location":"python_venv/lib/python3.10/site-packages/pymdown_extensions-10.14.3.dist-info/licenses/LICENSE/#pymdown-extensions","title":"PyMdown Extensions","text":"<p>The MIT License (MIT)</p> <p>Copyright (c) 2014 - 2024 Isaac Muse</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>"},{"location":"python_venv/lib/python3.10/site-packages/pymdown_extensions-10.14.3.dist-info/licenses/LICENSE/#superfences","title":"SuperFences","text":"<p><code>superfences.py</code> is derived from Python Markdown's fenced_code extension.</p> <pre><code>Fenced Code Extension for Python Markdown\n =========================================\nThis extension adds Fenced Code Blocks to Python-Markdown.\nSee &lt;https://python-markdown.github.io/extensions/fenced_code_blocks/&gt;\nfor documentation.\nOriginal code Copyright 2007-2008 [Waylan Limberg](http://achinghead.com/).\nAll changes Copyright 2008-2014 The Python Markdown Project\nLicense: [BSD](http://www.opensource.org/licenses/bsd-license.php)\n</code></pre>"},{"location":"python_venv/lib/python3.10/site-packages/pymdown_extensions-10.14.3.dist-info/licenses/LICENSE/#highlight","title":"Highlight","text":"<p><code>highlight.py</code> is derived from Python Markdown's CodeHilite extension.</p> <pre><code>CodeHilite Extension for Python-Markdown\n ========================================\nAdds code/syntax highlighting to standard Python-Markdown code blocks.\nSee &lt;https://python-markdown.github.io/extensions/code_hilite/&gt;\nfor documentation.\nOriginal code Copyright 2006-2008 [Waylan Limberg](http://achinghead.com/).\nAll changes Copyright 2008-2014 The Python Markdown Project\nLicense: [BSD](http://www.opensource.org/licenses/bsd-license.php)\n</code></pre>"},{"location":"python_venv/lib/python3.10/site-packages/pymdown_extensions-10.14.3.dist-info/licenses/LICENSE/#fancylists","title":"FancyLists","text":"<p><code>fancylists.py</code> is derived from Python Markdown's list handler.</p> <pre><code>Started by Manfred Stienstra (http://www.dwerg.net/).\nMaintained for a few years by Yuri Takhteyev (http://www.freewisdom.org).\nCurrently maintained by Waylan Limberg (https://github.com/waylan),\nDmitry Shachnev (https://github.com/mitya57) and Isaac Muse (https://github.com/facelessuser).\n\nCopyright 2007-2023 The Python Markdown Project (v. 1.7 and later)\nCopyright 2004, 2005, 2006 Yuri Takhteyev (v. 0.2-1.6b)\nCopyright 2004 Manfred Stienstra (the original version)\n\nLicense: [BSD](http://www.opensource.org/licenses/bsd-license.php)\n</code></pre>"},{"location":"python_venv/lib/python3.10/site-packages/pymdown_extensions-10.14.3.dist-info/licenses/LICENSE/#gemoji-index","title":"Gemoji Index","text":"<p><code>gemoji_db.py</code> is generated from Gemoji's source code: @github/gemoji.</p> <pre><code>Copyright (c) 2013 GitHub, Inc.\n\nPermission is hereby granted, free of charge, to any person\nobtaining a copy of this software and associated documentation\nfiles (the \"Software\"), to deal in the Software without\nrestriction, including without limitation the rights to use,\ncopy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the\nSoftware is furnished to do so, subject to the following\nconditions:\n\nThe above copyright notice and this permission notice shall be\nincluded in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\nEXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES\nOF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\nNONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT\nHOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,\nWHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\nFROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR\nOTHER DEALINGS IN THE SOFTWARE.\n</code></pre>"},{"location":"python_venv/lib/python3.10/site-packages/pymdown_extensions-10.14.3.dist-info/licenses/LICENSE/#emojione-index","title":"EmojiOne Index","text":"<p><code>emoji1_db.py</code> is generated from EmojiOne's source code: @Ranks/emojione</p> <pre><code>EmojiOne Non-Artwork\n\nApplies to the JavaScript, JSON, PHP, CSS, HTML files, and everything else not covered under the artwork license above.\nLicense: MIT\nComplete Legal Terms: http://opensource.org/licenses/MIT\n</code></pre>"},{"location":"python_venv/lib64/python3.10/site-packages/Markdown-3.7.dist-info/LICENSE/","title":"LICENSE","text":"<p>BSD 3-Clause License</p> <p>Copyright 2007, 2008 The Python Markdown Project (v. 1.7 and later) Copyright 2004, 2005, 2006 Yuri Takhteyev (v. 0.2-1.6b) Copyright 2004 Manfred Stienstra (the original version)</p> <p>Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:</p> <ol> <li> <p>Redistributions of source code must retain the above copyright notice, this    list of conditions and the following disclaimer.</p> </li> <li> <p>Redistributions in binary form must reproduce the above copyright notice,    this list of conditions and the following disclaimer in the documentation    and/or other materials provided with the distribution.</p> </li> <li> <p>Neither the name of the copyright holder nor the names of its    contributors may be used to endorse or promote products derived from    this software without specific prior written permission.</p> </li> </ol> <p>THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.</p>"},{"location":"python_venv/lib64/python3.10/site-packages/idna-3.10.dist-info/LICENSE/","title":"LICENSE","text":"<p>BSD 3-Clause License</p> <p>Copyright (c) 2013-2024, Kim Davies and contributors. All rights reserved.</p> <p>Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:</p> <ol> <li> <p>Redistributions of source code must retain the above copyright    notice, this list of conditions and the following disclaimer.</p> </li> <li> <p>Redistributions in binary form must reproduce the above copyright    notice, this list of conditions and the following disclaimer in the    documentation and/or other materials provided with the distribution.</p> </li> <li> <p>Neither the name of the copyright holder nor the names of its    contributors may be used to endorse or promote products derived from    this software without specific prior written permission.</p> </li> </ol> <p>THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.</p>"},{"location":"python_venv/lib64/python3.10/site-packages/mkdocs_get_deps-0.2.0.dist-info/licenses/LICENSE/","title":"LICENSE","text":"<p>MIT License</p> <p>Copyright (c) 2023 Oleh Prypin oleh@pryp.in</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>"},{"location":"python_venv/lib64/python3.10/site-packages/mkdocs_material_extensions-1.3.1.dist-info/licenses/LICENSE/","title":"LICENSE","text":"<p>MIT License</p> <p>Copyright (c) 2021 Isaac Muse</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>"},{"location":"python_venv/lib64/python3.10/site-packages/pymdown_extensions-10.14.3.dist-info/licenses/LICENSE/","title":"License","text":""},{"location":"python_venv/lib64/python3.10/site-packages/pymdown_extensions-10.14.3.dist-info/licenses/LICENSE/#pymdown-extensions","title":"PyMdown Extensions","text":"<p>The MIT License (MIT)</p> <p>Copyright (c) 2014 - 2024 Isaac Muse</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>"},{"location":"python_venv/lib64/python3.10/site-packages/pymdown_extensions-10.14.3.dist-info/licenses/LICENSE/#superfences","title":"SuperFences","text":"<p><code>superfences.py</code> is derived from Python Markdown's fenced_code extension.</p> <pre><code>Fenced Code Extension for Python Markdown\n =========================================\nThis extension adds Fenced Code Blocks to Python-Markdown.\nSee &lt;https://python-markdown.github.io/extensions/fenced_code_blocks/&gt;\nfor documentation.\nOriginal code Copyright 2007-2008 [Waylan Limberg](http://achinghead.com/).\nAll changes Copyright 2008-2014 The Python Markdown Project\nLicense: [BSD](http://www.opensource.org/licenses/bsd-license.php)\n</code></pre>"},{"location":"python_venv/lib64/python3.10/site-packages/pymdown_extensions-10.14.3.dist-info/licenses/LICENSE/#highlight","title":"Highlight","text":"<p><code>highlight.py</code> is derived from Python Markdown's CodeHilite extension.</p> <pre><code>CodeHilite Extension for Python-Markdown\n ========================================\nAdds code/syntax highlighting to standard Python-Markdown code blocks.\nSee &lt;https://python-markdown.github.io/extensions/code_hilite/&gt;\nfor documentation.\nOriginal code Copyright 2006-2008 [Waylan Limberg](http://achinghead.com/).\nAll changes Copyright 2008-2014 The Python Markdown Project\nLicense: [BSD](http://www.opensource.org/licenses/bsd-license.php)\n</code></pre>"},{"location":"python_venv/lib64/python3.10/site-packages/pymdown_extensions-10.14.3.dist-info/licenses/LICENSE/#fancylists","title":"FancyLists","text":"<p><code>fancylists.py</code> is derived from Python Markdown's list handler.</p> <pre><code>Started by Manfred Stienstra (http://www.dwerg.net/).\nMaintained for a few years by Yuri Takhteyev (http://www.freewisdom.org).\nCurrently maintained by Waylan Limberg (https://github.com/waylan),\nDmitry Shachnev (https://github.com/mitya57) and Isaac Muse (https://github.com/facelessuser).\n\nCopyright 2007-2023 The Python Markdown Project (v. 1.7 and later)\nCopyright 2004, 2005, 2006 Yuri Takhteyev (v. 0.2-1.6b)\nCopyright 2004 Manfred Stienstra (the original version)\n\nLicense: [BSD](http://www.opensource.org/licenses/bsd-license.php)\n</code></pre>"},{"location":"python_venv/lib64/python3.10/site-packages/pymdown_extensions-10.14.3.dist-info/licenses/LICENSE/#gemoji-index","title":"Gemoji Index","text":"<p><code>gemoji_db.py</code> is generated from Gemoji's source code: @github/gemoji.</p> <pre><code>Copyright (c) 2013 GitHub, Inc.\n\nPermission is hereby granted, free of charge, to any person\nobtaining a copy of this software and associated documentation\nfiles (the \"Software\"), to deal in the Software without\nrestriction, including without limitation the rights to use,\ncopy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the\nSoftware is furnished to do so, subject to the following\nconditions:\n\nThe above copyright notice and this permission notice shall be\nincluded in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\nEXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES\nOF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\nNONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT\nHOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,\nWHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\nFROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR\nOTHER DEALINGS IN THE SOFTWARE.\n</code></pre>"},{"location":"python_venv/lib64/python3.10/site-packages/pymdown_extensions-10.14.3.dist-info/licenses/LICENSE/#emojione-index","title":"EmojiOne Index","text":"<p><code>emoji1_db.py</code> is generated from EmojiOne's source code: @Ranks/emojione</p> <pre><code>EmojiOne Non-Artwork\n\nApplies to the JavaScript, JSON, PHP, CSS, HTML files, and everything else not covered under the artwork license above.\nLicense: MIT\nComplete Legal Terms: http://opensource.org/licenses/MIT\n</code></pre>"}]}